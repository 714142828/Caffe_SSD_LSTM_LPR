I0521 09:36:43.394917  3675 caffe.cpp:217] Using GPUs 0
I0521 09:36:43.475281  3675 caffe.cpp:222] GPU 0: Quadro P4000
I0521 09:36:43.940277  3675 solver.cpp:63] Initializing solver from parameters: 
test_iter: 100
test_interval: 1000
base_lr: 0.0001
display: 20
max_iter: 100000
lr_policy: "step"
gamma: 0.5
momentum: 0.9
weight_decay: 0.0002
stepsize: 10000
snapshot: 2000
snapshot_prefix: "models/LPR/lpr_resnet_lstm"
solver_mode: GPU
device_id: 0
debug_info: false
net: "./jobs/Resnet_LSTM_CTC/train.prototxt"
train_state {
  level: 0
  stage: ""
}
test_initialization: false
I0521 09:36:43.940665  3675 solver.cpp:106] Creating training net from net file: ./jobs/Resnet_LSTM_CTC/train.prototxt
I0521 09:36:43.943284  3675 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: ./jobs/Resnet_LSTM_CTC/train.prototxt
I0521 09:36:43.943336  3675 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I0521 09:36:43.944239  3675 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I0521 09:36:43.944380  3675 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer acc
I0521 09:36:43.945492  3675 net.cpp:58] Initializing net from parameters: 
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "data"
  type: "HDF5Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  hdf5_data_param {
    source: "/home/zhuyipin/DATASET/ccpd/bbox_caffe_data_gen/training.list"
    batch_size: 128
  }
}
layer {
  name: "indicator"
  type: "ContinuationIndicator"
  top: "indicator"
  continuation_indicator_param {
    time_step: 16
    batch_size: 128
  }
}
layer {
  name: "data_bn"
  type: "BatchNorm"
  bottom: "data"
  top: "data_bn"
}
layer {
  name: "data_scale"
  type: "Scale"
  bottom: "data_bn"
  top: "data_bn"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data_bn"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    pad: 3
    kernel_size: 7
    stride: 2
    weight_filler {
      type: "msra"
      variance_norm: FAN_OUT
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv1_bn"
  type: "BatchNorm"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "conv1_scale"
  type: "Scale"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv1_relu"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "conv1_pool"
  type: "Pooling"
  bottom: "conv1"
  top: "conv1_pool"
  pooling_param {
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "layer_64_1_conv1"
  type: "Convolution"
  bottom: "conv1_pool"
  top: "layer_64_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_64_1_bn2"
  type: "BatchNorm"
  bottom: "layer_64_1_conv1"
  top: "layer_64_1_conv1"
}
layer {
  name: "layer_64_1_scale2"
  type: "Scale"
  bottom: "layer_64_1_conv1"
  top: "layer_64_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_64_1_relu2"
  type: "ReLU"
  bottom: "layer_64_1_conv1"
  top: "layer_64_1_conv1"
}
layer {
  name: "layer_64_1_conv2"
  type: "Convolution"
  bottom: "layer_64_1_conv1"
  top: "layer_64_1_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_64_1_bn3"
  type: "BatchNorm"
  bottom: "layer_64_1_conv2"
  top: "layer_64_1_conv2"
}
layer {
  name: "layer_64_1_scale3"
  type: "Scale"
  bottom: "layer_64_1_conv2"
  top: "layer_64_1_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_64_1_relu3"
  type: "ReLU"
  bottom: "layer_64_1_conv2"
  top: "layer_64_1_conv2"
}
layer {
  name: "layer_64_1_conv3"
  type: "Convolution"
  bottom: "layer_64_1_conv2"
  top: "layer_64_1_conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_64_1_conv_expand"
  type: "Convolution"
  bottom: "layer_64_1_conv1"
  top: "layer_64_1_conv_expand"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_64_1_sum"
  type: "Eltwise"
  bottom: "layer_64_1_conv3"
  bottom: "layer_64_1_conv_expand"
  top: "layer_64_1_sum"
}
layer {
  name: "layer_64_2_bn1"
  type: "BatchNorm"
  bottom: "layer_64_1_sum"
  top: "layer_64_2_bn1"
}
layer {
  name: "layer_64_2_scale1"
  type: "Scale"
  bottom: "layer_64_2_bn1"
  top: "layer_64_2_bn1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_64_2_relu1"
  type: "ReLU"
  bottom: "layer_64_2_bn1"
  top: "layer_64_2_bn1"
}
layer {
  name: "layer_64_2_conv1"
  type: "Convolution"
  bottom: "layer_64_2_bn1"
  top: "layer_64_2_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_64_2_bn2"
  type: "BatchNorm"
  bottom: "layer_64_2_conv1"
  top: "layer_64_2_conv1"
}
layer {
  name: "layer_64_2_scale2"
  type: "Scale"
  bottom: "layer_64_2_conv1"
  top: "layer_64_2_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_64_2_relu2"
  type: "ReLU"
  bottom: "layer_64_2_conv1"
  top: "layer_64_2_conv1"
}
layer {
  name: "layer_64_2_conv2"
  type: "Convolution"
  bottom: "layer_64_2_conv1"
  top: "layer_64_2_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_64_2_bn3"
  type: "BatchNorm"
  bottom: "layer_64_2_conv2"
  top: "layer_64_2_conv2"
}
layer {
  name: "layer_64_2_scale3"
  type: "Scale"
  bottom: "layer_64_2_conv2"
  top: "layer_64_2_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_64_2_relu3"
  type: "ReLU"
  bottom: "layer_64_2_conv2"
  top: "layer_64_2_conv2"
}
layer {
  name: "layer_64_2_conv3"
  type: "Convolution"
  bottom: "layer_64_2_conv2"
  top: "layer_64_2_conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_64_2_sum"
  type: "Eltwise"
  bottom: "layer_64_2_conv3"
  bottom: "layer_64_1_sum"
  top: "layer_64_2_sum"
}
layer {
  name: "layer_64_3_bn1"
  type: "BatchNorm"
  bottom: "layer_64_2_sum"
  top: "layer_64_3_bn1"
}
layer {
  name: "layer_64_3_scale1"
  type: "Scale"
  bottom: "layer_64_3_bn1"
  top: "layer_64_3_bn1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_64_3_relu1"
  type: "ReLU"
  bottom: "layer_64_3_bn1"
  top: "layer_64_3_bn1"
}
layer {
  name: "layer_64_3_conv1"
  type: "Convolution"
  bottom: "layer_64_3_bn1"
  top: "layer_64_3_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_64_3_bn2"
  type: "BatchNorm"
  bottom: "layer_64_3_conv1"
  top: "layer_64_3_conv1"
}
layer {
  name: "layer_64_3_scale2"
  type: "Scale"
  bottom: "layer_64_3_conv1"
  top: "layer_64_3_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_64_3_relu2"
  type: "ReLU"
  bottom: "layer_64_3_conv1"
  top: "layer_64_3_conv1"
}
layer {
  name: "layer_64_3_conv2"
  type: "Convolution"
  bottom: "layer_64_3_conv1"
  top: "layer_64_3_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_64_3_bn3"
  type: "BatchNorm"
  bottom: "layer_64_3_conv2"
  top: "layer_64_3_conv2"
}
layer {
  name: "layer_64_3_scale3"
  type: "Scale"
  bottom: "layer_64_3_conv2"
  top: "layer_64_3_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_64_3_relu3"
  type: "ReLU"
  bottom: "layer_64_3_conv2"
  top: "layer_64_3_conv2"
}
layer {
  name: "layer_64_3_conv3"
  type: "Convolution"
  bottom: "layer_64_3_conv2"
  top: "layer_64_3_conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_64_3_sum"
  type: "Eltwise"
  bottom: "layer_64_3_conv3"
  bottom: "layer_64_2_sum"
  top: "layer_64_3_sum"
}
layer {
  name: "layer_128_1_bn1"
  type: "BatchNorm"
  bottom: "layer_64_3_sum"
  top: "layer_128_1_bn1"
}
layer {
  name: "layer_128_1_scale1"
  type: "Scale"
  bottom: "layer_128_1_bn1"
  top: "layer_128_1_bn1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_128_1_relu1"
  type: "ReLU"
  bottom: "layer_128_1_bn1"
  top: "layer_128_1_bn1"
}
layer {
  name: "layer_128_1_conv1"
  type: "Convolution"
  bottom: "layer_128_1_bn1"
  top: "layer_128_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_128_1_bn2"
  type: "BatchNorm"
  bottom: "layer_128_1_conv1"
  top: "layer_128_1_conv1"
}
layer {
  name: "layer_128_1_scale2"
  type: "Scale"
  bottom: "layer_128_1_conv1"
  top: "layer_128_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_128_1_relu2"
  type: "ReLU"
  bottom: "layer_128_1_conv1"
  top: "layer_128_1_conv1"
}
layer {
  name: "layer_128_1_conv2"
  type: "Convolution"
  bottom: "layer_128_1_conv1"
  top: "layer_128_1_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_128_1_bn3"
  type: "BatchNorm"
  bottom: "layer_128_1_conv2"
  top: "layer_128_1_conv2"
}
layer {
  name: "layer_128_1_scale3"
  type: "Scale"
  bottom: "layer_128_1_conv2"
  top: "layer_128_1_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_128_1_relu3"
  type: "ReLU"
  bottom: "layer_128_1_conv2"
  top: "layer_128_1_conv2"
}
layer {
  name: "layer_128_1_conv3"
  type: "Convolution"
  bottom: "layer_128_1_conv2"
  top: "layer_128_1_conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_128_1_conv_expand"
  type: "Convolution"
  bottom: "layer_128_1_bn1"
  top: "layer_128_1_conv_expand"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_128_1_sum"
  type: "Eltwise"
  bottom: "layer_128_1_conv3"
  bottom: "layer_128_1_conv_expand"
  top: "layer_128_1_sum"
}
layer {
  name: "layer_128_2_bn1"
  type: "BatchNorm"
  bottom: "layer_128_1_sum"
  top: "layer_128_2_bn1"
}
layer {
  name: "layer_128_2_scale1"
  type: "Scale"
  bottom: "layer_128_2_bn1"
  top: "layer_128_2_bn1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_128_2_relu1"
  type: "ReLU"
  bottom: "layer_128_2_bn1"
  top: "layer_128_2_bn1"
}
layer {
  name: "layer_128_2_conv1"
  type: "Convolution"
  bottom: "layer_128_2_bn1"
  top: "layer_128_2_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_128_2_bn2"
  type: "BatchNorm"
  bottom: "layer_128_2_conv1"
  top: "layer_128_2_conv1"
}
layer {
  name: "layer_128_2_scale2"
  type: "Scale"
  bottom: "layer_128_2_conv1"
  top: "layer_128_2_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_128_2_relu2"
  type: "ReLU"
  bottom: "layer_128_2_conv1"
  top: "layer_128_2_conv1"
}
layer {
  name: "layer_128_2_conv2"
  type: "Convolution"
  bottom: "layer_128_2_conv1"
  top: "layer_128_2_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_128_2_bn3"
  type: "BatchNorm"
  bottom: "layer_128_2_conv2"
  top: "layer_128_2_conv2"
}
layer {
  name: "layer_128_2_scale3"
  type: "Scale"
  bottom: "layer_128_2_conv2"
  top: "layer_128_2_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_128_2_relu3"
  type: "ReLU"
  bottom: "layer_128_2_conv2"
  top: "layer_128_2_conv2"
}
layer {
  name: "layer_128_2_conv3"
  type: "Convolution"
  bottom: "layer_128_2_conv2"
  top: "layer_128_2_conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_128_2_sum"
  type: "Eltwise"
  bottom: "layer_128_2_conv3"
  bottom: "layer_128_1_sum"
  top: "layer_128_2_sum"
}
layer {
  name: "layer_128_3_bn1"
  type: "BatchNorm"
  bottom: "layer_128_2_sum"
  top: "layer_128_3_bn1"
}
layer {
  name: "layer_128_3_scale1"
  type: "Scale"
  bottom: "layer_128_3_bn1"
  top: "layer_128_3_bn1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_128_3_relu1"
  type: "ReLU"
  bottom: "layer_128_3_bn1"
  top: "layer_128_3_bn1"
}
layer {
  name: "layer_128_3_conv1"
  type: "Convolution"
  bottom: "layer_128_3_bn1"
  top: "layer_128_3_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_128_3_bn2"
  type: "BatchNorm"
  bottom: "layer_128_3_conv1"
  top: "layer_128_3_conv1"
}
layer {
  name: "layer_128_3_scale2"
  type: "Scale"
  bottom: "layer_128_3_conv1"
  top: "layer_128_3_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_128_3_relu2"
  type: "ReLU"
  bottom: "layer_128_3_conv1"
  top: "layer_128_3_conv1"
}
layer {
  name: "layer_128_3_conv2"
  type: "Convolution"
  bottom: "layer_128_3_conv1"
  top: "layer_128_3_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_128_3_bn3"
  type: "BatchNorm"
  bottom: "layer_128_3_conv2"
  top: "layer_128_3_conv2"
}
layer {
  name: "layer_128_3_scale3"
  type: "Scale"
  bottom: "layer_128_3_conv2"
  top: "layer_128_3_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_128_3_relu3"
  type: "ReLU"
  bottom: "layer_128_3_conv2"
  top: "layer_128_3_conv2"
}
layer {
  name: "layer_128_3_conv3"
  type: "Convolution"
  bottom: "layer_128_3_conv2"
  top: "layer_128_3_conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_128_3_sum"
  type: "Eltwise"
  bottom: "layer_128_3_conv3"
  bottom: "layer_128_2_sum"
  top: "layer_128_3_sum"
}
layer {
  name: "layer_128_4_bn1"
  type: "BatchNorm"
  bottom: "layer_128_3_sum"
  top: "layer_128_4_bn1"
}
layer {
  name: "layer_128_4_scale1"
  type: "Scale"
  bottom: "layer_128_4_bn1"
  top: "layer_128_4_bn1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_128_4_relu1"
  type: "ReLU"
  bottom: "layer_128_4_bn1"
  top: "layer_128_4_bn1"
}
layer {
  name: "layer_128_4_conv1"
  type: "Convolution"
  bottom: "layer_128_4_bn1"
  top: "layer_128_4_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_128_4_bn2"
  type: "BatchNorm"
  bottom: "layer_128_4_conv1"
  top: "layer_128_4_conv1"
}
layer {
  name: "layer_128_4_scale2"
  type: "Scale"
  bottom: "layer_128_4_conv1"
  top: "layer_128_4_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_128_4_relu2"
  type: "ReLU"
  bottom: "layer_128_4_conv1"
  top: "layer_128_4_conv1"
}
layer {
  name: "layer_128_4_conv2"
  type: "Convolution"
  bottom: "layer_128_4_conv1"
  top: "layer_128_4_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_128_4_bn3"
  type: "BatchNorm"
  bottom: "layer_128_4_conv2"
  top: "layer_128_4_conv2"
}
layer {
  name: "layer_128_4_scale3"
  type: "Scale"
  bottom: "layer_128_4_conv2"
  top: "layer_128_4_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_128_4_relu3"
  type: "ReLU"
  bottom: "layer_128_4_conv2"
  top: "layer_128_4_conv2"
}
layer {
  name: "layer_128_4_conv3"
  type: "Convolution"
  bottom: "layer_128_4_conv2"
  top: "layer_128_4_conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_128_4_sum"
  type: "Eltwise"
  bottom: "layer_128_4_conv3"
  bottom: "layer_128_3_sum"
  top: "layer_128_4_sum"
}
layer {
  name: "last_bn"
  type: "BatchNorm"
  bottom: "layer_128_4_sum"
  top: "layer_128_4_sum"
}
layer {
  name: "last_scale"
  type: "Scale"
  bottom: "layer_128_4_sum"
  top: "layer_128_4_sum"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "last_relu"
  type: "ReLU"
  bottom: "layer_128_4_sum"
  top: "layer_128_4_sum"
}
layer {
  name: "dropout"
  type: "Dropout"
  bottom: "layer_128_4_sum"
  top: "layer_128_4_sum"
  dropout_param {
    dropout_ratio: 0.7
  }
}
layer {
  name: "permuted_data"
  type: "Permute"
  bottom: "layer_128_4_sum"
  top: "permuted_data"
  permute_param {
    order: 3
    order: 0
    order: 1
    order: 2
  }
}
layer {
  name: "lstm-reverse1"
  type: "Reverse"
  bottom: "permuted_data"
  top: "rlstm_input"
  reverse_param {
    axis: 0
  }
}
layer {
  name: "lstm2x"
  type: "LSTM"
  bottom: "rlstm_input"
  bottom: "indicator"
  top: "lstm2x"
  recurrent_param {
    num_output: 100
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "lstm-reverse2"
  type: "Reverse"
  bottom: "lstm2x"
  top: "rlstmx"
  reverse_param {
    axis: 0
  }
}
layer {
  name: "lstm1x"
  type: "LSTM"
  bottom: "permuted_data"
  bottom: "indicator"
  top: "lstm1x"
  recurrent_param {
    num_output: 100
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "merge_lstm_rlstmx"
  type: "Concat"
  bottom: "lstm1x"
  bottom: "rlstmx"
  top: "merge_lstm_rlstmx"
  concat_param {
    axis: 2
  }
}
layer {
  name: "fc1x"
  type: "InnerProduct"
  bottom: "merge_lstm_rlstmx"
  top: "fc1x"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 66
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    axis: 2
  }
}
layer {
  name: "ctcloss"
  type: "WarpCTCLoss"
  bottom: "fc1x"
  bottom: "label"
  top: "ctcloss"
  loss_weight: 1
  ctc_loss_param {
    blank_index: 65
  }
}
I0521 09:36:43.946563  3675 layer_factory.hpp:77] Creating layer data
I0521 09:36:43.946599  3675 net.cpp:100] Creating Layer data
I0521 09:36:43.946609  3675 net.cpp:408] data -> data
I0521 09:36:43.946635  3675 net.cpp:408] data -> label
I0521 09:36:43.946647  3675 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: /home/zhuyipin/DATASET/ccpd/bbox_caffe_data_gen/training.list
I0521 09:36:43.947023  3675 hdf5_data_layer.cpp:93] Number of HDF5 files: 10
I0521 09:36:43.962225  3675 hdf5.cpp:32] Datatype class: H5T_FLOAT
I0521 09:36:44.329705  3675 net.cpp:150] Setting up data
I0521 09:36:44.329756  3675 net.cpp:157] Top shape: 128 3 32 128 (1572864)
I0521 09:36:44.329761  3675 net.cpp:157] Top shape: 128 7 (896)
I0521 09:36:44.329763  3675 net.cpp:165] Memory required for data: 6295040
I0521 09:36:44.329787  3675 layer_factory.hpp:77] Creating layer indicator
I0521 09:36:44.329798  3675 net.cpp:100] Creating Layer indicator
I0521 09:36:44.329802  3675 net.cpp:408] indicator -> indicator
I0521 09:36:44.329826  3675 net.cpp:150] Setting up indicator
I0521 09:36:44.329829  3675 net.cpp:157] Top shape: 16 128 (2048)
I0521 09:36:44.329833  3675 net.cpp:165] Memory required for data: 6303232
I0521 09:36:44.329834  3675 layer_factory.hpp:77] Creating layer indicator_indicator_0_split
I0521 09:36:44.329839  3675 net.cpp:100] Creating Layer indicator_indicator_0_split
I0521 09:36:44.329843  3675 net.cpp:434] indicator_indicator_0_split <- indicator
I0521 09:36:44.329854  3675 net.cpp:408] indicator_indicator_0_split -> indicator_indicator_0_split_0
I0521 09:36:44.329859  3675 net.cpp:408] indicator_indicator_0_split -> indicator_indicator_0_split_1
I0521 09:36:44.329879  3675 net.cpp:150] Setting up indicator_indicator_0_split
I0521 09:36:44.329882  3675 net.cpp:157] Top shape: 16 128 (2048)
I0521 09:36:44.329885  3675 net.cpp:157] Top shape: 16 128 (2048)
I0521 09:36:44.329886  3675 net.cpp:165] Memory required for data: 6319616
I0521 09:36:44.329890  3675 layer_factory.hpp:77] Creating layer data_bn
I0521 09:36:44.329895  3675 net.cpp:100] Creating Layer data_bn
I0521 09:36:44.329896  3675 net.cpp:434] data_bn <- data
I0521 09:36:44.329900  3675 net.cpp:408] data_bn -> data_bn
I0521 09:36:44.330032  3675 net.cpp:150] Setting up data_bn
I0521 09:36:44.330039  3675 net.cpp:157] Top shape: 128 3 32 128 (1572864)
I0521 09:36:44.330041  3675 net.cpp:165] Memory required for data: 12611072
I0521 09:36:44.330055  3675 layer_factory.hpp:77] Creating layer data_scale
I0521 09:36:44.330062  3675 net.cpp:100] Creating Layer data_scale
I0521 09:36:44.330065  3675 net.cpp:434] data_scale <- data_bn
I0521 09:36:44.330068  3675 net.cpp:395] data_scale -> data_bn (in-place)
I0521 09:36:44.330096  3675 layer_factory.hpp:77] Creating layer data_scale
I0521 09:36:44.330413  3675 net.cpp:150] Setting up data_scale
I0521 09:36:44.330420  3675 net.cpp:157] Top shape: 128 3 32 128 (1572864)
I0521 09:36:44.330421  3675 net.cpp:165] Memory required for data: 18902528
I0521 09:36:44.330427  3675 layer_factory.hpp:77] Creating layer conv1
I0521 09:36:44.330438  3675 net.cpp:100] Creating Layer conv1
I0521 09:36:44.330440  3675 net.cpp:434] conv1 <- data_bn
I0521 09:36:44.330446  3675 net.cpp:408] conv1 -> conv1
I0521 09:36:45.557001  3675 net.cpp:150] Setting up conv1
I0521 09:36:45.557060  3675 net.cpp:157] Top shape: 128 64 16 64 (8388608)
I0521 09:36:45.557062  3675 net.cpp:165] Memory required for data: 52456960
I0521 09:36:45.557072  3675 layer_factory.hpp:77] Creating layer conv1_bn
I0521 09:36:45.557081  3675 net.cpp:100] Creating Layer conv1_bn
I0521 09:36:45.557085  3675 net.cpp:434] conv1_bn <- conv1
I0521 09:36:45.557091  3675 net.cpp:395] conv1_bn -> conv1 (in-place)
I0521 09:36:45.557222  3675 net.cpp:150] Setting up conv1_bn
I0521 09:36:45.557227  3675 net.cpp:157] Top shape: 128 64 16 64 (8388608)
I0521 09:36:45.557230  3675 net.cpp:165] Memory required for data: 86011392
I0521 09:36:45.557236  3675 layer_factory.hpp:77] Creating layer conv1_scale
I0521 09:36:45.557243  3675 net.cpp:100] Creating Layer conv1_scale
I0521 09:36:45.557245  3675 net.cpp:434] conv1_scale <- conv1
I0521 09:36:45.557250  3675 net.cpp:395] conv1_scale -> conv1 (in-place)
I0521 09:36:45.557272  3675 layer_factory.hpp:77] Creating layer conv1_scale
I0521 09:36:45.557339  3675 net.cpp:150] Setting up conv1_scale
I0521 09:36:45.557344  3675 net.cpp:157] Top shape: 128 64 16 64 (8388608)
I0521 09:36:45.557346  3675 net.cpp:165] Memory required for data: 119565824
I0521 09:36:45.557351  3675 layer_factory.hpp:77] Creating layer conv1_relu
I0521 09:36:45.557360  3675 net.cpp:100] Creating Layer conv1_relu
I0521 09:36:45.557389  3675 net.cpp:434] conv1_relu <- conv1
I0521 09:36:45.557394  3675 net.cpp:395] conv1_relu -> conv1 (in-place)
I0521 09:36:45.557641  3675 net.cpp:150] Setting up conv1_relu
I0521 09:36:45.557648  3675 net.cpp:157] Top shape: 128 64 16 64 (8388608)
I0521 09:36:45.557651  3675 net.cpp:165] Memory required for data: 153120256
I0521 09:36:45.557654  3675 layer_factory.hpp:77] Creating layer conv1_pool
I0521 09:36:45.557660  3675 net.cpp:100] Creating Layer conv1_pool
I0521 09:36:45.557663  3675 net.cpp:434] conv1_pool <- conv1
I0521 09:36:45.557667  3675 net.cpp:408] conv1_pool -> conv1_pool
I0521 09:36:45.557704  3675 net.cpp:150] Setting up conv1_pool
I0521 09:36:45.557713  3675 net.cpp:157] Top shape: 128 64 8 32 (2097152)
I0521 09:36:45.557715  3675 net.cpp:165] Memory required for data: 161508864
I0521 09:36:45.557718  3675 layer_factory.hpp:77] Creating layer layer_64_1_conv1
I0521 09:36:45.557729  3675 net.cpp:100] Creating Layer layer_64_1_conv1
I0521 09:36:45.557732  3675 net.cpp:434] layer_64_1_conv1 <- conv1_pool
I0521 09:36:45.557739  3675 net.cpp:408] layer_64_1_conv1 -> layer_64_1_conv1
I0521 09:36:45.559173  3675 net.cpp:150] Setting up layer_64_1_conv1
I0521 09:36:45.559193  3675 net.cpp:157] Top shape: 128 64 8 32 (2097152)
I0521 09:36:45.559197  3675 net.cpp:165] Memory required for data: 169897472
I0521 09:36:45.559206  3675 layer_factory.hpp:77] Creating layer layer_64_1_bn2
I0521 09:36:45.559214  3675 net.cpp:100] Creating Layer layer_64_1_bn2
I0521 09:36:45.559219  3675 net.cpp:434] layer_64_1_bn2 <- layer_64_1_conv1
I0521 09:36:45.559226  3675 net.cpp:395] layer_64_1_bn2 -> layer_64_1_conv1 (in-place)
I0521 09:36:45.559401  3675 net.cpp:150] Setting up layer_64_1_bn2
I0521 09:36:45.559408  3675 net.cpp:157] Top shape: 128 64 8 32 (2097152)
I0521 09:36:45.559412  3675 net.cpp:165] Memory required for data: 178286080
I0521 09:36:45.559417  3675 layer_factory.hpp:77] Creating layer layer_64_1_scale2
I0521 09:36:45.559423  3675 net.cpp:100] Creating Layer layer_64_1_scale2
I0521 09:36:45.559425  3675 net.cpp:434] layer_64_1_scale2 <- layer_64_1_conv1
I0521 09:36:45.559430  3675 net.cpp:395] layer_64_1_scale2 -> layer_64_1_conv1 (in-place)
I0521 09:36:45.559454  3675 layer_factory.hpp:77] Creating layer layer_64_1_scale2
I0521 09:36:45.559535  3675 net.cpp:150] Setting up layer_64_1_scale2
I0521 09:36:45.559542  3675 net.cpp:157] Top shape: 128 64 8 32 (2097152)
I0521 09:36:45.559545  3675 net.cpp:165] Memory required for data: 186674688
I0521 09:36:45.559551  3675 layer_factory.hpp:77] Creating layer layer_64_1_relu2
I0521 09:36:45.559558  3675 net.cpp:100] Creating Layer layer_64_1_relu2
I0521 09:36:45.559562  3675 net.cpp:434] layer_64_1_relu2 <- layer_64_1_conv1
I0521 09:36:45.559567  3675 net.cpp:395] layer_64_1_relu2 -> layer_64_1_conv1 (in-place)
I0521 09:36:45.560001  3675 net.cpp:150] Setting up layer_64_1_relu2
I0521 09:36:45.560016  3675 net.cpp:157] Top shape: 128 64 8 32 (2097152)
I0521 09:36:45.560021  3675 net.cpp:165] Memory required for data: 195063296
I0521 09:36:45.560026  3675 layer_factory.hpp:77] Creating layer layer_64_1_conv1_layer_64_1_relu2_0_split
I0521 09:36:45.560034  3675 net.cpp:100] Creating Layer layer_64_1_conv1_layer_64_1_relu2_0_split
I0521 09:36:45.560037  3675 net.cpp:434] layer_64_1_conv1_layer_64_1_relu2_0_split <- layer_64_1_conv1
I0521 09:36:45.560042  3675 net.cpp:408] layer_64_1_conv1_layer_64_1_relu2_0_split -> layer_64_1_conv1_layer_64_1_relu2_0_split_0
I0521 09:36:45.560048  3675 net.cpp:408] layer_64_1_conv1_layer_64_1_relu2_0_split -> layer_64_1_conv1_layer_64_1_relu2_0_split_1
I0521 09:36:45.560086  3675 net.cpp:150] Setting up layer_64_1_conv1_layer_64_1_relu2_0_split
I0521 09:36:45.560097  3675 net.cpp:157] Top shape: 128 64 8 32 (2097152)
I0521 09:36:45.560101  3675 net.cpp:157] Top shape: 128 64 8 32 (2097152)
I0521 09:36:45.560103  3675 net.cpp:165] Memory required for data: 211840512
I0521 09:36:45.560106  3675 layer_factory.hpp:77] Creating layer layer_64_1_conv2
I0521 09:36:45.560114  3675 net.cpp:100] Creating Layer layer_64_1_conv2
I0521 09:36:45.560134  3675 net.cpp:434] layer_64_1_conv2 <- layer_64_1_conv1_layer_64_1_relu2_0_split_0
I0521 09:36:45.560142  3675 net.cpp:408] layer_64_1_conv2 -> layer_64_1_conv2
I0521 09:36:45.562032  3675 net.cpp:150] Setting up layer_64_1_conv2
I0521 09:36:45.562047  3675 net.cpp:157] Top shape: 128 64 8 32 (2097152)
I0521 09:36:45.562049  3675 net.cpp:165] Memory required for data: 220229120
I0521 09:36:45.562054  3675 layer_factory.hpp:77] Creating layer layer_64_1_bn3
I0521 09:36:45.562062  3675 net.cpp:100] Creating Layer layer_64_1_bn3
I0521 09:36:45.562064  3675 net.cpp:434] layer_64_1_bn3 <- layer_64_1_conv2
I0521 09:36:45.562068  3675 net.cpp:395] layer_64_1_bn3 -> layer_64_1_conv2 (in-place)
I0521 09:36:45.562194  3675 net.cpp:150] Setting up layer_64_1_bn3
I0521 09:36:45.562201  3675 net.cpp:157] Top shape: 128 64 8 32 (2097152)
I0521 09:36:45.562202  3675 net.cpp:165] Memory required for data: 228617728
I0521 09:36:45.562207  3675 layer_factory.hpp:77] Creating layer layer_64_1_scale3
I0521 09:36:45.562212  3675 net.cpp:100] Creating Layer layer_64_1_scale3
I0521 09:36:45.562216  3675 net.cpp:434] layer_64_1_scale3 <- layer_64_1_conv2
I0521 09:36:45.562219  3675 net.cpp:395] layer_64_1_scale3 -> layer_64_1_conv2 (in-place)
I0521 09:36:45.562242  3675 layer_factory.hpp:77] Creating layer layer_64_1_scale3
I0521 09:36:45.562331  3675 net.cpp:150] Setting up layer_64_1_scale3
I0521 09:36:45.562340  3675 net.cpp:157] Top shape: 128 64 8 32 (2097152)
I0521 09:36:45.562345  3675 net.cpp:165] Memory required for data: 237006336
I0521 09:36:45.562351  3675 layer_factory.hpp:77] Creating layer layer_64_1_relu3
I0521 09:36:45.562357  3675 net.cpp:100] Creating Layer layer_64_1_relu3
I0521 09:36:45.562361  3675 net.cpp:434] layer_64_1_relu3 <- layer_64_1_conv2
I0521 09:36:45.562366  3675 net.cpp:395] layer_64_1_relu3 -> layer_64_1_conv2 (in-place)
I0521 09:36:45.562615  3675 net.cpp:150] Setting up layer_64_1_relu3
I0521 09:36:45.562628  3675 net.cpp:157] Top shape: 128 64 8 32 (2097152)
I0521 09:36:45.562631  3675 net.cpp:165] Memory required for data: 245394944
I0521 09:36:45.562635  3675 layer_factory.hpp:77] Creating layer layer_64_1_conv3
I0521 09:36:45.562644  3675 net.cpp:100] Creating Layer layer_64_1_conv3
I0521 09:36:45.562647  3675 net.cpp:434] layer_64_1_conv3 <- layer_64_1_conv2
I0521 09:36:45.562652  3675 net.cpp:408] layer_64_1_conv3 -> layer_64_1_conv3
I0521 09:36:45.564765  3675 net.cpp:150] Setting up layer_64_1_conv3
I0521 09:36:45.564792  3675 net.cpp:157] Top shape: 128 256 8 32 (8388608)
I0521 09:36:45.564796  3675 net.cpp:165] Memory required for data: 278949376
I0521 09:36:45.564802  3675 layer_factory.hpp:77] Creating layer layer_64_1_conv_expand
I0521 09:36:45.564811  3675 net.cpp:100] Creating Layer layer_64_1_conv_expand
I0521 09:36:45.564815  3675 net.cpp:434] layer_64_1_conv_expand <- layer_64_1_conv1_layer_64_1_relu2_0_split_1
I0521 09:36:45.564821  3675 net.cpp:408] layer_64_1_conv_expand -> layer_64_1_conv_expand
I0521 09:36:45.566020  3675 net.cpp:150] Setting up layer_64_1_conv_expand
I0521 09:36:45.566035  3675 net.cpp:157] Top shape: 128 256 8 32 (8388608)
I0521 09:36:45.566040  3675 net.cpp:165] Memory required for data: 312503808
I0521 09:36:45.566045  3675 layer_factory.hpp:77] Creating layer layer_64_1_sum
I0521 09:36:45.566051  3675 net.cpp:100] Creating Layer layer_64_1_sum
I0521 09:36:45.566056  3675 net.cpp:434] layer_64_1_sum <- layer_64_1_conv3
I0521 09:36:45.566061  3675 net.cpp:434] layer_64_1_sum <- layer_64_1_conv_expand
I0521 09:36:45.566066  3675 net.cpp:408] layer_64_1_sum -> layer_64_1_sum
I0521 09:36:45.566084  3675 net.cpp:150] Setting up layer_64_1_sum
I0521 09:36:45.566089  3675 net.cpp:157] Top shape: 128 256 8 32 (8388608)
I0521 09:36:45.566092  3675 net.cpp:165] Memory required for data: 346058240
I0521 09:36:45.566097  3675 layer_factory.hpp:77] Creating layer layer_64_1_sum_layer_64_1_sum_0_split
I0521 09:36:45.566102  3675 net.cpp:100] Creating Layer layer_64_1_sum_layer_64_1_sum_0_split
I0521 09:36:45.566107  3675 net.cpp:434] layer_64_1_sum_layer_64_1_sum_0_split <- layer_64_1_sum
I0521 09:36:45.566128  3675 net.cpp:408] layer_64_1_sum_layer_64_1_sum_0_split -> layer_64_1_sum_layer_64_1_sum_0_split_0
I0521 09:36:45.566133  3675 net.cpp:408] layer_64_1_sum_layer_64_1_sum_0_split -> layer_64_1_sum_layer_64_1_sum_0_split_1
I0521 09:36:45.566159  3675 net.cpp:150] Setting up layer_64_1_sum_layer_64_1_sum_0_split
I0521 09:36:45.566162  3675 net.cpp:157] Top shape: 128 256 8 32 (8388608)
I0521 09:36:45.566166  3675 net.cpp:157] Top shape: 128 256 8 32 (8388608)
I0521 09:36:45.566169  3675 net.cpp:165] Memory required for data: 413167104
I0521 09:36:45.566171  3675 layer_factory.hpp:77] Creating layer layer_64_2_bn1
I0521 09:36:45.566176  3675 net.cpp:100] Creating Layer layer_64_2_bn1
I0521 09:36:45.566180  3675 net.cpp:434] layer_64_2_bn1 <- layer_64_1_sum_layer_64_1_sum_0_split_0
I0521 09:36:45.566185  3675 net.cpp:408] layer_64_2_bn1 -> layer_64_2_bn1
I0521 09:36:45.566332  3675 net.cpp:150] Setting up layer_64_2_bn1
I0521 09:36:45.566342  3675 net.cpp:157] Top shape: 128 256 8 32 (8388608)
I0521 09:36:45.566345  3675 net.cpp:165] Memory required for data: 446721536
I0521 09:36:45.566351  3675 layer_factory.hpp:77] Creating layer layer_64_2_scale1
I0521 09:36:45.566359  3675 net.cpp:100] Creating Layer layer_64_2_scale1
I0521 09:36:45.566361  3675 net.cpp:434] layer_64_2_scale1 <- layer_64_2_bn1
I0521 09:36:45.566366  3675 net.cpp:395] layer_64_2_scale1 -> layer_64_2_bn1 (in-place)
I0521 09:36:45.566395  3675 layer_factory.hpp:77] Creating layer layer_64_2_scale1
I0521 09:36:45.566463  3675 net.cpp:150] Setting up layer_64_2_scale1
I0521 09:36:45.566468  3675 net.cpp:157] Top shape: 128 256 8 32 (8388608)
I0521 09:36:45.566473  3675 net.cpp:165] Memory required for data: 480275968
I0521 09:36:45.566476  3675 layer_factory.hpp:77] Creating layer layer_64_2_relu1
I0521 09:36:45.566480  3675 net.cpp:100] Creating Layer layer_64_2_relu1
I0521 09:36:45.566483  3675 net.cpp:434] layer_64_2_relu1 <- layer_64_2_bn1
I0521 09:36:45.566488  3675 net.cpp:395] layer_64_2_relu1 -> layer_64_2_bn1 (in-place)
I0521 09:36:45.566874  3675 net.cpp:150] Setting up layer_64_2_relu1
I0521 09:36:45.566887  3675 net.cpp:157] Top shape: 128 256 8 32 (8388608)
I0521 09:36:45.566891  3675 net.cpp:165] Memory required for data: 513830400
I0521 09:36:45.566895  3675 layer_factory.hpp:77] Creating layer layer_64_2_conv1
I0521 09:36:45.566906  3675 net.cpp:100] Creating Layer layer_64_2_conv1
I0521 09:36:45.566911  3675 net.cpp:434] layer_64_2_conv1 <- layer_64_2_bn1
I0521 09:36:45.566918  3675 net.cpp:408] layer_64_2_conv1 -> layer_64_2_conv1
I0521 09:36:45.568081  3675 net.cpp:150] Setting up layer_64_2_conv1
I0521 09:36:45.568095  3675 net.cpp:157] Top shape: 128 64 8 32 (2097152)
I0521 09:36:45.568099  3675 net.cpp:165] Memory required for data: 522219008
I0521 09:36:45.568104  3675 layer_factory.hpp:77] Creating layer layer_64_2_bn2
I0521 09:36:45.568109  3675 net.cpp:100] Creating Layer layer_64_2_bn2
I0521 09:36:45.568114  3675 net.cpp:434] layer_64_2_bn2 <- layer_64_2_conv1
I0521 09:36:45.568118  3675 net.cpp:395] layer_64_2_bn2 -> layer_64_2_conv1 (in-place)
I0521 09:36:45.568279  3675 net.cpp:150] Setting up layer_64_2_bn2
I0521 09:36:45.568285  3675 net.cpp:157] Top shape: 128 64 8 32 (2097152)
I0521 09:36:45.568289  3675 net.cpp:165] Memory required for data: 530607616
I0521 09:36:45.568297  3675 layer_factory.hpp:77] Creating layer layer_64_2_scale2
I0521 09:36:45.568306  3675 net.cpp:100] Creating Layer layer_64_2_scale2
I0521 09:36:45.568311  3675 net.cpp:434] layer_64_2_scale2 <- layer_64_2_conv1
I0521 09:36:45.568316  3675 net.cpp:395] layer_64_2_scale2 -> layer_64_2_conv1 (in-place)
I0521 09:36:45.568341  3675 layer_factory.hpp:77] Creating layer layer_64_2_scale2
I0521 09:36:45.568419  3675 net.cpp:150] Setting up layer_64_2_scale2
I0521 09:36:45.568428  3675 net.cpp:157] Top shape: 128 64 8 32 (2097152)
I0521 09:36:45.568431  3675 net.cpp:165] Memory required for data: 538996224
I0521 09:36:45.568437  3675 layer_factory.hpp:77] Creating layer layer_64_2_relu2
I0521 09:36:45.568442  3675 net.cpp:100] Creating Layer layer_64_2_relu2
I0521 09:36:45.568459  3675 net.cpp:434] layer_64_2_relu2 <- layer_64_2_conv1
I0521 09:36:45.568464  3675 net.cpp:395] layer_64_2_relu2 -> layer_64_2_conv1 (in-place)
I0521 09:36:45.568846  3675 net.cpp:150] Setting up layer_64_2_relu2
I0521 09:36:45.568861  3675 net.cpp:157] Top shape: 128 64 8 32 (2097152)
I0521 09:36:45.568863  3675 net.cpp:165] Memory required for data: 547384832
I0521 09:36:45.568866  3675 layer_factory.hpp:77] Creating layer layer_64_2_conv2
I0521 09:36:45.568874  3675 net.cpp:100] Creating Layer layer_64_2_conv2
I0521 09:36:45.568877  3675 net.cpp:434] layer_64_2_conv2 <- layer_64_2_conv1
I0521 09:36:45.568882  3675 net.cpp:408] layer_64_2_conv2 -> layer_64_2_conv2
I0521 09:36:45.571246  3675 net.cpp:150] Setting up layer_64_2_conv2
I0521 09:36:45.571264  3675 net.cpp:157] Top shape: 128 64 8 32 (2097152)
I0521 09:36:45.571267  3675 net.cpp:165] Memory required for data: 555773440
I0521 09:36:45.571274  3675 layer_factory.hpp:77] Creating layer layer_64_2_bn3
I0521 09:36:45.571282  3675 net.cpp:100] Creating Layer layer_64_2_bn3
I0521 09:36:45.571287  3675 net.cpp:434] layer_64_2_bn3 <- layer_64_2_conv2
I0521 09:36:45.571293  3675 net.cpp:395] layer_64_2_bn3 -> layer_64_2_conv2 (in-place)
I0521 09:36:45.571426  3675 net.cpp:150] Setting up layer_64_2_bn3
I0521 09:36:45.571432  3675 net.cpp:157] Top shape: 128 64 8 32 (2097152)
I0521 09:36:45.571436  3675 net.cpp:165] Memory required for data: 564162048
I0521 09:36:45.571444  3675 layer_factory.hpp:77] Creating layer layer_64_2_scale3
I0521 09:36:45.571456  3675 net.cpp:100] Creating Layer layer_64_2_scale3
I0521 09:36:45.571460  3675 net.cpp:434] layer_64_2_scale3 <- layer_64_2_conv2
I0521 09:36:45.571466  3675 net.cpp:395] layer_64_2_scale3 -> layer_64_2_conv2 (in-place)
I0521 09:36:45.571504  3675 layer_factory.hpp:77] Creating layer layer_64_2_scale3
I0521 09:36:45.571578  3675 net.cpp:150] Setting up layer_64_2_scale3
I0521 09:36:45.571584  3675 net.cpp:157] Top shape: 128 64 8 32 (2097152)
I0521 09:36:45.571588  3675 net.cpp:165] Memory required for data: 572550656
I0521 09:36:45.571594  3675 layer_factory.hpp:77] Creating layer layer_64_2_relu3
I0521 09:36:45.571602  3675 net.cpp:100] Creating Layer layer_64_2_relu3
I0521 09:36:45.571605  3675 net.cpp:434] layer_64_2_relu3 <- layer_64_2_conv2
I0521 09:36:45.571610  3675 net.cpp:395] layer_64_2_relu3 -> layer_64_2_conv2 (in-place)
I0521 09:36:45.571862  3675 net.cpp:150] Setting up layer_64_2_relu3
I0521 09:36:45.571877  3675 net.cpp:157] Top shape: 128 64 8 32 (2097152)
I0521 09:36:45.571879  3675 net.cpp:165] Memory required for data: 580939264
I0521 09:36:45.571882  3675 layer_factory.hpp:77] Creating layer layer_64_2_conv3
I0521 09:36:45.571892  3675 net.cpp:100] Creating Layer layer_64_2_conv3
I0521 09:36:45.571894  3675 net.cpp:434] layer_64_2_conv3 <- layer_64_2_conv2
I0521 09:36:45.571899  3675 net.cpp:408] layer_64_2_conv3 -> layer_64_2_conv3
I0521 09:36:45.573205  3675 net.cpp:150] Setting up layer_64_2_conv3
I0521 09:36:45.573220  3675 net.cpp:157] Top shape: 128 256 8 32 (8388608)
I0521 09:36:45.573222  3675 net.cpp:165] Memory required for data: 614493696
I0521 09:36:45.573227  3675 layer_factory.hpp:77] Creating layer layer_64_2_sum
I0521 09:36:45.573233  3675 net.cpp:100] Creating Layer layer_64_2_sum
I0521 09:36:45.573237  3675 net.cpp:434] layer_64_2_sum <- layer_64_2_conv3
I0521 09:36:45.573241  3675 net.cpp:434] layer_64_2_sum <- layer_64_1_sum_layer_64_1_sum_0_split_1
I0521 09:36:45.573246  3675 net.cpp:408] layer_64_2_sum -> layer_64_2_sum
I0521 09:36:45.573262  3675 net.cpp:150] Setting up layer_64_2_sum
I0521 09:36:45.573267  3675 net.cpp:157] Top shape: 128 256 8 32 (8388608)
I0521 09:36:45.573271  3675 net.cpp:165] Memory required for data: 648048128
I0521 09:36:45.573273  3675 layer_factory.hpp:77] Creating layer layer_64_2_sum_layer_64_2_sum_0_split
I0521 09:36:45.573279  3675 net.cpp:100] Creating Layer layer_64_2_sum_layer_64_2_sum_0_split
I0521 09:36:45.573282  3675 net.cpp:434] layer_64_2_sum_layer_64_2_sum_0_split <- layer_64_2_sum
I0521 09:36:45.573305  3675 net.cpp:408] layer_64_2_sum_layer_64_2_sum_0_split -> layer_64_2_sum_layer_64_2_sum_0_split_0
I0521 09:36:45.573310  3675 net.cpp:408] layer_64_2_sum_layer_64_2_sum_0_split -> layer_64_2_sum_layer_64_2_sum_0_split_1
I0521 09:36:45.573331  3675 net.cpp:150] Setting up layer_64_2_sum_layer_64_2_sum_0_split
I0521 09:36:45.573338  3675 net.cpp:157] Top shape: 128 256 8 32 (8388608)
I0521 09:36:45.573340  3675 net.cpp:157] Top shape: 128 256 8 32 (8388608)
I0521 09:36:45.573343  3675 net.cpp:165] Memory required for data: 715156992
I0521 09:36:45.573345  3675 layer_factory.hpp:77] Creating layer layer_64_3_bn1
I0521 09:36:45.573350  3675 net.cpp:100] Creating Layer layer_64_3_bn1
I0521 09:36:45.573354  3675 net.cpp:434] layer_64_3_bn1 <- layer_64_2_sum_layer_64_2_sum_0_split_0
I0521 09:36:45.573356  3675 net.cpp:408] layer_64_3_bn1 -> layer_64_3_bn1
I0521 09:36:45.573503  3675 net.cpp:150] Setting up layer_64_3_bn1
I0521 09:36:45.573509  3675 net.cpp:157] Top shape: 128 256 8 32 (8388608)
I0521 09:36:45.573513  3675 net.cpp:165] Memory required for data: 748711424
I0521 09:36:45.573519  3675 layer_factory.hpp:77] Creating layer layer_64_3_scale1
I0521 09:36:45.573525  3675 net.cpp:100] Creating Layer layer_64_3_scale1
I0521 09:36:45.573529  3675 net.cpp:434] layer_64_3_scale1 <- layer_64_3_bn1
I0521 09:36:45.573534  3675 net.cpp:395] layer_64_3_scale1 -> layer_64_3_bn1 (in-place)
I0521 09:36:45.573561  3675 layer_factory.hpp:77] Creating layer layer_64_3_scale1
I0521 09:36:45.573635  3675 net.cpp:150] Setting up layer_64_3_scale1
I0521 09:36:45.573642  3675 net.cpp:157] Top shape: 128 256 8 32 (8388608)
I0521 09:36:45.573644  3675 net.cpp:165] Memory required for data: 782265856
I0521 09:36:45.573648  3675 layer_factory.hpp:77] Creating layer layer_64_3_relu1
I0521 09:36:45.573653  3675 net.cpp:100] Creating Layer layer_64_3_relu1
I0521 09:36:45.573657  3675 net.cpp:434] layer_64_3_relu1 <- layer_64_3_bn1
I0521 09:36:45.573663  3675 net.cpp:395] layer_64_3_relu1 -> layer_64_3_bn1 (in-place)
I0521 09:36:45.574028  3675 net.cpp:150] Setting up layer_64_3_relu1
I0521 09:36:45.574043  3675 net.cpp:157] Top shape: 128 256 8 32 (8388608)
I0521 09:36:45.574048  3675 net.cpp:165] Memory required for data: 815820288
I0521 09:36:45.574051  3675 layer_factory.hpp:77] Creating layer layer_64_3_conv1
I0521 09:36:45.574059  3675 net.cpp:100] Creating Layer layer_64_3_conv1
I0521 09:36:45.574062  3675 net.cpp:434] layer_64_3_conv1 <- layer_64_3_bn1
I0521 09:36:45.574067  3675 net.cpp:408] layer_64_3_conv1 -> layer_64_3_conv1
I0521 09:36:45.575562  3675 net.cpp:150] Setting up layer_64_3_conv1
I0521 09:36:45.575575  3675 net.cpp:157] Top shape: 128 64 8 32 (2097152)
I0521 09:36:45.575578  3675 net.cpp:165] Memory required for data: 824208896
I0521 09:36:45.575583  3675 layer_factory.hpp:77] Creating layer layer_64_3_bn2
I0521 09:36:45.575593  3675 net.cpp:100] Creating Layer layer_64_3_bn2
I0521 09:36:45.575598  3675 net.cpp:434] layer_64_3_bn2 <- layer_64_3_conv1
I0521 09:36:45.575604  3675 net.cpp:395] layer_64_3_bn2 -> layer_64_3_conv1 (in-place)
I0521 09:36:45.575760  3675 net.cpp:150] Setting up layer_64_3_bn2
I0521 09:36:45.575772  3675 net.cpp:157] Top shape: 128 64 8 32 (2097152)
I0521 09:36:45.575774  3675 net.cpp:165] Memory required for data: 832597504
I0521 09:36:45.575783  3675 layer_factory.hpp:77] Creating layer layer_64_3_scale2
I0521 09:36:45.575791  3675 net.cpp:100] Creating Layer layer_64_3_scale2
I0521 09:36:45.575795  3675 net.cpp:434] layer_64_3_scale2 <- layer_64_3_conv1
I0521 09:36:45.575803  3675 net.cpp:395] layer_64_3_scale2 -> layer_64_3_conv1 (in-place)
I0521 09:36:45.575834  3675 layer_factory.hpp:77] Creating layer layer_64_3_scale2
I0521 09:36:45.575932  3675 net.cpp:150] Setting up layer_64_3_scale2
I0521 09:36:45.575942  3675 net.cpp:157] Top shape: 128 64 8 32 (2097152)
I0521 09:36:45.575945  3675 net.cpp:165] Memory required for data: 840986112
I0521 09:36:45.575951  3675 layer_factory.hpp:77] Creating layer layer_64_3_relu2
I0521 09:36:45.575958  3675 net.cpp:100] Creating Layer layer_64_3_relu2
I0521 09:36:45.575978  3675 net.cpp:434] layer_64_3_relu2 <- layer_64_3_conv1
I0521 09:36:45.575984  3675 net.cpp:395] layer_64_3_relu2 -> layer_64_3_conv1 (in-place)
I0521 09:36:45.576359  3675 net.cpp:150] Setting up layer_64_3_relu2
I0521 09:36:45.576373  3675 net.cpp:157] Top shape: 128 64 8 32 (2097152)
I0521 09:36:45.576378  3675 net.cpp:165] Memory required for data: 849374720
I0521 09:36:45.576382  3675 layer_factory.hpp:77] Creating layer layer_64_3_conv2
I0521 09:36:45.576395  3675 net.cpp:100] Creating Layer layer_64_3_conv2
I0521 09:36:45.576400  3675 net.cpp:434] layer_64_3_conv2 <- layer_64_3_conv1
I0521 09:36:45.576409  3675 net.cpp:408] layer_64_3_conv2 -> layer_64_3_conv2
I0521 09:36:45.578510  3675 net.cpp:150] Setting up layer_64_3_conv2
I0521 09:36:45.578526  3675 net.cpp:157] Top shape: 128 64 8 32 (2097152)
I0521 09:36:45.578531  3675 net.cpp:165] Memory required for data: 857763328
I0521 09:36:45.578536  3675 layer_factory.hpp:77] Creating layer layer_64_3_bn3
I0521 09:36:45.578546  3675 net.cpp:100] Creating Layer layer_64_3_bn3
I0521 09:36:45.578549  3675 net.cpp:434] layer_64_3_bn3 <- layer_64_3_conv2
I0521 09:36:45.578554  3675 net.cpp:395] layer_64_3_bn3 -> layer_64_3_conv2 (in-place)
I0521 09:36:45.578734  3675 net.cpp:150] Setting up layer_64_3_bn3
I0521 09:36:45.578744  3675 net.cpp:157] Top shape: 128 64 8 32 (2097152)
I0521 09:36:45.578748  3675 net.cpp:165] Memory required for data: 866151936
I0521 09:36:45.578755  3675 layer_factory.hpp:77] Creating layer layer_64_3_scale3
I0521 09:36:45.578765  3675 net.cpp:100] Creating Layer layer_64_3_scale3
I0521 09:36:45.578769  3675 net.cpp:434] layer_64_3_scale3 <- layer_64_3_conv2
I0521 09:36:45.578775  3675 net.cpp:395] layer_64_3_scale3 -> layer_64_3_conv2 (in-place)
I0521 09:36:45.578807  3675 layer_factory.hpp:77] Creating layer layer_64_3_scale3
I0521 09:36:45.578905  3675 net.cpp:150] Setting up layer_64_3_scale3
I0521 09:36:45.578913  3675 net.cpp:157] Top shape: 128 64 8 32 (2097152)
I0521 09:36:45.578917  3675 net.cpp:165] Memory required for data: 874540544
I0521 09:36:45.578922  3675 layer_factory.hpp:77] Creating layer layer_64_3_relu3
I0521 09:36:45.578930  3675 net.cpp:100] Creating Layer layer_64_3_relu3
I0521 09:36:45.578934  3675 net.cpp:434] layer_64_3_relu3 <- layer_64_3_conv2
I0521 09:36:45.578939  3675 net.cpp:395] layer_64_3_relu3 -> layer_64_3_conv2 (in-place)
I0521 09:36:45.580531  3675 net.cpp:150] Setting up layer_64_3_relu3
I0521 09:36:45.580549  3675 net.cpp:157] Top shape: 128 64 8 32 (2097152)
I0521 09:36:45.580552  3675 net.cpp:165] Memory required for data: 882929152
I0521 09:36:45.580557  3675 layer_factory.hpp:77] Creating layer layer_64_3_conv3
I0521 09:36:45.580569  3675 net.cpp:100] Creating Layer layer_64_3_conv3
I0521 09:36:45.580572  3675 net.cpp:434] layer_64_3_conv3 <- layer_64_3_conv2
I0521 09:36:45.580579  3675 net.cpp:408] layer_64_3_conv3 -> layer_64_3_conv3
I0521 09:36:45.582013  3675 net.cpp:150] Setting up layer_64_3_conv3
I0521 09:36:45.582027  3675 net.cpp:157] Top shape: 128 256 8 32 (8388608)
I0521 09:36:45.582031  3675 net.cpp:165] Memory required for data: 916483584
I0521 09:36:45.582036  3675 layer_factory.hpp:77] Creating layer layer_64_3_sum
I0521 09:36:45.582042  3675 net.cpp:100] Creating Layer layer_64_3_sum
I0521 09:36:45.582046  3675 net.cpp:434] layer_64_3_sum <- layer_64_3_conv3
I0521 09:36:45.582049  3675 net.cpp:434] layer_64_3_sum <- layer_64_2_sum_layer_64_2_sum_0_split_1
I0521 09:36:45.582054  3675 net.cpp:408] layer_64_3_sum -> layer_64_3_sum
I0521 09:36:45.582077  3675 net.cpp:150] Setting up layer_64_3_sum
I0521 09:36:45.582083  3675 net.cpp:157] Top shape: 128 256 8 32 (8388608)
I0521 09:36:45.582085  3675 net.cpp:165] Memory required for data: 950038016
I0521 09:36:45.582088  3675 layer_factory.hpp:77] Creating layer layer_128_1_bn1
I0521 09:36:45.582095  3675 net.cpp:100] Creating Layer layer_128_1_bn1
I0521 09:36:45.582098  3675 net.cpp:434] layer_128_1_bn1 <- layer_64_3_sum
I0521 09:36:45.582104  3675 net.cpp:408] layer_128_1_bn1 -> layer_128_1_bn1
I0521 09:36:45.582293  3675 net.cpp:150] Setting up layer_128_1_bn1
I0521 09:36:45.582304  3675 net.cpp:157] Top shape: 128 256 8 32 (8388608)
I0521 09:36:45.582306  3675 net.cpp:165] Memory required for data: 983592448
I0521 09:36:45.582321  3675 layer_factory.hpp:77] Creating layer layer_128_1_scale1
I0521 09:36:45.582331  3675 net.cpp:100] Creating Layer layer_128_1_scale1
I0521 09:36:45.582340  3675 net.cpp:434] layer_128_1_scale1 <- layer_128_1_bn1
I0521 09:36:45.582346  3675 net.cpp:395] layer_128_1_scale1 -> layer_128_1_bn1 (in-place)
I0521 09:36:45.582381  3675 layer_factory.hpp:77] Creating layer layer_128_1_scale1
I0521 09:36:45.582480  3675 net.cpp:150] Setting up layer_128_1_scale1
I0521 09:36:45.582489  3675 net.cpp:157] Top shape: 128 256 8 32 (8388608)
I0521 09:36:45.582494  3675 net.cpp:165] Memory required for data: 1017146880
I0521 09:36:45.582500  3675 layer_factory.hpp:77] Creating layer layer_128_1_relu1
I0521 09:36:45.582505  3675 net.cpp:100] Creating Layer layer_128_1_relu1
I0521 09:36:45.582509  3675 net.cpp:434] layer_128_1_relu1 <- layer_128_1_bn1
I0521 09:36:45.582515  3675 net.cpp:395] layer_128_1_relu1 -> layer_128_1_bn1 (in-place)
I0521 09:36:45.582872  3675 net.cpp:150] Setting up layer_128_1_relu1
I0521 09:36:45.582886  3675 net.cpp:157] Top shape: 128 256 8 32 (8388608)
I0521 09:36:45.582890  3675 net.cpp:165] Memory required for data: 1050701312
I0521 09:36:45.582892  3675 layer_factory.hpp:77] Creating layer layer_128_1_bn1_layer_128_1_relu1_0_split
I0521 09:36:45.582901  3675 net.cpp:100] Creating Layer layer_128_1_bn1_layer_128_1_relu1_0_split
I0521 09:36:45.582906  3675 net.cpp:434] layer_128_1_bn1_layer_128_1_relu1_0_split <- layer_128_1_bn1
I0521 09:36:45.582911  3675 net.cpp:408] layer_128_1_bn1_layer_128_1_relu1_0_split -> layer_128_1_bn1_layer_128_1_relu1_0_split_0
I0521 09:36:45.582919  3675 net.cpp:408] layer_128_1_bn1_layer_128_1_relu1_0_split -> layer_128_1_bn1_layer_128_1_relu1_0_split_1
I0521 09:36:45.582958  3675 net.cpp:150] Setting up layer_128_1_bn1_layer_128_1_relu1_0_split
I0521 09:36:45.582967  3675 net.cpp:157] Top shape: 128 256 8 32 (8388608)
I0521 09:36:45.582971  3675 net.cpp:157] Top shape: 128 256 8 32 (8388608)
I0521 09:36:45.582974  3675 net.cpp:165] Memory required for data: 1117810176
I0521 09:36:45.582979  3675 layer_factory.hpp:77] Creating layer layer_128_1_conv1
I0521 09:36:45.582989  3675 net.cpp:100] Creating Layer layer_128_1_conv1
I0521 09:36:45.582993  3675 net.cpp:434] layer_128_1_conv1 <- layer_128_1_bn1_layer_128_1_relu1_0_split_0
I0521 09:36:45.583000  3675 net.cpp:408] layer_128_1_conv1 -> layer_128_1_conv1
I0521 09:36:45.584636  3675 net.cpp:150] Setting up layer_128_1_conv1
I0521 09:36:45.584650  3675 net.cpp:157] Top shape: 128 128 8 32 (4194304)
I0521 09:36:45.584652  3675 net.cpp:165] Memory required for data: 1134587392
I0521 09:36:45.584657  3675 layer_factory.hpp:77] Creating layer layer_128_1_bn2
I0521 09:36:45.584664  3675 net.cpp:100] Creating Layer layer_128_1_bn2
I0521 09:36:45.584667  3675 net.cpp:434] layer_128_1_bn2 <- layer_128_1_conv1
I0521 09:36:45.584671  3675 net.cpp:395] layer_128_1_bn2 -> layer_128_1_conv1 (in-place)
I0521 09:36:45.584844  3675 net.cpp:150] Setting up layer_128_1_bn2
I0521 09:36:45.584853  3675 net.cpp:157] Top shape: 128 128 8 32 (4194304)
I0521 09:36:45.584857  3675 net.cpp:165] Memory required for data: 1151364608
I0521 09:36:45.584866  3675 layer_factory.hpp:77] Creating layer layer_128_1_scale2
I0521 09:36:45.584875  3675 net.cpp:100] Creating Layer layer_128_1_scale2
I0521 09:36:45.584879  3675 net.cpp:434] layer_128_1_scale2 <- layer_128_1_conv1
I0521 09:36:45.584885  3675 net.cpp:395] layer_128_1_scale2 -> layer_128_1_conv1 (in-place)
I0521 09:36:45.584918  3675 layer_factory.hpp:77] Creating layer layer_128_1_scale2
I0521 09:36:45.585012  3675 net.cpp:150] Setting up layer_128_1_scale2
I0521 09:36:45.585021  3675 net.cpp:157] Top shape: 128 128 8 32 (4194304)
I0521 09:36:45.585026  3675 net.cpp:165] Memory required for data: 1168141824
I0521 09:36:45.585031  3675 layer_factory.hpp:77] Creating layer layer_128_1_relu2
I0521 09:36:45.585057  3675 net.cpp:100] Creating Layer layer_128_1_relu2
I0521 09:36:45.585062  3675 net.cpp:434] layer_128_1_relu2 <- layer_128_1_conv1
I0521 09:36:45.585067  3675 net.cpp:395] layer_128_1_relu2 -> layer_128_1_conv1 (in-place)
I0521 09:36:45.585513  3675 net.cpp:150] Setting up layer_128_1_relu2
I0521 09:36:45.585526  3675 net.cpp:157] Top shape: 128 128 8 32 (4194304)
I0521 09:36:45.585528  3675 net.cpp:165] Memory required for data: 1184919040
I0521 09:36:45.585532  3675 layer_factory.hpp:77] Creating layer layer_128_1_conv2
I0521 09:36:45.585546  3675 net.cpp:100] Creating Layer layer_128_1_conv2
I0521 09:36:45.585549  3675 net.cpp:434] layer_128_1_conv2 <- layer_128_1_conv1
I0521 09:36:45.585556  3675 net.cpp:408] layer_128_1_conv2 -> layer_128_1_conv2
I0521 09:36:45.587790  3675 net.cpp:150] Setting up layer_128_1_conv2
I0521 09:36:45.587805  3675 net.cpp:157] Top shape: 128 128 4 16 (1048576)
I0521 09:36:45.587808  3675 net.cpp:165] Memory required for data: 1189113344
I0521 09:36:45.587813  3675 layer_factory.hpp:77] Creating layer layer_128_1_bn3
I0521 09:36:45.587819  3675 net.cpp:100] Creating Layer layer_128_1_bn3
I0521 09:36:45.587822  3675 net.cpp:434] layer_128_1_bn3 <- layer_128_1_conv2
I0521 09:36:45.587827  3675 net.cpp:395] layer_128_1_bn3 -> layer_128_1_conv2 (in-place)
I0521 09:36:45.588014  3675 net.cpp:150] Setting up layer_128_1_bn3
I0521 09:36:45.588027  3675 net.cpp:157] Top shape: 128 128 4 16 (1048576)
I0521 09:36:45.588030  3675 net.cpp:165] Memory required for data: 1193307648
I0521 09:36:45.588039  3675 layer_factory.hpp:77] Creating layer layer_128_1_scale3
I0521 09:36:45.588052  3675 net.cpp:100] Creating Layer layer_128_1_scale3
I0521 09:36:45.588057  3675 net.cpp:434] layer_128_1_scale3 <- layer_128_1_conv2
I0521 09:36:45.588063  3675 net.cpp:395] layer_128_1_scale3 -> layer_128_1_conv2 (in-place)
I0521 09:36:45.588099  3675 layer_factory.hpp:77] Creating layer layer_128_1_scale3
I0521 09:36:45.588212  3675 net.cpp:150] Setting up layer_128_1_scale3
I0521 09:36:45.588222  3675 net.cpp:157] Top shape: 128 128 4 16 (1048576)
I0521 09:36:45.588225  3675 net.cpp:165] Memory required for data: 1197501952
I0521 09:36:45.588232  3675 layer_factory.hpp:77] Creating layer layer_128_1_relu3
I0521 09:36:45.588239  3675 net.cpp:100] Creating Layer layer_128_1_relu3
I0521 09:36:45.588243  3675 net.cpp:434] layer_128_1_relu3 <- layer_128_1_conv2
I0521 09:36:45.588249  3675 net.cpp:395] layer_128_1_relu3 -> layer_128_1_conv2 (in-place)
I0521 09:36:45.588702  3675 net.cpp:150] Setting up layer_128_1_relu3
I0521 09:36:45.588721  3675 net.cpp:157] Top shape: 128 128 4 16 (1048576)
I0521 09:36:45.588723  3675 net.cpp:165] Memory required for data: 1201696256
I0521 09:36:45.588728  3675 layer_factory.hpp:77] Creating layer layer_128_1_conv3
I0521 09:36:45.588745  3675 net.cpp:100] Creating Layer layer_128_1_conv3
I0521 09:36:45.588752  3675 net.cpp:434] layer_128_1_conv3 <- layer_128_1_conv2
I0521 09:36:45.588760  3675 net.cpp:408] layer_128_1_conv3 -> layer_128_1_conv3
I0521 09:36:45.592638  3675 net.cpp:150] Setting up layer_128_1_conv3
I0521 09:36:45.592662  3675 net.cpp:157] Top shape: 128 512 4 16 (4194304)
I0521 09:36:45.592665  3675 net.cpp:165] Memory required for data: 1218473472
I0521 09:36:45.592674  3675 layer_factory.hpp:77] Creating layer layer_128_1_conv_expand
I0521 09:36:45.592692  3675 net.cpp:100] Creating Layer layer_128_1_conv_expand
I0521 09:36:45.592700  3675 net.cpp:434] layer_128_1_conv_expand <- layer_128_1_bn1_layer_128_1_relu1_0_split_1
I0521 09:36:45.592710  3675 net.cpp:408] layer_128_1_conv_expand -> layer_128_1_conv_expand
I0521 09:36:45.594965  3675 net.cpp:150] Setting up layer_128_1_conv_expand
I0521 09:36:45.594988  3675 net.cpp:157] Top shape: 128 512 4 16 (4194304)
I0521 09:36:45.594992  3675 net.cpp:165] Memory required for data: 1235250688
I0521 09:36:45.595000  3675 layer_factory.hpp:77] Creating layer layer_128_1_sum
I0521 09:36:45.595018  3675 net.cpp:100] Creating Layer layer_128_1_sum
I0521 09:36:45.595037  3675 net.cpp:434] layer_128_1_sum <- layer_128_1_conv3
I0521 09:36:45.595043  3675 net.cpp:434] layer_128_1_sum <- layer_128_1_conv_expand
I0521 09:36:45.595049  3675 net.cpp:408] layer_128_1_sum -> layer_128_1_sum
I0521 09:36:45.595072  3675 net.cpp:150] Setting up layer_128_1_sum
I0521 09:36:45.595077  3675 net.cpp:157] Top shape: 128 512 4 16 (4194304)
I0521 09:36:45.595080  3675 net.cpp:165] Memory required for data: 1252027904
I0521 09:36:45.595084  3675 layer_factory.hpp:77] Creating layer layer_128_1_sum_layer_128_1_sum_0_split
I0521 09:36:45.595091  3675 net.cpp:100] Creating Layer layer_128_1_sum_layer_128_1_sum_0_split
I0521 09:36:45.595095  3675 net.cpp:434] layer_128_1_sum_layer_128_1_sum_0_split <- layer_128_1_sum
I0521 09:36:45.595100  3675 net.cpp:408] layer_128_1_sum_layer_128_1_sum_0_split -> layer_128_1_sum_layer_128_1_sum_0_split_0
I0521 09:36:45.595108  3675 net.cpp:408] layer_128_1_sum_layer_128_1_sum_0_split -> layer_128_1_sum_layer_128_1_sum_0_split_1
I0521 09:36:45.595139  3675 net.cpp:150] Setting up layer_128_1_sum_layer_128_1_sum_0_split
I0521 09:36:45.595144  3675 net.cpp:157] Top shape: 128 512 4 16 (4194304)
I0521 09:36:45.595149  3675 net.cpp:157] Top shape: 128 512 4 16 (4194304)
I0521 09:36:45.595151  3675 net.cpp:165] Memory required for data: 1285582336
I0521 09:36:45.595155  3675 layer_factory.hpp:77] Creating layer layer_128_2_bn1
I0521 09:36:45.595161  3675 net.cpp:100] Creating Layer layer_128_2_bn1
I0521 09:36:45.595167  3675 net.cpp:434] layer_128_2_bn1 <- layer_128_1_sum_layer_128_1_sum_0_split_0
I0521 09:36:45.595172  3675 net.cpp:408] layer_128_2_bn1 -> layer_128_2_bn1
I0521 09:36:45.595307  3675 net.cpp:150] Setting up layer_128_2_bn1
I0521 09:36:45.595312  3675 net.cpp:157] Top shape: 128 512 4 16 (4194304)
I0521 09:36:45.595315  3675 net.cpp:165] Memory required for data: 1302359552
I0521 09:36:45.595321  3675 layer_factory.hpp:77] Creating layer layer_128_2_scale1
I0521 09:36:45.595329  3675 net.cpp:100] Creating Layer layer_128_2_scale1
I0521 09:36:45.595331  3675 net.cpp:434] layer_128_2_scale1 <- layer_128_2_bn1
I0521 09:36:45.595336  3675 net.cpp:395] layer_128_2_scale1 -> layer_128_2_bn1 (in-place)
I0521 09:36:45.595363  3675 layer_factory.hpp:77] Creating layer layer_128_2_scale1
I0521 09:36:45.595441  3675 net.cpp:150] Setting up layer_128_2_scale1
I0521 09:36:45.595446  3675 net.cpp:157] Top shape: 128 512 4 16 (4194304)
I0521 09:36:45.595449  3675 net.cpp:165] Memory required for data: 1319136768
I0521 09:36:45.595454  3675 layer_factory.hpp:77] Creating layer layer_128_2_relu1
I0521 09:36:45.595459  3675 net.cpp:100] Creating Layer layer_128_2_relu1
I0521 09:36:45.595463  3675 net.cpp:434] layer_128_2_relu1 <- layer_128_2_bn1
I0521 09:36:45.595468  3675 net.cpp:395] layer_128_2_relu1 -> layer_128_2_bn1 (in-place)
I0521 09:36:45.595727  3675 net.cpp:150] Setting up layer_128_2_relu1
I0521 09:36:45.595736  3675 net.cpp:157] Top shape: 128 512 4 16 (4194304)
I0521 09:36:45.595737  3675 net.cpp:165] Memory required for data: 1335913984
I0521 09:36:45.595741  3675 layer_factory.hpp:77] Creating layer layer_128_2_conv1
I0521 09:36:45.595749  3675 net.cpp:100] Creating Layer layer_128_2_conv1
I0521 09:36:45.595754  3675 net.cpp:434] layer_128_2_conv1 <- layer_128_2_bn1
I0521 09:36:45.595759  3675 net.cpp:408] layer_128_2_conv1 -> layer_128_2_conv1
I0521 09:36:45.597970  3675 net.cpp:150] Setting up layer_128_2_conv1
I0521 09:36:45.597987  3675 net.cpp:157] Top shape: 128 128 4 16 (1048576)
I0521 09:36:45.597990  3675 net.cpp:165] Memory required for data: 1340108288
I0521 09:36:45.597996  3675 layer_factory.hpp:77] Creating layer layer_128_2_bn2
I0521 09:36:45.598006  3675 net.cpp:100] Creating Layer layer_128_2_bn2
I0521 09:36:45.598011  3675 net.cpp:434] layer_128_2_bn2 <- layer_128_2_conv1
I0521 09:36:45.598016  3675 net.cpp:395] layer_128_2_bn2 -> layer_128_2_conv1 (in-place)
I0521 09:36:45.598148  3675 net.cpp:150] Setting up layer_128_2_bn2
I0521 09:36:45.598153  3675 net.cpp:157] Top shape: 128 128 4 16 (1048576)
I0521 09:36:45.598156  3675 net.cpp:165] Memory required for data: 1344302592
I0521 09:36:45.598179  3675 layer_factory.hpp:77] Creating layer layer_128_2_scale2
I0521 09:36:45.598186  3675 net.cpp:100] Creating Layer layer_128_2_scale2
I0521 09:36:45.598191  3675 net.cpp:434] layer_128_2_scale2 <- layer_128_2_conv1
I0521 09:36:45.598196  3675 net.cpp:395] layer_128_2_scale2 -> layer_128_2_conv1 (in-place)
I0521 09:36:45.598222  3675 layer_factory.hpp:77] Creating layer layer_128_2_scale2
I0521 09:36:45.598292  3675 net.cpp:150] Setting up layer_128_2_scale2
I0521 09:36:45.598297  3675 net.cpp:157] Top shape: 128 128 4 16 (1048576)
I0521 09:36:45.598299  3675 net.cpp:165] Memory required for data: 1348496896
I0521 09:36:45.598304  3675 layer_factory.hpp:77] Creating layer layer_128_2_relu2
I0521 09:36:45.598311  3675 net.cpp:100] Creating Layer layer_128_2_relu2
I0521 09:36:45.598316  3675 net.cpp:434] layer_128_2_relu2 <- layer_128_2_conv1
I0521 09:36:45.598320  3675 net.cpp:395] layer_128_2_relu2 -> layer_128_2_conv1 (in-place)
I0521 09:36:45.598687  3675 net.cpp:150] Setting up layer_128_2_relu2
I0521 09:36:45.598697  3675 net.cpp:157] Top shape: 128 128 4 16 (1048576)
I0521 09:36:45.598700  3675 net.cpp:165] Memory required for data: 1352691200
I0521 09:36:45.598703  3675 layer_factory.hpp:77] Creating layer layer_128_2_conv2
I0521 09:36:45.598714  3675 net.cpp:100] Creating Layer layer_128_2_conv2
I0521 09:36:45.598719  3675 net.cpp:434] layer_128_2_conv2 <- layer_128_2_conv1
I0521 09:36:45.598726  3675 net.cpp:408] layer_128_2_conv2 -> layer_128_2_conv2
I0521 09:36:45.601987  3675 net.cpp:150] Setting up layer_128_2_conv2
I0521 09:36:45.602005  3675 net.cpp:157] Top shape: 128 128 4 16 (1048576)
I0521 09:36:45.602006  3675 net.cpp:165] Memory required for data: 1356885504
I0521 09:36:45.602015  3675 layer_factory.hpp:77] Creating layer layer_128_2_bn3
I0521 09:36:45.602023  3675 net.cpp:100] Creating Layer layer_128_2_bn3
I0521 09:36:45.602028  3675 net.cpp:434] layer_128_2_bn3 <- layer_128_2_conv2
I0521 09:36:45.602035  3675 net.cpp:395] layer_128_2_bn3 -> layer_128_2_conv2 (in-place)
I0521 09:36:45.602171  3675 net.cpp:150] Setting up layer_128_2_bn3
I0521 09:36:45.602177  3675 net.cpp:157] Top shape: 128 128 4 16 (1048576)
I0521 09:36:45.602180  3675 net.cpp:165] Memory required for data: 1361079808
I0521 09:36:45.602187  3675 layer_factory.hpp:77] Creating layer layer_128_2_scale3
I0521 09:36:45.602195  3675 net.cpp:100] Creating Layer layer_128_2_scale3
I0521 09:36:45.602200  3675 net.cpp:434] layer_128_2_scale3 <- layer_128_2_conv2
I0521 09:36:45.602203  3675 net.cpp:395] layer_128_2_scale3 -> layer_128_2_conv2 (in-place)
I0521 09:36:45.602231  3675 layer_factory.hpp:77] Creating layer layer_128_2_scale3
I0521 09:36:45.602300  3675 net.cpp:150] Setting up layer_128_2_scale3
I0521 09:36:45.602305  3675 net.cpp:157] Top shape: 128 128 4 16 (1048576)
I0521 09:36:45.602308  3675 net.cpp:165] Memory required for data: 1365274112
I0521 09:36:45.602313  3675 layer_factory.hpp:77] Creating layer layer_128_2_relu3
I0521 09:36:45.602322  3675 net.cpp:100] Creating Layer layer_128_2_relu3
I0521 09:36:45.602325  3675 net.cpp:434] layer_128_2_relu3 <- layer_128_2_conv2
I0521 09:36:45.602330  3675 net.cpp:395] layer_128_2_relu3 -> layer_128_2_conv2 (in-place)
I0521 09:36:45.602670  3675 net.cpp:150] Setting up layer_128_2_relu3
I0521 09:36:45.602687  3675 net.cpp:157] Top shape: 128 128 4 16 (1048576)
I0521 09:36:45.602692  3675 net.cpp:165] Memory required for data: 1369468416
I0521 09:36:45.602697  3675 layer_factory.hpp:77] Creating layer layer_128_2_conv3
I0521 09:36:45.602710  3675 net.cpp:100] Creating Layer layer_128_2_conv3
I0521 09:36:45.602715  3675 net.cpp:434] layer_128_2_conv3 <- layer_128_2_conv2
I0521 09:36:45.602725  3675 net.cpp:408] layer_128_2_conv3 -> layer_128_2_conv3
I0521 09:36:45.604918  3675 net.cpp:150] Setting up layer_128_2_conv3
I0521 09:36:45.604933  3675 net.cpp:157] Top shape: 128 512 4 16 (4194304)
I0521 09:36:45.604934  3675 net.cpp:165] Memory required for data: 1386245632
I0521 09:36:45.604940  3675 layer_factory.hpp:77] Creating layer layer_128_2_sum
I0521 09:36:45.604964  3675 net.cpp:100] Creating Layer layer_128_2_sum
I0521 09:36:45.604967  3675 net.cpp:434] layer_128_2_sum <- layer_128_2_conv3
I0521 09:36:45.604971  3675 net.cpp:434] layer_128_2_sum <- layer_128_1_sum_layer_128_1_sum_0_split_1
I0521 09:36:45.604975  3675 net.cpp:408] layer_128_2_sum -> layer_128_2_sum
I0521 09:36:45.604993  3675 net.cpp:150] Setting up layer_128_2_sum
I0521 09:36:45.604998  3675 net.cpp:157] Top shape: 128 512 4 16 (4194304)
I0521 09:36:45.605000  3675 net.cpp:165] Memory required for data: 1403022848
I0521 09:36:45.605002  3675 layer_factory.hpp:77] Creating layer layer_128_2_sum_layer_128_2_sum_0_split
I0521 09:36:45.605007  3675 net.cpp:100] Creating Layer layer_128_2_sum_layer_128_2_sum_0_split
I0521 09:36:45.605010  3675 net.cpp:434] layer_128_2_sum_layer_128_2_sum_0_split <- layer_128_2_sum
I0521 09:36:45.605015  3675 net.cpp:408] layer_128_2_sum_layer_128_2_sum_0_split -> layer_128_2_sum_layer_128_2_sum_0_split_0
I0521 09:36:45.605020  3675 net.cpp:408] layer_128_2_sum_layer_128_2_sum_0_split -> layer_128_2_sum_layer_128_2_sum_0_split_1
I0521 09:36:45.605041  3675 net.cpp:150] Setting up layer_128_2_sum_layer_128_2_sum_0_split
I0521 09:36:45.605046  3675 net.cpp:157] Top shape: 128 512 4 16 (4194304)
I0521 09:36:45.605048  3675 net.cpp:157] Top shape: 128 512 4 16 (4194304)
I0521 09:36:45.605051  3675 net.cpp:165] Memory required for data: 1436577280
I0521 09:36:45.605053  3675 layer_factory.hpp:77] Creating layer layer_128_3_bn1
I0521 09:36:45.605058  3675 net.cpp:100] Creating Layer layer_128_3_bn1
I0521 09:36:45.605062  3675 net.cpp:434] layer_128_3_bn1 <- layer_128_2_sum_layer_128_2_sum_0_split_0
I0521 09:36:45.605064  3675 net.cpp:408] layer_128_3_bn1 -> layer_128_3_bn1
I0521 09:36:45.605195  3675 net.cpp:150] Setting up layer_128_3_bn1
I0521 09:36:45.605199  3675 net.cpp:157] Top shape: 128 512 4 16 (4194304)
I0521 09:36:45.605201  3675 net.cpp:165] Memory required for data: 1453354496
I0521 09:36:45.605206  3675 layer_factory.hpp:77] Creating layer layer_128_3_scale1
I0521 09:36:45.605211  3675 net.cpp:100] Creating Layer layer_128_3_scale1
I0521 09:36:45.605216  3675 net.cpp:434] layer_128_3_scale1 <- layer_128_3_bn1
I0521 09:36:45.605218  3675 net.cpp:395] layer_128_3_scale1 -> layer_128_3_bn1 (in-place)
I0521 09:36:45.605245  3675 layer_factory.hpp:77] Creating layer layer_128_3_scale1
I0521 09:36:45.605345  3675 net.cpp:150] Setting up layer_128_3_scale1
I0521 09:36:45.605353  3675 net.cpp:157] Top shape: 128 512 4 16 (4194304)
I0521 09:36:45.605356  3675 net.cpp:165] Memory required for data: 1470131712
I0521 09:36:45.605362  3675 layer_factory.hpp:77] Creating layer layer_128_3_relu1
I0521 09:36:45.605370  3675 net.cpp:100] Creating Layer layer_128_3_relu1
I0521 09:36:45.605376  3675 net.cpp:434] layer_128_3_relu1 <- layer_128_3_bn1
I0521 09:36:45.605381  3675 net.cpp:395] layer_128_3_relu1 -> layer_128_3_bn1 (in-place)
I0521 09:36:45.605890  3675 net.cpp:150] Setting up layer_128_3_relu1
I0521 09:36:45.605907  3675 net.cpp:157] Top shape: 128 512 4 16 (4194304)
I0521 09:36:45.605911  3675 net.cpp:165] Memory required for data: 1486908928
I0521 09:36:45.605916  3675 layer_factory.hpp:77] Creating layer layer_128_3_conv1
I0521 09:36:45.605929  3675 net.cpp:100] Creating Layer layer_128_3_conv1
I0521 09:36:45.605935  3675 net.cpp:434] layer_128_3_conv1 <- layer_128_3_bn1
I0521 09:36:45.605944  3675 net.cpp:408] layer_128_3_conv1 -> layer_128_3_conv1
I0521 09:36:45.609207  3675 net.cpp:150] Setting up layer_128_3_conv1
I0521 09:36:45.609225  3675 net.cpp:157] Top shape: 128 128 4 16 (1048576)
I0521 09:36:45.609230  3675 net.cpp:165] Memory required for data: 1491103232
I0521 09:36:45.609237  3675 layer_factory.hpp:77] Creating layer layer_128_3_bn2
I0521 09:36:45.609247  3675 net.cpp:100] Creating Layer layer_128_3_bn2
I0521 09:36:45.609253  3675 net.cpp:434] layer_128_3_bn2 <- layer_128_3_conv1
I0521 09:36:45.609261  3675 net.cpp:395] layer_128_3_bn2 -> layer_128_3_conv1 (in-place)
I0521 09:36:45.609454  3675 net.cpp:150] Setting up layer_128_3_bn2
I0521 09:36:45.609485  3675 net.cpp:157] Top shape: 128 128 4 16 (1048576)
I0521 09:36:45.609489  3675 net.cpp:165] Memory required for data: 1495297536
I0521 09:36:45.609499  3675 layer_factory.hpp:77] Creating layer layer_128_3_scale2
I0521 09:36:45.609509  3675 net.cpp:100] Creating Layer layer_128_3_scale2
I0521 09:36:45.609515  3675 net.cpp:434] layer_128_3_scale2 <- layer_128_3_conv1
I0521 09:36:45.609524  3675 net.cpp:395] layer_128_3_scale2 -> layer_128_3_conv1 (in-place)
I0521 09:36:45.609560  3675 layer_factory.hpp:77] Creating layer layer_128_3_scale2
I0521 09:36:45.609664  3675 net.cpp:150] Setting up layer_128_3_scale2
I0521 09:36:45.609674  3675 net.cpp:157] Top shape: 128 128 4 16 (1048576)
I0521 09:36:45.609678  3675 net.cpp:165] Memory required for data: 1499491840
I0521 09:36:45.609685  3675 layer_factory.hpp:77] Creating layer layer_128_3_relu2
I0521 09:36:45.609694  3675 net.cpp:100] Creating Layer layer_128_3_relu2
I0521 09:36:45.609699  3675 net.cpp:434] layer_128_3_relu2 <- layer_128_3_conv1
I0521 09:36:45.609704  3675 net.cpp:395] layer_128_3_relu2 -> layer_128_3_conv1 (in-place)
I0521 09:36:45.610074  3675 net.cpp:150] Setting up layer_128_3_relu2
I0521 09:36:45.610090  3675 net.cpp:157] Top shape: 128 128 4 16 (1048576)
I0521 09:36:45.610095  3675 net.cpp:165] Memory required for data: 1503686144
I0521 09:36:45.610100  3675 layer_factory.hpp:77] Creating layer layer_128_3_conv2
I0521 09:36:45.610112  3675 net.cpp:100] Creating Layer layer_128_3_conv2
I0521 09:36:45.610119  3675 net.cpp:434] layer_128_3_conv2 <- layer_128_3_conv1
I0521 09:36:45.610127  3675 net.cpp:408] layer_128_3_conv2 -> layer_128_3_conv2
I0521 09:36:45.613731  3675 net.cpp:150] Setting up layer_128_3_conv2
I0521 09:36:45.613754  3675 net.cpp:157] Top shape: 128 128 4 16 (1048576)
I0521 09:36:45.613757  3675 net.cpp:165] Memory required for data: 1507880448
I0521 09:36:45.613767  3675 layer_factory.hpp:77] Creating layer layer_128_3_bn3
I0521 09:36:45.613775  3675 net.cpp:100] Creating Layer layer_128_3_bn3
I0521 09:36:45.613780  3675 net.cpp:434] layer_128_3_bn3 <- layer_128_3_conv2
I0521 09:36:45.613788  3675 net.cpp:395] layer_128_3_bn3 -> layer_128_3_conv2 (in-place)
I0521 09:36:45.613989  3675 net.cpp:150] Setting up layer_128_3_bn3
I0521 09:36:45.614002  3675 net.cpp:157] Top shape: 128 128 4 16 (1048576)
I0521 09:36:45.614006  3675 net.cpp:165] Memory required for data: 1512074752
I0521 09:36:45.614015  3675 layer_factory.hpp:77] Creating layer layer_128_3_scale3
I0521 09:36:45.614023  3675 net.cpp:100] Creating Layer layer_128_3_scale3
I0521 09:36:45.614028  3675 net.cpp:434] layer_128_3_scale3 <- layer_128_3_conv2
I0521 09:36:45.614034  3675 net.cpp:395] layer_128_3_scale3 -> layer_128_3_conv2 (in-place)
I0521 09:36:45.614071  3675 layer_factory.hpp:77] Creating layer layer_128_3_scale3
I0521 09:36:45.614178  3675 net.cpp:150] Setting up layer_128_3_scale3
I0521 09:36:45.614187  3675 net.cpp:157] Top shape: 128 128 4 16 (1048576)
I0521 09:36:45.614192  3675 net.cpp:165] Memory required for data: 1516269056
I0521 09:36:45.614199  3675 layer_factory.hpp:77] Creating layer layer_128_3_relu3
I0521 09:36:45.614207  3675 net.cpp:100] Creating Layer layer_128_3_relu3
I0521 09:36:45.614213  3675 net.cpp:434] layer_128_3_relu3 <- layer_128_3_conv2
I0521 09:36:45.614219  3675 net.cpp:395] layer_128_3_relu3 -> layer_128_3_conv2 (in-place)
I0521 09:36:45.616017  3675 net.cpp:150] Setting up layer_128_3_relu3
I0521 09:36:45.616037  3675 net.cpp:157] Top shape: 128 128 4 16 (1048576)
I0521 09:36:45.616041  3675 net.cpp:165] Memory required for data: 1520463360
I0521 09:36:45.616047  3675 layer_factory.hpp:77] Creating layer layer_128_3_conv3
I0521 09:36:45.616063  3675 net.cpp:100] Creating Layer layer_128_3_conv3
I0521 09:36:45.616071  3675 net.cpp:434] layer_128_3_conv3 <- layer_128_3_conv2
I0521 09:36:45.616080  3675 net.cpp:408] layer_128_3_conv3 -> layer_128_3_conv3
I0521 09:36:45.618449  3675 net.cpp:150] Setting up layer_128_3_conv3
I0521 09:36:45.618470  3675 net.cpp:157] Top shape: 128 512 4 16 (4194304)
I0521 09:36:45.618499  3675 net.cpp:165] Memory required for data: 1537240576
I0521 09:36:45.618508  3675 layer_factory.hpp:77] Creating layer layer_128_3_sum
I0521 09:36:45.618520  3675 net.cpp:100] Creating Layer layer_128_3_sum
I0521 09:36:45.618525  3675 net.cpp:434] layer_128_3_sum <- layer_128_3_conv3
I0521 09:36:45.618532  3675 net.cpp:434] layer_128_3_sum <- layer_128_2_sum_layer_128_2_sum_0_split_1
I0521 09:36:45.618537  3675 net.cpp:408] layer_128_3_sum -> layer_128_3_sum
I0521 09:36:45.618569  3675 net.cpp:150] Setting up layer_128_3_sum
I0521 09:36:45.618578  3675 net.cpp:157] Top shape: 128 512 4 16 (4194304)
I0521 09:36:45.618582  3675 net.cpp:165] Memory required for data: 1554017792
I0521 09:36:45.618585  3675 layer_factory.hpp:77] Creating layer layer_128_3_sum_layer_128_3_sum_0_split
I0521 09:36:45.618592  3675 net.cpp:100] Creating Layer layer_128_3_sum_layer_128_3_sum_0_split
I0521 09:36:45.618597  3675 net.cpp:434] layer_128_3_sum_layer_128_3_sum_0_split <- layer_128_3_sum
I0521 09:36:45.618605  3675 net.cpp:408] layer_128_3_sum_layer_128_3_sum_0_split -> layer_128_3_sum_layer_128_3_sum_0_split_0
I0521 09:36:45.618613  3675 net.cpp:408] layer_128_3_sum_layer_128_3_sum_0_split -> layer_128_3_sum_layer_128_3_sum_0_split_1
I0521 09:36:45.618649  3675 net.cpp:150] Setting up layer_128_3_sum_layer_128_3_sum_0_split
I0521 09:36:45.618656  3675 net.cpp:157] Top shape: 128 512 4 16 (4194304)
I0521 09:36:45.618660  3675 net.cpp:157] Top shape: 128 512 4 16 (4194304)
I0521 09:36:45.618664  3675 net.cpp:165] Memory required for data: 1587572224
I0521 09:36:45.618667  3675 layer_factory.hpp:77] Creating layer layer_128_4_bn1
I0521 09:36:45.618674  3675 net.cpp:100] Creating Layer layer_128_4_bn1
I0521 09:36:45.618679  3675 net.cpp:434] layer_128_4_bn1 <- layer_128_3_sum_layer_128_3_sum_0_split_0
I0521 09:36:45.618685  3675 net.cpp:408] layer_128_4_bn1 -> layer_128_4_bn1
I0521 09:36:45.618872  3675 net.cpp:150] Setting up layer_128_4_bn1
I0521 09:36:45.618885  3675 net.cpp:157] Top shape: 128 512 4 16 (4194304)
I0521 09:36:45.618890  3675 net.cpp:165] Memory required for data: 1604349440
I0521 09:36:45.618898  3675 layer_factory.hpp:77] Creating layer layer_128_4_scale1
I0521 09:36:45.618908  3675 net.cpp:100] Creating Layer layer_128_4_scale1
I0521 09:36:45.618914  3675 net.cpp:434] layer_128_4_scale1 <- layer_128_4_bn1
I0521 09:36:45.618922  3675 net.cpp:395] layer_128_4_scale1 -> layer_128_4_bn1 (in-place)
I0521 09:36:45.618958  3675 layer_factory.hpp:77] Creating layer layer_128_4_scale1
I0521 09:36:45.619061  3675 net.cpp:150] Setting up layer_128_4_scale1
I0521 09:36:45.619071  3675 net.cpp:157] Top shape: 128 512 4 16 (4194304)
I0521 09:36:45.619076  3675 net.cpp:165] Memory required for data: 1621126656
I0521 09:36:45.619082  3675 layer_factory.hpp:77] Creating layer layer_128_4_relu1
I0521 09:36:45.619091  3675 net.cpp:100] Creating Layer layer_128_4_relu1
I0521 09:36:45.619096  3675 net.cpp:434] layer_128_4_relu1 <- layer_128_4_bn1
I0521 09:36:45.619102  3675 net.cpp:395] layer_128_4_relu1 -> layer_128_4_bn1 (in-place)
I0521 09:36:45.619638  3675 net.cpp:150] Setting up layer_128_4_relu1
I0521 09:36:45.619655  3675 net.cpp:157] Top shape: 128 512 4 16 (4194304)
I0521 09:36:45.619659  3675 net.cpp:165] Memory required for data: 1637903872
I0521 09:36:45.619664  3675 layer_factory.hpp:77] Creating layer layer_128_4_conv1
I0521 09:36:45.619678  3675 net.cpp:100] Creating Layer layer_128_4_conv1
I0521 09:36:45.619684  3675 net.cpp:434] layer_128_4_conv1 <- layer_128_4_bn1
I0521 09:36:45.619693  3675 net.cpp:408] layer_128_4_conv1 -> layer_128_4_conv1
I0521 09:36:45.622155  3675 net.cpp:150] Setting up layer_128_4_conv1
I0521 09:36:45.622179  3675 net.cpp:157] Top shape: 128 128 4 16 (1048576)
I0521 09:36:45.622184  3675 net.cpp:165] Memory required for data: 1642098176
I0521 09:36:45.622191  3675 layer_factory.hpp:77] Creating layer layer_128_4_bn2
I0521 09:36:45.622201  3675 net.cpp:100] Creating Layer layer_128_4_bn2
I0521 09:36:45.622206  3675 net.cpp:434] layer_128_4_bn2 <- layer_128_4_conv1
I0521 09:36:45.622236  3675 net.cpp:395] layer_128_4_bn2 -> layer_128_4_conv1 (in-place)
I0521 09:36:45.622433  3675 net.cpp:150] Setting up layer_128_4_bn2
I0521 09:36:45.622448  3675 net.cpp:157] Top shape: 128 128 4 16 (1048576)
I0521 09:36:45.622452  3675 net.cpp:165] Memory required for data: 1646292480
I0521 09:36:45.622462  3675 layer_factory.hpp:77] Creating layer layer_128_4_scale2
I0521 09:36:45.622475  3675 net.cpp:100] Creating Layer layer_128_4_scale2
I0521 09:36:45.622479  3675 net.cpp:434] layer_128_4_scale2 <- layer_128_4_conv1
I0521 09:36:45.622486  3675 net.cpp:395] layer_128_4_scale2 -> layer_128_4_conv1 (in-place)
I0521 09:36:45.622524  3675 layer_factory.hpp:77] Creating layer layer_128_4_scale2
I0521 09:36:45.622632  3675 net.cpp:150] Setting up layer_128_4_scale2
I0521 09:36:45.622642  3675 net.cpp:157] Top shape: 128 128 4 16 (1048576)
I0521 09:36:45.622644  3675 net.cpp:165] Memory required for data: 1650486784
I0521 09:36:45.622650  3675 layer_factory.hpp:77] Creating layer layer_128_4_relu2
I0521 09:36:45.622658  3675 net.cpp:100] Creating Layer layer_128_4_relu2
I0521 09:36:45.622663  3675 net.cpp:434] layer_128_4_relu2 <- layer_128_4_conv1
I0521 09:36:45.622669  3675 net.cpp:395] layer_128_4_relu2 -> layer_128_4_conv1 (in-place)
I0521 09:36:45.623049  3675 net.cpp:150] Setting up layer_128_4_relu2
I0521 09:36:45.623067  3675 net.cpp:157] Top shape: 128 128 4 16 (1048576)
I0521 09:36:45.623071  3675 net.cpp:165] Memory required for data: 1654681088
I0521 09:36:45.623076  3675 layer_factory.hpp:77] Creating layer layer_128_4_conv2
I0521 09:36:45.623096  3675 net.cpp:100] Creating Layer layer_128_4_conv2
I0521 09:36:45.623102  3675 net.cpp:434] layer_128_4_conv2 <- layer_128_4_conv1
I0521 09:36:45.623111  3675 net.cpp:408] layer_128_4_conv2 -> layer_128_4_conv2
I0521 09:36:45.627045  3675 net.cpp:150] Setting up layer_128_4_conv2
I0521 09:36:45.627077  3675 net.cpp:157] Top shape: 128 128 4 16 (1048576)
I0521 09:36:45.627081  3675 net.cpp:165] Memory required for data: 1658875392
I0521 09:36:45.627105  3675 layer_factory.hpp:77] Creating layer layer_128_4_bn3
I0521 09:36:45.627120  3675 net.cpp:100] Creating Layer layer_128_4_bn3
I0521 09:36:45.627126  3675 net.cpp:434] layer_128_4_bn3 <- layer_128_4_conv2
I0521 09:36:45.627138  3675 net.cpp:395] layer_128_4_bn3 -> layer_128_4_conv2 (in-place)
I0521 09:36:45.627344  3675 net.cpp:150] Setting up layer_128_4_bn3
I0521 09:36:45.627358  3675 net.cpp:157] Top shape: 128 128 4 16 (1048576)
I0521 09:36:45.627362  3675 net.cpp:165] Memory required for data: 1663069696
I0521 09:36:45.627372  3675 layer_factory.hpp:77] Creating layer layer_128_4_scale3
I0521 09:36:45.627382  3675 net.cpp:100] Creating Layer layer_128_4_scale3
I0521 09:36:45.627388  3675 net.cpp:434] layer_128_4_scale3 <- layer_128_4_conv2
I0521 09:36:45.627394  3675 net.cpp:395] layer_128_4_scale3 -> layer_128_4_conv2 (in-place)
I0521 09:36:45.627430  3675 layer_factory.hpp:77] Creating layer layer_128_4_scale3
I0521 09:36:45.627537  3675 net.cpp:150] Setting up layer_128_4_scale3
I0521 09:36:45.627549  3675 net.cpp:157] Top shape: 128 128 4 16 (1048576)
I0521 09:36:45.627553  3675 net.cpp:165] Memory required for data: 1667264000
I0521 09:36:45.627558  3675 layer_factory.hpp:77] Creating layer layer_128_4_relu3
I0521 09:36:45.627565  3675 net.cpp:100] Creating Layer layer_128_4_relu3
I0521 09:36:45.627569  3675 net.cpp:434] layer_128_4_relu3 <- layer_128_4_conv2
I0521 09:36:45.627574  3675 net.cpp:395] layer_128_4_relu3 -> layer_128_4_conv2 (in-place)
I0521 09:36:45.628070  3675 net.cpp:150] Setting up layer_128_4_relu3
I0521 09:36:45.628087  3675 net.cpp:157] Top shape: 128 128 4 16 (1048576)
I0521 09:36:45.628091  3675 net.cpp:165] Memory required for data: 1671458304
I0521 09:36:45.628095  3675 layer_factory.hpp:77] Creating layer layer_128_4_conv3
I0521 09:36:45.628108  3675 net.cpp:100] Creating Layer layer_128_4_conv3
I0521 09:36:45.628114  3675 net.cpp:434] layer_128_4_conv3 <- layer_128_4_conv2
I0521 09:36:45.628121  3675 net.cpp:408] layer_128_4_conv3 -> layer_128_4_conv3
I0521 09:36:45.632685  3675 net.cpp:150] Setting up layer_128_4_conv3
I0521 09:36:45.632745  3675 net.cpp:157] Top shape: 128 512 4 16 (4194304)
I0521 09:36:45.632750  3675 net.cpp:165] Memory required for data: 1688235520
I0521 09:36:45.632761  3675 layer_factory.hpp:77] Creating layer layer_128_4_sum
I0521 09:36:45.632772  3675 net.cpp:100] Creating Layer layer_128_4_sum
I0521 09:36:45.632778  3675 net.cpp:434] layer_128_4_sum <- layer_128_4_conv3
I0521 09:36:45.632793  3675 net.cpp:434] layer_128_4_sum <- layer_128_3_sum_layer_128_3_sum_0_split_1
I0521 09:36:45.632800  3675 net.cpp:408] layer_128_4_sum -> layer_128_4_sum
I0521 09:36:45.632843  3675 net.cpp:150] Setting up layer_128_4_sum
I0521 09:36:45.632850  3675 net.cpp:157] Top shape: 128 512 4 16 (4194304)
I0521 09:36:45.632853  3675 net.cpp:165] Memory required for data: 1705012736
I0521 09:36:45.632858  3675 layer_factory.hpp:77] Creating layer last_bn
I0521 09:36:45.632865  3675 net.cpp:100] Creating Layer last_bn
I0521 09:36:45.632869  3675 net.cpp:434] last_bn <- layer_128_4_sum
I0521 09:36:45.632874  3675 net.cpp:395] last_bn -> layer_128_4_sum (in-place)
I0521 09:36:45.633065  3675 net.cpp:150] Setting up last_bn
I0521 09:36:45.633075  3675 net.cpp:157] Top shape: 128 512 4 16 (4194304)
I0521 09:36:45.633080  3675 net.cpp:165] Memory required for data: 1721789952
I0521 09:36:45.633087  3675 layer_factory.hpp:77] Creating layer last_scale
I0521 09:36:45.633095  3675 net.cpp:100] Creating Layer last_scale
I0521 09:36:45.633100  3675 net.cpp:434] last_scale <- layer_128_4_sum
I0521 09:36:45.633108  3675 net.cpp:395] last_scale -> layer_128_4_sum (in-place)
I0521 09:36:45.633142  3675 layer_factory.hpp:77] Creating layer last_scale
I0521 09:36:45.633246  3675 net.cpp:150] Setting up last_scale
I0521 09:36:45.633255  3675 net.cpp:157] Top shape: 128 512 4 16 (4194304)
I0521 09:36:45.633258  3675 net.cpp:165] Memory required for data: 1738567168
I0521 09:36:45.633265  3675 layer_factory.hpp:77] Creating layer last_relu
I0521 09:36:45.633272  3675 net.cpp:100] Creating Layer last_relu
I0521 09:36:45.633275  3675 net.cpp:434] last_relu <- layer_128_4_sum
I0521 09:36:45.633281  3675 net.cpp:395] last_relu -> layer_128_4_sum (in-place)
I0521 09:36:45.633649  3675 net.cpp:150] Setting up last_relu
I0521 09:36:45.633666  3675 net.cpp:157] Top shape: 128 512 4 16 (4194304)
I0521 09:36:45.633671  3675 net.cpp:165] Memory required for data: 1755344384
I0521 09:36:45.633675  3675 layer_factory.hpp:77] Creating layer dropout
I0521 09:36:45.633684  3675 net.cpp:100] Creating Layer dropout
I0521 09:36:45.633689  3675 net.cpp:434] dropout <- layer_128_4_sum
I0521 09:36:45.633695  3675 net.cpp:395] dropout -> layer_128_4_sum (in-place)
I0521 09:36:45.633734  3675 net.cpp:150] Setting up dropout
I0521 09:36:45.633743  3675 net.cpp:157] Top shape: 128 512 4 16 (4194304)
I0521 09:36:45.633745  3675 net.cpp:165] Memory required for data: 1772121600
I0521 09:36:45.633749  3675 layer_factory.hpp:77] Creating layer permuted_data
I0521 09:36:45.633765  3675 net.cpp:100] Creating Layer permuted_data
I0521 09:36:45.633800  3675 net.cpp:434] permuted_data <- layer_128_4_sum
I0521 09:36:45.633817  3675 net.cpp:408] permuted_data -> permuted_data
I0521 09:36:45.633929  3675 net.cpp:150] Setting up permuted_data
I0521 09:36:45.633939  3675 net.cpp:157] Top shape: 16 128 512 4 (4194304)
I0521 09:36:45.633944  3675 net.cpp:165] Memory required for data: 1788898816
I0521 09:36:45.633946  3675 layer_factory.hpp:77] Creating layer permuted_data_permuted_data_0_split
I0521 09:36:45.633954  3675 net.cpp:100] Creating Layer permuted_data_permuted_data_0_split
I0521 09:36:45.633957  3675 net.cpp:434] permuted_data_permuted_data_0_split <- permuted_data
I0521 09:36:45.633963  3675 net.cpp:408] permuted_data_permuted_data_0_split -> permuted_data_permuted_data_0_split_0
I0521 09:36:45.633970  3675 net.cpp:408] permuted_data_permuted_data_0_split -> permuted_data_permuted_data_0_split_1
I0521 09:36:45.634001  3675 net.cpp:150] Setting up permuted_data_permuted_data_0_split
I0521 09:36:45.634009  3675 net.cpp:157] Top shape: 16 128 512 4 (4194304)
I0521 09:36:45.634029  3675 net.cpp:157] Top shape: 16 128 512 4 (4194304)
I0521 09:36:45.634032  3675 net.cpp:165] Memory required for data: 1822453248
I0521 09:36:45.634037  3675 layer_factory.hpp:77] Creating layer lstm-reverse1
I0521 09:36:45.634044  3675 net.cpp:100] Creating Layer lstm-reverse1
I0521 09:36:45.634048  3675 net.cpp:434] lstm-reverse1 <- permuted_data_permuted_data_0_split_0
I0521 09:36:45.634054  3675 net.cpp:408] lstm-reverse1 -> rlstm_input
I0521 09:36:45.634074  3675 net.cpp:150] Setting up lstm-reverse1
I0521 09:36:45.634083  3675 net.cpp:157] Top shape: 16 128 512 4 (4194304)
I0521 09:36:45.634085  3675 net.cpp:165] Memory required for data: 1839230464
I0521 09:36:45.634089  3675 layer_factory.hpp:77] Creating layer lstm2x
I0521 09:36:45.634101  3675 net.cpp:100] Creating Layer lstm2x
I0521 09:36:45.634105  3675 net.cpp:434] lstm2x <- rlstm_input
I0521 09:36:45.634110  3675 net.cpp:434] lstm2x <- indicator_indicator_0_split_0
I0521 09:36:45.634115  3675 net.cpp:408] lstm2x -> lstm2x
I0521 09:36:45.634124  3675 recurrent_layer.cpp:20] Initializing recurrent layer: assuming input batch contains 16 timesteps of 128 independent streams.
I0521 09:36:45.634752  3675 net.cpp:58] Initializing net from parameters: 
layer {
  name: "lstm2x_"
  type: "Input"
  top: "x"
  top: "cont"
  input_param {
    shape {
      dim: 16
      dim: 128
      dim: 512
      dim: 4
    }
    shape {
      dim: 16
      dim: 128
    }
  }
}
layer {
  name: "lstm2x_"
  type: "Input"
  top: "c_0"
  top: "h_0"
  input_param {
    shape {
      dim: 1
      dim: 128
      dim: 100
    }
    shape {
      dim: 1
      dim: 128
      dim: 100
    }
  }
}
layer {
  name: "lstm2x_cont_slice"
  type: "Slice"
  bottom: "cont"
  top: "cont_1"
  top: "cont_2"
  top: "cont_3"
  top: "cont_4"
  top: "cont_5"
  top: "cont_6"
  top: "cont_7"
  top: "cont_8"
  top: "cont_9"
  top: "cont_10"
  top: "cont_11"
  top: "cont_12"
  top: "cont_13"
  top: "cont_14"
  top: "cont_15"
  top: "cont_16"
  slice_param {
    axis: 0
  }
}
layer {
  name: "lstm2x_x_transform"
  type: "InnerProduct"
  bottom: "x"
  top: "W_xc_x"
  param {
    name: "W_xc"
  }
  param {
    name: "b_c"
  }
  propagate_down: true
  inner_product_param {
    num_output: 400
    bias_term: true
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    axis: 2
  }
}
layer {
  name: "lstm2x_W_xc_x_slice"
  type: "Slice"
  bottom: "W_xc_x"
  top: "W_xc_x_1"
  top: "W_xc_x_2"
  top: "W_xc_x_3"
  top: "W_xc_x_4"
  top: "W_xc_x_5"
  top: "W_xc_x_6"
  top: "W_xc_x_7"
  top: "W_xc_x_8"
  top: "W_xc_x_9"
  top: "W_xc_x_10"
  top: "W_xc_x_11"
  top: "W_xc_x_12"
  top: "W_xc_x_13"
  top: "W_xc_x_14"
  top: "W_xc_x_15"
  top: "W_xc_x_16"
  slice_param {
    axis: 0
  }
}
layer {
  name: "lstm2x_h_conted_0"
  type: "Scale"
  bottom: "h_0"
  bottom: "cont_1"
  top: "h_conted_0"
  scale_param {
    axis: 0
  }
}
layer {
  name: "lstm2x_transform_1"
  type: "InnerProduct"
  bottom: "h_conted_0"
  top: "W_hc_h_0"
  param {
    name: "W_hc"
  }
  inner_product_param {
    num_output: 400
    bias_term: false
    weight_filler {
      type: "xavier"
    }
    axis: 2
  }
}
layer {
  name: "lstm2x_gate_input_1"
  type: "Eltwise"
  bottom: "W_hc_h_0"
  bottom: "W_xc_x_1"
  top: "gate_input_1"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "lstm2x_unit_1"
  type: "LSTMUnit"
  bottom: "c_0"
  bottom: "gate_input_1"
  bottom: "cont_1"
  top: "c_1"
  top: "h_1"
}
layer {
  name: "lstm2x_h_conted_1"
  type: "Scale"
  bottom: "h_1"
  bottom: "cont_2"
  top: "h_conted_1"
  scale_param {
    axis: 0
  }
}
layer {
  name: "lstm2x_transform_2"
  type: "InnerProduct"
  bottom: "h_conted_1"
  top: "W_hc_h_1"
  param {
    name: "W_hc"
  }
  inner_product_param {
    num_output: 400
    bias_term: false
    weight_filler {
      type: "xavier"
    }
    axis: 2
  }
}
layer {
  name: "lstm2x_gate_input_2"
  type: "Eltwise"
  bottom: "W_hc_h_1"
  bottom: "W_xc_x_2"
  top: "gate_input_2"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "lstm2x_unit_2"
  type: "LSTMUnit"
  bottom: "c_1"
  bottom: "gate_input_2"
  bottom: "cont_2"
  top: "c_2"
  top: "h_2"
}
layer {
  name: "lstm2x_h_conted_2"
  type: "Scale"
  bottom: "h_2"
  bottom: "cont_3"
  top: "h_conted_2"
  scale_param {
    axis: 0
  }
}
layer {
  name: "lstm2x_transform_3"
  type: "InnerProduct"
  bottom: "h_conted_2"
  top: "W_hc_h_2"
  param {
    name: "W_hc"
  }
  inner_product_param {
    num_output: 400
    bias_term: false
    weight_filler {
      type: "xavier"
    }
    axis: 2
  }
}
layer {
  name: "lstm2x_gate_input_3"
  type: "Eltwise"
  bottom: "W_hc_h_2"
  bottom: "W_xc_x_3"
  top: "gate_input_3"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "lstm2x_unit_3"
  type: "LSTMUnit"
  bottom: "c_2"
  bottom: "gate_input_3"
  bottom: "cont_3"
  top: "c_3"
  top: "h_3"
}
layer {
  name: "lstm2x_h_conted_3"
  type: "Scale"
  bottom: "h_3"
  bottom: "cont_4"
  top: "h_conted_3"
  scale_param {
    axis: 0
  }
}
layer {
  name: "lstm2x_transform_4"
  type: "InnerProduct"
  bottom: "h_conted_3"
  top: "W_hc_h_3"
  param {
    name: "W_hc"
  }
  inner_product_param {
    num_output: 400
    bias_term: false
    weight_filler {
      type: "xavier"
    }
    axis: 2
  }
}
layer {
  name: "lstm2x_gate_input_4"
  type: "Eltwise"
  bottom: "W_hc_h_3"
  bottom: "W_xc_x_4"
  top: "gate_input_4"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "lstm2x_unit_4"
  type: "LSTMUnit"
  bottom: "c_3"
  bottom: "gate_input_4"
  bottom: "cont_4"
  top: "c_4"
  top: "h_4"
}
layer {
  name: "lstm2x_h_conted_4"
  type: "Scale"
  bottom: "h_4"
  bottom: "cont_5"
  top: "h_conted_4"
  scale_param {
    axis: 0
  }
}
layer {
  name: "lstm2x_transform_5"
  type: "InnerProduct"
  bottom: "h_conted_4"
  top: "W_hc_h_4"
  param {
    name: "W_hc"
  }
  inner_product_param {
    num_output: 400
    bias_term: false
    weight_filler {
      type: "xavier"
    }
    axis: 2
  }
}
layer {
  name: "lstm2x_gate_input_5"
  type: "Eltwise"
  bottom: "W_hc_h_4"
  bottom: "W_xc_x_5"
  top: "gate_input_5"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "lstm2x_unit_5"
  type: "LSTMUnit"
  bottom: "c_4"
  bottom: "gate_input_5"
  bottom: "cont_5"
  top: "c_5"
  top: "h_5"
}
layer {
  name: "lstm2x_h_conted_5"
  type: "Scale"
  bottom: "h_5"
  bottom: "cont_6"
  top: "h_conted_5"
  scale_param {
    axis: 0
  }
}
layer {
  name: "lstm2x_transform_6"
  type: "InnerProduct"
  bottom: "h_conted_5"
  top: "W_hc_h_5"
  param {
    name: "W_hc"
  }
  inner_product_param {
    num_output: 400
    bias_term: false
    weight_filler {
      type: "xavier"
    }
    axis: 2
  }
}
layer {
  name: "lstm2x_gate_input_6"
  type: "Eltwise"
  bottom: "W_hc_h_5"
  bottom: "W_xc_x_6"
  top: "gate_input_6"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "lstm2x_unit_6"
  type: "LSTMUnit"
  bottom: "c_5"
  bottom: "gate_input_6"
  bottom: "cont_6"
  top: "c_6"
  top: "h_6"
}
layer {
  name: "lstm2x_h_conted_6"
  type: "Scale"
  bottom: "h_6"
  bottom: "cont_7"
  top: "h_conted_6"
  scale_param {
    axis: 0
  }
}
layer {
  name: "lstm2x_transform_7"
  type: "InnerProduct"
  bottom: "h_conted_6"
  top: "W_hc_h_6"
  param {
    name: "W_hc"
  }
  inner_product_param {
    num_output: 400
    bias_term: false
    weight_filler {
      type: "xavier"
    }
    axis: 2
  }
}
layer {
  name: "lstm2x_gate_input_7"
  type: "Eltwise"
  bottom: "W_hc_h_6"
  bottom: "W_xc_x_7"
  top: "gate_input_7"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "lstm2x_unit_7"
  type: "LSTMUnit"
  bottom: "c_6"
  bottom: "gate_input_7"
  bottom: "cont_7"
  top: "c_7"
  top: "h_7"
}
layer {
  name: "lstm2x_h_conted_7"
  type: "Scale"
  bottom: "h_7"
  bottom: "cont_8"
  top: "h_conted_7"
  scale_param {
    axis: 0
  }
}
layer {
  name: "lstm2x_transform_8"
  type: "InnerProduct"
  bottom: "h_conted_7"
  top: "W_hc_h_7"
  param {
    name: "W_hc"
  }
  inner_product_param {
    num_output: 400
    bias_term: false
    weight_filler {
      type: "xavier"
    }
    axis: 2
  }
}
layer {
  name: "lstm2x_gate_input_8"
  type: "Eltwise"
  bottom: "W_hc_h_7"
  bottom: "W_xc_x_8"
  top: "gate_input_8"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "lstm2x_unit_8"
  type: "LSTMUnit"
  bottom: "c_7"
  bottom: "gate_input_8"
  bottom: "cont_8"
  top: "c_8"
  top: "h_8"
}
layer {
  name: "lstm2x_h_conted_8"
  type: "Scale"
  bottom: "h_8"
  bottom: "cont_9"
  top: "h_conted_8"
  scale_param {
    axis: 0
  }
}
layer {
  name: "lstm2x_transform_9"
  type: "InnerProduct"
  bottom: "h_conted_8"
  top: "W_hc_h_8"
  param {
    name: "W_hc"
  }
  inner_product_param {
    num_output: 400
    bias_term: false
    weight_filler {
      type: "xavier"
    }
    axis: 2
  }
}
layer {
  name: "lstm2x_gate_input_9"
  type: "Eltwise"
  bottom: "W_hc_h_8"
  bottom: "W_xc_x_9"
  top: "gate_input_9"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "lstm2x_unit_9"
  type: "LSTMUnit"
  bottom: "c_8"
  bottom: "gate_input_9"
  bottom: "cont_9"
  top: "c_9"
  top: "h_9"
}
layer {
  name: "lstm2x_h_conted_9"
  type: "Scale"
  bottom: "h_9"
  bottom: "cont_10"
  top: "h_conted_9"
  scale_param {
    axis: 0
  }
}
layer {
  name: "lstm2x_transform_10"
  type: "InnerProduct"
  bottom: "h_conted_9"
  top: "W_hc_h_9"
  param {
    name: "W_hc"
  }
  inner_product_param {
    num_output: 400
    bias_term: false
    weight_filler {
      type: "xavier"
    }
    axis: 2
  }
}
layer {
  name: "lstm2x_gate_input_10"
  type: "Eltwise"
  bottom: "W_hc_h_9"
  bottom: "W_xc_x_10"
  top: "gate_input_10"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "lstm2x_unit_10"
  type: "LSTMUnit"
  bottom: "c_9"
  bottom: "gate_input_10"
  bottom: "cont_10"
  top: "c_10"
  top: "h_10"
}
layer {
  name: "lstm2x_h_conted_10"
  type: "Scale"
  bottom: "h_10"
  bottom: "cont_11"
  top: "h_conted_10"
  scale_param {
    axis: 0
  }
}
layer {
  name: "lstm2x_transform_11"
  type: "InnerProduct"
  bottom: "h_conted_10"
  top: "W_hc_h_10"
  param {
    name: "W_hc"
  }
  inner_product_param {
    num_output: 400
    bias_term: false
    weight_filler {
      type: "xavier"
    }
    axis: 2
  }
}
layer {
  name: "lstm2x_gate_input_11"
  type: "Eltwise"
  bottom: "W_hc_h_10"
  bottom: "W_xc_x_11"
  top: "gate_input_11"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "lstm2x_unit_11"
  type: "LSTMUnit"
  bottom: "c_10"
  bottom: "gate_input_11"
  bottom: "cont_11"
  top: "c_11"
  top: "h_11"
}
layer {
  name: "lstm2x_h_conted_11"
  type: "Scale"
  bottom: "h_11"
  bottom: "cont_12"
  top: "h_conted_11"
  scale_param {
    axis: 0
  }
}
layer {
  name: "lstm2x_transform_12"
  type: "InnerProduct"
  bottom: "h_conted_11"
  top: "W_hc_h_11"
  param {
    name: "W_hc"
  }
  inner_product_param {
    num_output: 400
    bias_term: false
    weight_filler {
      type: "xavier"
    }
    axis: 2
  }
}
layer {
  name: "lstm2x_gate_input_12"
  type: "Eltwise"
  bottom: "W_hc_h_11"
  bottom: "W_xc_x_12"
  top: "gate_input_12"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "lstm2x_unit_12"
  type: "LSTMUnit"
  bottom: "c_11"
  bottom: "gate_input_12"
  bottom: "cont_12"
  top: "c_12"
  top: "h_12"
}
layer {
  name: "lstm2x_h_conted_12"
  type: "Scale"
  bottom: "h_12"
  bottom: "cont_13"
  top: "h_conted_12"
  scale_param {
    axis: 0
  }
}
layer {
  name: "lstm2x_transform_13"
  type: "InnerProduct"
  bottom: "h_conted_12"
  top: "W_hc_h_12"
  param {
    name: "W_hc"
  }
  inner_product_param {
    num_output: 400
    bias_term: false
    weight_filler {
      type: "xavier"
    }
    axis: 2
  }
}
layer {
  name: "lstm2x_gate_input_13"
  type: "Eltwise"
  bottom: "W_hc_h_12"
  bottom: "W_xc_x_13"
  top: "gate_input_13"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "lstm2x_unit_13"
  type: "LSTMUnit"
  bottom: "c_12"
  bottom: "gate_input_13"
  bottom: "cont_13"
  top: "c_13"
  top: "h_13"
}
layer {
  name: "lstm2x_h_conted_13"
  type: "Scale"
  bottom: "h_13"
  bottom: "cont_14"
  top: "h_conted_13"
  scale_param {
    axis: 0
  }
}
layer {
  name: "lstm2x_transform_14"
  type: "InnerProduct"
  bottom: "h_conted_13"
  top: "W_hc_h_13"
  param {
    name: "W_hc"
  }
  inner_product_param {
    num_output: 400
    bias_term: false
    weight_filler {
      type: "xavier"
    }
    axis: 2
  }
}
layer {
  name: "lstm2x_gate_input_14"
  type: "Eltwise"
  bottom: "W_hc_h_13"
  bottom: "W_xc_x_14"
  top: "gate_input_14"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "lstm2x_unit_14"
  type: "LSTMUnit"
  bottom: "c_13"
  bottom: "gate_input_14"
  bottom: "cont_14"
  top: "c_14"
  top: "h_14"
}
layer {
  name: "lstm2x_h_conted_14"
  type: "Scale"
  bottom: "h_14"
  bottom: "cont_15"
  top: "h_conted_14"
  scale_param {
    axis: 0
  }
}
layer {
  name: "lstm2x_transform_15"
  type: "InnerProduct"
  bottom: "h_conted_14"
  top: "W_hc_h_14"
  param {
    name: "W_hc"
  }
  inner_product_param {
    num_output: 400
    bias_term: false
    weight_filler {
      type: "xavier"
    }
    axis: 2
  }
}
layer {
  name: "lstm2x_gate_input_15"
  type: "Eltwise"
  bottom: "W_hc_h_14"
  bottom: "W_xc_x_15"
  top: "gate_input_15"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "lstm2x_unit_15"
  type: "LSTMUnit"
  bottom: "c_14"
  bottom: "gate_input_15"
  bottom: "cont_15"
  top: "c_15"
  top: "h_15"
}
layer {
  name: "lstm2x_h_conted_15"
  type: "Scale"
  bottom: "h_15"
  bottom: "cont_16"
  top: "h_conted_15"
  scale_param {
    axis: 0
  }
}
layer {
  name: "lstm2x_transform_16"
  type: "InnerProduct"
  bottom: "h_conted_15"
  top: "W_hc_h_15"
  param {
    name: "W_hc"
  }
  inner_product_param {
    num_output: 400
    bias_term: false
    weight_filler {
      type: "xavier"
    }
    axis: 2
  }
}
layer {
  name: "lstm2x_gate_input_16"
  type: "Eltwise"
  bottom: "W_hc_h_15"
  bottom: "W_xc_x_16"
  top: "gate_input_16"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "lstm2x_unit_16"
  type: "LSTMUnit"
  bottom: "c_15"
  bottom: "gate_input_16"
  bottom: "cont_16"
  top: "c_16"
  top: "h_16"
}
layer {
  name: "lstm2x_"
  type: "Split"
  bottom: "c_16"
  top: "c_T"
}
layer {
  name: "lstm2x_h_concat"
  type: "Concat"
  bottom: "h_1"
  bottom: "h_2"
  bottom: "h_3"
  bottom: "h_4"
  bottom: "h_5"
  bottom: "h_6"
  bottom: "h_7"
  bottom: "h_8"
  bottom: "h_9"
  bottom: "h_10"
  bottom: "h_11"
  bottom: "h_12"
  bottom: "h_13"
  bottom: "h_14"
  bottom: "h_15"
  bottom: "h_16"
  top: "h"
  concat_param {
    axis: 0
  }
}
layer {
  name: "h_pseudoloss"
  type: "Reduction"
  bottom: "h"
  top: "h_pseudoloss"
  loss_weight: 1
}
I0521 09:36:45.635274  3675 layer_factory.hpp:77] Creating layer lstm2x_
I0521 09:36:45.635287  3675 net.cpp:100] Creating Layer lstm2x_
I0521 09:36:45.635293  3675 net.cpp:408] lstm2x_ -> x
I0521 09:36:45.635305  3675 net.cpp:408] lstm2x_ -> cont
I0521 09:36:45.635362  3675 net.cpp:150] Setting up lstm2x_
I0521 09:36:45.635370  3675 net.cpp:157] Top shape: 16 128 512 4 (4194304)
I0521 09:36:45.635373  3675 net.cpp:157] Top shape: 16 128 (2048)
I0521 09:36:45.635377  3675 net.cpp:165] Memory required for data: 16785408
I0521 09:36:45.635381  3675 layer_factory.hpp:77] Creating layer lstm2x_
I0521 09:36:45.635386  3675 net.cpp:100] Creating Layer lstm2x_
I0521 09:36:45.635391  3675 net.cpp:408] lstm2x_ -> c_0
I0521 09:36:45.635398  3675 net.cpp:408] lstm2x_ -> h_0
I0521 09:36:45.635443  3675 net.cpp:150] Setting up lstm2x_
I0521 09:36:45.635449  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.635453  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.635457  3675 net.cpp:165] Memory required for data: 16887808
I0521 09:36:45.635460  3675 layer_factory.hpp:77] Creating layer lstm2x_cont_slice
I0521 09:36:45.635474  3675 net.cpp:100] Creating Layer lstm2x_cont_slice
I0521 09:36:45.635478  3675 net.cpp:434] lstm2x_cont_slice <- cont
I0521 09:36:45.635484  3675 net.cpp:408] lstm2x_cont_slice -> cont_1
I0521 09:36:45.635493  3675 net.cpp:408] lstm2x_cont_slice -> cont_2
I0521 09:36:45.635499  3675 net.cpp:408] lstm2x_cont_slice -> cont_3
I0521 09:36:45.635505  3675 net.cpp:408] lstm2x_cont_slice -> cont_4
I0521 09:36:45.635511  3675 net.cpp:408] lstm2x_cont_slice -> cont_5
I0521 09:36:45.635530  3675 net.cpp:408] lstm2x_cont_slice -> cont_6
I0521 09:36:45.635536  3675 net.cpp:408] lstm2x_cont_slice -> cont_7
I0521 09:36:45.635542  3675 net.cpp:408] lstm2x_cont_slice -> cont_8
I0521 09:36:45.635548  3675 net.cpp:408] lstm2x_cont_slice -> cont_9
I0521 09:36:45.635553  3675 net.cpp:408] lstm2x_cont_slice -> cont_10
I0521 09:36:45.635560  3675 net.cpp:408] lstm2x_cont_slice -> cont_11
I0521 09:36:45.635565  3675 net.cpp:408] lstm2x_cont_slice -> cont_12
I0521 09:36:45.635571  3675 net.cpp:408] lstm2x_cont_slice -> cont_13
I0521 09:36:45.635579  3675 net.cpp:408] lstm2x_cont_slice -> cont_14
I0521 09:36:45.635584  3675 net.cpp:408] lstm2x_cont_slice -> cont_15
I0521 09:36:45.635591  3675 net.cpp:408] lstm2x_cont_slice -> cont_16
I0521 09:36:45.635794  3675 net.cpp:150] Setting up lstm2x_cont_slice
I0521 09:36:45.635802  3675 net.cpp:157] Top shape: 1 128 (128)
I0521 09:36:45.635805  3675 net.cpp:157] Top shape: 1 128 (128)
I0521 09:36:45.635809  3675 net.cpp:157] Top shape: 1 128 (128)
I0521 09:36:45.635813  3675 net.cpp:157] Top shape: 1 128 (128)
I0521 09:36:45.635818  3675 net.cpp:157] Top shape: 1 128 (128)
I0521 09:36:45.635821  3675 net.cpp:157] Top shape: 1 128 (128)
I0521 09:36:45.635825  3675 net.cpp:157] Top shape: 1 128 (128)
I0521 09:36:45.635829  3675 net.cpp:157] Top shape: 1 128 (128)
I0521 09:36:45.635833  3675 net.cpp:157] Top shape: 1 128 (128)
I0521 09:36:45.635836  3675 net.cpp:157] Top shape: 1 128 (128)
I0521 09:36:45.635840  3675 net.cpp:157] Top shape: 1 128 (128)
I0521 09:36:45.635844  3675 net.cpp:157] Top shape: 1 128 (128)
I0521 09:36:45.635848  3675 net.cpp:157] Top shape: 1 128 (128)
I0521 09:36:45.635852  3675 net.cpp:157] Top shape: 1 128 (128)
I0521 09:36:45.635856  3675 net.cpp:157] Top shape: 1 128 (128)
I0521 09:36:45.635860  3675 net.cpp:157] Top shape: 1 128 (128)
I0521 09:36:45.635864  3675 net.cpp:165] Memory required for data: 16896000
I0521 09:36:45.635867  3675 layer_factory.hpp:77] Creating layer cont_1_lstm2x_cont_slice_0_split
I0521 09:36:45.635876  3675 net.cpp:100] Creating Layer cont_1_lstm2x_cont_slice_0_split
I0521 09:36:45.635880  3675 net.cpp:434] cont_1_lstm2x_cont_slice_0_split <- cont_1
I0521 09:36:45.635886  3675 net.cpp:408] cont_1_lstm2x_cont_slice_0_split -> cont_1_lstm2x_cont_slice_0_split_0
I0521 09:36:45.635892  3675 net.cpp:408] cont_1_lstm2x_cont_slice_0_split -> cont_1_lstm2x_cont_slice_0_split_1
I0521 09:36:45.635928  3675 net.cpp:150] Setting up cont_1_lstm2x_cont_slice_0_split
I0521 09:36:45.635933  3675 net.cpp:157] Top shape: 1 128 (128)
I0521 09:36:45.635936  3675 net.cpp:157] Top shape: 1 128 (128)
I0521 09:36:45.635941  3675 net.cpp:165] Memory required for data: 16897024
I0521 09:36:45.635943  3675 layer_factory.hpp:77] Creating layer cont_2_lstm2x_cont_slice_1_split
I0521 09:36:45.635951  3675 net.cpp:100] Creating Layer cont_2_lstm2x_cont_slice_1_split
I0521 09:36:45.635954  3675 net.cpp:434] cont_2_lstm2x_cont_slice_1_split <- cont_2
I0521 09:36:45.635959  3675 net.cpp:408] cont_2_lstm2x_cont_slice_1_split -> cont_2_lstm2x_cont_slice_1_split_0
I0521 09:36:45.635965  3675 net.cpp:408] cont_2_lstm2x_cont_slice_1_split -> cont_2_lstm2x_cont_slice_1_split_1
I0521 09:36:45.635995  3675 net.cpp:150] Setting up cont_2_lstm2x_cont_slice_1_split
I0521 09:36:45.636000  3675 net.cpp:157] Top shape: 1 128 (128)
I0521 09:36:45.636004  3675 net.cpp:157] Top shape: 1 128 (128)
I0521 09:36:45.636008  3675 net.cpp:165] Memory required for data: 16898048
I0521 09:36:45.636011  3675 layer_factory.hpp:77] Creating layer cont_3_lstm2x_cont_slice_2_split
I0521 09:36:45.636018  3675 net.cpp:100] Creating Layer cont_3_lstm2x_cont_slice_2_split
I0521 09:36:45.636021  3675 net.cpp:434] cont_3_lstm2x_cont_slice_2_split <- cont_3
I0521 09:36:45.636027  3675 net.cpp:408] cont_3_lstm2x_cont_slice_2_split -> cont_3_lstm2x_cont_slice_2_split_0
I0521 09:36:45.636032  3675 net.cpp:408] cont_3_lstm2x_cont_slice_2_split -> cont_3_lstm2x_cont_slice_2_split_1
I0521 09:36:45.636061  3675 net.cpp:150] Setting up cont_3_lstm2x_cont_slice_2_split
I0521 09:36:45.636076  3675 net.cpp:157] Top shape: 1 128 (128)
I0521 09:36:45.636080  3675 net.cpp:157] Top shape: 1 128 (128)
I0521 09:36:45.636085  3675 net.cpp:165] Memory required for data: 16899072
I0521 09:36:45.636087  3675 layer_factory.hpp:77] Creating layer cont_4_lstm2x_cont_slice_3_split
I0521 09:36:45.636095  3675 net.cpp:100] Creating Layer cont_4_lstm2x_cont_slice_3_split
I0521 09:36:45.636097  3675 net.cpp:434] cont_4_lstm2x_cont_slice_3_split <- cont_4
I0521 09:36:45.636102  3675 net.cpp:408] cont_4_lstm2x_cont_slice_3_split -> cont_4_lstm2x_cont_slice_3_split_0
I0521 09:36:45.636108  3675 net.cpp:408] cont_4_lstm2x_cont_slice_3_split -> cont_4_lstm2x_cont_slice_3_split_1
I0521 09:36:45.636138  3675 net.cpp:150] Setting up cont_4_lstm2x_cont_slice_3_split
I0521 09:36:45.636142  3675 net.cpp:157] Top shape: 1 128 (128)
I0521 09:36:45.636147  3675 net.cpp:157] Top shape: 1 128 (128)
I0521 09:36:45.636149  3675 net.cpp:165] Memory required for data: 16900096
I0521 09:36:45.636152  3675 layer_factory.hpp:77] Creating layer cont_5_lstm2x_cont_slice_4_split
I0521 09:36:45.636158  3675 net.cpp:100] Creating Layer cont_5_lstm2x_cont_slice_4_split
I0521 09:36:45.636162  3675 net.cpp:434] cont_5_lstm2x_cont_slice_4_split <- cont_5
I0521 09:36:45.636166  3675 net.cpp:408] cont_5_lstm2x_cont_slice_4_split -> cont_5_lstm2x_cont_slice_4_split_0
I0521 09:36:45.636173  3675 net.cpp:408] cont_5_lstm2x_cont_slice_4_split -> cont_5_lstm2x_cont_slice_4_split_1
I0521 09:36:45.636201  3675 net.cpp:150] Setting up cont_5_lstm2x_cont_slice_4_split
I0521 09:36:45.636206  3675 net.cpp:157] Top shape: 1 128 (128)
I0521 09:36:45.636210  3675 net.cpp:157] Top shape: 1 128 (128)
I0521 09:36:45.636214  3675 net.cpp:165] Memory required for data: 16901120
I0521 09:36:45.636217  3675 layer_factory.hpp:77] Creating layer cont_6_lstm2x_cont_slice_5_split
I0521 09:36:45.636224  3675 net.cpp:100] Creating Layer cont_6_lstm2x_cont_slice_5_split
I0521 09:36:45.636226  3675 net.cpp:434] cont_6_lstm2x_cont_slice_5_split <- cont_6
I0521 09:36:45.636231  3675 net.cpp:408] cont_6_lstm2x_cont_slice_5_split -> cont_6_lstm2x_cont_slice_5_split_0
I0521 09:36:45.636237  3675 net.cpp:408] cont_6_lstm2x_cont_slice_5_split -> cont_6_lstm2x_cont_slice_5_split_1
I0521 09:36:45.636267  3675 net.cpp:150] Setting up cont_6_lstm2x_cont_slice_5_split
I0521 09:36:45.636274  3675 net.cpp:157] Top shape: 1 128 (128)
I0521 09:36:45.636278  3675 net.cpp:157] Top shape: 1 128 (128)
I0521 09:36:45.636281  3675 net.cpp:165] Memory required for data: 16902144
I0521 09:36:45.636286  3675 layer_factory.hpp:77] Creating layer cont_7_lstm2x_cont_slice_6_split
I0521 09:36:45.636291  3675 net.cpp:100] Creating Layer cont_7_lstm2x_cont_slice_6_split
I0521 09:36:45.636293  3675 net.cpp:434] cont_7_lstm2x_cont_slice_6_split <- cont_7
I0521 09:36:45.636301  3675 net.cpp:408] cont_7_lstm2x_cont_slice_6_split -> cont_7_lstm2x_cont_slice_6_split_0
I0521 09:36:45.636310  3675 net.cpp:408] cont_7_lstm2x_cont_slice_6_split -> cont_7_lstm2x_cont_slice_6_split_1
I0521 09:36:45.636338  3675 net.cpp:150] Setting up cont_7_lstm2x_cont_slice_6_split
I0521 09:36:45.636345  3675 net.cpp:157] Top shape: 1 128 (128)
I0521 09:36:45.636349  3675 net.cpp:157] Top shape: 1 128 (128)
I0521 09:36:45.636353  3675 net.cpp:165] Memory required for data: 16903168
I0521 09:36:45.636356  3675 layer_factory.hpp:77] Creating layer cont_8_lstm2x_cont_slice_7_split
I0521 09:36:45.636363  3675 net.cpp:100] Creating Layer cont_8_lstm2x_cont_slice_7_split
I0521 09:36:45.636366  3675 net.cpp:434] cont_8_lstm2x_cont_slice_7_split <- cont_8
I0521 09:36:45.636371  3675 net.cpp:408] cont_8_lstm2x_cont_slice_7_split -> cont_8_lstm2x_cont_slice_7_split_0
I0521 09:36:45.636376  3675 net.cpp:408] cont_8_lstm2x_cont_slice_7_split -> cont_8_lstm2x_cont_slice_7_split_1
I0521 09:36:45.636405  3675 net.cpp:150] Setting up cont_8_lstm2x_cont_slice_7_split
I0521 09:36:45.636409  3675 net.cpp:157] Top shape: 1 128 (128)
I0521 09:36:45.636413  3675 net.cpp:157] Top shape: 1 128 (128)
I0521 09:36:45.636416  3675 net.cpp:165] Memory required for data: 16904192
I0521 09:36:45.636430  3675 layer_factory.hpp:77] Creating layer cont_9_lstm2x_cont_slice_8_split
I0521 09:36:45.636435  3675 net.cpp:100] Creating Layer cont_9_lstm2x_cont_slice_8_split
I0521 09:36:45.636438  3675 net.cpp:434] cont_9_lstm2x_cont_slice_8_split <- cont_9
I0521 09:36:45.636443  3675 net.cpp:408] cont_9_lstm2x_cont_slice_8_split -> cont_9_lstm2x_cont_slice_8_split_0
I0521 09:36:45.636449  3675 net.cpp:408] cont_9_lstm2x_cont_slice_8_split -> cont_9_lstm2x_cont_slice_8_split_1
I0521 09:36:45.636477  3675 net.cpp:150] Setting up cont_9_lstm2x_cont_slice_8_split
I0521 09:36:45.636482  3675 net.cpp:157] Top shape: 1 128 (128)
I0521 09:36:45.636487  3675 net.cpp:157] Top shape: 1 128 (128)
I0521 09:36:45.636489  3675 net.cpp:165] Memory required for data: 16905216
I0521 09:36:45.636492  3675 layer_factory.hpp:77] Creating layer cont_10_lstm2x_cont_slice_9_split
I0521 09:36:45.636498  3675 net.cpp:100] Creating Layer cont_10_lstm2x_cont_slice_9_split
I0521 09:36:45.636502  3675 net.cpp:434] cont_10_lstm2x_cont_slice_9_split <- cont_10
I0521 09:36:45.636507  3675 net.cpp:408] cont_10_lstm2x_cont_slice_9_split -> cont_10_lstm2x_cont_slice_9_split_0
I0521 09:36:45.636512  3675 net.cpp:408] cont_10_lstm2x_cont_slice_9_split -> cont_10_lstm2x_cont_slice_9_split_1
I0521 09:36:45.636541  3675 net.cpp:150] Setting up cont_10_lstm2x_cont_slice_9_split
I0521 09:36:45.636545  3675 net.cpp:157] Top shape: 1 128 (128)
I0521 09:36:45.636549  3675 net.cpp:157] Top shape: 1 128 (128)
I0521 09:36:45.636552  3675 net.cpp:165] Memory required for data: 16906240
I0521 09:36:45.636556  3675 layer_factory.hpp:77] Creating layer cont_11_lstm2x_cont_slice_10_split
I0521 09:36:45.636561  3675 net.cpp:100] Creating Layer cont_11_lstm2x_cont_slice_10_split
I0521 09:36:45.636565  3675 net.cpp:434] cont_11_lstm2x_cont_slice_10_split <- cont_11
I0521 09:36:45.636570  3675 net.cpp:408] cont_11_lstm2x_cont_slice_10_split -> cont_11_lstm2x_cont_slice_10_split_0
I0521 09:36:45.636575  3675 net.cpp:408] cont_11_lstm2x_cont_slice_10_split -> cont_11_lstm2x_cont_slice_10_split_1
I0521 09:36:45.636605  3675 net.cpp:150] Setting up cont_11_lstm2x_cont_slice_10_split
I0521 09:36:45.636610  3675 net.cpp:157] Top shape: 1 128 (128)
I0521 09:36:45.636612  3675 net.cpp:157] Top shape: 1 128 (128)
I0521 09:36:45.636615  3675 net.cpp:165] Memory required for data: 16907264
I0521 09:36:45.636620  3675 layer_factory.hpp:77] Creating layer cont_12_lstm2x_cont_slice_11_split
I0521 09:36:45.636626  3675 net.cpp:100] Creating Layer cont_12_lstm2x_cont_slice_11_split
I0521 09:36:45.636628  3675 net.cpp:434] cont_12_lstm2x_cont_slice_11_split <- cont_12
I0521 09:36:45.636633  3675 net.cpp:408] cont_12_lstm2x_cont_slice_11_split -> cont_12_lstm2x_cont_slice_11_split_0
I0521 09:36:45.636639  3675 net.cpp:408] cont_12_lstm2x_cont_slice_11_split -> cont_12_lstm2x_cont_slice_11_split_1
I0521 09:36:45.636667  3675 net.cpp:150] Setting up cont_12_lstm2x_cont_slice_11_split
I0521 09:36:45.636672  3675 net.cpp:157] Top shape: 1 128 (128)
I0521 09:36:45.636675  3675 net.cpp:157] Top shape: 1 128 (128)
I0521 09:36:45.636678  3675 net.cpp:165] Memory required for data: 16908288
I0521 09:36:45.636682  3675 layer_factory.hpp:77] Creating layer cont_13_lstm2x_cont_slice_12_split
I0521 09:36:45.636687  3675 net.cpp:100] Creating Layer cont_13_lstm2x_cont_slice_12_split
I0521 09:36:45.636689  3675 net.cpp:434] cont_13_lstm2x_cont_slice_12_split <- cont_13
I0521 09:36:45.636694  3675 net.cpp:408] cont_13_lstm2x_cont_slice_12_split -> cont_13_lstm2x_cont_slice_12_split_0
I0521 09:36:45.636699  3675 net.cpp:408] cont_13_lstm2x_cont_slice_12_split -> cont_13_lstm2x_cont_slice_12_split_1
I0521 09:36:45.636728  3675 net.cpp:150] Setting up cont_13_lstm2x_cont_slice_12_split
I0521 09:36:45.636732  3675 net.cpp:157] Top shape: 1 128 (128)
I0521 09:36:45.636736  3675 net.cpp:157] Top shape: 1 128 (128)
I0521 09:36:45.636739  3675 net.cpp:165] Memory required for data: 16909312
I0521 09:36:45.636742  3675 layer_factory.hpp:77] Creating layer cont_14_lstm2x_cont_slice_13_split
I0521 09:36:45.636757  3675 net.cpp:100] Creating Layer cont_14_lstm2x_cont_slice_13_split
I0521 09:36:45.636761  3675 net.cpp:434] cont_14_lstm2x_cont_slice_13_split <- cont_14
I0521 09:36:45.636767  3675 net.cpp:408] cont_14_lstm2x_cont_slice_13_split -> cont_14_lstm2x_cont_slice_13_split_0
I0521 09:36:45.636773  3675 net.cpp:408] cont_14_lstm2x_cont_slice_13_split -> cont_14_lstm2x_cont_slice_13_split_1
I0521 09:36:45.636813  3675 net.cpp:150] Setting up cont_14_lstm2x_cont_slice_13_split
I0521 09:36:45.636819  3675 net.cpp:157] Top shape: 1 128 (128)
I0521 09:36:45.636822  3675 net.cpp:157] Top shape: 1 128 (128)
I0521 09:36:45.636826  3675 net.cpp:165] Memory required for data: 16910336
I0521 09:36:45.636828  3675 layer_factory.hpp:77] Creating layer cont_15_lstm2x_cont_slice_14_split
I0521 09:36:45.636834  3675 net.cpp:100] Creating Layer cont_15_lstm2x_cont_slice_14_split
I0521 09:36:45.636837  3675 net.cpp:434] cont_15_lstm2x_cont_slice_14_split <- cont_15
I0521 09:36:45.636842  3675 net.cpp:408] cont_15_lstm2x_cont_slice_14_split -> cont_15_lstm2x_cont_slice_14_split_0
I0521 09:36:45.636847  3675 net.cpp:408] cont_15_lstm2x_cont_slice_14_split -> cont_15_lstm2x_cont_slice_14_split_1
I0521 09:36:45.636878  3675 net.cpp:150] Setting up cont_15_lstm2x_cont_slice_14_split
I0521 09:36:45.636881  3675 net.cpp:157] Top shape: 1 128 (128)
I0521 09:36:45.636885  3675 net.cpp:157] Top shape: 1 128 (128)
I0521 09:36:45.636888  3675 net.cpp:165] Memory required for data: 16911360
I0521 09:36:45.636893  3675 layer_factory.hpp:77] Creating layer cont_16_lstm2x_cont_slice_15_split
I0521 09:36:45.636896  3675 net.cpp:100] Creating Layer cont_16_lstm2x_cont_slice_15_split
I0521 09:36:45.636900  3675 net.cpp:434] cont_16_lstm2x_cont_slice_15_split <- cont_16
I0521 09:36:45.636905  3675 net.cpp:408] cont_16_lstm2x_cont_slice_15_split -> cont_16_lstm2x_cont_slice_15_split_0
I0521 09:36:45.636911  3675 net.cpp:408] cont_16_lstm2x_cont_slice_15_split -> cont_16_lstm2x_cont_slice_15_split_1
I0521 09:36:45.636940  3675 net.cpp:150] Setting up cont_16_lstm2x_cont_slice_15_split
I0521 09:36:45.636945  3675 net.cpp:157] Top shape: 1 128 (128)
I0521 09:36:45.636947  3675 net.cpp:157] Top shape: 1 128 (128)
I0521 09:36:45.636950  3675 net.cpp:165] Memory required for data: 16912384
I0521 09:36:45.636955  3675 layer_factory.hpp:77] Creating layer lstm2x_x_transform
I0521 09:36:45.636961  3675 net.cpp:100] Creating Layer lstm2x_x_transform
I0521 09:36:45.636965  3675 net.cpp:434] lstm2x_x_transform <- x
I0521 09:36:45.636970  3675 net.cpp:408] lstm2x_x_transform -> W_xc_x
I0521 09:36:45.644474  3675 net.cpp:150] Setting up lstm2x_x_transform
I0521 09:36:45.644506  3675 net.cpp:157] Top shape: 16 128 400 (819200)
I0521 09:36:45.644510  3675 net.cpp:165] Memory required for data: 20189184
I0521 09:36:45.644526  3675 layer_factory.hpp:77] Creating layer lstm2x_W_xc_x_slice
I0521 09:36:45.644539  3675 net.cpp:100] Creating Layer lstm2x_W_xc_x_slice
I0521 09:36:45.644544  3675 net.cpp:434] lstm2x_W_xc_x_slice <- W_xc_x
I0521 09:36:45.644552  3675 net.cpp:408] lstm2x_W_xc_x_slice -> W_xc_x_1
I0521 09:36:45.644562  3675 net.cpp:408] lstm2x_W_xc_x_slice -> W_xc_x_2
I0521 09:36:45.644569  3675 net.cpp:408] lstm2x_W_xc_x_slice -> W_xc_x_3
I0521 09:36:45.644575  3675 net.cpp:408] lstm2x_W_xc_x_slice -> W_xc_x_4
I0521 09:36:45.644582  3675 net.cpp:408] lstm2x_W_xc_x_slice -> W_xc_x_5
I0521 09:36:45.644588  3675 net.cpp:408] lstm2x_W_xc_x_slice -> W_xc_x_6
I0521 09:36:45.644594  3675 net.cpp:408] lstm2x_W_xc_x_slice -> W_xc_x_7
I0521 09:36:45.644600  3675 net.cpp:408] lstm2x_W_xc_x_slice -> W_xc_x_8
I0521 09:36:45.644606  3675 net.cpp:408] lstm2x_W_xc_x_slice -> W_xc_x_9
I0521 09:36:45.644613  3675 net.cpp:408] lstm2x_W_xc_x_slice -> W_xc_x_10
I0521 09:36:45.644618  3675 net.cpp:408] lstm2x_W_xc_x_slice -> W_xc_x_11
I0521 09:36:45.644624  3675 net.cpp:408] lstm2x_W_xc_x_slice -> W_xc_x_12
I0521 09:36:45.644634  3675 net.cpp:408] lstm2x_W_xc_x_slice -> W_xc_x_13
I0521 09:36:45.644639  3675 net.cpp:408] lstm2x_W_xc_x_slice -> W_xc_x_14
I0521 09:36:45.644645  3675 net.cpp:408] lstm2x_W_xc_x_slice -> W_xc_x_15
I0521 09:36:45.644675  3675 net.cpp:408] lstm2x_W_xc_x_slice -> W_xc_x_16
I0521 09:36:45.644906  3675 net.cpp:150] Setting up lstm2x_W_xc_x_slice
I0521 09:36:45.644917  3675 net.cpp:157] Top shape: 1 128 400 (51200)
I0521 09:36:45.644920  3675 net.cpp:157] Top shape: 1 128 400 (51200)
I0521 09:36:45.644924  3675 net.cpp:157] Top shape: 1 128 400 (51200)
I0521 09:36:45.644929  3675 net.cpp:157] Top shape: 1 128 400 (51200)
I0521 09:36:45.644933  3675 net.cpp:157] Top shape: 1 128 400 (51200)
I0521 09:36:45.644937  3675 net.cpp:157] Top shape: 1 128 400 (51200)
I0521 09:36:45.644942  3675 net.cpp:157] Top shape: 1 128 400 (51200)
I0521 09:36:45.644945  3675 net.cpp:157] Top shape: 1 128 400 (51200)
I0521 09:36:45.644949  3675 net.cpp:157] Top shape: 1 128 400 (51200)
I0521 09:36:45.644953  3675 net.cpp:157] Top shape: 1 128 400 (51200)
I0521 09:36:45.644958  3675 net.cpp:157] Top shape: 1 128 400 (51200)
I0521 09:36:45.644963  3675 net.cpp:157] Top shape: 1 128 400 (51200)
I0521 09:36:45.644966  3675 net.cpp:157] Top shape: 1 128 400 (51200)
I0521 09:36:45.644970  3675 net.cpp:157] Top shape: 1 128 400 (51200)
I0521 09:36:45.644975  3675 net.cpp:157] Top shape: 1 128 400 (51200)
I0521 09:36:45.644979  3675 net.cpp:157] Top shape: 1 128 400 (51200)
I0521 09:36:45.644982  3675 net.cpp:165] Memory required for data: 23465984
I0521 09:36:45.644986  3675 layer_factory.hpp:77] Creating layer lstm2x_h_conted_0
I0521 09:36:45.644994  3675 net.cpp:100] Creating Layer lstm2x_h_conted_0
I0521 09:36:45.644999  3675 net.cpp:434] lstm2x_h_conted_0 <- h_0
I0521 09:36:45.645005  3675 net.cpp:434] lstm2x_h_conted_0 <- cont_1_lstm2x_cont_slice_0_split_0
I0521 09:36:45.645011  3675 net.cpp:408] lstm2x_h_conted_0 -> h_conted_0
I0521 09:36:45.645087  3675 net.cpp:150] Setting up lstm2x_h_conted_0
I0521 09:36:45.645092  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.645095  3675 net.cpp:165] Memory required for data: 23517184
I0521 09:36:45.645099  3675 layer_factory.hpp:77] Creating layer lstm2x_transform_1
I0521 09:36:45.645107  3675 net.cpp:100] Creating Layer lstm2x_transform_1
I0521 09:36:45.645110  3675 net.cpp:434] lstm2x_transform_1 <- h_conted_0
I0521 09:36:45.645117  3675 net.cpp:408] lstm2x_transform_1 -> W_hc_h_0
I0521 09:36:45.645527  3675 net.cpp:150] Setting up lstm2x_transform_1
I0521 09:36:45.645537  3675 net.cpp:157] Top shape: 1 128 400 (51200)
I0521 09:36:45.645541  3675 net.cpp:165] Memory required for data: 23721984
I0521 09:36:45.645548  3675 layer_factory.hpp:77] Creating layer lstm2x_gate_input_1
I0521 09:36:45.645555  3675 net.cpp:100] Creating Layer lstm2x_gate_input_1
I0521 09:36:45.645560  3675 net.cpp:434] lstm2x_gate_input_1 <- W_hc_h_0
I0521 09:36:45.645565  3675 net.cpp:434] lstm2x_gate_input_1 <- W_xc_x_1
I0521 09:36:45.645570  3675 net.cpp:408] lstm2x_gate_input_1 -> gate_input_1
I0521 09:36:45.645596  3675 net.cpp:150] Setting up lstm2x_gate_input_1
I0521 09:36:45.645601  3675 net.cpp:157] Top shape: 1 128 400 (51200)
I0521 09:36:45.645604  3675 net.cpp:165] Memory required for data: 23926784
I0521 09:36:45.645607  3675 layer_factory.hpp:77] Creating layer lstm2x_unit_1
I0521 09:36:45.645613  3675 net.cpp:100] Creating Layer lstm2x_unit_1
I0521 09:36:45.645617  3675 net.cpp:434] lstm2x_unit_1 <- c_0
I0521 09:36:45.645622  3675 net.cpp:434] lstm2x_unit_1 <- gate_input_1
I0521 09:36:45.645627  3675 net.cpp:434] lstm2x_unit_1 <- cont_1_lstm2x_cont_slice_0_split_1
I0521 09:36:45.645632  3675 net.cpp:408] lstm2x_unit_1 -> c_1
I0521 09:36:45.645637  3675 net.cpp:408] lstm2x_unit_1 -> h_1
I0521 09:36:45.645682  3675 net.cpp:150] Setting up lstm2x_unit_1
I0521 09:36:45.645687  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.645691  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.645694  3675 net.cpp:165] Memory required for data: 24029184
I0521 09:36:45.645699  3675 layer_factory.hpp:77] Creating layer h_1_lstm2x_unit_1_1_split
I0521 09:36:45.645704  3675 net.cpp:100] Creating Layer h_1_lstm2x_unit_1_1_split
I0521 09:36:45.645725  3675 net.cpp:434] h_1_lstm2x_unit_1_1_split <- h_1
I0521 09:36:45.645731  3675 net.cpp:408] h_1_lstm2x_unit_1_1_split -> h_1_lstm2x_unit_1_1_split_0
I0521 09:36:45.645738  3675 net.cpp:408] h_1_lstm2x_unit_1_1_split -> h_1_lstm2x_unit_1_1_split_1
I0521 09:36:45.645767  3675 net.cpp:150] Setting up h_1_lstm2x_unit_1_1_split
I0521 09:36:45.645772  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.645776  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.645779  3675 net.cpp:165] Memory required for data: 24131584
I0521 09:36:45.645784  3675 layer_factory.hpp:77] Creating layer lstm2x_h_conted_1
I0521 09:36:45.645792  3675 net.cpp:100] Creating Layer lstm2x_h_conted_1
I0521 09:36:45.645795  3675 net.cpp:434] lstm2x_h_conted_1 <- h_1_lstm2x_unit_1_1_split_0
I0521 09:36:45.645800  3675 net.cpp:434] lstm2x_h_conted_1 <- cont_2_lstm2x_cont_slice_1_split_0
I0521 09:36:45.645807  3675 net.cpp:408] lstm2x_h_conted_1 -> h_conted_1
I0521 09:36:45.645867  3675 net.cpp:150] Setting up lstm2x_h_conted_1
I0521 09:36:45.645872  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.645875  3675 net.cpp:165] Memory required for data: 24182784
I0521 09:36:45.645879  3675 layer_factory.hpp:77] Creating layer lstm2x_transform_2
I0521 09:36:45.645886  3675 net.cpp:100] Creating Layer lstm2x_transform_2
I0521 09:36:45.645889  3675 net.cpp:434] lstm2x_transform_2 <- h_conted_1
I0521 09:36:45.645895  3675 net.cpp:408] lstm2x_transform_2 -> W_hc_h_1
I0521 09:36:45.646265  3675 net.cpp:150] Setting up lstm2x_transform_2
I0521 09:36:45.646281  3675 net.cpp:157] Top shape: 1 128 400 (51200)
I0521 09:36:45.646283  3675 net.cpp:165] Memory required for data: 24387584
I0521 09:36:45.646289  3675 net.cpp:493] Sharing parameters 'W_hc' owned by layer 'lstm2x_transform_1', param index 0
I0521 09:36:45.646293  3675 layer_factory.hpp:77] Creating layer lstm2x_gate_input_2
I0521 09:36:45.646301  3675 net.cpp:100] Creating Layer lstm2x_gate_input_2
I0521 09:36:45.646306  3675 net.cpp:434] lstm2x_gate_input_2 <- W_hc_h_1
I0521 09:36:45.646311  3675 net.cpp:434] lstm2x_gate_input_2 <- W_xc_x_2
I0521 09:36:45.646317  3675 net.cpp:408] lstm2x_gate_input_2 -> gate_input_2
I0521 09:36:45.646342  3675 net.cpp:150] Setting up lstm2x_gate_input_2
I0521 09:36:45.646347  3675 net.cpp:157] Top shape: 1 128 400 (51200)
I0521 09:36:45.646349  3675 net.cpp:165] Memory required for data: 24592384
I0521 09:36:45.646353  3675 layer_factory.hpp:77] Creating layer lstm2x_unit_2
I0521 09:36:45.646360  3675 net.cpp:100] Creating Layer lstm2x_unit_2
I0521 09:36:45.646364  3675 net.cpp:434] lstm2x_unit_2 <- c_1
I0521 09:36:45.646368  3675 net.cpp:434] lstm2x_unit_2 <- gate_input_2
I0521 09:36:45.646373  3675 net.cpp:434] lstm2x_unit_2 <- cont_2_lstm2x_cont_slice_1_split_1
I0521 09:36:45.646378  3675 net.cpp:408] lstm2x_unit_2 -> c_2
I0521 09:36:45.646384  3675 net.cpp:408] lstm2x_unit_2 -> h_2
I0521 09:36:45.646426  3675 net.cpp:150] Setting up lstm2x_unit_2
I0521 09:36:45.646431  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.646435  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.646438  3675 net.cpp:165] Memory required for data: 24694784
I0521 09:36:45.646442  3675 layer_factory.hpp:77] Creating layer h_2_lstm2x_unit_2_1_split
I0521 09:36:45.646448  3675 net.cpp:100] Creating Layer h_2_lstm2x_unit_2_1_split
I0521 09:36:45.646451  3675 net.cpp:434] h_2_lstm2x_unit_2_1_split <- h_2
I0521 09:36:45.646457  3675 net.cpp:408] h_2_lstm2x_unit_2_1_split -> h_2_lstm2x_unit_2_1_split_0
I0521 09:36:45.646464  3675 net.cpp:408] h_2_lstm2x_unit_2_1_split -> h_2_lstm2x_unit_2_1_split_1
I0521 09:36:45.646494  3675 net.cpp:150] Setting up h_2_lstm2x_unit_2_1_split
I0521 09:36:45.646499  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.646503  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.646507  3675 net.cpp:165] Memory required for data: 24797184
I0521 09:36:45.646509  3675 layer_factory.hpp:77] Creating layer lstm2x_h_conted_2
I0521 09:36:45.646517  3675 net.cpp:100] Creating Layer lstm2x_h_conted_2
I0521 09:36:45.646533  3675 net.cpp:434] lstm2x_h_conted_2 <- h_2_lstm2x_unit_2_1_split_0
I0521 09:36:45.646538  3675 net.cpp:434] lstm2x_h_conted_2 <- cont_3_lstm2x_cont_slice_2_split_0
I0521 09:36:45.646543  3675 net.cpp:408] lstm2x_h_conted_2 -> h_conted_2
I0521 09:36:45.646601  3675 net.cpp:150] Setting up lstm2x_h_conted_2
I0521 09:36:45.646607  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.646610  3675 net.cpp:165] Memory required for data: 24848384
I0521 09:36:45.646615  3675 layer_factory.hpp:77] Creating layer lstm2x_transform_3
I0521 09:36:45.646625  3675 net.cpp:100] Creating Layer lstm2x_transform_3
I0521 09:36:45.646628  3675 net.cpp:434] lstm2x_transform_3 <- h_conted_2
I0521 09:36:45.646633  3675 net.cpp:408] lstm2x_transform_3 -> W_hc_h_2
I0521 09:36:45.647034  3675 net.cpp:150] Setting up lstm2x_transform_3
I0521 09:36:45.647043  3675 net.cpp:157] Top shape: 1 128 400 (51200)
I0521 09:36:45.647047  3675 net.cpp:165] Memory required for data: 25053184
I0521 09:36:45.647051  3675 net.cpp:493] Sharing parameters 'W_hc' owned by layer 'lstm2x_transform_1', param index 0
I0521 09:36:45.647056  3675 layer_factory.hpp:77] Creating layer lstm2x_gate_input_3
I0521 09:36:45.647063  3675 net.cpp:100] Creating Layer lstm2x_gate_input_3
I0521 09:36:45.647066  3675 net.cpp:434] lstm2x_gate_input_3 <- W_hc_h_2
I0521 09:36:45.647070  3675 net.cpp:434] lstm2x_gate_input_3 <- W_xc_x_3
I0521 09:36:45.647076  3675 net.cpp:408] lstm2x_gate_input_3 -> gate_input_3
I0521 09:36:45.647101  3675 net.cpp:150] Setting up lstm2x_gate_input_3
I0521 09:36:45.647106  3675 net.cpp:157] Top shape: 1 128 400 (51200)
I0521 09:36:45.647109  3675 net.cpp:165] Memory required for data: 25257984
I0521 09:36:45.647112  3675 layer_factory.hpp:77] Creating layer lstm2x_unit_3
I0521 09:36:45.647119  3675 net.cpp:100] Creating Layer lstm2x_unit_3
I0521 09:36:45.647122  3675 net.cpp:434] lstm2x_unit_3 <- c_2
I0521 09:36:45.647126  3675 net.cpp:434] lstm2x_unit_3 <- gate_input_3
I0521 09:36:45.647130  3675 net.cpp:434] lstm2x_unit_3 <- cont_3_lstm2x_cont_slice_2_split_1
I0521 09:36:45.647135  3675 net.cpp:408] lstm2x_unit_3 -> c_3
I0521 09:36:45.647145  3675 net.cpp:408] lstm2x_unit_3 -> h_3
I0521 09:36:45.647186  3675 net.cpp:150] Setting up lstm2x_unit_3
I0521 09:36:45.647192  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.647195  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.647198  3675 net.cpp:165] Memory required for data: 25360384
I0521 09:36:45.647202  3675 layer_factory.hpp:77] Creating layer h_3_lstm2x_unit_3_1_split
I0521 09:36:45.647207  3675 net.cpp:100] Creating Layer h_3_lstm2x_unit_3_1_split
I0521 09:36:45.647210  3675 net.cpp:434] h_3_lstm2x_unit_3_1_split <- h_3
I0521 09:36:45.647215  3675 net.cpp:408] h_3_lstm2x_unit_3_1_split -> h_3_lstm2x_unit_3_1_split_0
I0521 09:36:45.647222  3675 net.cpp:408] h_3_lstm2x_unit_3_1_split -> h_3_lstm2x_unit_3_1_split_1
I0521 09:36:45.647253  3675 net.cpp:150] Setting up h_3_lstm2x_unit_3_1_split
I0521 09:36:45.647258  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.647262  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.647265  3675 net.cpp:165] Memory required for data: 25462784
I0521 09:36:45.647269  3675 layer_factory.hpp:77] Creating layer lstm2x_h_conted_3
I0521 09:36:45.647276  3675 net.cpp:100] Creating Layer lstm2x_h_conted_3
I0521 09:36:45.647279  3675 net.cpp:434] lstm2x_h_conted_3 <- h_3_lstm2x_unit_3_1_split_0
I0521 09:36:45.647284  3675 net.cpp:434] lstm2x_h_conted_3 <- cont_4_lstm2x_cont_slice_3_split_0
I0521 09:36:45.647289  3675 net.cpp:408] lstm2x_h_conted_3 -> h_conted_3
I0521 09:36:45.647344  3675 net.cpp:150] Setting up lstm2x_h_conted_3
I0521 09:36:45.647349  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.647352  3675 net.cpp:165] Memory required for data: 25513984
I0521 09:36:45.647356  3675 layer_factory.hpp:77] Creating layer lstm2x_transform_4
I0521 09:36:45.647364  3675 net.cpp:100] Creating Layer lstm2x_transform_4
I0521 09:36:45.647367  3675 net.cpp:434] lstm2x_transform_4 <- h_conted_3
I0521 09:36:45.647384  3675 net.cpp:408] lstm2x_transform_4 -> W_hc_h_3
I0521 09:36:45.647748  3675 net.cpp:150] Setting up lstm2x_transform_4
I0521 09:36:45.647763  3675 net.cpp:157] Top shape: 1 128 400 (51200)
I0521 09:36:45.647766  3675 net.cpp:165] Memory required for data: 25718784
I0521 09:36:45.647771  3675 net.cpp:493] Sharing parameters 'W_hc' owned by layer 'lstm2x_transform_1', param index 0
I0521 09:36:45.647775  3675 layer_factory.hpp:77] Creating layer lstm2x_gate_input_4
I0521 09:36:45.647783  3675 net.cpp:100] Creating Layer lstm2x_gate_input_4
I0521 09:36:45.647788  3675 net.cpp:434] lstm2x_gate_input_4 <- W_hc_h_3
I0521 09:36:45.647792  3675 net.cpp:434] lstm2x_gate_input_4 <- W_xc_x_4
I0521 09:36:45.647797  3675 net.cpp:408] lstm2x_gate_input_4 -> gate_input_4
I0521 09:36:45.647823  3675 net.cpp:150] Setting up lstm2x_gate_input_4
I0521 09:36:45.647828  3675 net.cpp:157] Top shape: 1 128 400 (51200)
I0521 09:36:45.647831  3675 net.cpp:165] Memory required for data: 25923584
I0521 09:36:45.647835  3675 layer_factory.hpp:77] Creating layer lstm2x_unit_4
I0521 09:36:45.647840  3675 net.cpp:100] Creating Layer lstm2x_unit_4
I0521 09:36:45.647843  3675 net.cpp:434] lstm2x_unit_4 <- c_3
I0521 09:36:45.647847  3675 net.cpp:434] lstm2x_unit_4 <- gate_input_4
I0521 09:36:45.647852  3675 net.cpp:434] lstm2x_unit_4 <- cont_4_lstm2x_cont_slice_3_split_1
I0521 09:36:45.647858  3675 net.cpp:408] lstm2x_unit_4 -> c_4
I0521 09:36:45.647864  3675 net.cpp:408] lstm2x_unit_4 -> h_4
I0521 09:36:45.647907  3675 net.cpp:150] Setting up lstm2x_unit_4
I0521 09:36:45.647910  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.647915  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.647918  3675 net.cpp:165] Memory required for data: 26025984
I0521 09:36:45.647922  3675 layer_factory.hpp:77] Creating layer h_4_lstm2x_unit_4_1_split
I0521 09:36:45.647927  3675 net.cpp:100] Creating Layer h_4_lstm2x_unit_4_1_split
I0521 09:36:45.647930  3675 net.cpp:434] h_4_lstm2x_unit_4_1_split <- h_4
I0521 09:36:45.647935  3675 net.cpp:408] h_4_lstm2x_unit_4_1_split -> h_4_lstm2x_unit_4_1_split_0
I0521 09:36:45.647943  3675 net.cpp:408] h_4_lstm2x_unit_4_1_split -> h_4_lstm2x_unit_4_1_split_1
I0521 09:36:45.647971  3675 net.cpp:150] Setting up h_4_lstm2x_unit_4_1_split
I0521 09:36:45.647976  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.647980  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.647984  3675 net.cpp:165] Memory required for data: 26128384
I0521 09:36:45.647987  3675 layer_factory.hpp:77] Creating layer lstm2x_h_conted_4
I0521 09:36:45.648000  3675 net.cpp:100] Creating Layer lstm2x_h_conted_4
I0521 09:36:45.648005  3675 net.cpp:434] lstm2x_h_conted_4 <- h_4_lstm2x_unit_4_1_split_0
I0521 09:36:45.648010  3675 net.cpp:434] lstm2x_h_conted_4 <- cont_5_lstm2x_cont_slice_4_split_0
I0521 09:36:45.648015  3675 net.cpp:408] lstm2x_h_conted_4 -> h_conted_4
I0521 09:36:45.648072  3675 net.cpp:150] Setting up lstm2x_h_conted_4
I0521 09:36:45.648077  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.648082  3675 net.cpp:165] Memory required for data: 26179584
I0521 09:36:45.648084  3675 layer_factory.hpp:77] Creating layer lstm2x_transform_5
I0521 09:36:45.648092  3675 net.cpp:100] Creating Layer lstm2x_transform_5
I0521 09:36:45.648095  3675 net.cpp:434] lstm2x_transform_5 <- h_conted_4
I0521 09:36:45.648102  3675 net.cpp:408] lstm2x_transform_5 -> W_hc_h_4
I0521 09:36:45.648499  3675 net.cpp:150] Setting up lstm2x_transform_5
I0521 09:36:45.648509  3675 net.cpp:157] Top shape: 1 128 400 (51200)
I0521 09:36:45.648514  3675 net.cpp:165] Memory required for data: 26384384
I0521 09:36:45.648517  3675 net.cpp:493] Sharing parameters 'W_hc' owned by layer 'lstm2x_transform_1', param index 0
I0521 09:36:45.648521  3675 layer_factory.hpp:77] Creating layer lstm2x_gate_input_5
I0521 09:36:45.648530  3675 net.cpp:100] Creating Layer lstm2x_gate_input_5
I0521 09:36:45.648533  3675 net.cpp:434] lstm2x_gate_input_5 <- W_hc_h_4
I0521 09:36:45.648538  3675 net.cpp:434] lstm2x_gate_input_5 <- W_xc_x_5
I0521 09:36:45.648557  3675 net.cpp:408] lstm2x_gate_input_5 -> gate_input_5
I0521 09:36:45.648584  3675 net.cpp:150] Setting up lstm2x_gate_input_5
I0521 09:36:45.648589  3675 net.cpp:157] Top shape: 1 128 400 (51200)
I0521 09:36:45.648592  3675 net.cpp:165] Memory required for data: 26589184
I0521 09:36:45.648596  3675 layer_factory.hpp:77] Creating layer lstm2x_unit_5
I0521 09:36:45.648602  3675 net.cpp:100] Creating Layer lstm2x_unit_5
I0521 09:36:45.648607  3675 net.cpp:434] lstm2x_unit_5 <- c_4
I0521 09:36:45.648610  3675 net.cpp:434] lstm2x_unit_5 <- gate_input_5
I0521 09:36:45.648614  3675 net.cpp:434] lstm2x_unit_5 <- cont_5_lstm2x_cont_slice_4_split_1
I0521 09:36:45.648619  3675 net.cpp:408] lstm2x_unit_5 -> c_5
I0521 09:36:45.648625  3675 net.cpp:408] lstm2x_unit_5 -> h_5
I0521 09:36:45.648667  3675 net.cpp:150] Setting up lstm2x_unit_5
I0521 09:36:45.648672  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.648676  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.648679  3675 net.cpp:165] Memory required for data: 26691584
I0521 09:36:45.648684  3675 layer_factory.hpp:77] Creating layer h_5_lstm2x_unit_5_1_split
I0521 09:36:45.648689  3675 net.cpp:100] Creating Layer h_5_lstm2x_unit_5_1_split
I0521 09:36:45.648691  3675 net.cpp:434] h_5_lstm2x_unit_5_1_split <- h_5
I0521 09:36:45.648699  3675 net.cpp:408] h_5_lstm2x_unit_5_1_split -> h_5_lstm2x_unit_5_1_split_0
I0521 09:36:45.648705  3675 net.cpp:408] h_5_lstm2x_unit_5_1_split -> h_5_lstm2x_unit_5_1_split_1
I0521 09:36:45.648733  3675 net.cpp:150] Setting up h_5_lstm2x_unit_5_1_split
I0521 09:36:45.648738  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.648742  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.648746  3675 net.cpp:165] Memory required for data: 26793984
I0521 09:36:45.648749  3675 layer_factory.hpp:77] Creating layer lstm2x_h_conted_5
I0521 09:36:45.648756  3675 net.cpp:100] Creating Layer lstm2x_h_conted_5
I0521 09:36:45.648759  3675 net.cpp:434] lstm2x_h_conted_5 <- h_5_lstm2x_unit_5_1_split_0
I0521 09:36:45.648763  3675 net.cpp:434] lstm2x_h_conted_5 <- cont_6_lstm2x_cont_slice_5_split_0
I0521 09:36:45.648768  3675 net.cpp:408] lstm2x_h_conted_5 -> h_conted_5
I0521 09:36:45.648833  3675 net.cpp:150] Setting up lstm2x_h_conted_5
I0521 09:36:45.648839  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.648842  3675 net.cpp:165] Memory required for data: 26845184
I0521 09:36:45.648846  3675 layer_factory.hpp:77] Creating layer lstm2x_transform_6
I0521 09:36:45.648852  3675 net.cpp:100] Creating Layer lstm2x_transform_6
I0521 09:36:45.648856  3675 net.cpp:434] lstm2x_transform_6 <- h_conted_5
I0521 09:36:45.648861  3675 net.cpp:408] lstm2x_transform_6 -> W_hc_h_5
I0521 09:36:45.649226  3675 net.cpp:150] Setting up lstm2x_transform_6
I0521 09:36:45.649240  3675 net.cpp:157] Top shape: 1 128 400 (51200)
I0521 09:36:45.649243  3675 net.cpp:165] Memory required for data: 27049984
I0521 09:36:45.649247  3675 net.cpp:493] Sharing parameters 'W_hc' owned by layer 'lstm2x_transform_1', param index 0
I0521 09:36:45.649252  3675 layer_factory.hpp:77] Creating layer lstm2x_gate_input_6
I0521 09:36:45.649258  3675 net.cpp:100] Creating Layer lstm2x_gate_input_6
I0521 09:36:45.649263  3675 net.cpp:434] lstm2x_gate_input_6 <- W_hc_h_5
I0521 09:36:45.649268  3675 net.cpp:434] lstm2x_gate_input_6 <- W_xc_x_6
I0521 09:36:45.649274  3675 net.cpp:408] lstm2x_gate_input_6 -> gate_input_6
I0521 09:36:45.649298  3675 net.cpp:150] Setting up lstm2x_gate_input_6
I0521 09:36:45.649303  3675 net.cpp:157] Top shape: 1 128 400 (51200)
I0521 09:36:45.649307  3675 net.cpp:165] Memory required for data: 27254784
I0521 09:36:45.649309  3675 layer_factory.hpp:77] Creating layer lstm2x_unit_6
I0521 09:36:45.649317  3675 net.cpp:100] Creating Layer lstm2x_unit_6
I0521 09:36:45.649320  3675 net.cpp:434] lstm2x_unit_6 <- c_5
I0521 09:36:45.649325  3675 net.cpp:434] lstm2x_unit_6 <- gate_input_6
I0521 09:36:45.649329  3675 net.cpp:434] lstm2x_unit_6 <- cont_6_lstm2x_cont_slice_5_split_1
I0521 09:36:45.649346  3675 net.cpp:408] lstm2x_unit_6 -> c_6
I0521 09:36:45.649353  3675 net.cpp:408] lstm2x_unit_6 -> h_6
I0521 09:36:45.649396  3675 net.cpp:150] Setting up lstm2x_unit_6
I0521 09:36:45.649401  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.649406  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.649410  3675 net.cpp:165] Memory required for data: 27357184
I0521 09:36:45.649412  3675 layer_factory.hpp:77] Creating layer h_6_lstm2x_unit_6_1_split
I0521 09:36:45.649420  3675 net.cpp:100] Creating Layer h_6_lstm2x_unit_6_1_split
I0521 09:36:45.649422  3675 net.cpp:434] h_6_lstm2x_unit_6_1_split <- h_6
I0521 09:36:45.649428  3675 net.cpp:408] h_6_lstm2x_unit_6_1_split -> h_6_lstm2x_unit_6_1_split_0
I0521 09:36:45.649433  3675 net.cpp:408] h_6_lstm2x_unit_6_1_split -> h_6_lstm2x_unit_6_1_split_1
I0521 09:36:45.649463  3675 net.cpp:150] Setting up h_6_lstm2x_unit_6_1_split
I0521 09:36:45.649468  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.649472  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.649475  3675 net.cpp:165] Memory required for data: 27459584
I0521 09:36:45.649479  3675 layer_factory.hpp:77] Creating layer lstm2x_h_conted_6
I0521 09:36:45.649490  3675 net.cpp:100] Creating Layer lstm2x_h_conted_6
I0521 09:36:45.649494  3675 net.cpp:434] lstm2x_h_conted_6 <- h_6_lstm2x_unit_6_1_split_0
I0521 09:36:45.649498  3675 net.cpp:434] lstm2x_h_conted_6 <- cont_7_lstm2x_cont_slice_6_split_0
I0521 09:36:45.649504  3675 net.cpp:408] lstm2x_h_conted_6 -> h_conted_6
I0521 09:36:45.649560  3675 net.cpp:150] Setting up lstm2x_h_conted_6
I0521 09:36:45.649566  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.649569  3675 net.cpp:165] Memory required for data: 27510784
I0521 09:36:45.649574  3675 layer_factory.hpp:77] Creating layer lstm2x_transform_7
I0521 09:36:45.649580  3675 net.cpp:100] Creating Layer lstm2x_transform_7
I0521 09:36:45.649585  3675 net.cpp:434] lstm2x_transform_7 <- h_conted_6
I0521 09:36:45.649590  3675 net.cpp:408] lstm2x_transform_7 -> W_hc_h_6
I0521 09:36:45.649986  3675 net.cpp:150] Setting up lstm2x_transform_7
I0521 09:36:45.649996  3675 net.cpp:157] Top shape: 1 128 400 (51200)
I0521 09:36:45.649998  3675 net.cpp:165] Memory required for data: 27715584
I0521 09:36:45.650004  3675 net.cpp:493] Sharing parameters 'W_hc' owned by layer 'lstm2x_transform_1', param index 0
I0521 09:36:45.650008  3675 layer_factory.hpp:77] Creating layer lstm2x_gate_input_7
I0521 09:36:45.650014  3675 net.cpp:100] Creating Layer lstm2x_gate_input_7
I0521 09:36:45.650019  3675 net.cpp:434] lstm2x_gate_input_7 <- W_hc_h_6
I0521 09:36:45.650024  3675 net.cpp:434] lstm2x_gate_input_7 <- W_xc_x_7
I0521 09:36:45.650029  3675 net.cpp:408] lstm2x_gate_input_7 -> gate_input_7
I0521 09:36:45.650055  3675 net.cpp:150] Setting up lstm2x_gate_input_7
I0521 09:36:45.650060  3675 net.cpp:157] Top shape: 1 128 400 (51200)
I0521 09:36:45.650064  3675 net.cpp:165] Memory required for data: 27920384
I0521 09:36:45.650068  3675 layer_factory.hpp:77] Creating layer lstm2x_unit_7
I0521 09:36:45.650072  3675 net.cpp:100] Creating Layer lstm2x_unit_7
I0521 09:36:45.650076  3675 net.cpp:434] lstm2x_unit_7 <- c_6
I0521 09:36:45.650080  3675 net.cpp:434] lstm2x_unit_7 <- gate_input_7
I0521 09:36:45.650084  3675 net.cpp:434] lstm2x_unit_7 <- cont_7_lstm2x_cont_slice_6_split_1
I0521 09:36:45.650089  3675 net.cpp:408] lstm2x_unit_7 -> c_7
I0521 09:36:45.650095  3675 net.cpp:408] lstm2x_unit_7 -> h_7
I0521 09:36:45.650140  3675 net.cpp:150] Setting up lstm2x_unit_7
I0521 09:36:45.650144  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.650148  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.650151  3675 net.cpp:165] Memory required for data: 28022784
I0521 09:36:45.650156  3675 layer_factory.hpp:77] Creating layer h_7_lstm2x_unit_7_1_split
I0521 09:36:45.650161  3675 net.cpp:100] Creating Layer h_7_lstm2x_unit_7_1_split
I0521 09:36:45.650166  3675 net.cpp:434] h_7_lstm2x_unit_7_1_split <- h_7
I0521 09:36:45.650169  3675 net.cpp:408] h_7_lstm2x_unit_7_1_split -> h_7_lstm2x_unit_7_1_split_0
I0521 09:36:45.650187  3675 net.cpp:408] h_7_lstm2x_unit_7_1_split -> h_7_lstm2x_unit_7_1_split_1
I0521 09:36:45.650216  3675 net.cpp:150] Setting up h_7_lstm2x_unit_7_1_split
I0521 09:36:45.650221  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.650225  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.650228  3675 net.cpp:165] Memory required for data: 28125184
I0521 09:36:45.650233  3675 layer_factory.hpp:77] Creating layer lstm2x_h_conted_7
I0521 09:36:45.650239  3675 net.cpp:100] Creating Layer lstm2x_h_conted_7
I0521 09:36:45.650243  3675 net.cpp:434] lstm2x_h_conted_7 <- h_7_lstm2x_unit_7_1_split_0
I0521 09:36:45.650249  3675 net.cpp:434] lstm2x_h_conted_7 <- cont_8_lstm2x_cont_slice_7_split_0
I0521 09:36:45.650254  3675 net.cpp:408] lstm2x_h_conted_7 -> h_conted_7
I0521 09:36:45.650310  3675 net.cpp:150] Setting up lstm2x_h_conted_7
I0521 09:36:45.650315  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.650318  3675 net.cpp:165] Memory required for data: 28176384
I0521 09:36:45.650322  3675 layer_factory.hpp:77] Creating layer lstm2x_transform_8
I0521 09:36:45.650328  3675 net.cpp:100] Creating Layer lstm2x_transform_8
I0521 09:36:45.650332  3675 net.cpp:434] lstm2x_transform_8 <- h_conted_7
I0521 09:36:45.650338  3675 net.cpp:408] lstm2x_transform_8 -> W_hc_h_7
I0521 09:36:45.650660  3675 net.cpp:150] Setting up lstm2x_transform_8
I0521 09:36:45.650668  3675 net.cpp:157] Top shape: 1 128 400 (51200)
I0521 09:36:45.650671  3675 net.cpp:165] Memory required for data: 28381184
I0521 09:36:45.650674  3675 net.cpp:493] Sharing parameters 'W_hc' owned by layer 'lstm2x_transform_1', param index 0
I0521 09:36:45.650677  3675 layer_factory.hpp:77] Creating layer lstm2x_gate_input_8
I0521 09:36:45.650681  3675 net.cpp:100] Creating Layer lstm2x_gate_input_8
I0521 09:36:45.650686  3675 net.cpp:434] lstm2x_gate_input_8 <- W_hc_h_7
I0521 09:36:45.650691  3675 net.cpp:434] lstm2x_gate_input_8 <- W_xc_x_8
I0521 09:36:45.650696  3675 net.cpp:408] lstm2x_gate_input_8 -> gate_input_8
I0521 09:36:45.650717  3675 net.cpp:150] Setting up lstm2x_gate_input_8
I0521 09:36:45.650720  3675 net.cpp:157] Top shape: 1 128 400 (51200)
I0521 09:36:45.650723  3675 net.cpp:165] Memory required for data: 28585984
I0521 09:36:45.650727  3675 layer_factory.hpp:77] Creating layer lstm2x_unit_8
I0521 09:36:45.650732  3675 net.cpp:100] Creating Layer lstm2x_unit_8
I0521 09:36:45.650734  3675 net.cpp:434] lstm2x_unit_8 <- c_7
I0521 09:36:45.650738  3675 net.cpp:434] lstm2x_unit_8 <- gate_input_8
I0521 09:36:45.650743  3675 net.cpp:434] lstm2x_unit_8 <- cont_8_lstm2x_cont_slice_7_split_1
I0521 09:36:45.650748  3675 net.cpp:408] lstm2x_unit_8 -> c_8
I0521 09:36:45.650753  3675 net.cpp:408] lstm2x_unit_8 -> h_8
I0521 09:36:45.650789  3675 net.cpp:150] Setting up lstm2x_unit_8
I0521 09:36:45.650792  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.650795  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.650797  3675 net.cpp:165] Memory required for data: 28688384
I0521 09:36:45.650800  3675 layer_factory.hpp:77] Creating layer h_8_lstm2x_unit_8_1_split
I0521 09:36:45.650805  3675 net.cpp:100] Creating Layer h_8_lstm2x_unit_8_1_split
I0521 09:36:45.650807  3675 net.cpp:434] h_8_lstm2x_unit_8_1_split <- h_8
I0521 09:36:45.650811  3675 net.cpp:408] h_8_lstm2x_unit_8_1_split -> h_8_lstm2x_unit_8_1_split_0
I0521 09:36:45.650815  3675 net.cpp:408] h_8_lstm2x_unit_8_1_split -> h_8_lstm2x_unit_8_1_split_1
I0521 09:36:45.650838  3675 net.cpp:150] Setting up h_8_lstm2x_unit_8_1_split
I0521 09:36:45.650841  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.650844  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.650846  3675 net.cpp:165] Memory required for data: 28790784
I0521 09:36:45.650848  3675 layer_factory.hpp:77] Creating layer lstm2x_h_conted_8
I0521 09:36:45.650852  3675 net.cpp:100] Creating Layer lstm2x_h_conted_8
I0521 09:36:45.650856  3675 net.cpp:434] lstm2x_h_conted_8 <- h_8_lstm2x_unit_8_1_split_0
I0521 09:36:45.650858  3675 net.cpp:434] lstm2x_h_conted_8 <- cont_9_lstm2x_cont_slice_8_split_0
I0521 09:36:45.650877  3675 net.cpp:408] lstm2x_h_conted_8 -> h_conted_8
I0521 09:36:45.650919  3675 net.cpp:150] Setting up lstm2x_h_conted_8
I0521 09:36:45.650923  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.650924  3675 net.cpp:165] Memory required for data: 28841984
I0521 09:36:45.650926  3675 layer_factory.hpp:77] Creating layer lstm2x_transform_9
I0521 09:36:45.650933  3675 net.cpp:100] Creating Layer lstm2x_transform_9
I0521 09:36:45.650934  3675 net.cpp:434] lstm2x_transform_9 <- h_conted_8
I0521 09:36:45.650944  3675 net.cpp:408] lstm2x_transform_9 -> W_hc_h_8
I0521 09:36:45.651149  3675 net.cpp:150] Setting up lstm2x_transform_9
I0521 09:36:45.651152  3675 net.cpp:157] Top shape: 1 128 400 (51200)
I0521 09:36:45.651155  3675 net.cpp:165] Memory required for data: 29046784
I0521 09:36:45.651157  3675 net.cpp:493] Sharing parameters 'W_hc' owned by layer 'lstm2x_transform_1', param index 0
I0521 09:36:45.651160  3675 layer_factory.hpp:77] Creating layer lstm2x_gate_input_9
I0521 09:36:45.651165  3675 net.cpp:100] Creating Layer lstm2x_gate_input_9
I0521 09:36:45.651166  3675 net.cpp:434] lstm2x_gate_input_9 <- W_hc_h_8
I0521 09:36:45.651170  3675 net.cpp:434] lstm2x_gate_input_9 <- W_xc_x_9
I0521 09:36:45.651173  3675 net.cpp:408] lstm2x_gate_input_9 -> gate_input_9
I0521 09:36:45.651187  3675 net.cpp:150] Setting up lstm2x_gate_input_9
I0521 09:36:45.651190  3675 net.cpp:157] Top shape: 1 128 400 (51200)
I0521 09:36:45.651192  3675 net.cpp:165] Memory required for data: 29251584
I0521 09:36:45.651194  3675 layer_factory.hpp:77] Creating layer lstm2x_unit_9
I0521 09:36:45.651201  3675 net.cpp:100] Creating Layer lstm2x_unit_9
I0521 09:36:45.651204  3675 net.cpp:434] lstm2x_unit_9 <- c_8
I0521 09:36:45.651207  3675 net.cpp:434] lstm2x_unit_9 <- gate_input_9
I0521 09:36:45.651211  3675 net.cpp:434] lstm2x_unit_9 <- cont_9_lstm2x_cont_slice_8_split_1
I0521 09:36:45.651213  3675 net.cpp:408] lstm2x_unit_9 -> c_9
I0521 09:36:45.651221  3675 net.cpp:408] lstm2x_unit_9 -> h_9
I0521 09:36:45.651250  3675 net.cpp:150] Setting up lstm2x_unit_9
I0521 09:36:45.651253  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.651257  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.651258  3675 net.cpp:165] Memory required for data: 29353984
I0521 09:36:45.651260  3675 layer_factory.hpp:77] Creating layer h_9_lstm2x_unit_9_1_split
I0521 09:36:45.651264  3675 net.cpp:100] Creating Layer h_9_lstm2x_unit_9_1_split
I0521 09:36:45.651266  3675 net.cpp:434] h_9_lstm2x_unit_9_1_split <- h_9
I0521 09:36:45.651270  3675 net.cpp:408] h_9_lstm2x_unit_9_1_split -> h_9_lstm2x_unit_9_1_split_0
I0521 09:36:45.651274  3675 net.cpp:408] h_9_lstm2x_unit_9_1_split -> h_9_lstm2x_unit_9_1_split_1
I0521 09:36:45.651294  3675 net.cpp:150] Setting up h_9_lstm2x_unit_9_1_split
I0521 09:36:45.651298  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.651300  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.651302  3675 net.cpp:165] Memory required for data: 29456384
I0521 09:36:45.651305  3675 layer_factory.hpp:77] Creating layer lstm2x_h_conted_9
I0521 09:36:45.651309  3675 net.cpp:100] Creating Layer lstm2x_h_conted_9
I0521 09:36:45.651311  3675 net.cpp:434] lstm2x_h_conted_9 <- h_9_lstm2x_unit_9_1_split_0
I0521 09:36:45.651314  3675 net.cpp:434] lstm2x_h_conted_9 <- cont_10_lstm2x_cont_slice_9_split_0
I0521 09:36:45.651317  3675 net.cpp:408] lstm2x_h_conted_9 -> h_conted_9
I0521 09:36:45.651361  3675 net.cpp:150] Setting up lstm2x_h_conted_9
I0521 09:36:45.651365  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.651367  3675 net.cpp:165] Memory required for data: 29507584
I0521 09:36:45.651370  3675 layer_factory.hpp:77] Creating layer lstm2x_transform_10
I0521 09:36:45.651374  3675 net.cpp:100] Creating Layer lstm2x_transform_10
I0521 09:36:45.651376  3675 net.cpp:434] lstm2x_transform_10 <- h_conted_9
I0521 09:36:45.651381  3675 net.cpp:408] lstm2x_transform_10 -> W_hc_h_9
I0521 09:36:45.651582  3675 net.cpp:150] Setting up lstm2x_transform_10
I0521 09:36:45.651594  3675 net.cpp:157] Top shape: 1 128 400 (51200)
I0521 09:36:45.651597  3675 net.cpp:165] Memory required for data: 29712384
I0521 09:36:45.651600  3675 net.cpp:493] Sharing parameters 'W_hc' owned by layer 'lstm2x_transform_1', param index 0
I0521 09:36:45.651602  3675 layer_factory.hpp:77] Creating layer lstm2x_gate_input_10
I0521 09:36:45.651607  3675 net.cpp:100] Creating Layer lstm2x_gate_input_10
I0521 09:36:45.651612  3675 net.cpp:434] lstm2x_gate_input_10 <- W_hc_h_9
I0521 09:36:45.651614  3675 net.cpp:434] lstm2x_gate_input_10 <- W_xc_x_10
I0521 09:36:45.651618  3675 net.cpp:408] lstm2x_gate_input_10 -> gate_input_10
I0521 09:36:45.651638  3675 net.cpp:150] Setting up lstm2x_gate_input_10
I0521 09:36:45.651640  3675 net.cpp:157] Top shape: 1 128 400 (51200)
I0521 09:36:45.651643  3675 net.cpp:165] Memory required for data: 29917184
I0521 09:36:45.651644  3675 layer_factory.hpp:77] Creating layer lstm2x_unit_10
I0521 09:36:45.651648  3675 net.cpp:100] Creating Layer lstm2x_unit_10
I0521 09:36:45.651650  3675 net.cpp:434] lstm2x_unit_10 <- c_9
I0521 09:36:45.651654  3675 net.cpp:434] lstm2x_unit_10 <- gate_input_10
I0521 09:36:45.651655  3675 net.cpp:434] lstm2x_unit_10 <- cont_10_lstm2x_cont_slice_9_split_1
I0521 09:36:45.651660  3675 net.cpp:408] lstm2x_unit_10 -> c_10
I0521 09:36:45.651664  3675 net.cpp:408] lstm2x_unit_10 -> h_10
I0521 09:36:45.651692  3675 net.cpp:150] Setting up lstm2x_unit_10
I0521 09:36:45.651695  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.651698  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.651700  3675 net.cpp:165] Memory required for data: 30019584
I0521 09:36:45.651703  3675 layer_factory.hpp:77] Creating layer h_10_lstm2x_unit_10_1_split
I0521 09:36:45.651707  3675 net.cpp:100] Creating Layer h_10_lstm2x_unit_10_1_split
I0521 09:36:45.651710  3675 net.cpp:434] h_10_lstm2x_unit_10_1_split <- h_10
I0521 09:36:45.651713  3675 net.cpp:408] h_10_lstm2x_unit_10_1_split -> h_10_lstm2x_unit_10_1_split_0
I0521 09:36:45.651717  3675 net.cpp:408] h_10_lstm2x_unit_10_1_split -> h_10_lstm2x_unit_10_1_split_1
I0521 09:36:45.651737  3675 net.cpp:150] Setting up h_10_lstm2x_unit_10_1_split
I0521 09:36:45.651741  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.651742  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.651746  3675 net.cpp:165] Memory required for data: 30121984
I0521 09:36:45.651747  3675 layer_factory.hpp:77] Creating layer lstm2x_h_conted_10
I0521 09:36:45.651751  3675 net.cpp:100] Creating Layer lstm2x_h_conted_10
I0521 09:36:45.651754  3675 net.cpp:434] lstm2x_h_conted_10 <- h_10_lstm2x_unit_10_1_split_0
I0521 09:36:45.651757  3675 net.cpp:434] lstm2x_h_conted_10 <- cont_11_lstm2x_cont_slice_10_split_0
I0521 09:36:45.651760  3675 net.cpp:408] lstm2x_h_conted_10 -> h_conted_10
I0521 09:36:45.651799  3675 net.cpp:150] Setting up lstm2x_h_conted_10
I0521 09:36:45.651803  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.651805  3675 net.cpp:165] Memory required for data: 30173184
I0521 09:36:45.651808  3675 layer_factory.hpp:77] Creating layer lstm2x_transform_11
I0521 09:36:45.651813  3675 net.cpp:100] Creating Layer lstm2x_transform_11
I0521 09:36:45.651815  3675 net.cpp:434] lstm2x_transform_11 <- h_conted_10
I0521 09:36:45.651818  3675 net.cpp:408] lstm2x_transform_11 -> W_hc_h_10
I0521 09:36:45.652009  3675 net.cpp:150] Setting up lstm2x_transform_11
I0521 09:36:45.652012  3675 net.cpp:157] Top shape: 1 128 400 (51200)
I0521 09:36:45.652014  3675 net.cpp:165] Memory required for data: 30377984
I0521 09:36:45.652016  3675 net.cpp:493] Sharing parameters 'W_hc' owned by layer 'lstm2x_transform_1', param index 0
I0521 09:36:45.652019  3675 layer_factory.hpp:77] Creating layer lstm2x_gate_input_11
I0521 09:36:45.652022  3675 net.cpp:100] Creating Layer lstm2x_gate_input_11
I0521 09:36:45.652024  3675 net.cpp:434] lstm2x_gate_input_11 <- W_hc_h_10
I0521 09:36:45.652027  3675 net.cpp:434] lstm2x_gate_input_11 <- W_xc_x_11
I0521 09:36:45.652030  3675 net.cpp:408] lstm2x_gate_input_11 -> gate_input_11
I0521 09:36:45.652050  3675 net.cpp:150] Setting up lstm2x_gate_input_11
I0521 09:36:45.652053  3675 net.cpp:157] Top shape: 1 128 400 (51200)
I0521 09:36:45.652055  3675 net.cpp:165] Memory required for data: 30582784
I0521 09:36:45.652057  3675 layer_factory.hpp:77] Creating layer lstm2x_unit_11
I0521 09:36:45.652061  3675 net.cpp:100] Creating Layer lstm2x_unit_11
I0521 09:36:45.652063  3675 net.cpp:434] lstm2x_unit_11 <- c_10
I0521 09:36:45.652066  3675 net.cpp:434] lstm2x_unit_11 <- gate_input_11
I0521 09:36:45.652070  3675 net.cpp:434] lstm2x_unit_11 <- cont_11_lstm2x_cont_slice_10_split_1
I0521 09:36:45.652072  3675 net.cpp:408] lstm2x_unit_11 -> c_11
I0521 09:36:45.652076  3675 net.cpp:408] lstm2x_unit_11 -> h_11
I0521 09:36:45.652104  3675 net.cpp:150] Setting up lstm2x_unit_11
I0521 09:36:45.652107  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.652110  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.652112  3675 net.cpp:165] Memory required for data: 30685184
I0521 09:36:45.652114  3675 layer_factory.hpp:77] Creating layer h_11_lstm2x_unit_11_1_split
I0521 09:36:45.652118  3675 net.cpp:100] Creating Layer h_11_lstm2x_unit_11_1_split
I0521 09:36:45.652120  3675 net.cpp:434] h_11_lstm2x_unit_11_1_split <- h_11
I0521 09:36:45.652124  3675 net.cpp:408] h_11_lstm2x_unit_11_1_split -> h_11_lstm2x_unit_11_1_split_0
I0521 09:36:45.652128  3675 net.cpp:408] h_11_lstm2x_unit_11_1_split -> h_11_lstm2x_unit_11_1_split_1
I0521 09:36:45.652148  3675 net.cpp:150] Setting up h_11_lstm2x_unit_11_1_split
I0521 09:36:45.652153  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.652154  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.652158  3675 net.cpp:165] Memory required for data: 30787584
I0521 09:36:45.652159  3675 layer_factory.hpp:77] Creating layer lstm2x_h_conted_11
I0521 09:36:45.652163  3675 net.cpp:100] Creating Layer lstm2x_h_conted_11
I0521 09:36:45.652165  3675 net.cpp:434] lstm2x_h_conted_11 <- h_11_lstm2x_unit_11_1_split_0
I0521 09:36:45.652168  3675 net.cpp:434] lstm2x_h_conted_11 <- cont_12_lstm2x_cont_slice_11_split_0
I0521 09:36:45.652171  3675 net.cpp:408] lstm2x_h_conted_11 -> h_conted_11
I0521 09:36:45.652209  3675 net.cpp:150] Setting up lstm2x_h_conted_11
I0521 09:36:45.652211  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.652213  3675 net.cpp:165] Memory required for data: 30838784
I0521 09:36:45.652216  3675 layer_factory.hpp:77] Creating layer lstm2x_transform_12
I0521 09:36:45.652220  3675 net.cpp:100] Creating Layer lstm2x_transform_12
I0521 09:36:45.652222  3675 net.cpp:434] lstm2x_transform_12 <- h_conted_11
I0521 09:36:45.652226  3675 net.cpp:408] lstm2x_transform_12 -> W_hc_h_11
I0521 09:36:45.653084  3675 net.cpp:150] Setting up lstm2x_transform_12
I0521 09:36:45.653096  3675 net.cpp:157] Top shape: 1 128 400 (51200)
I0521 09:36:45.653098  3675 net.cpp:165] Memory required for data: 31043584
I0521 09:36:45.653101  3675 net.cpp:493] Sharing parameters 'W_hc' owned by layer 'lstm2x_transform_1', param index 0
I0521 09:36:45.653105  3675 layer_factory.hpp:77] Creating layer lstm2x_gate_input_12
I0521 09:36:45.653110  3675 net.cpp:100] Creating Layer lstm2x_gate_input_12
I0521 09:36:45.653113  3675 net.cpp:434] lstm2x_gate_input_12 <- W_hc_h_11
I0521 09:36:45.653117  3675 net.cpp:434] lstm2x_gate_input_12 <- W_xc_x_12
I0521 09:36:45.653120  3675 net.cpp:408] lstm2x_gate_input_12 -> gate_input_12
I0521 09:36:45.653138  3675 net.cpp:150] Setting up lstm2x_gate_input_12
I0521 09:36:45.653141  3675 net.cpp:157] Top shape: 1 128 400 (51200)
I0521 09:36:45.653143  3675 net.cpp:165] Memory required for data: 31248384
I0521 09:36:45.653146  3675 layer_factory.hpp:77] Creating layer lstm2x_unit_12
I0521 09:36:45.653151  3675 net.cpp:100] Creating Layer lstm2x_unit_12
I0521 09:36:45.653153  3675 net.cpp:434] lstm2x_unit_12 <- c_11
I0521 09:36:45.653156  3675 net.cpp:434] lstm2x_unit_12 <- gate_input_12
I0521 09:36:45.653159  3675 net.cpp:434] lstm2x_unit_12 <- cont_12_lstm2x_cont_slice_11_split_1
I0521 09:36:45.653173  3675 net.cpp:408] lstm2x_unit_12 -> c_12
I0521 09:36:45.653177  3675 net.cpp:408] lstm2x_unit_12 -> h_12
I0521 09:36:45.653210  3675 net.cpp:150] Setting up lstm2x_unit_12
I0521 09:36:45.653213  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.653216  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.653218  3675 net.cpp:165] Memory required for data: 31350784
I0521 09:36:45.653220  3675 layer_factory.hpp:77] Creating layer h_12_lstm2x_unit_12_1_split
I0521 09:36:45.653224  3675 net.cpp:100] Creating Layer h_12_lstm2x_unit_12_1_split
I0521 09:36:45.653228  3675 net.cpp:434] h_12_lstm2x_unit_12_1_split <- h_12
I0521 09:36:45.653231  3675 net.cpp:408] h_12_lstm2x_unit_12_1_split -> h_12_lstm2x_unit_12_1_split_0
I0521 09:36:45.653236  3675 net.cpp:408] h_12_lstm2x_unit_12_1_split -> h_12_lstm2x_unit_12_1_split_1
I0521 09:36:45.653257  3675 net.cpp:150] Setting up h_12_lstm2x_unit_12_1_split
I0521 09:36:45.653260  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.653264  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.653265  3675 net.cpp:165] Memory required for data: 31453184
I0521 09:36:45.653267  3675 layer_factory.hpp:77] Creating layer lstm2x_h_conted_12
I0521 09:36:45.653271  3675 net.cpp:100] Creating Layer lstm2x_h_conted_12
I0521 09:36:45.653275  3675 net.cpp:434] lstm2x_h_conted_12 <- h_12_lstm2x_unit_12_1_split_0
I0521 09:36:45.653277  3675 net.cpp:434] lstm2x_h_conted_12 <- cont_13_lstm2x_cont_slice_12_split_0
I0521 09:36:45.653280  3675 net.cpp:408] lstm2x_h_conted_12 -> h_conted_12
I0521 09:36:45.653322  3675 net.cpp:150] Setting up lstm2x_h_conted_12
I0521 09:36:45.653326  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.653327  3675 net.cpp:165] Memory required for data: 31504384
I0521 09:36:45.653329  3675 layer_factory.hpp:77] Creating layer lstm2x_transform_13
I0521 09:36:45.653333  3675 net.cpp:100] Creating Layer lstm2x_transform_13
I0521 09:36:45.653337  3675 net.cpp:434] lstm2x_transform_13 <- h_conted_12
I0521 09:36:45.653339  3675 net.cpp:408] lstm2x_transform_13 -> W_hc_h_12
I0521 09:36:45.653543  3675 net.cpp:150] Setting up lstm2x_transform_13
I0521 09:36:45.653548  3675 net.cpp:157] Top shape: 1 128 400 (51200)
I0521 09:36:45.653550  3675 net.cpp:165] Memory required for data: 31709184
I0521 09:36:45.653553  3675 net.cpp:493] Sharing parameters 'W_hc' owned by layer 'lstm2x_transform_1', param index 0
I0521 09:36:45.653555  3675 layer_factory.hpp:77] Creating layer lstm2x_gate_input_13
I0521 09:36:45.653559  3675 net.cpp:100] Creating Layer lstm2x_gate_input_13
I0521 09:36:45.653563  3675 net.cpp:434] lstm2x_gate_input_13 <- W_hc_h_12
I0521 09:36:45.653564  3675 net.cpp:434] lstm2x_gate_input_13 <- W_xc_x_13
I0521 09:36:45.653568  3675 net.cpp:408] lstm2x_gate_input_13 -> gate_input_13
I0521 09:36:45.653581  3675 net.cpp:150] Setting up lstm2x_gate_input_13
I0521 09:36:45.653584  3675 net.cpp:157] Top shape: 1 128 400 (51200)
I0521 09:36:45.653586  3675 net.cpp:165] Memory required for data: 31913984
I0521 09:36:45.653589  3675 layer_factory.hpp:77] Creating layer lstm2x_unit_13
I0521 09:36:45.653594  3675 net.cpp:100] Creating Layer lstm2x_unit_13
I0521 09:36:45.653596  3675 net.cpp:434] lstm2x_unit_13 <- c_12
I0521 09:36:45.653599  3675 net.cpp:434] lstm2x_unit_13 <- gate_input_13
I0521 09:36:45.653601  3675 net.cpp:434] lstm2x_unit_13 <- cont_13_lstm2x_cont_slice_12_split_1
I0521 09:36:45.653605  3675 net.cpp:408] lstm2x_unit_13 -> c_13
I0521 09:36:45.653609  3675 net.cpp:408] lstm2x_unit_13 -> h_13
I0521 09:36:45.653638  3675 net.cpp:150] Setting up lstm2x_unit_13
I0521 09:36:45.653642  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.653645  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.653646  3675 net.cpp:165] Memory required for data: 32016384
I0521 09:36:45.653650  3675 layer_factory.hpp:77] Creating layer h_13_lstm2x_unit_13_1_split
I0521 09:36:45.653653  3675 net.cpp:100] Creating Layer h_13_lstm2x_unit_13_1_split
I0521 09:36:45.653656  3675 net.cpp:434] h_13_lstm2x_unit_13_1_split <- h_13
I0521 09:36:45.653666  3675 net.cpp:408] h_13_lstm2x_unit_13_1_split -> h_13_lstm2x_unit_13_1_split_0
I0521 09:36:45.653671  3675 net.cpp:408] h_13_lstm2x_unit_13_1_split -> h_13_lstm2x_unit_13_1_split_1
I0521 09:36:45.653690  3675 net.cpp:150] Setting up h_13_lstm2x_unit_13_1_split
I0521 09:36:45.653693  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.653697  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.653698  3675 net.cpp:165] Memory required for data: 32118784
I0521 09:36:45.653702  3675 layer_factory.hpp:77] Creating layer lstm2x_h_conted_13
I0521 09:36:45.653705  3675 net.cpp:100] Creating Layer lstm2x_h_conted_13
I0521 09:36:45.653708  3675 net.cpp:434] lstm2x_h_conted_13 <- h_13_lstm2x_unit_13_1_split_0
I0521 09:36:45.653712  3675 net.cpp:434] lstm2x_h_conted_13 <- cont_14_lstm2x_cont_slice_13_split_0
I0521 09:36:45.653714  3675 net.cpp:408] lstm2x_h_conted_13 -> h_conted_13
I0521 09:36:45.653753  3675 net.cpp:150] Setting up lstm2x_h_conted_13
I0521 09:36:45.653755  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.653757  3675 net.cpp:165] Memory required for data: 32169984
I0521 09:36:45.653759  3675 layer_factory.hpp:77] Creating layer lstm2x_transform_14
I0521 09:36:45.653764  3675 net.cpp:100] Creating Layer lstm2x_transform_14
I0521 09:36:45.653766  3675 net.cpp:434] lstm2x_transform_14 <- h_conted_13
I0521 09:36:45.653769  3675 net.cpp:408] lstm2x_transform_14 -> W_hc_h_13
I0521 09:36:45.653976  3675 net.cpp:150] Setting up lstm2x_transform_14
I0521 09:36:45.653982  3675 net.cpp:157] Top shape: 1 128 400 (51200)
I0521 09:36:45.653985  3675 net.cpp:165] Memory required for data: 32374784
I0521 09:36:45.653988  3675 net.cpp:493] Sharing parameters 'W_hc' owned by layer 'lstm2x_transform_1', param index 0
I0521 09:36:45.653991  3675 layer_factory.hpp:77] Creating layer lstm2x_gate_input_14
I0521 09:36:45.653996  3675 net.cpp:100] Creating Layer lstm2x_gate_input_14
I0521 09:36:45.654000  3675 net.cpp:434] lstm2x_gate_input_14 <- W_hc_h_13
I0521 09:36:45.654003  3675 net.cpp:434] lstm2x_gate_input_14 <- W_xc_x_14
I0521 09:36:45.654007  3675 net.cpp:408] lstm2x_gate_input_14 -> gate_input_14
I0521 09:36:45.654026  3675 net.cpp:150] Setting up lstm2x_gate_input_14
I0521 09:36:45.654029  3675 net.cpp:157] Top shape: 1 128 400 (51200)
I0521 09:36:45.654033  3675 net.cpp:165] Memory required for data: 32579584
I0521 09:36:45.654037  3675 layer_factory.hpp:77] Creating layer lstm2x_unit_14
I0521 09:36:45.654043  3675 net.cpp:100] Creating Layer lstm2x_unit_14
I0521 09:36:45.654047  3675 net.cpp:434] lstm2x_unit_14 <- c_13
I0521 09:36:45.654052  3675 net.cpp:434] lstm2x_unit_14 <- gate_input_14
I0521 09:36:45.654055  3675 net.cpp:434] lstm2x_unit_14 <- cont_14_lstm2x_cont_slice_13_split_1
I0521 09:36:45.654059  3675 net.cpp:408] lstm2x_unit_14 -> c_14
I0521 09:36:45.654064  3675 net.cpp:408] lstm2x_unit_14 -> h_14
I0521 09:36:45.654100  3675 net.cpp:150] Setting up lstm2x_unit_14
I0521 09:36:45.654105  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.654109  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.654111  3675 net.cpp:165] Memory required for data: 32681984
I0521 09:36:45.654114  3675 layer_factory.hpp:77] Creating layer h_14_lstm2x_unit_14_1_split
I0521 09:36:45.654120  3675 net.cpp:100] Creating Layer h_14_lstm2x_unit_14_1_split
I0521 09:36:45.654124  3675 net.cpp:434] h_14_lstm2x_unit_14_1_split <- h_14
I0521 09:36:45.654129  3675 net.cpp:408] h_14_lstm2x_unit_14_1_split -> h_14_lstm2x_unit_14_1_split_0
I0521 09:36:45.654134  3675 net.cpp:408] h_14_lstm2x_unit_14_1_split -> h_14_lstm2x_unit_14_1_split_1
I0521 09:36:45.654160  3675 net.cpp:150] Setting up h_14_lstm2x_unit_14_1_split
I0521 09:36:45.654165  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.654170  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.654172  3675 net.cpp:165] Memory required for data: 32784384
I0521 09:36:45.654176  3675 layer_factory.hpp:77] Creating layer lstm2x_h_conted_14
I0521 09:36:45.654182  3675 net.cpp:100] Creating Layer lstm2x_h_conted_14
I0521 09:36:45.654196  3675 net.cpp:434] lstm2x_h_conted_14 <- h_14_lstm2x_unit_14_1_split_0
I0521 09:36:45.654201  3675 net.cpp:434] lstm2x_h_conted_14 <- cont_15_lstm2x_cont_slice_14_split_0
I0521 09:36:45.654206  3675 net.cpp:408] lstm2x_h_conted_14 -> h_conted_14
I0521 09:36:45.654258  3675 net.cpp:150] Setting up lstm2x_h_conted_14
I0521 09:36:45.654263  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.654266  3675 net.cpp:165] Memory required for data: 32835584
I0521 09:36:45.654269  3675 layer_factory.hpp:77] Creating layer lstm2x_transform_15
I0521 09:36:45.654275  3675 net.cpp:100] Creating Layer lstm2x_transform_15
I0521 09:36:45.654279  3675 net.cpp:434] lstm2x_transform_15 <- h_conted_14
I0521 09:36:45.654289  3675 net.cpp:408] lstm2x_transform_15 -> W_hc_h_14
I0521 09:36:45.654623  3675 net.cpp:150] Setting up lstm2x_transform_15
I0521 09:36:45.654636  3675 net.cpp:157] Top shape: 1 128 400 (51200)
I0521 09:36:45.654640  3675 net.cpp:165] Memory required for data: 33040384
I0521 09:36:45.654647  3675 net.cpp:493] Sharing parameters 'W_hc' owned by layer 'lstm2x_transform_1', param index 0
I0521 09:36:45.654652  3675 layer_factory.hpp:77] Creating layer lstm2x_gate_input_15
I0521 09:36:45.654659  3675 net.cpp:100] Creating Layer lstm2x_gate_input_15
I0521 09:36:45.654664  3675 net.cpp:434] lstm2x_gate_input_15 <- W_hc_h_14
I0521 09:36:45.654669  3675 net.cpp:434] lstm2x_gate_input_15 <- W_xc_x_15
I0521 09:36:45.654673  3675 net.cpp:408] lstm2x_gate_input_15 -> gate_input_15
I0521 09:36:45.654701  3675 net.cpp:150] Setting up lstm2x_gate_input_15
I0521 09:36:45.654708  3675 net.cpp:157] Top shape: 1 128 400 (51200)
I0521 09:36:45.654712  3675 net.cpp:165] Memory required for data: 33245184
I0521 09:36:45.654716  3675 layer_factory.hpp:77] Creating layer lstm2x_unit_15
I0521 09:36:45.654721  3675 net.cpp:100] Creating Layer lstm2x_unit_15
I0521 09:36:45.654724  3675 net.cpp:434] lstm2x_unit_15 <- c_14
I0521 09:36:45.654729  3675 net.cpp:434] lstm2x_unit_15 <- gate_input_15
I0521 09:36:45.654733  3675 net.cpp:434] lstm2x_unit_15 <- cont_15_lstm2x_cont_slice_14_split_1
I0521 09:36:45.654738  3675 net.cpp:408] lstm2x_unit_15 -> c_15
I0521 09:36:45.654745  3675 net.cpp:408] lstm2x_unit_15 -> h_15
I0521 09:36:45.654788  3675 net.cpp:150] Setting up lstm2x_unit_15
I0521 09:36:45.654793  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.654798  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.654800  3675 net.cpp:165] Memory required for data: 33347584
I0521 09:36:45.654804  3675 layer_factory.hpp:77] Creating layer h_15_lstm2x_unit_15_1_split
I0521 09:36:45.654809  3675 net.cpp:100] Creating Layer h_15_lstm2x_unit_15_1_split
I0521 09:36:45.654814  3675 net.cpp:434] h_15_lstm2x_unit_15_1_split <- h_15
I0521 09:36:45.654819  3675 net.cpp:408] h_15_lstm2x_unit_15_1_split -> h_15_lstm2x_unit_15_1_split_0
I0521 09:36:45.654824  3675 net.cpp:408] h_15_lstm2x_unit_15_1_split -> h_15_lstm2x_unit_15_1_split_1
I0521 09:36:45.654855  3675 net.cpp:150] Setting up h_15_lstm2x_unit_15_1_split
I0521 09:36:45.654860  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.654865  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.654867  3675 net.cpp:165] Memory required for data: 33449984
I0521 09:36:45.654870  3675 layer_factory.hpp:77] Creating layer lstm2x_h_conted_15
I0521 09:36:45.654876  3675 net.cpp:100] Creating Layer lstm2x_h_conted_15
I0521 09:36:45.654881  3675 net.cpp:434] lstm2x_h_conted_15 <- h_15_lstm2x_unit_15_1_split_0
I0521 09:36:45.654886  3675 net.cpp:434] lstm2x_h_conted_15 <- cont_16_lstm2x_cont_slice_15_split_0
I0521 09:36:45.654891  3675 net.cpp:408] lstm2x_h_conted_15 -> h_conted_15
I0521 09:36:45.654947  3675 net.cpp:150] Setting up lstm2x_h_conted_15
I0521 09:36:45.654953  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.654955  3675 net.cpp:165] Memory required for data: 33501184
I0521 09:36:45.654959  3675 layer_factory.hpp:77] Creating layer lstm2x_transform_16
I0521 09:36:45.654965  3675 net.cpp:100] Creating Layer lstm2x_transform_16
I0521 09:36:45.654980  3675 net.cpp:434] lstm2x_transform_16 <- h_conted_15
I0521 09:36:45.654989  3675 net.cpp:408] lstm2x_transform_16 -> W_hc_h_15
I0521 09:36:45.655337  3675 net.cpp:150] Setting up lstm2x_transform_16
I0521 09:36:45.655349  3675 net.cpp:157] Top shape: 1 128 400 (51200)
I0521 09:36:45.655352  3675 net.cpp:165] Memory required for data: 33705984
I0521 09:36:45.655357  3675 net.cpp:493] Sharing parameters 'W_hc' owned by layer 'lstm2x_transform_1', param index 0
I0521 09:36:45.655361  3675 layer_factory.hpp:77] Creating layer lstm2x_gate_input_16
I0521 09:36:45.655367  3675 net.cpp:100] Creating Layer lstm2x_gate_input_16
I0521 09:36:45.655371  3675 net.cpp:434] lstm2x_gate_input_16 <- W_hc_h_15
I0521 09:36:45.655376  3675 net.cpp:434] lstm2x_gate_input_16 <- W_xc_x_16
I0521 09:36:45.655381  3675 net.cpp:408] lstm2x_gate_input_16 -> gate_input_16
I0521 09:36:45.655405  3675 net.cpp:150] Setting up lstm2x_gate_input_16
I0521 09:36:45.655411  3675 net.cpp:157] Top shape: 1 128 400 (51200)
I0521 09:36:45.655414  3675 net.cpp:165] Memory required for data: 33910784
I0521 09:36:45.655418  3675 layer_factory.hpp:77] Creating layer lstm2x_unit_16
I0521 09:36:45.655423  3675 net.cpp:100] Creating Layer lstm2x_unit_16
I0521 09:36:45.655427  3675 net.cpp:434] lstm2x_unit_16 <- c_15
I0521 09:36:45.655431  3675 net.cpp:434] lstm2x_unit_16 <- gate_input_16
I0521 09:36:45.655436  3675 net.cpp:434] lstm2x_unit_16 <- cont_16_lstm2x_cont_slice_15_split_1
I0521 09:36:45.655439  3675 net.cpp:408] lstm2x_unit_16 -> c_16
I0521 09:36:45.655445  3675 net.cpp:408] lstm2x_unit_16 -> h_16
I0521 09:36:45.655491  3675 net.cpp:150] Setting up lstm2x_unit_16
I0521 09:36:45.655498  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.655501  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.655505  3675 net.cpp:165] Memory required for data: 34013184
I0521 09:36:45.655508  3675 layer_factory.hpp:77] Creating layer lstm2x_
I0521 09:36:45.655514  3675 net.cpp:100] Creating Layer lstm2x_
I0521 09:36:45.655517  3675 net.cpp:434] lstm2x_ <- c_16
I0521 09:36:45.655522  3675 net.cpp:408] lstm2x_ -> c_T
I0521 09:36:45.655539  3675 net.cpp:150] Setting up lstm2x_
I0521 09:36:45.655544  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.655546  3675 net.cpp:165] Memory required for data: 34064384
I0521 09:36:45.655550  3675 layer_factory.hpp:77] Creating layer lstm2x_h_concat
I0521 09:36:45.655562  3675 net.cpp:100] Creating Layer lstm2x_h_concat
I0521 09:36:45.655566  3675 net.cpp:434] lstm2x_h_concat <- h_1_lstm2x_unit_1_1_split_1
I0521 09:36:45.655570  3675 net.cpp:434] lstm2x_h_concat <- h_2_lstm2x_unit_2_1_split_1
I0521 09:36:45.655575  3675 net.cpp:434] lstm2x_h_concat <- h_3_lstm2x_unit_3_1_split_1
I0521 09:36:45.655578  3675 net.cpp:434] lstm2x_h_concat <- h_4_lstm2x_unit_4_1_split_1
I0521 09:36:45.655582  3675 net.cpp:434] lstm2x_h_concat <- h_5_lstm2x_unit_5_1_split_1
I0521 09:36:45.655586  3675 net.cpp:434] lstm2x_h_concat <- h_6_lstm2x_unit_6_1_split_1
I0521 09:36:45.655591  3675 net.cpp:434] lstm2x_h_concat <- h_7_lstm2x_unit_7_1_split_1
I0521 09:36:45.655593  3675 net.cpp:434] lstm2x_h_concat <- h_8_lstm2x_unit_8_1_split_1
I0521 09:36:45.655597  3675 net.cpp:434] lstm2x_h_concat <- h_9_lstm2x_unit_9_1_split_1
I0521 09:36:45.655601  3675 net.cpp:434] lstm2x_h_concat <- h_10_lstm2x_unit_10_1_split_1
I0521 09:36:45.655606  3675 net.cpp:434] lstm2x_h_concat <- h_11_lstm2x_unit_11_1_split_1
I0521 09:36:45.655609  3675 net.cpp:434] lstm2x_h_concat <- h_12_lstm2x_unit_12_1_split_1
I0521 09:36:45.655612  3675 net.cpp:434] lstm2x_h_concat <- h_13_lstm2x_unit_13_1_split_1
I0521 09:36:45.655616  3675 net.cpp:434] lstm2x_h_concat <- h_14_lstm2x_unit_14_1_split_1
I0521 09:36:45.655619  3675 net.cpp:434] lstm2x_h_concat <- h_15_lstm2x_unit_15_1_split_1
I0521 09:36:45.655623  3675 net.cpp:434] lstm2x_h_concat <- h_16
I0521 09:36:45.655629  3675 net.cpp:408] lstm2x_h_concat -> h
I0521 09:36:45.655655  3675 net.cpp:150] Setting up lstm2x_h_concat
I0521 09:36:45.655660  3675 net.cpp:157] Top shape: 16 128 100 (204800)
I0521 09:36:45.655674  3675 net.cpp:165] Memory required for data: 34883584
I0521 09:36:45.655678  3675 layer_factory.hpp:77] Creating layer h_pseudoloss
I0521 09:36:45.655684  3675 net.cpp:100] Creating Layer h_pseudoloss
I0521 09:36:45.655688  3675 net.cpp:434] h_pseudoloss <- h
I0521 09:36:45.655692  3675 net.cpp:408] h_pseudoloss -> h_pseudoloss
I0521 09:36:45.655908  3675 net.cpp:150] Setting up h_pseudoloss
I0521 09:36:45.655920  3675 net.cpp:157] Top shape: (1)
I0521 09:36:45.655923  3675 net.cpp:160]     with loss weight 1
I0521 09:36:45.655944  3675 net.cpp:165] Memory required for data: 34883588
I0521 09:36:45.655948  3675 net.cpp:226] h_pseudoloss needs backward computation.
I0521 09:36:45.655956  3675 net.cpp:226] lstm2x_h_concat needs backward computation.
I0521 09:36:45.655966  3675 net.cpp:228] lstm2x_ does not need backward computation.
I0521 09:36:45.655969  3675 net.cpp:226] lstm2x_unit_16 needs backward computation.
I0521 09:36:45.655974  3675 net.cpp:226] lstm2x_gate_input_16 needs backward computation.
I0521 09:36:45.655978  3675 net.cpp:226] lstm2x_transform_16 needs backward computation.
I0521 09:36:45.655982  3675 net.cpp:226] lstm2x_h_conted_15 needs backward computation.
I0521 09:36:45.655987  3675 net.cpp:226] h_15_lstm2x_unit_15_1_split needs backward computation.
I0521 09:36:45.655990  3675 net.cpp:226] lstm2x_unit_15 needs backward computation.
I0521 09:36:45.655995  3675 net.cpp:226] lstm2x_gate_input_15 needs backward computation.
I0521 09:36:45.655999  3675 net.cpp:226] lstm2x_transform_15 needs backward computation.
I0521 09:36:45.656003  3675 net.cpp:226] lstm2x_h_conted_14 needs backward computation.
I0521 09:36:45.656008  3675 net.cpp:226] h_14_lstm2x_unit_14_1_split needs backward computation.
I0521 09:36:45.656011  3675 net.cpp:226] lstm2x_unit_14 needs backward computation.
I0521 09:36:45.656016  3675 net.cpp:226] lstm2x_gate_input_14 needs backward computation.
I0521 09:36:45.656020  3675 net.cpp:226] lstm2x_transform_14 needs backward computation.
I0521 09:36:45.656023  3675 net.cpp:226] lstm2x_h_conted_13 needs backward computation.
I0521 09:36:45.656028  3675 net.cpp:226] h_13_lstm2x_unit_13_1_split needs backward computation.
I0521 09:36:45.656033  3675 net.cpp:226] lstm2x_unit_13 needs backward computation.
I0521 09:36:45.656038  3675 net.cpp:226] lstm2x_gate_input_13 needs backward computation.
I0521 09:36:45.656041  3675 net.cpp:226] lstm2x_transform_13 needs backward computation.
I0521 09:36:45.656046  3675 net.cpp:226] lstm2x_h_conted_12 needs backward computation.
I0521 09:36:45.656051  3675 net.cpp:226] h_12_lstm2x_unit_12_1_split needs backward computation.
I0521 09:36:45.656055  3675 net.cpp:226] lstm2x_unit_12 needs backward computation.
I0521 09:36:45.656060  3675 net.cpp:226] lstm2x_gate_input_12 needs backward computation.
I0521 09:36:45.656065  3675 net.cpp:226] lstm2x_transform_12 needs backward computation.
I0521 09:36:45.656069  3675 net.cpp:226] lstm2x_h_conted_11 needs backward computation.
I0521 09:36:45.656075  3675 net.cpp:226] h_11_lstm2x_unit_11_1_split needs backward computation.
I0521 09:36:45.656078  3675 net.cpp:226] lstm2x_unit_11 needs backward computation.
I0521 09:36:45.656082  3675 net.cpp:226] lstm2x_gate_input_11 needs backward computation.
I0521 09:36:45.656086  3675 net.cpp:226] lstm2x_transform_11 needs backward computation.
I0521 09:36:45.656090  3675 net.cpp:226] lstm2x_h_conted_10 needs backward computation.
I0521 09:36:45.656095  3675 net.cpp:226] h_10_lstm2x_unit_10_1_split needs backward computation.
I0521 09:36:45.656098  3675 net.cpp:226] lstm2x_unit_10 needs backward computation.
I0521 09:36:45.656103  3675 net.cpp:226] lstm2x_gate_input_10 needs backward computation.
I0521 09:36:45.656107  3675 net.cpp:226] lstm2x_transform_10 needs backward computation.
I0521 09:36:45.656111  3675 net.cpp:226] lstm2x_h_conted_9 needs backward computation.
I0521 09:36:45.656116  3675 net.cpp:226] h_9_lstm2x_unit_9_1_split needs backward computation.
I0521 09:36:45.656121  3675 net.cpp:226] lstm2x_unit_9 needs backward computation.
I0521 09:36:45.656137  3675 net.cpp:226] lstm2x_gate_input_9 needs backward computation.
I0521 09:36:45.656142  3675 net.cpp:226] lstm2x_transform_9 needs backward computation.
I0521 09:36:45.656147  3675 net.cpp:226] lstm2x_h_conted_8 needs backward computation.
I0521 09:36:45.656150  3675 net.cpp:226] h_8_lstm2x_unit_8_1_split needs backward computation.
I0521 09:36:45.656154  3675 net.cpp:226] lstm2x_unit_8 needs backward computation.
I0521 09:36:45.656159  3675 net.cpp:226] lstm2x_gate_input_8 needs backward computation.
I0521 09:36:45.656163  3675 net.cpp:226] lstm2x_transform_8 needs backward computation.
I0521 09:36:45.656167  3675 net.cpp:226] lstm2x_h_conted_7 needs backward computation.
I0521 09:36:45.656172  3675 net.cpp:226] h_7_lstm2x_unit_7_1_split needs backward computation.
I0521 09:36:45.656177  3675 net.cpp:226] lstm2x_unit_7 needs backward computation.
I0521 09:36:45.656181  3675 net.cpp:226] lstm2x_gate_input_7 needs backward computation.
I0521 09:36:45.656186  3675 net.cpp:226] lstm2x_transform_7 needs backward computation.
I0521 09:36:45.656190  3675 net.cpp:226] lstm2x_h_conted_6 needs backward computation.
I0521 09:36:45.656195  3675 net.cpp:226] h_6_lstm2x_unit_6_1_split needs backward computation.
I0521 09:36:45.656199  3675 net.cpp:226] lstm2x_unit_6 needs backward computation.
I0521 09:36:45.656203  3675 net.cpp:226] lstm2x_gate_input_6 needs backward computation.
I0521 09:36:45.656208  3675 net.cpp:226] lstm2x_transform_6 needs backward computation.
I0521 09:36:45.656211  3675 net.cpp:226] lstm2x_h_conted_5 needs backward computation.
I0521 09:36:45.656216  3675 net.cpp:226] h_5_lstm2x_unit_5_1_split needs backward computation.
I0521 09:36:45.656220  3675 net.cpp:226] lstm2x_unit_5 needs backward computation.
I0521 09:36:45.656225  3675 net.cpp:226] lstm2x_gate_input_5 needs backward computation.
I0521 09:36:45.656229  3675 net.cpp:226] lstm2x_transform_5 needs backward computation.
I0521 09:36:45.656234  3675 net.cpp:226] lstm2x_h_conted_4 needs backward computation.
I0521 09:36:45.656239  3675 net.cpp:226] h_4_lstm2x_unit_4_1_split needs backward computation.
I0521 09:36:45.656242  3675 net.cpp:226] lstm2x_unit_4 needs backward computation.
I0521 09:36:45.656246  3675 net.cpp:226] lstm2x_gate_input_4 needs backward computation.
I0521 09:36:45.656250  3675 net.cpp:226] lstm2x_transform_4 needs backward computation.
I0521 09:36:45.656255  3675 net.cpp:226] lstm2x_h_conted_3 needs backward computation.
I0521 09:36:45.656260  3675 net.cpp:226] h_3_lstm2x_unit_3_1_split needs backward computation.
I0521 09:36:45.656265  3675 net.cpp:226] lstm2x_unit_3 needs backward computation.
I0521 09:36:45.656270  3675 net.cpp:226] lstm2x_gate_input_3 needs backward computation.
I0521 09:36:45.656273  3675 net.cpp:226] lstm2x_transform_3 needs backward computation.
I0521 09:36:45.656277  3675 net.cpp:226] lstm2x_h_conted_2 needs backward computation.
I0521 09:36:45.656281  3675 net.cpp:226] h_2_lstm2x_unit_2_1_split needs backward computation.
I0521 09:36:45.656286  3675 net.cpp:226] lstm2x_unit_2 needs backward computation.
I0521 09:36:45.656289  3675 net.cpp:226] lstm2x_gate_input_2 needs backward computation.
I0521 09:36:45.656296  3675 net.cpp:226] lstm2x_transform_2 needs backward computation.
I0521 09:36:45.656299  3675 net.cpp:226] lstm2x_h_conted_1 needs backward computation.
I0521 09:36:45.656304  3675 net.cpp:226] h_1_lstm2x_unit_1_1_split needs backward computation.
I0521 09:36:45.656309  3675 net.cpp:226] lstm2x_unit_1 needs backward computation.
I0521 09:36:45.656314  3675 net.cpp:226] lstm2x_gate_input_1 needs backward computation.
I0521 09:36:45.656319  3675 net.cpp:226] lstm2x_transform_1 needs backward computation.
I0521 09:36:45.656323  3675 net.cpp:228] lstm2x_h_conted_0 does not need backward computation.
I0521 09:36:45.656328  3675 net.cpp:226] lstm2x_W_xc_x_slice needs backward computation.
I0521 09:36:45.656333  3675 net.cpp:226] lstm2x_x_transform needs backward computation.
I0521 09:36:45.656338  3675 net.cpp:228] cont_16_lstm2x_cont_slice_15_split does not need backward computation.
I0521 09:36:45.656350  3675 net.cpp:228] cont_15_lstm2x_cont_slice_14_split does not need backward computation.
I0521 09:36:45.656355  3675 net.cpp:228] cont_14_lstm2x_cont_slice_13_split does not need backward computation.
I0521 09:36:45.656359  3675 net.cpp:228] cont_13_lstm2x_cont_slice_12_split does not need backward computation.
I0521 09:36:45.656363  3675 net.cpp:228] cont_12_lstm2x_cont_slice_11_split does not need backward computation.
I0521 09:36:45.656368  3675 net.cpp:228] cont_11_lstm2x_cont_slice_10_split does not need backward computation.
I0521 09:36:45.656371  3675 net.cpp:228] cont_10_lstm2x_cont_slice_9_split does not need backward computation.
I0521 09:36:45.656376  3675 net.cpp:228] cont_9_lstm2x_cont_slice_8_split does not need backward computation.
I0521 09:36:45.656381  3675 net.cpp:228] cont_8_lstm2x_cont_slice_7_split does not need backward computation.
I0521 09:36:45.656385  3675 net.cpp:228] cont_7_lstm2x_cont_slice_6_split does not need backward computation.
I0521 09:36:45.656389  3675 net.cpp:228] cont_6_lstm2x_cont_slice_5_split does not need backward computation.
I0521 09:36:45.656394  3675 net.cpp:228] cont_5_lstm2x_cont_slice_4_split does not need backward computation.
I0521 09:36:45.656399  3675 net.cpp:228] cont_4_lstm2x_cont_slice_3_split does not need backward computation.
I0521 09:36:45.656404  3675 net.cpp:228] cont_3_lstm2x_cont_slice_2_split does not need backward computation.
I0521 09:36:45.656409  3675 net.cpp:228] cont_2_lstm2x_cont_slice_1_split does not need backward computation.
I0521 09:36:45.656414  3675 net.cpp:228] cont_1_lstm2x_cont_slice_0_split does not need backward computation.
I0521 09:36:45.656421  3675 net.cpp:228] lstm2x_cont_slice does not need backward computation.
I0521 09:36:45.656425  3675 net.cpp:228] lstm2x_ does not need backward computation.
I0521 09:36:45.656430  3675 net.cpp:228] lstm2x_ does not need backward computation.
I0521 09:36:45.656432  3675 net.cpp:270] This network produces output c_T
I0521 09:36:45.656436  3675 net.cpp:270] This network produces output h_pseudoloss
I0521 09:36:45.656697  3675 net.cpp:283] Network initialization done.
I0521 09:36:45.656901  3675 recurrent_layer.cpp:150] Adding parameter 0: W_xc
I0521 09:36:45.656913  3675 recurrent_layer.cpp:150] Adding parameter 1: b_c
I0521 09:36:45.656915  3675 recurrent_layer.cpp:150] Adding parameter 2: W_hc
I0521 09:36:45.657238  3675 net.cpp:150] Setting up lstm2x
I0521 09:36:45.657250  3675 net.cpp:157] Top shape: 16 128 100 (204800)
I0521 09:36:45.657254  3675 net.cpp:165] Memory required for data: 1840049664
I0521 09:36:45.657263  3675 layer_factory.hpp:77] Creating layer lstm-reverse2
I0521 09:36:45.657270  3675 net.cpp:100] Creating Layer lstm-reverse2
I0521 09:36:45.657275  3675 net.cpp:434] lstm-reverse2 <- lstm2x
I0521 09:36:45.657281  3675 net.cpp:408] lstm-reverse2 -> rlstmx
I0521 09:36:45.657310  3675 net.cpp:150] Setting up lstm-reverse2
I0521 09:36:45.657315  3675 net.cpp:157] Top shape: 16 128 100 (204800)
I0521 09:36:45.657320  3675 net.cpp:165] Memory required for data: 1840868864
I0521 09:36:45.657323  3675 layer_factory.hpp:77] Creating layer lstm1x
I0521 09:36:45.657331  3675 net.cpp:100] Creating Layer lstm1x
I0521 09:36:45.657335  3675 net.cpp:434] lstm1x <- permuted_data_permuted_data_0_split_1
I0521 09:36:45.657341  3675 net.cpp:434] lstm1x <- indicator_indicator_0_split_1
I0521 09:36:45.657346  3675 net.cpp:408] lstm1x -> lstm1x
I0521 09:36:45.657357  3675 recurrent_layer.cpp:20] Initializing recurrent layer: assuming input batch contains 16 timesteps of 128 independent streams.
I0521 09:36:45.657896  3675 net.cpp:58] Initializing net from parameters: 
layer {
  name: "lstm1x_"
  type: "Input"
  top: "x"
  top: "cont"
  input_param {
    shape {
      dim: 16
      dim: 128
      dim: 512
      dim: 4
    }
    shape {
      dim: 16
      dim: 128
    }
  }
}
layer {
  name: "lstm1x_"
  type: "Input"
  top: "c_0"
  top: "h_0"
  input_param {
    shape {
      dim: 1
      dim: 128
      dim: 100
    }
    shape {
      dim: 1
      dim: 128
      dim: 100
    }
  }
}
layer {
  name: "lstm1x_cont_slice"
  type: "Slice"
  bottom: "cont"
  top: "cont_1"
  top: "cont_2"
  top: "cont_3"
  top: "cont_4"
  top: "cont_5"
  top: "cont_6"
  top: "cont_7"
  top: "cont_8"
  top: "cont_9"
  top: "cont_10"
  top: "cont_11"
  top: "cont_12"
  top: "cont_13"
  top: "cont_14"
  top: "cont_15"
  top: "cont_16"
  slice_param {
    axis: 0
  }
}
layer {
  name: "lstm1x_x_transform"
  type: "InnerProduct"
  bottom: "x"
  top: "W_xc_x"
  param {
    name: "W_xc"
  }
  param {
    name: "b_c"
  }
  propagate_down: true
  inner_product_param {
    num_output: 400
    bias_term: true
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    axis: 2
  }
}
layer {
  name: "lstm1x_W_xc_x_slice"
  type: "Slice"
  bottom: "W_xc_x"
  top: "W_xc_x_1"
  top: "W_xc_x_2"
  top: "W_xc_x_3"
  top: "W_xc_x_4"
  top: "W_xc_x_5"
  top: "W_xc_x_6"
  top: "W_xc_x_7"
  top: "W_xc_x_8"
  top: "W_xc_x_9"
  top: "W_xc_x_10"
  top: "W_xc_x_11"
  top: "W_xc_x_12"
  top: "W_xc_x_13"
  top: "W_xc_x_14"
  top: "W_xc_x_15"
  top: "W_xc_x_16"
  slice_param {
    axis: 0
  }
}
layer {
  name: "lstm1x_h_conted_0"
  type: "Scale"
  bottom: "h_0"
  bottom: "cont_1"
  top: "h_conted_0"
  scale_param {
    axis: 0
  }
}
layer {
  name: "lstm1x_transform_1"
  type: "InnerProduct"
  bottom: "h_conted_0"
  top: "W_hc_h_0"
  param {
    name: "W_hc"
  }
  inner_product_param {
    num_output: 400
    bias_term: false
    weight_filler {
      type: "xavier"
    }
    axis: 2
  }
}
layer {
  name: "lstm1x_gate_input_1"
  type: "Eltwise"
  bottom: "W_hc_h_0"
  bottom: "W_xc_x_1"
  top: "gate_input_1"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "lstm1x_unit_1"
  type: "LSTMUnit"
  bottom: "c_0"
  bottom: "gate_input_1"
  bottom: "cont_1"
  top: "c_1"
  top: "h_1"
}
layer {
  name: "lstm1x_h_conted_1"
  type: "Scale"
  bottom: "h_1"
  bottom: "cont_2"
  top: "h_conted_1"
  scale_param {
    axis: 0
  }
}
layer {
  name: "lstm1x_transform_2"
  type: "InnerProduct"
  bottom: "h_conted_1"
  top: "W_hc_h_1"
  param {
    name: "W_hc"
  }
  inner_product_param {
    num_output: 400
    bias_term: false
    weight_filler {
      type: "xavier"
    }
    axis: 2
  }
}
layer {
  name: "lstm1x_gate_input_2"
  type: "Eltwise"
  bottom: "W_hc_h_1"
  bottom: "W_xc_x_2"
  top: "gate_input_2"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "lstm1x_unit_2"
  type: "LSTMUnit"
  bottom: "c_1"
  bottom: "gate_input_2"
  bottom: "cont_2"
  top: "c_2"
  top: "h_2"
}
layer {
  name: "lstm1x_h_conted_2"
  type: "Scale"
  bottom: "h_2"
  bottom: "cont_3"
  top: "h_conted_2"
  scale_param {
    axis: 0
  }
}
layer {
  name: "lstm1x_transform_3"
  type: "InnerProduct"
  bottom: "h_conted_2"
  top: "W_hc_h_2"
  param {
    name: "W_hc"
  }
  inner_product_param {
    num_output: 400
    bias_term: false
    weight_filler {
      type: "xavier"
    }
    axis: 2
  }
}
layer {
  name: "lstm1x_gate_input_3"
  type: "Eltwise"
  bottom: "W_hc_h_2"
  bottom: "W_xc_x_3"
  top: "gate_input_3"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "lstm1x_unit_3"
  type: "LSTMUnit"
  bottom: "c_2"
  bottom: "gate_input_3"
  bottom: "cont_3"
  top: "c_3"
  top: "h_3"
}
layer {
  name: "lstm1x_h_conted_3"
  type: "Scale"
  bottom: "h_3"
  bottom: "cont_4"
  top: "h_conted_3"
  scale_param {
    axis: 0
  }
}
layer {
  name: "lstm1x_transform_4"
  type: "InnerProduct"
  bottom: "h_conted_3"
  top: "W_hc_h_3"
  param {
    name: "W_hc"
  }
  inner_product_param {
    num_output: 400
    bias_term: false
    weight_filler {
      type: "xavier"
    }
    axis: 2
  }
}
layer {
  name: "lstm1x_gate_input_4"
  type: "Eltwise"
  bottom: "W_hc_h_3"
  bottom: "W_xc_x_4"
  top: "gate_input_4"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "lstm1x_unit_4"
  type: "LSTMUnit"
  bottom: "c_3"
  bottom: "gate_input_4"
  bottom: "cont_4"
  top: "c_4"
  top: "h_4"
}
layer {
  name: "lstm1x_h_conted_4"
  type: "Scale"
  bottom: "h_4"
  bottom: "cont_5"
  top: "h_conted_4"
  scale_param {
    axis: 0
  }
}
layer {
  name: "lstm1x_transform_5"
  type: "InnerProduct"
  bottom: "h_conted_4"
  top: "W_hc_h_4"
  param {
    name: "W_hc"
  }
  inner_product_param {
    num_output: 400
    bias_term: false
    weight_filler {
      type: "xavier"
    }
    axis: 2
  }
}
layer {
  name: "lstm1x_gate_input_5"
  type: "Eltwise"
  bottom: "W_hc_h_4"
  bottom: "W_xc_x_5"
  top: "gate_input_5"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "lstm1x_unit_5"
  type: "LSTMUnit"
  bottom: "c_4"
  bottom: "gate_input_5"
  bottom: "cont_5"
  top: "c_5"
  top: "h_5"
}
layer {
  name: "lstm1x_h_conted_5"
  type: "Scale"
  bottom: "h_5"
  bottom: "cont_6"
  top: "h_conted_5"
  scale_param {
    axis: 0
  }
}
layer {
  name: "lstm1x_transform_6"
  type: "InnerProduct"
  bottom: "h_conted_5"
  top: "W_hc_h_5"
  param {
    name: "W_hc"
  }
  inner_product_param {
    num_output: 400
    bias_term: false
    weight_filler {
      type: "xavier"
    }
    axis: 2
  }
}
layer {
  name: "lstm1x_gate_input_6"
  type: "Eltwise"
  bottom: "W_hc_h_5"
  bottom: "W_xc_x_6"
  top: "gate_input_6"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "lstm1x_unit_6"
  type: "LSTMUnit"
  bottom: "c_5"
  bottom: "gate_input_6"
  bottom: "cont_6"
  top: "c_6"
  top: "h_6"
}
layer {
  name: "lstm1x_h_conted_6"
  type: "Scale"
  bottom: "h_6"
  bottom: "cont_7"
  top: "h_conted_6"
  scale_param {
    axis: 0
  }
}
layer {
  name: "lstm1x_transform_7"
  type: "InnerProduct"
  bottom: "h_conted_6"
  top: "W_hc_h_6"
  param {
    name: "W_hc"
  }
  inner_product_param {
    num_output: 400
    bias_term: false
    weight_filler {
      type: "xavier"
    }
    axis: 2
  }
}
layer {
  name: "lstm1x_gate_input_7"
  type: "Eltwise"
  bottom: "W_hc_h_6"
  bottom: "W_xc_x_7"
  top: "gate_input_7"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "lstm1x_unit_7"
  type: "LSTMUnit"
  bottom: "c_6"
  bottom: "gate_input_7"
  bottom: "cont_7"
  top: "c_7"
  top: "h_7"
}
layer {
  name: "lstm1x_h_conted_7"
  type: "Scale"
  bottom: "h_7"
  bottom: "cont_8"
  top: "h_conted_7"
  scale_param {
    axis: 0
  }
}
layer {
  name: "lstm1x_transform_8"
  type: "InnerProduct"
  bottom: "h_conted_7"
  top: "W_hc_h_7"
  param {
    name: "W_hc"
  }
  inner_product_param {
    num_output: 400
    bias_term: false
    weight_filler {
      type: "xavier"
    }
    axis: 2
  }
}
layer {
  name: "lstm1x_gate_input_8"
  type: "Eltwise"
  bottom: "W_hc_h_7"
  bottom: "W_xc_x_8"
  top: "gate_input_8"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "lstm1x_unit_8"
  type: "LSTMUnit"
  bottom: "c_7"
  bottom: "gate_input_8"
  bottom: "cont_8"
  top: "c_8"
  top: "h_8"
}
layer {
  name: "lstm1x_h_conted_8"
  type: "Scale"
  bottom: "h_8"
  bottom: "cont_9"
  top: "h_conted_8"
  scale_param {
    axis: 0
  }
}
layer {
  name: "lstm1x_transform_9"
  type: "InnerProduct"
  bottom: "h_conted_8"
  top: "W_hc_h_8"
  param {
    name: "W_hc"
  }
  inner_product_param {
    num_output: 400
    bias_term: false
    weight_filler {
      type: "xavier"
    }
    axis: 2
  }
}
layer {
  name: "lstm1x_gate_input_9"
  type: "Eltwise"
  bottom: "W_hc_h_8"
  bottom: "W_xc_x_9"
  top: "gate_input_9"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "lstm1x_unit_9"
  type: "LSTMUnit"
  bottom: "c_8"
  bottom: "gate_input_9"
  bottom: "cont_9"
  top: "c_9"
  top: "h_9"
}
layer {
  name: "lstm1x_h_conted_9"
  type: "Scale"
  bottom: "h_9"
  bottom: "cont_10"
  top: "h_conted_9"
  scale_param {
    axis: 0
  }
}
layer {
  name: "lstm1x_transform_10"
  type: "InnerProduct"
  bottom: "h_conted_9"
  top: "W_hc_h_9"
  param {
    name: "W_hc"
  }
  inner_product_param {
    num_output: 400
    bias_term: false
    weight_filler {
      type: "xavier"
    }
    axis: 2
  }
}
layer {
  name: "lstm1x_gate_input_10"
  type: "Eltwise"
  bottom: "W_hc_h_9"
  bottom: "W_xc_x_10"
  top: "gate_input_10"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "lstm1x_unit_10"
  type: "LSTMUnit"
  bottom: "c_9"
  bottom: "gate_input_10"
  bottom: "cont_10"
  top: "c_10"
  top: "h_10"
}
layer {
  name: "lstm1x_h_conted_10"
  type: "Scale"
  bottom: "h_10"
  bottom: "cont_11"
  top: "h_conted_10"
  scale_param {
    axis: 0
  }
}
layer {
  name: "lstm1x_transform_11"
  type: "InnerProduct"
  bottom: "h_conted_10"
  top: "W_hc_h_10"
  param {
    name: "W_hc"
  }
  inner_product_param {
    num_output: 400
    bias_term: false
    weight_filler {
      type: "xavier"
    }
    axis: 2
  }
}
layer {
  name: "lstm1x_gate_input_11"
  type: "Eltwise"
  bottom: "W_hc_h_10"
  bottom: "W_xc_x_11"
  top: "gate_input_11"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "lstm1x_unit_11"
  type: "LSTMUnit"
  bottom: "c_10"
  bottom: "gate_input_11"
  bottom: "cont_11"
  top: "c_11"
  top: "h_11"
}
layer {
  name: "lstm1x_h_conted_11"
  type: "Scale"
  bottom: "h_11"
  bottom: "cont_12"
  top: "h_conted_11"
  scale_param {
    axis: 0
  }
}
layer {
  name: "lstm1x_transform_12"
  type: "InnerProduct"
  bottom: "h_conted_11"
  top: "W_hc_h_11"
  param {
    name: "W_hc"
  }
  inner_product_param {
    num_output: 400
    bias_term: false
    weight_filler {
      type: "xavier"
    }
    axis: 2
  }
}
layer {
  name: "lstm1x_gate_input_12"
  type: "Eltwise"
  bottom: "W_hc_h_11"
  bottom: "W_xc_x_12"
  top: "gate_input_12"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "lstm1x_unit_12"
  type: "LSTMUnit"
  bottom: "c_11"
  bottom: "gate_input_12"
  bottom: "cont_12"
  top: "c_12"
  top: "h_12"
}
layer {
  name: "lstm1x_h_conted_12"
  type: "Scale"
  bottom: "h_12"
  bottom: "cont_13"
  top: "h_conted_12"
  scale_param {
    axis: 0
  }
}
layer {
  name: "lstm1x_transform_13"
  type: "InnerProduct"
  bottom: "h_conted_12"
  top: "W_hc_h_12"
  param {
    name: "W_hc"
  }
  inner_product_param {
    num_output: 400
    bias_term: false
    weight_filler {
      type: "xavier"
    }
    axis: 2
  }
}
layer {
  name: "lstm1x_gate_input_13"
  type: "Eltwise"
  bottom: "W_hc_h_12"
  bottom: "W_xc_x_13"
  top: "gate_input_13"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "lstm1x_unit_13"
  type: "LSTMUnit"
  bottom: "c_12"
  bottom: "gate_input_13"
  bottom: "cont_13"
  top: "c_13"
  top: "h_13"
}
layer {
  name: "lstm1x_h_conted_13"
  type: "Scale"
  bottom: "h_13"
  bottom: "cont_14"
  top: "h_conted_13"
  scale_param {
    axis: 0
  }
}
layer {
  name: "lstm1x_transform_14"
  type: "InnerProduct"
  bottom: "h_conted_13"
  top: "W_hc_h_13"
  param {
    name: "W_hc"
  }
  inner_product_param {
    num_output: 400
    bias_term: false
    weight_filler {
      type: "xavier"
    }
    axis: 2
  }
}
layer {
  name: "lstm1x_gate_input_14"
  type: "Eltwise"
  bottom: "W_hc_h_13"
  bottom: "W_xc_x_14"
  top: "gate_input_14"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "lstm1x_unit_14"
  type: "LSTMUnit"
  bottom: "c_13"
  bottom: "gate_input_14"
  bottom: "cont_14"
  top: "c_14"
  top: "h_14"
}
layer {
  name: "lstm1x_h_conted_14"
  type: "Scale"
  bottom: "h_14"
  bottom: "cont_15"
  top: "h_conted_14"
  scale_param {
    axis: 0
  }
}
layer {
  name: "lstm1x_transform_15"
  type: "InnerProduct"
  bottom: "h_conted_14"
  top: "W_hc_h_14"
  param {
    name: "W_hc"
  }
  inner_product_param {
    num_output: 400
    bias_term: false
    weight_filler {
      type: "xavier"
    }
    axis: 2
  }
}
layer {
  name: "lstm1x_gate_input_15"
  type: "Eltwise"
  bottom: "W_hc_h_14"
  bottom: "W_xc_x_15"
  top: "gate_input_15"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "lstm1x_unit_15"
  type: "LSTMUnit"
  bottom: "c_14"
  bottom: "gate_input_15"
  bottom: "cont_15"
  top: "c_15"
  top: "h_15"
}
layer {
  name: "lstm1x_h_conted_15"
  type: "Scale"
  bottom: "h_15"
  bottom: "cont_16"
  top: "h_conted_15"
  scale_param {
    axis: 0
  }
}
layer {
  name: "lstm1x_transform_16"
  type: "InnerProduct"
  bottom: "h_conted_15"
  top: "W_hc_h_15"
  param {
    name: "W_hc"
  }
  inner_product_param {
    num_output: 400
    bias_term: false
    weight_filler {
      type: "xavier"
    }
    axis: 2
  }
}
layer {
  name: "lstm1x_gate_input_16"
  type: "Eltwise"
  bottom: "W_hc_h_15"
  bottom: "W_xc_x_16"
  top: "gate_input_16"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "lstm1x_unit_16"
  type: "LSTMUnit"
  bottom: "c_15"
  bottom: "gate_input_16"
  bottom: "cont_16"
  top: "c_16"
  top: "h_16"
}
layer {
  name: "lstm1x_"
  type: "Split"
  bottom: "c_16"
  top: "c_T"
}
layer {
  name: "lstm1x_h_concat"
  type: "Concat"
  bottom: "h_1"
  bottom: "h_2"
  bottom: "h_3"
  bottom: "h_4"
  bottom: "h_5"
  bottom: "h_6"
  bottom: "h_7"
  bottom: "h_8"
  bottom: "h_9"
  bottom: "h_10"
  bottom: "h_11"
  bottom: "h_12"
  bottom: "h_13"
  bottom: "h_14"
  bottom: "h_15"
  bottom: "h_16"
  top: "h"
  concat_param {
    axis: 0
  }
}
layer {
  name: "h_pseudoloss"
  type: "Reduction"
  bottom: "h"
  top: "h_pseudoloss"
  loss_weight: 1
}
I0521 09:36:45.658396  3675 layer_factory.hpp:77] Creating layer lstm1x_
I0521 09:36:45.658408  3675 net.cpp:100] Creating Layer lstm1x_
I0521 09:36:45.658414  3675 net.cpp:408] lstm1x_ -> x
I0521 09:36:45.658422  3675 net.cpp:408] lstm1x_ -> cont
I0521 09:36:45.658475  3675 net.cpp:150] Setting up lstm1x_
I0521 09:36:45.658481  3675 net.cpp:157] Top shape: 16 128 512 4 (4194304)
I0521 09:36:45.658485  3675 net.cpp:157] Top shape: 16 128 (2048)
I0521 09:36:45.658488  3675 net.cpp:165] Memory required for data: 16785408
I0521 09:36:45.658491  3675 layer_factory.hpp:77] Creating layer lstm1x_
I0521 09:36:45.658496  3675 net.cpp:100] Creating Layer lstm1x_
I0521 09:36:45.658501  3675 net.cpp:408] lstm1x_ -> c_0
I0521 09:36:45.658507  3675 net.cpp:408] lstm1x_ -> h_0
I0521 09:36:45.658538  3675 net.cpp:150] Setting up lstm1x_
I0521 09:36:45.658542  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.658547  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.658550  3675 net.cpp:165] Memory required for data: 16887808
I0521 09:36:45.658553  3675 layer_factory.hpp:77] Creating layer lstm1x_cont_slice
I0521 09:36:45.658560  3675 net.cpp:100] Creating Layer lstm1x_cont_slice
I0521 09:36:45.658562  3675 net.cpp:434] lstm1x_cont_slice <- cont
I0521 09:36:45.658568  3675 net.cpp:408] lstm1x_cont_slice -> cont_1
I0521 09:36:45.658576  3675 net.cpp:408] lstm1x_cont_slice -> cont_2
I0521 09:36:45.658582  3675 net.cpp:408] lstm1x_cont_slice -> cont_3
I0521 09:36:45.658588  3675 net.cpp:408] lstm1x_cont_slice -> cont_4
I0521 09:36:45.658593  3675 net.cpp:408] lstm1x_cont_slice -> cont_5
I0521 09:36:45.658601  3675 net.cpp:408] lstm1x_cont_slice -> cont_6
I0521 09:36:45.658607  3675 net.cpp:408] lstm1x_cont_slice -> cont_7
I0521 09:36:45.658612  3675 net.cpp:408] lstm1x_cont_slice -> cont_8
I0521 09:36:45.658617  3675 net.cpp:408] lstm1x_cont_slice -> cont_9
I0521 09:36:45.658623  3675 net.cpp:408] lstm1x_cont_slice -> cont_10
I0521 09:36:45.658629  3675 net.cpp:408] lstm1x_cont_slice -> cont_11
I0521 09:36:45.658635  3675 net.cpp:408] lstm1x_cont_slice -> cont_12
I0521 09:36:45.658641  3675 net.cpp:408] lstm1x_cont_slice -> cont_13
I0521 09:36:45.658648  3675 net.cpp:408] lstm1x_cont_slice -> cont_14
I0521 09:36:45.658653  3675 net.cpp:408] lstm1x_cont_slice -> cont_15
I0521 09:36:45.658659  3675 net.cpp:408] lstm1x_cont_slice -> cont_16
I0521 09:36:45.658844  3675 net.cpp:150] Setting up lstm1x_cont_slice
I0521 09:36:45.658854  3675 net.cpp:157] Top shape: 1 128 (128)
I0521 09:36:45.658859  3675 net.cpp:157] Top shape: 1 128 (128)
I0521 09:36:45.658862  3675 net.cpp:157] Top shape: 1 128 (128)
I0521 09:36:45.658866  3675 net.cpp:157] Top shape: 1 128 (128)
I0521 09:36:45.658870  3675 net.cpp:157] Top shape: 1 128 (128)
I0521 09:36:45.658874  3675 net.cpp:157] Top shape: 1 128 (128)
I0521 09:36:45.660962  3675 net.cpp:157] Top shape: 1 128 (128)
I0521 09:36:45.660974  3675 net.cpp:157] Top shape: 1 128 (128)
I0521 09:36:45.660979  3675 net.cpp:157] Top shape: 1 128 (128)
I0521 09:36:45.660984  3675 net.cpp:157] Top shape: 1 128 (128)
I0521 09:36:45.660987  3675 net.cpp:157] Top shape: 1 128 (128)
I0521 09:36:45.660991  3675 net.cpp:157] Top shape: 1 128 (128)
I0521 09:36:45.660995  3675 net.cpp:157] Top shape: 1 128 (128)
I0521 09:36:45.661020  3675 net.cpp:157] Top shape: 1 128 (128)
I0521 09:36:45.661025  3675 net.cpp:157] Top shape: 1 128 (128)
I0521 09:36:45.661027  3675 net.cpp:157] Top shape: 1 128 (128)
I0521 09:36:45.661031  3675 net.cpp:165] Memory required for data: 16896000
I0521 09:36:45.661036  3675 layer_factory.hpp:77] Creating layer cont_1_lstm1x_cont_slice_0_split
I0521 09:36:45.661046  3675 net.cpp:100] Creating Layer cont_1_lstm1x_cont_slice_0_split
I0521 09:36:45.661051  3675 net.cpp:434] cont_1_lstm1x_cont_slice_0_split <- cont_1
I0521 09:36:45.661058  3675 net.cpp:408] cont_1_lstm1x_cont_slice_0_split -> cont_1_lstm1x_cont_slice_0_split_0
I0521 09:36:45.661067  3675 net.cpp:408] cont_1_lstm1x_cont_slice_0_split -> cont_1_lstm1x_cont_slice_0_split_1
I0521 09:36:45.661128  3675 net.cpp:150] Setting up cont_1_lstm1x_cont_slice_0_split
I0521 09:36:45.661134  3675 net.cpp:157] Top shape: 1 128 (128)
I0521 09:36:45.661137  3675 net.cpp:157] Top shape: 1 128 (128)
I0521 09:36:45.661140  3675 net.cpp:165] Memory required for data: 16897024
I0521 09:36:45.661144  3675 layer_factory.hpp:77] Creating layer cont_2_lstm1x_cont_slice_1_split
I0521 09:36:45.661150  3675 net.cpp:100] Creating Layer cont_2_lstm1x_cont_slice_1_split
I0521 09:36:45.661154  3675 net.cpp:434] cont_2_lstm1x_cont_slice_1_split <- cont_2
I0521 09:36:45.661159  3675 net.cpp:408] cont_2_lstm1x_cont_slice_1_split -> cont_2_lstm1x_cont_slice_1_split_0
I0521 09:36:45.661165  3675 net.cpp:408] cont_2_lstm1x_cont_slice_1_split -> cont_2_lstm1x_cont_slice_1_split_1
I0521 09:36:45.661197  3675 net.cpp:150] Setting up cont_2_lstm1x_cont_slice_1_split
I0521 09:36:45.661202  3675 net.cpp:157] Top shape: 1 128 (128)
I0521 09:36:45.661206  3675 net.cpp:157] Top shape: 1 128 (128)
I0521 09:36:45.661209  3675 net.cpp:165] Memory required for data: 16898048
I0521 09:36:45.661213  3675 layer_factory.hpp:77] Creating layer cont_3_lstm1x_cont_slice_2_split
I0521 09:36:45.661218  3675 net.cpp:100] Creating Layer cont_3_lstm1x_cont_slice_2_split
I0521 09:36:45.661222  3675 net.cpp:434] cont_3_lstm1x_cont_slice_2_split <- cont_3
I0521 09:36:45.661228  3675 net.cpp:408] cont_3_lstm1x_cont_slice_2_split -> cont_3_lstm1x_cont_slice_2_split_0
I0521 09:36:45.661233  3675 net.cpp:408] cont_3_lstm1x_cont_slice_2_split -> cont_3_lstm1x_cont_slice_2_split_1
I0521 09:36:45.661264  3675 net.cpp:150] Setting up cont_3_lstm1x_cont_slice_2_split
I0521 09:36:45.661269  3675 net.cpp:157] Top shape: 1 128 (128)
I0521 09:36:45.661273  3675 net.cpp:157] Top shape: 1 128 (128)
I0521 09:36:45.661276  3675 net.cpp:165] Memory required for data: 16899072
I0521 09:36:45.661280  3675 layer_factory.hpp:77] Creating layer cont_4_lstm1x_cont_slice_3_split
I0521 09:36:45.661285  3675 net.cpp:100] Creating Layer cont_4_lstm1x_cont_slice_3_split
I0521 09:36:45.661289  3675 net.cpp:434] cont_4_lstm1x_cont_slice_3_split <- cont_4
I0521 09:36:45.661294  3675 net.cpp:408] cont_4_lstm1x_cont_slice_3_split -> cont_4_lstm1x_cont_slice_3_split_0
I0521 09:36:45.661301  3675 net.cpp:408] cont_4_lstm1x_cont_slice_3_split -> cont_4_lstm1x_cont_slice_3_split_1
I0521 09:36:45.661331  3675 net.cpp:150] Setting up cont_4_lstm1x_cont_slice_3_split
I0521 09:36:45.661336  3675 net.cpp:157] Top shape: 1 128 (128)
I0521 09:36:45.661340  3675 net.cpp:157] Top shape: 1 128 (128)
I0521 09:36:45.661345  3675 net.cpp:165] Memory required for data: 16900096
I0521 09:36:45.661347  3675 layer_factory.hpp:77] Creating layer cont_5_lstm1x_cont_slice_4_split
I0521 09:36:45.661353  3675 net.cpp:100] Creating Layer cont_5_lstm1x_cont_slice_4_split
I0521 09:36:45.661357  3675 net.cpp:434] cont_5_lstm1x_cont_slice_4_split <- cont_5
I0521 09:36:45.661363  3675 net.cpp:408] cont_5_lstm1x_cont_slice_4_split -> cont_5_lstm1x_cont_slice_4_split_0
I0521 09:36:45.661370  3675 net.cpp:408] cont_5_lstm1x_cont_slice_4_split -> cont_5_lstm1x_cont_slice_4_split_1
I0521 09:36:45.661399  3675 net.cpp:150] Setting up cont_5_lstm1x_cont_slice_4_split
I0521 09:36:45.661404  3675 net.cpp:157] Top shape: 1 128 (128)
I0521 09:36:45.661408  3675 net.cpp:157] Top shape: 1 128 (128)
I0521 09:36:45.661424  3675 net.cpp:165] Memory required for data: 16901120
I0521 09:36:45.661428  3675 layer_factory.hpp:77] Creating layer cont_6_lstm1x_cont_slice_5_split
I0521 09:36:45.661435  3675 net.cpp:100] Creating Layer cont_6_lstm1x_cont_slice_5_split
I0521 09:36:45.661438  3675 net.cpp:434] cont_6_lstm1x_cont_slice_5_split <- cont_6
I0521 09:36:45.661444  3675 net.cpp:408] cont_6_lstm1x_cont_slice_5_split -> cont_6_lstm1x_cont_slice_5_split_0
I0521 09:36:45.661453  3675 net.cpp:408] cont_6_lstm1x_cont_slice_5_split -> cont_6_lstm1x_cont_slice_5_split_1
I0521 09:36:45.661482  3675 net.cpp:150] Setting up cont_6_lstm1x_cont_slice_5_split
I0521 09:36:45.661489  3675 net.cpp:157] Top shape: 1 128 (128)
I0521 09:36:45.661492  3675 net.cpp:157] Top shape: 1 128 (128)
I0521 09:36:45.661495  3675 net.cpp:165] Memory required for data: 16902144
I0521 09:36:45.661499  3675 layer_factory.hpp:77] Creating layer cont_7_lstm1x_cont_slice_6_split
I0521 09:36:45.661507  3675 net.cpp:100] Creating Layer cont_7_lstm1x_cont_slice_6_split
I0521 09:36:45.661511  3675 net.cpp:434] cont_7_lstm1x_cont_slice_6_split <- cont_7
I0521 09:36:45.661516  3675 net.cpp:408] cont_7_lstm1x_cont_slice_6_split -> cont_7_lstm1x_cont_slice_6_split_0
I0521 09:36:45.661525  3675 net.cpp:408] cont_7_lstm1x_cont_slice_6_split -> cont_7_lstm1x_cont_slice_6_split_1
I0521 09:36:45.661556  3675 net.cpp:150] Setting up cont_7_lstm1x_cont_slice_6_split
I0521 09:36:45.661561  3675 net.cpp:157] Top shape: 1 128 (128)
I0521 09:36:45.661564  3675 net.cpp:157] Top shape: 1 128 (128)
I0521 09:36:45.661567  3675 net.cpp:165] Memory required for data: 16903168
I0521 09:36:45.661571  3675 layer_factory.hpp:77] Creating layer cont_8_lstm1x_cont_slice_7_split
I0521 09:36:45.661577  3675 net.cpp:100] Creating Layer cont_8_lstm1x_cont_slice_7_split
I0521 09:36:45.661581  3675 net.cpp:434] cont_8_lstm1x_cont_slice_7_split <- cont_8
I0521 09:36:45.661586  3675 net.cpp:408] cont_8_lstm1x_cont_slice_7_split -> cont_8_lstm1x_cont_slice_7_split_0
I0521 09:36:45.661593  3675 net.cpp:408] cont_8_lstm1x_cont_slice_7_split -> cont_8_lstm1x_cont_slice_7_split_1
I0521 09:36:45.661622  3675 net.cpp:150] Setting up cont_8_lstm1x_cont_slice_7_split
I0521 09:36:45.661628  3675 net.cpp:157] Top shape: 1 128 (128)
I0521 09:36:45.661631  3675 net.cpp:157] Top shape: 1 128 (128)
I0521 09:36:45.661635  3675 net.cpp:165] Memory required for data: 16904192
I0521 09:36:45.661639  3675 layer_factory.hpp:77] Creating layer cont_9_lstm1x_cont_slice_8_split
I0521 09:36:45.661644  3675 net.cpp:100] Creating Layer cont_9_lstm1x_cont_slice_8_split
I0521 09:36:45.661648  3675 net.cpp:434] cont_9_lstm1x_cont_slice_8_split <- cont_9
I0521 09:36:45.661653  3675 net.cpp:408] cont_9_lstm1x_cont_slice_8_split -> cont_9_lstm1x_cont_slice_8_split_0
I0521 09:36:45.661660  3675 net.cpp:408] cont_9_lstm1x_cont_slice_8_split -> cont_9_lstm1x_cont_slice_8_split_1
I0521 09:36:45.661698  3675 net.cpp:150] Setting up cont_9_lstm1x_cont_slice_8_split
I0521 09:36:45.661705  3675 net.cpp:157] Top shape: 1 128 (128)
I0521 09:36:45.661710  3675 net.cpp:157] Top shape: 1 128 (128)
I0521 09:36:45.661712  3675 net.cpp:165] Memory required for data: 16905216
I0521 09:36:45.661716  3675 layer_factory.hpp:77] Creating layer cont_10_lstm1x_cont_slice_9_split
I0521 09:36:45.661723  3675 net.cpp:100] Creating Layer cont_10_lstm1x_cont_slice_9_split
I0521 09:36:45.661727  3675 net.cpp:434] cont_10_lstm1x_cont_slice_9_split <- cont_10
I0521 09:36:45.662950  3675 net.cpp:408] cont_10_lstm1x_cont_slice_9_split -> cont_10_lstm1x_cont_slice_9_split_0
I0521 09:36:45.662966  3675 net.cpp:408] cont_10_lstm1x_cont_slice_9_split -> cont_10_lstm1x_cont_slice_9_split_1
I0521 09:36:45.663031  3675 net.cpp:150] Setting up cont_10_lstm1x_cont_slice_9_split
I0521 09:36:45.663038  3675 net.cpp:157] Top shape: 1 128 (128)
I0521 09:36:45.663043  3675 net.cpp:157] Top shape: 1 128 (128)
I0521 09:36:45.663048  3675 net.cpp:165] Memory required for data: 16906240
I0521 09:36:45.663051  3675 layer_factory.hpp:77] Creating layer cont_11_lstm1x_cont_slice_10_split
I0521 09:36:45.663074  3675 net.cpp:100] Creating Layer cont_11_lstm1x_cont_slice_10_split
I0521 09:36:45.663079  3675 net.cpp:434] cont_11_lstm1x_cont_slice_10_split <- cont_11
I0521 09:36:45.663084  3675 net.cpp:408] cont_11_lstm1x_cont_slice_10_split -> cont_11_lstm1x_cont_slice_10_split_0
I0521 09:36:45.663094  3675 net.cpp:408] cont_11_lstm1x_cont_slice_10_split -> cont_11_lstm1x_cont_slice_10_split_1
I0521 09:36:45.663128  3675 net.cpp:150] Setting up cont_11_lstm1x_cont_slice_10_split
I0521 09:36:45.663133  3675 net.cpp:157] Top shape: 1 128 (128)
I0521 09:36:45.663138  3675 net.cpp:157] Top shape: 1 128 (128)
I0521 09:36:45.663142  3675 net.cpp:165] Memory required for data: 16907264
I0521 09:36:45.663146  3675 layer_factory.hpp:77] Creating layer cont_12_lstm1x_cont_slice_11_split
I0521 09:36:45.663152  3675 net.cpp:100] Creating Layer cont_12_lstm1x_cont_slice_11_split
I0521 09:36:45.663157  3675 net.cpp:434] cont_12_lstm1x_cont_slice_11_split <- cont_12
I0521 09:36:45.663162  3675 net.cpp:408] cont_12_lstm1x_cont_slice_11_split -> cont_12_lstm1x_cont_slice_11_split_0
I0521 09:36:45.663168  3675 net.cpp:408] cont_12_lstm1x_cont_slice_11_split -> cont_12_lstm1x_cont_slice_11_split_1
I0521 09:36:45.663202  3675 net.cpp:150] Setting up cont_12_lstm1x_cont_slice_11_split
I0521 09:36:45.663205  3675 net.cpp:157] Top shape: 1 128 (128)
I0521 09:36:45.663210  3675 net.cpp:157] Top shape: 1 128 (128)
I0521 09:36:45.663213  3675 net.cpp:165] Memory required for data: 16908288
I0521 09:36:45.663218  3675 layer_factory.hpp:77] Creating layer cont_13_lstm1x_cont_slice_12_split
I0521 09:36:45.663223  3675 net.cpp:100] Creating Layer cont_13_lstm1x_cont_slice_12_split
I0521 09:36:45.663228  3675 net.cpp:434] cont_13_lstm1x_cont_slice_12_split <- cont_13
I0521 09:36:45.663233  3675 net.cpp:408] cont_13_lstm1x_cont_slice_12_split -> cont_13_lstm1x_cont_slice_12_split_0
I0521 09:36:45.663239  3675 net.cpp:408] cont_13_lstm1x_cont_slice_12_split -> cont_13_lstm1x_cont_slice_12_split_1
I0521 09:36:45.663272  3675 net.cpp:150] Setting up cont_13_lstm1x_cont_slice_12_split
I0521 09:36:45.663277  3675 net.cpp:157] Top shape: 1 128 (128)
I0521 09:36:45.663282  3675 net.cpp:157] Top shape: 1 128 (128)
I0521 09:36:45.663285  3675 net.cpp:165] Memory required for data: 16909312
I0521 09:36:45.663290  3675 layer_factory.hpp:77] Creating layer cont_14_lstm1x_cont_slice_13_split
I0521 09:36:45.663297  3675 net.cpp:100] Creating Layer cont_14_lstm1x_cont_slice_13_split
I0521 09:36:45.663301  3675 net.cpp:434] cont_14_lstm1x_cont_slice_13_split <- cont_14
I0521 09:36:45.663307  3675 net.cpp:408] cont_14_lstm1x_cont_slice_13_split -> cont_14_lstm1x_cont_slice_13_split_0
I0521 09:36:45.663313  3675 net.cpp:408] cont_14_lstm1x_cont_slice_13_split -> cont_14_lstm1x_cont_slice_13_split_1
I0521 09:36:45.663347  3675 net.cpp:150] Setting up cont_14_lstm1x_cont_slice_13_split
I0521 09:36:45.663352  3675 net.cpp:157] Top shape: 1 128 (128)
I0521 09:36:45.663357  3675 net.cpp:157] Top shape: 1 128 (128)
I0521 09:36:45.663360  3675 net.cpp:165] Memory required for data: 16910336
I0521 09:36:45.663364  3675 layer_factory.hpp:77] Creating layer cont_15_lstm1x_cont_slice_14_split
I0521 09:36:45.663369  3675 net.cpp:100] Creating Layer cont_15_lstm1x_cont_slice_14_split
I0521 09:36:45.663374  3675 net.cpp:434] cont_15_lstm1x_cont_slice_14_split <- cont_15
I0521 09:36:45.663379  3675 net.cpp:408] cont_15_lstm1x_cont_slice_14_split -> cont_15_lstm1x_cont_slice_14_split_0
I0521 09:36:45.663386  3675 net.cpp:408] cont_15_lstm1x_cont_slice_14_split -> cont_15_lstm1x_cont_slice_14_split_1
I0521 09:36:45.663419  3675 net.cpp:150] Setting up cont_15_lstm1x_cont_slice_14_split
I0521 09:36:45.663424  3675 net.cpp:157] Top shape: 1 128 (128)
I0521 09:36:45.663437  3675 net.cpp:157] Top shape: 1 128 (128)
I0521 09:36:45.663440  3675 net.cpp:165] Memory required for data: 16911360
I0521 09:36:45.663444  3675 layer_factory.hpp:77] Creating layer cont_16_lstm1x_cont_slice_15_split
I0521 09:36:45.663450  3675 net.cpp:100] Creating Layer cont_16_lstm1x_cont_slice_15_split
I0521 09:36:45.663465  3675 net.cpp:434] cont_16_lstm1x_cont_slice_15_split <- cont_16
I0521 09:36:45.663471  3675 net.cpp:408] cont_16_lstm1x_cont_slice_15_split -> cont_16_lstm1x_cont_slice_15_split_0
I0521 09:36:45.663477  3675 net.cpp:408] cont_16_lstm1x_cont_slice_15_split -> cont_16_lstm1x_cont_slice_15_split_1
I0521 09:36:45.663506  3675 net.cpp:150] Setting up cont_16_lstm1x_cont_slice_15_split
I0521 09:36:45.663511  3675 net.cpp:157] Top shape: 1 128 (128)
I0521 09:36:45.663516  3675 net.cpp:157] Top shape: 1 128 (128)
I0521 09:36:45.663518  3675 net.cpp:165] Memory required for data: 16912384
I0521 09:36:45.663522  3675 layer_factory.hpp:77] Creating layer lstm1x_x_transform
I0521 09:36:45.663532  3675 net.cpp:100] Creating Layer lstm1x_x_transform
I0521 09:36:45.663535  3675 net.cpp:434] lstm1x_x_transform <- x
I0521 09:36:45.663542  3675 net.cpp:408] lstm1x_x_transform -> W_xc_x
I0521 09:36:45.670774  3675 net.cpp:150] Setting up lstm1x_x_transform
I0521 09:36:45.670805  3675 net.cpp:157] Top shape: 16 128 400 (819200)
I0521 09:36:45.670810  3675 net.cpp:165] Memory required for data: 20189184
I0521 09:36:45.670826  3675 layer_factory.hpp:77] Creating layer lstm1x_W_xc_x_slice
I0521 09:36:45.670840  3675 net.cpp:100] Creating Layer lstm1x_W_xc_x_slice
I0521 09:36:45.670846  3675 net.cpp:434] lstm1x_W_xc_x_slice <- W_xc_x
I0521 09:36:45.670855  3675 net.cpp:408] lstm1x_W_xc_x_slice -> W_xc_x_1
I0521 09:36:45.670864  3675 net.cpp:408] lstm1x_W_xc_x_slice -> W_xc_x_2
I0521 09:36:45.670874  3675 net.cpp:408] lstm1x_W_xc_x_slice -> W_xc_x_3
I0521 09:36:45.670881  3675 net.cpp:408] lstm1x_W_xc_x_slice -> W_xc_x_4
I0521 09:36:45.670886  3675 net.cpp:408] lstm1x_W_xc_x_slice -> W_xc_x_5
I0521 09:36:45.670893  3675 net.cpp:408] lstm1x_W_xc_x_slice -> W_xc_x_6
I0521 09:36:45.670899  3675 net.cpp:408] lstm1x_W_xc_x_slice -> W_xc_x_7
I0521 09:36:45.670905  3675 net.cpp:408] lstm1x_W_xc_x_slice -> W_xc_x_8
I0521 09:36:45.670912  3675 net.cpp:408] lstm1x_W_xc_x_slice -> W_xc_x_9
I0521 09:36:45.670917  3675 net.cpp:408] lstm1x_W_xc_x_slice -> W_xc_x_10
I0521 09:36:45.670923  3675 net.cpp:408] lstm1x_W_xc_x_slice -> W_xc_x_11
I0521 09:36:45.670929  3675 net.cpp:408] lstm1x_W_xc_x_slice -> W_xc_x_12
I0521 09:36:45.670939  3675 net.cpp:408] lstm1x_W_xc_x_slice -> W_xc_x_13
I0521 09:36:45.670946  3675 net.cpp:408] lstm1x_W_xc_x_slice -> W_xc_x_14
I0521 09:36:45.670953  3675 net.cpp:408] lstm1x_W_xc_x_slice -> W_xc_x_15
I0521 09:36:45.670958  3675 net.cpp:408] lstm1x_W_xc_x_slice -> W_xc_x_16
I0521 09:36:45.671156  3675 net.cpp:150] Setting up lstm1x_W_xc_x_slice
I0521 09:36:45.671169  3675 net.cpp:157] Top shape: 1 128 400 (51200)
I0521 09:36:45.671173  3675 net.cpp:157] Top shape: 1 128 400 (51200)
I0521 09:36:45.671178  3675 net.cpp:157] Top shape: 1 128 400 (51200)
I0521 09:36:45.671182  3675 net.cpp:157] Top shape: 1 128 400 (51200)
I0521 09:36:45.671186  3675 net.cpp:157] Top shape: 1 128 400 (51200)
I0521 09:36:45.671190  3675 net.cpp:157] Top shape: 1 128 400 (51200)
I0521 09:36:45.671195  3675 net.cpp:157] Top shape: 1 128 400 (51200)
I0521 09:36:45.671200  3675 net.cpp:157] Top shape: 1 128 400 (51200)
I0521 09:36:45.671203  3675 net.cpp:157] Top shape: 1 128 400 (51200)
I0521 09:36:45.671207  3675 net.cpp:157] Top shape: 1 128 400 (51200)
I0521 09:36:45.671211  3675 net.cpp:157] Top shape: 1 128 400 (51200)
I0521 09:36:45.671216  3675 net.cpp:157] Top shape: 1 128 400 (51200)
I0521 09:36:45.671221  3675 net.cpp:157] Top shape: 1 128 400 (51200)
I0521 09:36:45.671224  3675 net.cpp:157] Top shape: 1 128 400 (51200)
I0521 09:36:45.671228  3675 net.cpp:157] Top shape: 1 128 400 (51200)
I0521 09:36:45.671232  3675 net.cpp:157] Top shape: 1 128 400 (51200)
I0521 09:36:45.671236  3675 net.cpp:165] Memory required for data: 23465984
I0521 09:36:45.671241  3675 layer_factory.hpp:77] Creating layer lstm1x_h_conted_0
I0521 09:36:45.671249  3675 net.cpp:100] Creating Layer lstm1x_h_conted_0
I0521 09:36:45.671254  3675 net.cpp:434] lstm1x_h_conted_0 <- h_0
I0521 09:36:45.671263  3675 net.cpp:434] lstm1x_h_conted_0 <- cont_1_lstm1x_cont_slice_0_split_0
I0521 09:36:45.671294  3675 net.cpp:408] lstm1x_h_conted_0 -> h_conted_0
I0521 09:36:45.671377  3675 net.cpp:150] Setting up lstm1x_h_conted_0
I0521 09:36:45.671384  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.671388  3675 net.cpp:165] Memory required for data: 23517184
I0521 09:36:45.671392  3675 layer_factory.hpp:77] Creating layer lstm1x_transform_1
I0521 09:36:45.671402  3675 net.cpp:100] Creating Layer lstm1x_transform_1
I0521 09:36:45.671406  3675 net.cpp:434] lstm1x_transform_1 <- h_conted_0
I0521 09:36:45.671412  3675 net.cpp:408] lstm1x_transform_1 -> W_hc_h_0
I0521 09:36:45.671785  3675 net.cpp:150] Setting up lstm1x_transform_1
I0521 09:36:45.671798  3675 net.cpp:157] Top shape: 1 128 400 (51200)
I0521 09:36:45.671802  3675 net.cpp:165] Memory required for data: 23721984
I0521 09:36:45.671809  3675 layer_factory.hpp:77] Creating layer lstm1x_gate_input_1
I0521 09:36:45.671818  3675 net.cpp:100] Creating Layer lstm1x_gate_input_1
I0521 09:36:45.671821  3675 net.cpp:434] lstm1x_gate_input_1 <- W_hc_h_0
I0521 09:36:45.671826  3675 net.cpp:434] lstm1x_gate_input_1 <- W_xc_x_1
I0521 09:36:45.671831  3675 net.cpp:408] lstm1x_gate_input_1 -> gate_input_1
I0521 09:36:45.671860  3675 net.cpp:150] Setting up lstm1x_gate_input_1
I0521 09:36:45.671866  3675 net.cpp:157] Top shape: 1 128 400 (51200)
I0521 09:36:45.671870  3675 net.cpp:165] Memory required for data: 23926784
I0521 09:36:45.671875  3675 layer_factory.hpp:77] Creating layer lstm1x_unit_1
I0521 09:36:45.671880  3675 net.cpp:100] Creating Layer lstm1x_unit_1
I0521 09:36:45.671885  3675 net.cpp:434] lstm1x_unit_1 <- c_0
I0521 09:36:45.671890  3675 net.cpp:434] lstm1x_unit_1 <- gate_input_1
I0521 09:36:45.671895  3675 net.cpp:434] lstm1x_unit_1 <- cont_1_lstm1x_cont_slice_0_split_1
I0521 09:36:45.671900  3675 net.cpp:408] lstm1x_unit_1 -> c_1
I0521 09:36:45.671906  3675 net.cpp:408] lstm1x_unit_1 -> h_1
I0521 09:36:45.671952  3675 net.cpp:150] Setting up lstm1x_unit_1
I0521 09:36:45.671957  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.671962  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.671965  3675 net.cpp:165] Memory required for data: 24029184
I0521 09:36:45.671969  3675 layer_factory.hpp:77] Creating layer h_1_lstm1x_unit_1_1_split
I0521 09:36:45.671977  3675 net.cpp:100] Creating Layer h_1_lstm1x_unit_1_1_split
I0521 09:36:45.671980  3675 net.cpp:434] h_1_lstm1x_unit_1_1_split <- h_1
I0521 09:36:45.671986  3675 net.cpp:408] h_1_lstm1x_unit_1_1_split -> h_1_lstm1x_unit_1_1_split_0
I0521 09:36:45.671993  3675 net.cpp:408] h_1_lstm1x_unit_1_1_split -> h_1_lstm1x_unit_1_1_split_1
I0521 09:36:45.672024  3675 net.cpp:150] Setting up h_1_lstm1x_unit_1_1_split
I0521 09:36:45.672029  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.672032  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.672035  3675 net.cpp:165] Memory required for data: 24131584
I0521 09:36:45.672040  3675 layer_factory.hpp:77] Creating layer lstm1x_h_conted_1
I0521 09:36:45.672047  3675 net.cpp:100] Creating Layer lstm1x_h_conted_1
I0521 09:36:45.672050  3675 net.cpp:434] lstm1x_h_conted_1 <- h_1_lstm1x_unit_1_1_split_0
I0521 09:36:45.672055  3675 net.cpp:434] lstm1x_h_conted_1 <- cont_2_lstm1x_cont_slice_1_split_0
I0521 09:36:45.672061  3675 net.cpp:408] lstm1x_h_conted_1 -> h_conted_1
I0521 09:36:45.672128  3675 net.cpp:150] Setting up lstm1x_h_conted_1
I0521 09:36:45.672135  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.672139  3675 net.cpp:165] Memory required for data: 24182784
I0521 09:36:45.672142  3675 layer_factory.hpp:77] Creating layer lstm1x_transform_2
I0521 09:36:45.672149  3675 net.cpp:100] Creating Layer lstm1x_transform_2
I0521 09:36:45.672153  3675 net.cpp:434] lstm1x_transform_2 <- h_conted_1
I0521 09:36:45.672160  3675 net.cpp:408] lstm1x_transform_2 -> W_hc_h_1
I0521 09:36:45.672516  3675 net.cpp:150] Setting up lstm1x_transform_2
I0521 09:36:45.672529  3675 net.cpp:157] Top shape: 1 128 400 (51200)
I0521 09:36:45.672533  3675 net.cpp:165] Memory required for data: 24387584
I0521 09:36:45.672554  3675 net.cpp:493] Sharing parameters 'W_hc' owned by layer 'lstm1x_transform_1', param index 0
I0521 09:36:45.672559  3675 layer_factory.hpp:77] Creating layer lstm1x_gate_input_2
I0521 09:36:45.672566  3675 net.cpp:100] Creating Layer lstm1x_gate_input_2
I0521 09:36:45.672570  3675 net.cpp:434] lstm1x_gate_input_2 <- W_hc_h_1
I0521 09:36:45.672576  3675 net.cpp:434] lstm1x_gate_input_2 <- W_xc_x_2
I0521 09:36:45.672581  3675 net.cpp:408] lstm1x_gate_input_2 -> gate_input_2
I0521 09:36:45.672610  3675 net.cpp:150] Setting up lstm1x_gate_input_2
I0521 09:36:45.672617  3675 net.cpp:157] Top shape: 1 128 400 (51200)
I0521 09:36:45.672621  3675 net.cpp:165] Memory required for data: 24592384
I0521 09:36:45.672624  3675 layer_factory.hpp:77] Creating layer lstm1x_unit_2
I0521 09:36:45.672631  3675 net.cpp:100] Creating Layer lstm1x_unit_2
I0521 09:36:45.672634  3675 net.cpp:434] lstm1x_unit_2 <- c_1
I0521 09:36:45.672639  3675 net.cpp:434] lstm1x_unit_2 <- gate_input_2
I0521 09:36:45.672643  3675 net.cpp:434] lstm1x_unit_2 <- cont_2_lstm1x_cont_slice_1_split_1
I0521 09:36:45.672649  3675 net.cpp:408] lstm1x_unit_2 -> c_2
I0521 09:36:45.672655  3675 net.cpp:408] lstm1x_unit_2 -> h_2
I0521 09:36:45.672698  3675 net.cpp:150] Setting up lstm1x_unit_2
I0521 09:36:45.672705  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.672709  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.672713  3675 net.cpp:165] Memory required for data: 24694784
I0521 09:36:45.672716  3675 layer_factory.hpp:77] Creating layer h_2_lstm1x_unit_2_1_split
I0521 09:36:45.672724  3675 net.cpp:100] Creating Layer h_2_lstm1x_unit_2_1_split
I0521 09:36:45.672727  3675 net.cpp:434] h_2_lstm1x_unit_2_1_split <- h_2
I0521 09:36:45.672734  3675 net.cpp:408] h_2_lstm1x_unit_2_1_split -> h_2_lstm1x_unit_2_1_split_0
I0521 09:36:45.672739  3675 net.cpp:408] h_2_lstm1x_unit_2_1_split -> h_2_lstm1x_unit_2_1_split_1
I0521 09:36:45.672773  3675 net.cpp:150] Setting up h_2_lstm1x_unit_2_1_split
I0521 09:36:45.672780  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.672791  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.672794  3675 net.cpp:165] Memory required for data: 24797184
I0521 09:36:45.672797  3675 layer_factory.hpp:77] Creating layer lstm1x_h_conted_2
I0521 09:36:45.672804  3675 net.cpp:100] Creating Layer lstm1x_h_conted_2
I0521 09:36:45.672808  3675 net.cpp:434] lstm1x_h_conted_2 <- h_2_lstm1x_unit_2_1_split_0
I0521 09:36:45.672813  3675 net.cpp:434] lstm1x_h_conted_2 <- cont_3_lstm1x_cont_slice_2_split_0
I0521 09:36:45.672819  3675 net.cpp:408] lstm1x_h_conted_2 -> h_conted_2
I0521 09:36:45.672880  3675 net.cpp:150] Setting up lstm1x_h_conted_2
I0521 09:36:45.672886  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.672890  3675 net.cpp:165] Memory required for data: 24848384
I0521 09:36:45.672894  3675 layer_factory.hpp:77] Creating layer lstm1x_transform_3
I0521 09:36:45.672904  3675 net.cpp:100] Creating Layer lstm1x_transform_3
I0521 09:36:45.672909  3675 net.cpp:434] lstm1x_transform_3 <- h_conted_2
I0521 09:36:45.672915  3675 net.cpp:408] lstm1x_transform_3 -> W_hc_h_2
I0521 09:36:45.673269  3675 net.cpp:150] Setting up lstm1x_transform_3
I0521 09:36:45.673282  3675 net.cpp:157] Top shape: 1 128 400 (51200)
I0521 09:36:45.673286  3675 net.cpp:165] Memory required for data: 25053184
I0521 09:36:45.673292  3675 net.cpp:493] Sharing parameters 'W_hc' owned by layer 'lstm1x_transform_1', param index 0
I0521 09:36:45.673296  3675 layer_factory.hpp:77] Creating layer lstm1x_gate_input_3
I0521 09:36:45.673305  3675 net.cpp:100] Creating Layer lstm1x_gate_input_3
I0521 09:36:45.673310  3675 net.cpp:434] lstm1x_gate_input_3 <- W_hc_h_2
I0521 09:36:45.673315  3675 net.cpp:434] lstm1x_gate_input_3 <- W_xc_x_3
I0521 09:36:45.673321  3675 net.cpp:408] lstm1x_gate_input_3 -> gate_input_3
I0521 09:36:45.673346  3675 net.cpp:150] Setting up lstm1x_gate_input_3
I0521 09:36:45.673352  3675 net.cpp:157] Top shape: 1 128 400 (51200)
I0521 09:36:45.673368  3675 net.cpp:165] Memory required for data: 25257984
I0521 09:36:45.673372  3675 layer_factory.hpp:77] Creating layer lstm1x_unit_3
I0521 09:36:45.673380  3675 net.cpp:100] Creating Layer lstm1x_unit_3
I0521 09:36:45.673384  3675 net.cpp:434] lstm1x_unit_3 <- c_2
I0521 09:36:45.673389  3675 net.cpp:434] lstm1x_unit_3 <- gate_input_3
I0521 09:36:45.673393  3675 net.cpp:434] lstm1x_unit_3 <- cont_3_lstm1x_cont_slice_2_split_1
I0521 09:36:45.673398  3675 net.cpp:408] lstm1x_unit_3 -> c_3
I0521 09:36:45.673405  3675 net.cpp:408] lstm1x_unit_3 -> h_3
I0521 09:36:45.673449  3675 net.cpp:150] Setting up lstm1x_unit_3
I0521 09:36:45.673455  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.673460  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.673463  3675 net.cpp:165] Memory required for data: 25360384
I0521 09:36:45.673467  3675 layer_factory.hpp:77] Creating layer h_3_lstm1x_unit_3_1_split
I0521 09:36:45.673472  3675 net.cpp:100] Creating Layer h_3_lstm1x_unit_3_1_split
I0521 09:36:45.673476  3675 net.cpp:434] h_3_lstm1x_unit_3_1_split <- h_3
I0521 09:36:45.673483  3675 net.cpp:408] h_3_lstm1x_unit_3_1_split -> h_3_lstm1x_unit_3_1_split_0
I0521 09:36:45.673491  3675 net.cpp:408] h_3_lstm1x_unit_3_1_split -> h_3_lstm1x_unit_3_1_split_1
I0521 09:36:45.673523  3675 net.cpp:150] Setting up h_3_lstm1x_unit_3_1_split
I0521 09:36:45.673529  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.673534  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.673537  3675 net.cpp:165] Memory required for data: 25462784
I0521 09:36:45.673542  3675 layer_factory.hpp:77] Creating layer lstm1x_h_conted_3
I0521 09:36:45.673547  3675 net.cpp:100] Creating Layer lstm1x_h_conted_3
I0521 09:36:45.673552  3675 net.cpp:434] lstm1x_h_conted_3 <- h_3_lstm1x_unit_3_1_split_0
I0521 09:36:45.673557  3675 net.cpp:434] lstm1x_h_conted_3 <- cont_4_lstm1x_cont_slice_3_split_0
I0521 09:36:45.673563  3675 net.cpp:408] lstm1x_h_conted_3 -> h_conted_3
I0521 09:36:45.673622  3675 net.cpp:150] Setting up lstm1x_h_conted_3
I0521 09:36:45.673629  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.673633  3675 net.cpp:165] Memory required for data: 25513984
I0521 09:36:45.673636  3675 layer_factory.hpp:77] Creating layer lstm1x_transform_4
I0521 09:36:45.673643  3675 net.cpp:100] Creating Layer lstm1x_transform_4
I0521 09:36:45.673648  3675 net.cpp:434] lstm1x_transform_4 <- h_conted_3
I0521 09:36:45.673653  3675 net.cpp:408] lstm1x_transform_4 -> W_hc_h_3
I0521 09:36:45.674012  3675 net.cpp:150] Setting up lstm1x_transform_4
I0521 09:36:45.674026  3675 net.cpp:157] Top shape: 1 128 400 (51200)
I0521 09:36:45.674029  3675 net.cpp:165] Memory required for data: 25718784
I0521 09:36:45.674034  3675 net.cpp:493] Sharing parameters 'W_hc' owned by layer 'lstm1x_transform_1', param index 0
I0521 09:36:45.674039  3675 layer_factory.hpp:77] Creating layer lstm1x_gate_input_4
I0521 09:36:45.674046  3675 net.cpp:100] Creating Layer lstm1x_gate_input_4
I0521 09:36:45.674051  3675 net.cpp:434] lstm1x_gate_input_4 <- W_hc_h_3
I0521 09:36:45.674055  3675 net.cpp:434] lstm1x_gate_input_4 <- W_xc_x_4
I0521 09:36:45.674062  3675 net.cpp:408] lstm1x_gate_input_4 -> gate_input_4
I0521 09:36:45.674087  3675 net.cpp:150] Setting up lstm1x_gate_input_4
I0521 09:36:45.674093  3675 net.cpp:157] Top shape: 1 128 400 (51200)
I0521 09:36:45.674096  3675 net.cpp:165] Memory required for data: 25923584
I0521 09:36:45.674099  3675 layer_factory.hpp:77] Creating layer lstm1x_unit_4
I0521 09:36:45.674108  3675 net.cpp:100] Creating Layer lstm1x_unit_4
I0521 09:36:45.674111  3675 net.cpp:434] lstm1x_unit_4 <- c_3
I0521 09:36:45.674116  3675 net.cpp:434] lstm1x_unit_4 <- gate_input_4
I0521 09:36:45.674121  3675 net.cpp:434] lstm1x_unit_4 <- cont_4_lstm1x_cont_slice_3_split_1
I0521 09:36:45.674126  3675 net.cpp:408] lstm1x_unit_4 -> c_4
I0521 09:36:45.674132  3675 net.cpp:408] lstm1x_unit_4 -> h_4
I0521 09:36:45.674175  3675 net.cpp:150] Setting up lstm1x_unit_4
I0521 09:36:45.674180  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.674196  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.674199  3675 net.cpp:165] Memory required for data: 26025984
I0521 09:36:45.674202  3675 layer_factory.hpp:77] Creating layer h_4_lstm1x_unit_4_1_split
I0521 09:36:45.674209  3675 net.cpp:100] Creating Layer h_4_lstm1x_unit_4_1_split
I0521 09:36:45.674213  3675 net.cpp:434] h_4_lstm1x_unit_4_1_split <- h_4
I0521 09:36:45.674218  3675 net.cpp:408] h_4_lstm1x_unit_4_1_split -> h_4_lstm1x_unit_4_1_split_0
I0521 09:36:45.674224  3675 net.cpp:408] h_4_lstm1x_unit_4_1_split -> h_4_lstm1x_unit_4_1_split_1
I0521 09:36:45.674252  3675 net.cpp:150] Setting up h_4_lstm1x_unit_4_1_split
I0521 09:36:45.674257  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.674260  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.674263  3675 net.cpp:165] Memory required for data: 26128384
I0521 09:36:45.674268  3675 layer_factory.hpp:77] Creating layer lstm1x_h_conted_4
I0521 09:36:45.674274  3675 net.cpp:100] Creating Layer lstm1x_h_conted_4
I0521 09:36:45.674278  3675 net.cpp:434] lstm1x_h_conted_4 <- h_4_lstm1x_unit_4_1_split_0
I0521 09:36:45.674283  3675 net.cpp:434] lstm1x_h_conted_4 <- cont_5_lstm1x_cont_slice_4_split_0
I0521 09:36:45.674288  3675 net.cpp:408] lstm1x_h_conted_4 -> h_conted_4
I0521 09:36:45.674345  3675 net.cpp:150] Setting up lstm1x_h_conted_4
I0521 09:36:45.674351  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.674355  3675 net.cpp:165] Memory required for data: 26179584
I0521 09:36:45.674360  3675 layer_factory.hpp:77] Creating layer lstm1x_transform_5
I0521 09:36:45.674366  3675 net.cpp:100] Creating Layer lstm1x_transform_5
I0521 09:36:45.674371  3675 net.cpp:434] lstm1x_transform_5 <- h_conted_4
I0521 09:36:45.674376  3675 net.cpp:408] lstm1x_transform_5 -> W_hc_h_4
I0521 09:36:45.674731  3675 net.cpp:150] Setting up lstm1x_transform_5
I0521 09:36:45.674743  3675 net.cpp:157] Top shape: 1 128 400 (51200)
I0521 09:36:45.674746  3675 net.cpp:165] Memory required for data: 26384384
I0521 09:36:45.674751  3675 net.cpp:493] Sharing parameters 'W_hc' owned by layer 'lstm1x_transform_1', param index 0
I0521 09:36:45.674755  3675 layer_factory.hpp:77] Creating layer lstm1x_gate_input_5
I0521 09:36:45.674762  3675 net.cpp:100] Creating Layer lstm1x_gate_input_5
I0521 09:36:45.674767  3675 net.cpp:434] lstm1x_gate_input_5 <- W_hc_h_4
I0521 09:36:45.674772  3675 net.cpp:434] lstm1x_gate_input_5 <- W_xc_x_5
I0521 09:36:45.674777  3675 net.cpp:408] lstm1x_gate_input_5 -> gate_input_5
I0521 09:36:45.674803  3675 net.cpp:150] Setting up lstm1x_gate_input_5
I0521 09:36:45.674809  3675 net.cpp:157] Top shape: 1 128 400 (51200)
I0521 09:36:45.674813  3675 net.cpp:165] Memory required for data: 26589184
I0521 09:36:45.674818  3675 layer_factory.hpp:77] Creating layer lstm1x_unit_5
I0521 09:36:45.674823  3675 net.cpp:100] Creating Layer lstm1x_unit_5
I0521 09:36:45.674827  3675 net.cpp:434] lstm1x_unit_5 <- c_4
I0521 09:36:45.674832  3675 net.cpp:434] lstm1x_unit_5 <- gate_input_5
I0521 09:36:45.674836  3675 net.cpp:434] lstm1x_unit_5 <- cont_5_lstm1x_cont_slice_4_split_1
I0521 09:36:45.674842  3675 net.cpp:408] lstm1x_unit_5 -> c_5
I0521 09:36:45.674849  3675 net.cpp:408] lstm1x_unit_5 -> h_5
I0521 09:36:45.674891  3675 net.cpp:150] Setting up lstm1x_unit_5
I0521 09:36:45.674898  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.674903  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.674907  3675 net.cpp:165] Memory required for data: 26691584
I0521 09:36:45.674911  3675 layer_factory.hpp:77] Creating layer h_5_lstm1x_unit_5_1_split
I0521 09:36:45.674919  3675 net.cpp:100] Creating Layer h_5_lstm1x_unit_5_1_split
I0521 09:36:45.674923  3675 net.cpp:434] h_5_lstm1x_unit_5_1_split <- h_5
I0521 09:36:45.674928  3675 net.cpp:408] h_5_lstm1x_unit_5_1_split -> h_5_lstm1x_unit_5_1_split_0
I0521 09:36:45.674935  3675 net.cpp:408] h_5_lstm1x_unit_5_1_split -> h_5_lstm1x_unit_5_1_split_1
I0521 09:36:45.674966  3675 net.cpp:150] Setting up h_5_lstm1x_unit_5_1_split
I0521 09:36:45.674973  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.674989  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.674993  3675 net.cpp:165] Memory required for data: 26793984
I0521 09:36:45.674996  3675 layer_factory.hpp:77] Creating layer lstm1x_h_conted_5
I0521 09:36:45.675004  3675 net.cpp:100] Creating Layer lstm1x_h_conted_5
I0521 09:36:45.675009  3675 net.cpp:434] lstm1x_h_conted_5 <- h_5_lstm1x_unit_5_1_split_0
I0521 09:36:45.675014  3675 net.cpp:434] lstm1x_h_conted_5 <- cont_6_lstm1x_cont_slice_5_split_0
I0521 09:36:45.675019  3675 net.cpp:408] lstm1x_h_conted_5 -> h_conted_5
I0521 09:36:45.675086  3675 net.cpp:150] Setting up lstm1x_h_conted_5
I0521 09:36:45.675093  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.675096  3675 net.cpp:165] Memory required for data: 26845184
I0521 09:36:45.675107  3675 layer_factory.hpp:77] Creating layer lstm1x_transform_6
I0521 09:36:45.675114  3675 net.cpp:100] Creating Layer lstm1x_transform_6
I0521 09:36:45.675118  3675 net.cpp:434] lstm1x_transform_6 <- h_conted_5
I0521 09:36:45.675125  3675 net.cpp:408] lstm1x_transform_6 -> W_hc_h_5
I0521 09:36:45.675485  3675 net.cpp:150] Setting up lstm1x_transform_6
I0521 09:36:45.675498  3675 net.cpp:157] Top shape: 1 128 400 (51200)
I0521 09:36:45.675503  3675 net.cpp:165] Memory required for data: 27049984
I0521 09:36:45.675508  3675 net.cpp:493] Sharing parameters 'W_hc' owned by layer 'lstm1x_transform_1', param index 0
I0521 09:36:45.675511  3675 layer_factory.hpp:77] Creating layer lstm1x_gate_input_6
I0521 09:36:45.675518  3675 net.cpp:100] Creating Layer lstm1x_gate_input_6
I0521 09:36:45.675523  3675 net.cpp:434] lstm1x_gate_input_6 <- W_hc_h_5
I0521 09:36:45.675527  3675 net.cpp:434] lstm1x_gate_input_6 <- W_xc_x_6
I0521 09:36:45.675534  3675 net.cpp:408] lstm1x_gate_input_6 -> gate_input_6
I0521 09:36:45.675559  3675 net.cpp:150] Setting up lstm1x_gate_input_6
I0521 09:36:45.675565  3675 net.cpp:157] Top shape: 1 128 400 (51200)
I0521 09:36:45.675568  3675 net.cpp:165] Memory required for data: 27254784
I0521 09:36:45.675572  3675 layer_factory.hpp:77] Creating layer lstm1x_unit_6
I0521 09:36:45.675578  3675 net.cpp:100] Creating Layer lstm1x_unit_6
I0521 09:36:45.675582  3675 net.cpp:434] lstm1x_unit_6 <- c_5
I0521 09:36:45.675587  3675 net.cpp:434] lstm1x_unit_6 <- gate_input_6
I0521 09:36:45.675591  3675 net.cpp:434] lstm1x_unit_6 <- cont_6_lstm1x_cont_slice_5_split_1
I0521 09:36:45.675596  3675 net.cpp:408] lstm1x_unit_6 -> c_6
I0521 09:36:45.675603  3675 net.cpp:408] lstm1x_unit_6 -> h_6
I0521 09:36:45.675647  3675 net.cpp:150] Setting up lstm1x_unit_6
I0521 09:36:45.675654  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.675658  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.675662  3675 net.cpp:165] Memory required for data: 27357184
I0521 09:36:45.675665  3675 layer_factory.hpp:77] Creating layer h_6_lstm1x_unit_6_1_split
I0521 09:36:45.675670  3675 net.cpp:100] Creating Layer h_6_lstm1x_unit_6_1_split
I0521 09:36:45.675674  3675 net.cpp:434] h_6_lstm1x_unit_6_1_split <- h_6
I0521 09:36:45.675680  3675 net.cpp:408] h_6_lstm1x_unit_6_1_split -> h_6_lstm1x_unit_6_1_split_0
I0521 09:36:45.675688  3675 net.cpp:408] h_6_lstm1x_unit_6_1_split -> h_6_lstm1x_unit_6_1_split_1
I0521 09:36:45.675719  3675 net.cpp:150] Setting up h_6_lstm1x_unit_6_1_split
I0521 09:36:45.675726  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.675730  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.675734  3675 net.cpp:165] Memory required for data: 27459584
I0521 09:36:45.675737  3675 layer_factory.hpp:77] Creating layer lstm1x_h_conted_6
I0521 09:36:45.675745  3675 net.cpp:100] Creating Layer lstm1x_h_conted_6
I0521 09:36:45.675748  3675 net.cpp:434] lstm1x_h_conted_6 <- h_6_lstm1x_unit_6_1_split_0
I0521 09:36:45.675753  3675 net.cpp:434] lstm1x_h_conted_6 <- cont_7_lstm1x_cont_slice_6_split_0
I0521 09:36:45.675761  3675 net.cpp:408] lstm1x_h_conted_6 -> h_conted_6
I0521 09:36:45.675822  3675 net.cpp:150] Setting up lstm1x_h_conted_6
I0521 09:36:45.675828  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.675846  3675 net.cpp:165] Memory required for data: 27510784
I0521 09:36:45.675850  3675 layer_factory.hpp:77] Creating layer lstm1x_transform_7
I0521 09:36:45.675859  3675 net.cpp:100] Creating Layer lstm1x_transform_7
I0521 09:36:45.675863  3675 net.cpp:434] lstm1x_transform_7 <- h_conted_6
I0521 09:36:45.675869  3675 net.cpp:408] lstm1x_transform_7 -> W_hc_h_6
I0521 09:36:45.676232  3675 net.cpp:150] Setting up lstm1x_transform_7
I0521 09:36:45.676244  3675 net.cpp:157] Top shape: 1 128 400 (51200)
I0521 09:36:45.676247  3675 net.cpp:165] Memory required for data: 27715584
I0521 09:36:45.676254  3675 net.cpp:493] Sharing parameters 'W_hc' owned by layer 'lstm1x_transform_1', param index 0
I0521 09:36:45.676259  3675 layer_factory.hpp:77] Creating layer lstm1x_gate_input_7
I0521 09:36:45.676265  3675 net.cpp:100] Creating Layer lstm1x_gate_input_7
I0521 09:36:45.676270  3675 net.cpp:434] lstm1x_gate_input_7 <- W_hc_h_6
I0521 09:36:45.676275  3675 net.cpp:434] lstm1x_gate_input_7 <- W_xc_x_7
I0521 09:36:45.676280  3675 net.cpp:408] lstm1x_gate_input_7 -> gate_input_7
I0521 09:36:45.676312  3675 net.cpp:150] Setting up lstm1x_gate_input_7
I0521 09:36:45.676319  3675 net.cpp:157] Top shape: 1 128 400 (51200)
I0521 09:36:45.676323  3675 net.cpp:165] Memory required for data: 27920384
I0521 09:36:45.676326  3675 layer_factory.hpp:77] Creating layer lstm1x_unit_7
I0521 09:36:45.676332  3675 net.cpp:100] Creating Layer lstm1x_unit_7
I0521 09:36:45.676337  3675 net.cpp:434] lstm1x_unit_7 <- c_6
I0521 09:36:45.676342  3675 net.cpp:434] lstm1x_unit_7 <- gate_input_7
I0521 09:36:45.676345  3675 net.cpp:434] lstm1x_unit_7 <- cont_7_lstm1x_cont_slice_6_split_1
I0521 09:36:45.676352  3675 net.cpp:408] lstm1x_unit_7 -> c_7
I0521 09:36:45.676357  3675 net.cpp:408] lstm1x_unit_7 -> h_7
I0521 09:36:45.676404  3675 net.cpp:150] Setting up lstm1x_unit_7
I0521 09:36:45.676411  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.676415  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.676419  3675 net.cpp:165] Memory required for data: 28022784
I0521 09:36:45.676422  3675 layer_factory.hpp:77] Creating layer h_7_lstm1x_unit_7_1_split
I0521 09:36:45.676429  3675 net.cpp:100] Creating Layer h_7_lstm1x_unit_7_1_split
I0521 09:36:45.676432  3675 net.cpp:434] h_7_lstm1x_unit_7_1_split <- h_7
I0521 09:36:45.676439  3675 net.cpp:408] h_7_lstm1x_unit_7_1_split -> h_7_lstm1x_unit_7_1_split_0
I0521 09:36:45.676445  3675 net.cpp:408] h_7_lstm1x_unit_7_1_split -> h_7_lstm1x_unit_7_1_split_1
I0521 09:36:45.676476  3675 net.cpp:150] Setting up h_7_lstm1x_unit_7_1_split
I0521 09:36:45.676481  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.676486  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.676489  3675 net.cpp:165] Memory required for data: 28125184
I0521 09:36:45.676493  3675 layer_factory.hpp:77] Creating layer lstm1x_h_conted_7
I0521 09:36:45.676501  3675 net.cpp:100] Creating Layer lstm1x_h_conted_7
I0521 09:36:45.676506  3675 net.cpp:434] lstm1x_h_conted_7 <- h_7_lstm1x_unit_7_1_split_0
I0521 09:36:45.676510  3675 net.cpp:434] lstm1x_h_conted_7 <- cont_8_lstm1x_cont_slice_7_split_0
I0521 09:36:45.676515  3675 net.cpp:408] lstm1x_h_conted_7 -> h_conted_7
I0521 09:36:45.676575  3675 net.cpp:150] Setting up lstm1x_h_conted_7
I0521 09:36:45.676582  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.676585  3675 net.cpp:165] Memory required for data: 28176384
I0521 09:36:45.676589  3675 layer_factory.hpp:77] Creating layer lstm1x_transform_8
I0521 09:36:45.676596  3675 net.cpp:100] Creating Layer lstm1x_transform_8
I0521 09:36:45.676600  3675 net.cpp:434] lstm1x_transform_8 <- h_conted_7
I0521 09:36:45.676606  3675 net.cpp:408] lstm1x_transform_8 -> W_hc_h_7
I0521 09:36:45.676936  3675 net.cpp:150] Setting up lstm1x_transform_8
I0521 09:36:45.676949  3675 net.cpp:157] Top shape: 1 128 400 (51200)
I0521 09:36:45.676952  3675 net.cpp:165] Memory required for data: 28381184
I0521 09:36:45.676957  3675 net.cpp:493] Sharing parameters 'W_hc' owned by layer 'lstm1x_transform_1', param index 0
I0521 09:36:45.676977  3675 layer_factory.hpp:77] Creating layer lstm1x_gate_input_8
I0521 09:36:45.676985  3675 net.cpp:100] Creating Layer lstm1x_gate_input_8
I0521 09:36:45.676990  3675 net.cpp:434] lstm1x_gate_input_8 <- W_hc_h_7
I0521 09:36:45.676995  3675 net.cpp:434] lstm1x_gate_input_8 <- W_xc_x_8
I0521 09:36:45.677002  3675 net.cpp:408] lstm1x_gate_input_8 -> gate_input_8
I0521 09:36:45.677032  3675 net.cpp:150] Setting up lstm1x_gate_input_8
I0521 09:36:45.677038  3675 net.cpp:157] Top shape: 1 128 400 (51200)
I0521 09:36:45.677042  3675 net.cpp:165] Memory required for data: 28585984
I0521 09:36:45.677045  3675 layer_factory.hpp:77] Creating layer lstm1x_unit_8
I0521 09:36:45.677052  3675 net.cpp:100] Creating Layer lstm1x_unit_8
I0521 09:36:45.677055  3675 net.cpp:434] lstm1x_unit_8 <- c_7
I0521 09:36:45.677059  3675 net.cpp:434] lstm1x_unit_8 <- gate_input_8
I0521 09:36:45.677064  3675 net.cpp:434] lstm1x_unit_8 <- cont_8_lstm1x_cont_slice_7_split_1
I0521 09:36:45.677069  3675 net.cpp:408] lstm1x_unit_8 -> c_8
I0521 09:36:45.677078  3675 net.cpp:408] lstm1x_unit_8 -> h_8
I0521 09:36:45.677122  3675 net.cpp:150] Setting up lstm1x_unit_8
I0521 09:36:45.677129  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.677134  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.677137  3675 net.cpp:165] Memory required for data: 28688384
I0521 09:36:45.677141  3675 layer_factory.hpp:77] Creating layer h_8_lstm1x_unit_8_1_split
I0521 09:36:45.677147  3675 net.cpp:100] Creating Layer h_8_lstm1x_unit_8_1_split
I0521 09:36:45.677150  3675 net.cpp:434] h_8_lstm1x_unit_8_1_split <- h_8
I0521 09:36:45.677156  3675 net.cpp:408] h_8_lstm1x_unit_8_1_split -> h_8_lstm1x_unit_8_1_split_0
I0521 09:36:45.677163  3675 net.cpp:408] h_8_lstm1x_unit_8_1_split -> h_8_lstm1x_unit_8_1_split_1
I0521 09:36:45.677196  3675 net.cpp:150] Setting up h_8_lstm1x_unit_8_1_split
I0521 09:36:45.677202  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.677206  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.677209  3675 net.cpp:165] Memory required for data: 28790784
I0521 09:36:45.677213  3675 layer_factory.hpp:77] Creating layer lstm1x_h_conted_8
I0521 09:36:45.677222  3675 net.cpp:100] Creating Layer lstm1x_h_conted_8
I0521 09:36:45.677225  3675 net.cpp:434] lstm1x_h_conted_8 <- h_8_lstm1x_unit_8_1_split_0
I0521 09:36:45.677230  3675 net.cpp:434] lstm1x_h_conted_8 <- cont_9_lstm1x_cont_slice_8_split_0
I0521 09:36:45.677235  3675 net.cpp:408] lstm1x_h_conted_8 -> h_conted_8
I0521 09:36:45.677294  3675 net.cpp:150] Setting up lstm1x_h_conted_8
I0521 09:36:45.677302  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.677305  3675 net.cpp:165] Memory required for data: 28841984
I0521 09:36:45.677309  3675 layer_factory.hpp:77] Creating layer lstm1x_transform_9
I0521 09:36:45.677317  3675 net.cpp:100] Creating Layer lstm1x_transform_9
I0521 09:36:45.677321  3675 net.cpp:434] lstm1x_transform_9 <- h_conted_8
I0521 09:36:45.677327  3675 net.cpp:408] lstm1x_transform_9 -> W_hc_h_8
I0521 09:36:45.677681  3675 net.cpp:150] Setting up lstm1x_transform_9
I0521 09:36:45.677693  3675 net.cpp:157] Top shape: 1 128 400 (51200)
I0521 09:36:45.677697  3675 net.cpp:165] Memory required for data: 29046784
I0521 09:36:45.677702  3675 net.cpp:493] Sharing parameters 'W_hc' owned by layer 'lstm1x_transform_1', param index 0
I0521 09:36:45.677706  3675 layer_factory.hpp:77] Creating layer lstm1x_gate_input_9
I0521 09:36:45.677714  3675 net.cpp:100] Creating Layer lstm1x_gate_input_9
I0521 09:36:45.677718  3675 net.cpp:434] lstm1x_gate_input_9 <- W_hc_h_8
I0521 09:36:45.677724  3675 net.cpp:434] lstm1x_gate_input_9 <- W_xc_x_9
I0521 09:36:45.677729  3675 net.cpp:408] lstm1x_gate_input_9 -> gate_input_9
I0521 09:36:45.677754  3675 net.cpp:150] Setting up lstm1x_gate_input_9
I0521 09:36:45.677760  3675 net.cpp:157] Top shape: 1 128 400 (51200)
I0521 09:36:45.677763  3675 net.cpp:165] Memory required for data: 29251584
I0521 09:36:45.677767  3675 layer_factory.hpp:77] Creating layer lstm1x_unit_9
I0521 09:36:45.677791  3675 net.cpp:100] Creating Layer lstm1x_unit_9
I0521 09:36:45.677796  3675 net.cpp:434] lstm1x_unit_9 <- c_8
I0521 09:36:45.677801  3675 net.cpp:434] lstm1x_unit_9 <- gate_input_9
I0521 09:36:45.677805  3675 net.cpp:434] lstm1x_unit_9 <- cont_9_lstm1x_cont_slice_8_split_1
I0521 09:36:45.677811  3675 net.cpp:408] lstm1x_unit_9 -> c_9
I0521 09:36:45.677824  3675 net.cpp:408] lstm1x_unit_9 -> h_9
I0521 09:36:45.677870  3675 net.cpp:150] Setting up lstm1x_unit_9
I0521 09:36:45.677876  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.677881  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.677883  3675 net.cpp:165] Memory required for data: 29353984
I0521 09:36:45.677887  3675 layer_factory.hpp:77] Creating layer h_9_lstm1x_unit_9_1_split
I0521 09:36:45.677893  3675 net.cpp:100] Creating Layer h_9_lstm1x_unit_9_1_split
I0521 09:36:45.677896  3675 net.cpp:434] h_9_lstm1x_unit_9_1_split <- h_9
I0521 09:36:45.677902  3675 net.cpp:408] h_9_lstm1x_unit_9_1_split -> h_9_lstm1x_unit_9_1_split_0
I0521 09:36:45.677909  3675 net.cpp:408] h_9_lstm1x_unit_9_1_split -> h_9_lstm1x_unit_9_1_split_1
I0521 09:36:45.677947  3675 net.cpp:150] Setting up h_9_lstm1x_unit_9_1_split
I0521 09:36:45.677953  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.677956  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.677959  3675 net.cpp:165] Memory required for data: 29456384
I0521 09:36:45.677963  3675 layer_factory.hpp:77] Creating layer lstm1x_h_conted_9
I0521 09:36:45.677969  3675 net.cpp:100] Creating Layer lstm1x_h_conted_9
I0521 09:36:45.677973  3675 net.cpp:434] lstm1x_h_conted_9 <- h_9_lstm1x_unit_9_1_split_0
I0521 09:36:45.677978  3675 net.cpp:434] lstm1x_h_conted_9 <- cont_10_lstm1x_cont_slice_9_split_0
I0521 09:36:45.677983  3675 net.cpp:408] lstm1x_h_conted_9 -> h_conted_9
I0521 09:36:45.678042  3675 net.cpp:150] Setting up lstm1x_h_conted_9
I0521 09:36:45.678050  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.678052  3675 net.cpp:165] Memory required for data: 29507584
I0521 09:36:45.678056  3675 layer_factory.hpp:77] Creating layer lstm1x_transform_10
I0521 09:36:45.678063  3675 net.cpp:100] Creating Layer lstm1x_transform_10
I0521 09:36:45.678067  3675 net.cpp:434] lstm1x_transform_10 <- h_conted_9
I0521 09:36:45.678074  3675 net.cpp:408] lstm1x_transform_10 -> W_hc_h_9
I0521 09:36:45.678431  3675 net.cpp:150] Setting up lstm1x_transform_10
I0521 09:36:45.678443  3675 net.cpp:157] Top shape: 1 128 400 (51200)
I0521 09:36:45.678447  3675 net.cpp:165] Memory required for data: 29712384
I0521 09:36:45.678452  3675 net.cpp:493] Sharing parameters 'W_hc' owned by layer 'lstm1x_transform_1', param index 0
I0521 09:36:45.678457  3675 layer_factory.hpp:77] Creating layer lstm1x_gate_input_10
I0521 09:36:45.678464  3675 net.cpp:100] Creating Layer lstm1x_gate_input_10
I0521 09:36:45.678468  3675 net.cpp:434] lstm1x_gate_input_10 <- W_hc_h_9
I0521 09:36:45.678473  3675 net.cpp:434] lstm1x_gate_input_10 <- W_xc_x_10
I0521 09:36:45.678479  3675 net.cpp:408] lstm1x_gate_input_10 -> gate_input_10
I0521 09:36:45.678508  3675 net.cpp:150] Setting up lstm1x_gate_input_10
I0521 09:36:45.678514  3675 net.cpp:157] Top shape: 1 128 400 (51200)
I0521 09:36:45.678517  3675 net.cpp:165] Memory required for data: 29917184
I0521 09:36:45.678520  3675 layer_factory.hpp:77] Creating layer lstm1x_unit_10
I0521 09:36:45.678527  3675 net.cpp:100] Creating Layer lstm1x_unit_10
I0521 09:36:45.678531  3675 net.cpp:434] lstm1x_unit_10 <- c_9
I0521 09:36:45.678535  3675 net.cpp:434] lstm1x_unit_10 <- gate_input_10
I0521 09:36:45.678540  3675 net.cpp:434] lstm1x_unit_10 <- cont_10_lstm1x_cont_slice_9_split_1
I0521 09:36:45.678545  3675 net.cpp:408] lstm1x_unit_10 -> c_10
I0521 09:36:45.678551  3675 net.cpp:408] lstm1x_unit_10 -> h_10
I0521 09:36:45.678596  3675 net.cpp:150] Setting up lstm1x_unit_10
I0521 09:36:45.678604  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.678608  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.678612  3675 net.cpp:165] Memory required for data: 30019584
I0521 09:36:45.678628  3675 layer_factory.hpp:77] Creating layer h_10_lstm1x_unit_10_1_split
I0521 09:36:45.678634  3675 net.cpp:100] Creating Layer h_10_lstm1x_unit_10_1_split
I0521 09:36:45.678638  3675 net.cpp:434] h_10_lstm1x_unit_10_1_split <- h_10
I0521 09:36:45.678643  3675 net.cpp:408] h_10_lstm1x_unit_10_1_split -> h_10_lstm1x_unit_10_1_split_0
I0521 09:36:45.678650  3675 net.cpp:408] h_10_lstm1x_unit_10_1_split -> h_10_lstm1x_unit_10_1_split_1
I0521 09:36:45.678683  3675 net.cpp:150] Setting up h_10_lstm1x_unit_10_1_split
I0521 09:36:45.678689  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.678694  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.678697  3675 net.cpp:165] Memory required for data: 30121984
I0521 09:36:45.678701  3675 layer_factory.hpp:77] Creating layer lstm1x_h_conted_10
I0521 09:36:45.678707  3675 net.cpp:100] Creating Layer lstm1x_h_conted_10
I0521 09:36:45.678711  3675 net.cpp:434] lstm1x_h_conted_10 <- h_10_lstm1x_unit_10_1_split_0
I0521 09:36:45.678716  3675 net.cpp:434] lstm1x_h_conted_10 <- cont_11_lstm1x_cont_slice_10_split_0
I0521 09:36:45.678725  3675 net.cpp:408] lstm1x_h_conted_10 -> h_conted_10
I0521 09:36:45.678781  3675 net.cpp:150] Setting up lstm1x_h_conted_10
I0521 09:36:45.678787  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.678791  3675 net.cpp:165] Memory required for data: 30173184
I0521 09:36:45.678795  3675 layer_factory.hpp:77] Creating layer lstm1x_transform_11
I0521 09:36:45.678803  3675 net.cpp:100] Creating Layer lstm1x_transform_11
I0521 09:36:45.678807  3675 net.cpp:434] lstm1x_transform_11 <- h_conted_10
I0521 09:36:45.678813  3675 net.cpp:408] lstm1x_transform_11 -> W_hc_h_10
I0521 09:36:45.679164  3675 net.cpp:150] Setting up lstm1x_transform_11
I0521 09:36:45.679175  3675 net.cpp:157] Top shape: 1 128 400 (51200)
I0521 09:36:45.679179  3675 net.cpp:165] Memory required for data: 30377984
I0521 09:36:45.679184  3675 net.cpp:493] Sharing parameters 'W_hc' owned by layer 'lstm1x_transform_1', param index 0
I0521 09:36:45.679188  3675 layer_factory.hpp:77] Creating layer lstm1x_gate_input_11
I0521 09:36:45.679195  3675 net.cpp:100] Creating Layer lstm1x_gate_input_11
I0521 09:36:45.679199  3675 net.cpp:434] lstm1x_gate_input_11 <- W_hc_h_10
I0521 09:36:45.679204  3675 net.cpp:434] lstm1x_gate_input_11 <- W_xc_x_11
I0521 09:36:45.679210  3675 net.cpp:408] lstm1x_gate_input_11 -> gate_input_11
I0521 09:36:45.679239  3675 net.cpp:150] Setting up lstm1x_gate_input_11
I0521 09:36:45.679245  3675 net.cpp:157] Top shape: 1 128 400 (51200)
I0521 09:36:45.679249  3675 net.cpp:165] Memory required for data: 30582784
I0521 09:36:45.679251  3675 layer_factory.hpp:77] Creating layer lstm1x_unit_11
I0521 09:36:45.679257  3675 net.cpp:100] Creating Layer lstm1x_unit_11
I0521 09:36:45.679261  3675 net.cpp:434] lstm1x_unit_11 <- c_10
I0521 09:36:45.679266  3675 net.cpp:434] lstm1x_unit_11 <- gate_input_11
I0521 09:36:45.679270  3675 net.cpp:434] lstm1x_unit_11 <- cont_11_lstm1x_cont_slice_10_split_1
I0521 09:36:45.679276  3675 net.cpp:408] lstm1x_unit_11 -> c_11
I0521 09:36:45.679283  3675 net.cpp:408] lstm1x_unit_11 -> h_11
I0521 09:36:45.679327  3675 net.cpp:150] Setting up lstm1x_unit_11
I0521 09:36:45.679334  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.679339  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.679342  3675 net.cpp:165] Memory required for data: 30685184
I0521 09:36:45.679347  3675 layer_factory.hpp:77] Creating layer h_11_lstm1x_unit_11_1_split
I0521 09:36:45.679352  3675 net.cpp:100] Creating Layer h_11_lstm1x_unit_11_1_split
I0521 09:36:45.679355  3675 net.cpp:434] h_11_lstm1x_unit_11_1_split <- h_11
I0521 09:36:45.679360  3675 net.cpp:408] h_11_lstm1x_unit_11_1_split -> h_11_lstm1x_unit_11_1_split_0
I0521 09:36:45.679368  3675 net.cpp:408] h_11_lstm1x_unit_11_1_split -> h_11_lstm1x_unit_11_1_split_1
I0521 09:36:45.679399  3675 net.cpp:150] Setting up h_11_lstm1x_unit_11_1_split
I0521 09:36:45.679405  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.679422  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.679425  3675 net.cpp:165] Memory required for data: 30787584
I0521 09:36:45.679430  3675 layer_factory.hpp:77] Creating layer lstm1x_h_conted_11
I0521 09:36:45.679440  3675 net.cpp:100] Creating Layer lstm1x_h_conted_11
I0521 09:36:45.679445  3675 net.cpp:434] lstm1x_h_conted_11 <- h_11_lstm1x_unit_11_1_split_0
I0521 09:36:45.679448  3675 net.cpp:434] lstm1x_h_conted_11 <- cont_12_lstm1x_cont_slice_11_split_0
I0521 09:36:45.679455  3675 net.cpp:408] lstm1x_h_conted_11 -> h_conted_11
I0521 09:36:45.679514  3675 net.cpp:150] Setting up lstm1x_h_conted_11
I0521 09:36:45.679522  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.679524  3675 net.cpp:165] Memory required for data: 30838784
I0521 09:36:45.679527  3675 layer_factory.hpp:77] Creating layer lstm1x_transform_12
I0521 09:36:45.679535  3675 net.cpp:100] Creating Layer lstm1x_transform_12
I0521 09:36:45.679539  3675 net.cpp:434] lstm1x_transform_12 <- h_conted_11
I0521 09:36:45.679545  3675 net.cpp:408] lstm1x_transform_12 -> W_hc_h_11
I0521 09:36:45.679890  3675 net.cpp:150] Setting up lstm1x_transform_12
I0521 09:36:45.679903  3675 net.cpp:157] Top shape: 1 128 400 (51200)
I0521 09:36:45.679905  3675 net.cpp:165] Memory required for data: 31043584
I0521 09:36:45.679910  3675 net.cpp:493] Sharing parameters 'W_hc' owned by layer 'lstm1x_transform_1', param index 0
I0521 09:36:45.679914  3675 layer_factory.hpp:77] Creating layer lstm1x_gate_input_12
I0521 09:36:45.679920  3675 net.cpp:100] Creating Layer lstm1x_gate_input_12
I0521 09:36:45.679925  3675 net.cpp:434] lstm1x_gate_input_12 <- W_hc_h_11
I0521 09:36:45.679931  3675 net.cpp:434] lstm1x_gate_input_12 <- W_xc_x_12
I0521 09:36:45.679937  3675 net.cpp:408] lstm1x_gate_input_12 -> gate_input_12
I0521 09:36:45.679965  3675 net.cpp:150] Setting up lstm1x_gate_input_12
I0521 09:36:45.679970  3675 net.cpp:157] Top shape: 1 128 400 (51200)
I0521 09:36:45.679973  3675 net.cpp:165] Memory required for data: 31248384
I0521 09:36:45.679976  3675 layer_factory.hpp:77] Creating layer lstm1x_unit_12
I0521 09:36:45.679982  3675 net.cpp:100] Creating Layer lstm1x_unit_12
I0521 09:36:45.679986  3675 net.cpp:434] lstm1x_unit_12 <- c_11
I0521 09:36:45.679991  3675 net.cpp:434] lstm1x_unit_12 <- gate_input_12
I0521 09:36:45.679996  3675 net.cpp:434] lstm1x_unit_12 <- cont_12_lstm1x_cont_slice_11_split_1
I0521 09:36:45.680003  3675 net.cpp:408] lstm1x_unit_12 -> c_12
I0521 09:36:45.680009  3675 net.cpp:408] lstm1x_unit_12 -> h_12
I0521 09:36:45.680052  3675 net.cpp:150] Setting up lstm1x_unit_12
I0521 09:36:45.680058  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.680063  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.680066  3675 net.cpp:165] Memory required for data: 31350784
I0521 09:36:45.680070  3675 layer_factory.hpp:77] Creating layer h_12_lstm1x_unit_12_1_split
I0521 09:36:45.680075  3675 net.cpp:100] Creating Layer h_12_lstm1x_unit_12_1_split
I0521 09:36:45.680080  3675 net.cpp:434] h_12_lstm1x_unit_12_1_split <- h_12
I0521 09:36:45.680085  3675 net.cpp:408] h_12_lstm1x_unit_12_1_split -> h_12_lstm1x_unit_12_1_split_0
I0521 09:36:45.680094  3675 net.cpp:408] h_12_lstm1x_unit_12_1_split -> h_12_lstm1x_unit_12_1_split_1
I0521 09:36:45.680122  3675 net.cpp:150] Setting up h_12_lstm1x_unit_12_1_split
I0521 09:36:45.680128  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.680133  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.680136  3675 net.cpp:165] Memory required for data: 31453184
I0521 09:36:45.680140  3675 layer_factory.hpp:77] Creating layer lstm1x_h_conted_12
I0521 09:36:45.680150  3675 net.cpp:100] Creating Layer lstm1x_h_conted_12
I0521 09:36:45.680155  3675 net.cpp:434] lstm1x_h_conted_12 <- h_12_lstm1x_unit_12_1_split_0
I0521 09:36:45.680158  3675 net.cpp:434] lstm1x_h_conted_12 <- cont_13_lstm1x_cont_slice_12_split_0
I0521 09:36:45.680164  3675 net.cpp:408] lstm1x_h_conted_12 -> h_conted_12
I0521 09:36:45.680223  3675 net.cpp:150] Setting up lstm1x_h_conted_12
I0521 09:36:45.680240  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.680244  3675 net.cpp:165] Memory required for data: 31504384
I0521 09:36:45.680248  3675 layer_factory.hpp:77] Creating layer lstm1x_transform_13
I0521 09:36:45.680256  3675 net.cpp:100] Creating Layer lstm1x_transform_13
I0521 09:36:45.680260  3675 net.cpp:434] lstm1x_transform_13 <- h_conted_12
I0521 09:36:45.680266  3675 net.cpp:408] lstm1x_transform_13 -> W_hc_h_12
I0521 09:36:45.680610  3675 net.cpp:150] Setting up lstm1x_transform_13
I0521 09:36:45.680621  3675 net.cpp:157] Top shape: 1 128 400 (51200)
I0521 09:36:45.680624  3675 net.cpp:165] Memory required for data: 31709184
I0521 09:36:45.680629  3675 net.cpp:493] Sharing parameters 'W_hc' owned by layer 'lstm1x_transform_1', param index 0
I0521 09:36:45.680634  3675 layer_factory.hpp:77] Creating layer lstm1x_gate_input_13
I0521 09:36:45.680641  3675 net.cpp:100] Creating Layer lstm1x_gate_input_13
I0521 09:36:45.680645  3675 net.cpp:434] lstm1x_gate_input_13 <- W_hc_h_12
I0521 09:36:45.680650  3675 net.cpp:434] lstm1x_gate_input_13 <- W_xc_x_13
I0521 09:36:45.680655  3675 net.cpp:408] lstm1x_gate_input_13 -> gate_input_13
I0521 09:36:45.680680  3675 net.cpp:150] Setting up lstm1x_gate_input_13
I0521 09:36:45.680685  3675 net.cpp:157] Top shape: 1 128 400 (51200)
I0521 09:36:45.680688  3675 net.cpp:165] Memory required for data: 31913984
I0521 09:36:45.680692  3675 layer_factory.hpp:77] Creating layer lstm1x_unit_13
I0521 09:36:45.680701  3675 net.cpp:100] Creating Layer lstm1x_unit_13
I0521 09:36:45.680706  3675 net.cpp:434] lstm1x_unit_13 <- c_12
I0521 09:36:45.680709  3675 net.cpp:434] lstm1x_unit_13 <- gate_input_13
I0521 09:36:45.680714  3675 net.cpp:434] lstm1x_unit_13 <- cont_13_lstm1x_cont_slice_12_split_1
I0521 09:36:45.680719  3675 net.cpp:408] lstm1x_unit_13 -> c_13
I0521 09:36:45.680725  3675 net.cpp:408] lstm1x_unit_13 -> h_13
I0521 09:36:45.680768  3675 net.cpp:150] Setting up lstm1x_unit_13
I0521 09:36:45.680773  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.680776  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.680779  3675 net.cpp:165] Memory required for data: 32016384
I0521 09:36:45.680841  3675 layer_factory.hpp:77] Creating layer h_13_lstm1x_unit_13_1_split
I0521 09:36:45.680848  3675 net.cpp:100] Creating Layer h_13_lstm1x_unit_13_1_split
I0521 09:36:45.680852  3675 net.cpp:434] h_13_lstm1x_unit_13_1_split <- h_13
I0521 09:36:45.680858  3675 net.cpp:408] h_13_lstm1x_unit_13_1_split -> h_13_lstm1x_unit_13_1_split_0
I0521 09:36:45.680866  3675 net.cpp:408] h_13_lstm1x_unit_13_1_split -> h_13_lstm1x_unit_13_1_split_1
I0521 09:36:45.680900  3675 net.cpp:150] Setting up h_13_lstm1x_unit_13_1_split
I0521 09:36:45.680907  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.680912  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.680914  3675 net.cpp:165] Memory required for data: 32118784
I0521 09:36:45.680917  3675 layer_factory.hpp:77] Creating layer lstm1x_h_conted_13
I0521 09:36:45.680932  3675 net.cpp:100] Creating Layer lstm1x_h_conted_13
I0521 09:36:45.680938  3675 net.cpp:434] lstm1x_h_conted_13 <- h_13_lstm1x_unit_13_1_split_0
I0521 09:36:45.680943  3675 net.cpp:434] lstm1x_h_conted_13 <- cont_14_lstm1x_cont_slice_13_split_0
I0521 09:36:45.680948  3675 net.cpp:408] lstm1x_h_conted_13 -> h_conted_13
I0521 09:36:45.681010  3675 net.cpp:150] Setting up lstm1x_h_conted_13
I0521 09:36:45.681016  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.681020  3675 net.cpp:165] Memory required for data: 32169984
I0521 09:36:45.681023  3675 layer_factory.hpp:77] Creating layer lstm1x_transform_14
I0521 09:36:45.681030  3675 net.cpp:100] Creating Layer lstm1x_transform_14
I0521 09:36:45.681035  3675 net.cpp:434] lstm1x_transform_14 <- h_conted_13
I0521 09:36:45.681041  3675 net.cpp:408] lstm1x_transform_14 -> W_hc_h_13
I0521 09:36:45.681390  3675 net.cpp:150] Setting up lstm1x_transform_14
I0521 09:36:45.681401  3675 net.cpp:157] Top shape: 1 128 400 (51200)
I0521 09:36:45.681406  3675 net.cpp:165] Memory required for data: 32374784
I0521 09:36:45.681423  3675 net.cpp:493] Sharing parameters 'W_hc' owned by layer 'lstm1x_transform_1', param index 0
I0521 09:36:45.681428  3675 layer_factory.hpp:77] Creating layer lstm1x_gate_input_14
I0521 09:36:45.681437  3675 net.cpp:100] Creating Layer lstm1x_gate_input_14
I0521 09:36:45.681442  3675 net.cpp:434] lstm1x_gate_input_14 <- W_hc_h_13
I0521 09:36:45.681447  3675 net.cpp:434] lstm1x_gate_input_14 <- W_xc_x_14
I0521 09:36:45.681452  3675 net.cpp:408] lstm1x_gate_input_14 -> gate_input_14
I0521 09:36:45.681479  3675 net.cpp:150] Setting up lstm1x_gate_input_14
I0521 09:36:45.681485  3675 net.cpp:157] Top shape: 1 128 400 (51200)
I0521 09:36:45.681489  3675 net.cpp:165] Memory required for data: 32579584
I0521 09:36:45.681493  3675 layer_factory.hpp:77] Creating layer lstm1x_unit_14
I0521 09:36:45.681500  3675 net.cpp:100] Creating Layer lstm1x_unit_14
I0521 09:36:45.681505  3675 net.cpp:434] lstm1x_unit_14 <- c_13
I0521 09:36:45.681509  3675 net.cpp:434] lstm1x_unit_14 <- gate_input_14
I0521 09:36:45.681514  3675 net.cpp:434] lstm1x_unit_14 <- cont_14_lstm1x_cont_slice_13_split_1
I0521 09:36:45.681519  3675 net.cpp:408] lstm1x_unit_14 -> c_14
I0521 09:36:45.681526  3675 net.cpp:408] lstm1x_unit_14 -> h_14
I0521 09:36:45.681571  3675 net.cpp:150] Setting up lstm1x_unit_14
I0521 09:36:45.681578  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.681582  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.681586  3675 net.cpp:165] Memory required for data: 32681984
I0521 09:36:45.681591  3675 layer_factory.hpp:77] Creating layer h_14_lstm1x_unit_14_1_split
I0521 09:36:45.681596  3675 net.cpp:100] Creating Layer h_14_lstm1x_unit_14_1_split
I0521 09:36:45.681599  3675 net.cpp:434] h_14_lstm1x_unit_14_1_split <- h_14
I0521 09:36:45.681607  3675 net.cpp:408] h_14_lstm1x_unit_14_1_split -> h_14_lstm1x_unit_14_1_split_0
I0521 09:36:45.681613  3675 net.cpp:408] h_14_lstm1x_unit_14_1_split -> h_14_lstm1x_unit_14_1_split_1
I0521 09:36:45.681645  3675 net.cpp:150] Setting up h_14_lstm1x_unit_14_1_split
I0521 09:36:45.681650  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.681655  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.681658  3675 net.cpp:165] Memory required for data: 32784384
I0521 09:36:45.681663  3675 layer_factory.hpp:77] Creating layer lstm1x_h_conted_14
I0521 09:36:45.681669  3675 net.cpp:100] Creating Layer lstm1x_h_conted_14
I0521 09:36:45.681674  3675 net.cpp:434] lstm1x_h_conted_14 <- h_14_lstm1x_unit_14_1_split_0
I0521 09:36:45.681679  3675 net.cpp:434] lstm1x_h_conted_14 <- cont_15_lstm1x_cont_slice_14_split_0
I0521 09:36:45.681684  3675 net.cpp:408] lstm1x_h_conted_14 -> h_conted_14
I0521 09:36:45.681742  3675 net.cpp:150] Setting up lstm1x_h_conted_14
I0521 09:36:45.681748  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.681751  3675 net.cpp:165] Memory required for data: 32835584
I0521 09:36:45.681756  3675 layer_factory.hpp:77] Creating layer lstm1x_transform_15
I0521 09:36:45.681762  3675 net.cpp:100] Creating Layer lstm1x_transform_15
I0521 09:36:45.681766  3675 net.cpp:434] lstm1x_transform_15 <- h_conted_14
I0521 09:36:45.681771  3675 net.cpp:408] lstm1x_transform_15 -> W_hc_h_14
I0521 09:36:45.682116  3675 net.cpp:150] Setting up lstm1x_transform_15
I0521 09:36:45.682126  3675 net.cpp:157] Top shape: 1 128 400 (51200)
I0521 09:36:45.682130  3675 net.cpp:165] Memory required for data: 33040384
I0521 09:36:45.682137  3675 net.cpp:493] Sharing parameters 'W_hc' owned by layer 'lstm1x_transform_1', param index 0
I0521 09:36:45.682142  3675 layer_factory.hpp:77] Creating layer lstm1x_gate_input_15
I0521 09:36:45.682149  3675 net.cpp:100] Creating Layer lstm1x_gate_input_15
I0521 09:36:45.682153  3675 net.cpp:434] lstm1x_gate_input_15 <- W_hc_h_14
I0521 09:36:45.682158  3675 net.cpp:434] lstm1x_gate_input_15 <- W_xc_x_15
I0521 09:36:45.682164  3675 net.cpp:408] lstm1x_gate_input_15 -> gate_input_15
I0521 09:36:45.682193  3675 net.cpp:150] Setting up lstm1x_gate_input_15
I0521 09:36:45.682199  3675 net.cpp:157] Top shape: 1 128 400 (51200)
I0521 09:36:45.682214  3675 net.cpp:165] Memory required for data: 33245184
I0521 09:36:45.682217  3675 layer_factory.hpp:77] Creating layer lstm1x_unit_15
I0521 09:36:45.682224  3675 net.cpp:100] Creating Layer lstm1x_unit_15
I0521 09:36:45.682229  3675 net.cpp:434] lstm1x_unit_15 <- c_14
I0521 09:36:45.682232  3675 net.cpp:434] lstm1x_unit_15 <- gate_input_15
I0521 09:36:45.682237  3675 net.cpp:434] lstm1x_unit_15 <- cont_15_lstm1x_cont_slice_14_split_1
I0521 09:36:45.682242  3675 net.cpp:408] lstm1x_unit_15 -> c_15
I0521 09:36:45.682250  3675 net.cpp:408] lstm1x_unit_15 -> h_15
I0521 09:36:45.682294  3675 net.cpp:150] Setting up lstm1x_unit_15
I0521 09:36:45.682301  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.682305  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.682308  3675 net.cpp:165] Memory required for data: 33347584
I0521 09:36:45.682312  3675 layer_factory.hpp:77] Creating layer h_15_lstm1x_unit_15_1_split
I0521 09:36:45.682318  3675 net.cpp:100] Creating Layer h_15_lstm1x_unit_15_1_split
I0521 09:36:45.682322  3675 net.cpp:434] h_15_lstm1x_unit_15_1_split <- h_15
I0521 09:36:45.682328  3675 net.cpp:408] h_15_lstm1x_unit_15_1_split -> h_15_lstm1x_unit_15_1_split_0
I0521 09:36:45.682335  3675 net.cpp:408] h_15_lstm1x_unit_15_1_split -> h_15_lstm1x_unit_15_1_split_1
I0521 09:36:45.682366  3675 net.cpp:150] Setting up h_15_lstm1x_unit_15_1_split
I0521 09:36:45.682373  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.682377  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.682380  3675 net.cpp:165] Memory required for data: 33449984
I0521 09:36:45.682384  3675 layer_factory.hpp:77] Creating layer lstm1x_h_conted_15
I0521 09:36:45.682391  3675 net.cpp:100] Creating Layer lstm1x_h_conted_15
I0521 09:36:45.682396  3675 net.cpp:434] lstm1x_h_conted_15 <- h_15_lstm1x_unit_15_1_split_0
I0521 09:36:45.682400  3675 net.cpp:434] lstm1x_h_conted_15 <- cont_16_lstm1x_cont_slice_15_split_0
I0521 09:36:45.682406  3675 net.cpp:408] lstm1x_h_conted_15 -> h_conted_15
I0521 09:36:45.682463  3675 net.cpp:150] Setting up lstm1x_h_conted_15
I0521 09:36:45.682471  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.682473  3675 net.cpp:165] Memory required for data: 33501184
I0521 09:36:45.682477  3675 layer_factory.hpp:77] Creating layer lstm1x_transform_16
I0521 09:36:45.682485  3675 net.cpp:100] Creating Layer lstm1x_transform_16
I0521 09:36:45.682489  3675 net.cpp:434] lstm1x_transform_16 <- h_conted_15
I0521 09:36:45.682495  3675 net.cpp:408] lstm1x_transform_16 -> W_hc_h_15
I0521 09:36:45.682848  3675 net.cpp:150] Setting up lstm1x_transform_16
I0521 09:36:45.682860  3675 net.cpp:157] Top shape: 1 128 400 (51200)
I0521 09:36:45.682864  3675 net.cpp:165] Memory required for data: 33705984
I0521 09:36:45.682869  3675 net.cpp:493] Sharing parameters 'W_hc' owned by layer 'lstm1x_transform_1', param index 0
I0521 09:36:45.682874  3675 layer_factory.hpp:77] Creating layer lstm1x_gate_input_16
I0521 09:36:45.682880  3675 net.cpp:100] Creating Layer lstm1x_gate_input_16
I0521 09:36:45.682885  3675 net.cpp:434] lstm1x_gate_input_16 <- W_hc_h_15
I0521 09:36:45.682890  3675 net.cpp:434] lstm1x_gate_input_16 <- W_xc_x_16
I0521 09:36:45.682895  3675 net.cpp:408] lstm1x_gate_input_16 -> gate_input_16
I0521 09:36:45.682922  3675 net.cpp:150] Setting up lstm1x_gate_input_16
I0521 09:36:45.682927  3675 net.cpp:157] Top shape: 1 128 400 (51200)
I0521 09:36:45.682931  3675 net.cpp:165] Memory required for data: 33910784
I0521 09:36:45.682934  3675 layer_factory.hpp:77] Creating layer lstm1x_unit_16
I0521 09:36:45.682940  3675 net.cpp:100] Creating Layer lstm1x_unit_16
I0521 09:36:45.682945  3675 net.cpp:434] lstm1x_unit_16 <- c_15
I0521 09:36:45.682948  3675 net.cpp:434] lstm1x_unit_16 <- gate_input_16
I0521 09:36:45.682952  3675 net.cpp:434] lstm1x_unit_16 <- cont_16_lstm1x_cont_slice_15_split_1
I0521 09:36:45.682958  3675 net.cpp:408] lstm1x_unit_16 -> c_16
I0521 09:36:45.682965  3675 net.cpp:408] lstm1x_unit_16 -> h_16
I0521 09:36:45.683022  3675 net.cpp:150] Setting up lstm1x_unit_16
I0521 09:36:45.683029  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.683033  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.683037  3675 net.cpp:165] Memory required for data: 34013184
I0521 09:36:45.683040  3675 layer_factory.hpp:77] Creating layer lstm1x_
I0521 09:36:45.683048  3675 net.cpp:100] Creating Layer lstm1x_
I0521 09:36:45.683050  3675 net.cpp:434] lstm1x_ <- c_16
I0521 09:36:45.683056  3675 net.cpp:408] lstm1x_ -> c_T
I0521 09:36:45.683073  3675 net.cpp:150] Setting up lstm1x_
I0521 09:36:45.683079  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.683082  3675 net.cpp:165] Memory required for data: 34064384
I0521 09:36:45.683086  3675 layer_factory.hpp:77] Creating layer lstm1x_h_concat
I0521 09:36:45.683096  3675 net.cpp:100] Creating Layer lstm1x_h_concat
I0521 09:36:45.683100  3675 net.cpp:434] lstm1x_h_concat <- h_1_lstm1x_unit_1_1_split_1
I0521 09:36:45.683104  3675 net.cpp:434] lstm1x_h_concat <- h_2_lstm1x_unit_2_1_split_1
I0521 09:36:45.683109  3675 net.cpp:434] lstm1x_h_concat <- h_3_lstm1x_unit_3_1_split_1
I0521 09:36:45.683113  3675 net.cpp:434] lstm1x_h_concat <- h_4_lstm1x_unit_4_1_split_1
I0521 09:36:45.683116  3675 net.cpp:434] lstm1x_h_concat <- h_5_lstm1x_unit_5_1_split_1
I0521 09:36:45.683120  3675 net.cpp:434] lstm1x_h_concat <- h_6_lstm1x_unit_6_1_split_1
I0521 09:36:45.683125  3675 net.cpp:434] lstm1x_h_concat <- h_7_lstm1x_unit_7_1_split_1
I0521 09:36:45.683127  3675 net.cpp:434] lstm1x_h_concat <- h_8_lstm1x_unit_8_1_split_1
I0521 09:36:45.683131  3675 net.cpp:434] lstm1x_h_concat <- h_9_lstm1x_unit_9_1_split_1
I0521 09:36:45.683136  3675 net.cpp:434] lstm1x_h_concat <- h_10_lstm1x_unit_10_1_split_1
I0521 09:36:45.683140  3675 net.cpp:434] lstm1x_h_concat <- h_11_lstm1x_unit_11_1_split_1
I0521 09:36:45.683143  3675 net.cpp:434] lstm1x_h_concat <- h_12_lstm1x_unit_12_1_split_1
I0521 09:36:45.683147  3675 net.cpp:434] lstm1x_h_concat <- h_13_lstm1x_unit_13_1_split_1
I0521 09:36:45.683151  3675 net.cpp:434] lstm1x_h_concat <- h_14_lstm1x_unit_14_1_split_1
I0521 09:36:45.683154  3675 net.cpp:434] lstm1x_h_concat <- h_15_lstm1x_unit_15_1_split_1
I0521 09:36:45.683157  3675 net.cpp:434] lstm1x_h_concat <- h_16
I0521 09:36:45.683163  3675 net.cpp:408] lstm1x_h_concat -> h
I0521 09:36:45.683187  3675 net.cpp:150] Setting up lstm1x_h_concat
I0521 09:36:45.683192  3675 net.cpp:157] Top shape: 16 128 100 (204800)
I0521 09:36:45.683195  3675 net.cpp:165] Memory required for data: 34883584
I0521 09:36:45.683198  3675 layer_factory.hpp:77] Creating layer h_pseudoloss
I0521 09:36:45.683204  3675 net.cpp:100] Creating Layer h_pseudoloss
I0521 09:36:45.683207  3675 net.cpp:434] h_pseudoloss <- h
I0521 09:36:45.683212  3675 net.cpp:408] h_pseudoloss -> h_pseudoloss
I0521 09:36:45.684293  3675 net.cpp:150] Setting up h_pseudoloss
I0521 09:36:45.684307  3675 net.cpp:157] Top shape: (1)
I0521 09:36:45.684311  3675 net.cpp:160]     with loss weight 1
I0521 09:36:45.684322  3675 net.cpp:165] Memory required for data: 34883588
I0521 09:36:45.684327  3675 net.cpp:226] h_pseudoloss needs backward computation.
I0521 09:36:45.684332  3675 net.cpp:226] lstm1x_h_concat needs backward computation.
I0521 09:36:45.684341  3675 net.cpp:228] lstm1x_ does not need backward computation.
I0521 09:36:45.684345  3675 net.cpp:226] lstm1x_unit_16 needs backward computation.
I0521 09:36:45.684350  3675 net.cpp:226] lstm1x_gate_input_16 needs backward computation.
I0521 09:36:45.684353  3675 net.cpp:226] lstm1x_transform_16 needs backward computation.
I0521 09:36:45.684357  3675 net.cpp:226] lstm1x_h_conted_15 needs backward computation.
I0521 09:36:45.684362  3675 net.cpp:226] h_15_lstm1x_unit_15_1_split needs backward computation.
I0521 09:36:45.684367  3675 net.cpp:226] lstm1x_unit_15 needs backward computation.
I0521 09:36:45.684372  3675 net.cpp:226] lstm1x_gate_input_15 needs backward computation.
I0521 09:36:45.684377  3675 net.cpp:226] lstm1x_transform_15 needs backward computation.
I0521 09:36:45.684381  3675 net.cpp:226] lstm1x_h_conted_14 needs backward computation.
I0521 09:36:45.684399  3675 net.cpp:226] h_14_lstm1x_unit_14_1_split needs backward computation.
I0521 09:36:45.684404  3675 net.cpp:226] lstm1x_unit_14 needs backward computation.
I0521 09:36:45.684409  3675 net.cpp:226] lstm1x_gate_input_14 needs backward computation.
I0521 09:36:45.684413  3675 net.cpp:226] lstm1x_transform_14 needs backward computation.
I0521 09:36:45.684417  3675 net.cpp:226] lstm1x_h_conted_13 needs backward computation.
I0521 09:36:45.684423  3675 net.cpp:226] h_13_lstm1x_unit_13_1_split needs backward computation.
I0521 09:36:45.684428  3675 net.cpp:226] lstm1x_unit_13 needs backward computation.
I0521 09:36:45.684433  3675 net.cpp:226] lstm1x_gate_input_13 needs backward computation.
I0521 09:36:45.684437  3675 net.cpp:226] lstm1x_transform_13 needs backward computation.
I0521 09:36:45.684442  3675 net.cpp:226] lstm1x_h_conted_12 needs backward computation.
I0521 09:36:45.684446  3675 net.cpp:226] h_12_lstm1x_unit_12_1_split needs backward computation.
I0521 09:36:45.684450  3675 net.cpp:226] lstm1x_unit_12 needs backward computation.
I0521 09:36:45.684455  3675 net.cpp:226] lstm1x_gate_input_12 needs backward computation.
I0521 09:36:45.684459  3675 net.cpp:226] lstm1x_transform_12 needs backward computation.
I0521 09:36:45.684464  3675 net.cpp:226] lstm1x_h_conted_11 needs backward computation.
I0521 09:36:45.684468  3675 net.cpp:226] h_11_lstm1x_unit_11_1_split needs backward computation.
I0521 09:36:45.684473  3675 net.cpp:226] lstm1x_unit_11 needs backward computation.
I0521 09:36:45.684479  3675 net.cpp:226] lstm1x_gate_input_11 needs backward computation.
I0521 09:36:45.684484  3675 net.cpp:226] lstm1x_transform_11 needs backward computation.
I0521 09:36:45.684487  3675 net.cpp:226] lstm1x_h_conted_10 needs backward computation.
I0521 09:36:45.684492  3675 net.cpp:226] h_10_lstm1x_unit_10_1_split needs backward computation.
I0521 09:36:45.684496  3675 net.cpp:226] lstm1x_unit_10 needs backward computation.
I0521 09:36:45.684502  3675 net.cpp:226] lstm1x_gate_input_10 needs backward computation.
I0521 09:36:45.684509  3675 net.cpp:226] lstm1x_transform_10 needs backward computation.
I0521 09:36:45.684512  3675 net.cpp:226] lstm1x_h_conted_9 needs backward computation.
I0521 09:36:45.684517  3675 net.cpp:226] h_9_lstm1x_unit_9_1_split needs backward computation.
I0521 09:36:45.684521  3675 net.cpp:226] lstm1x_unit_9 needs backward computation.
I0521 09:36:45.684527  3675 net.cpp:226] lstm1x_gate_input_9 needs backward computation.
I0521 09:36:45.684531  3675 net.cpp:226] lstm1x_transform_9 needs backward computation.
I0521 09:36:45.684536  3675 net.cpp:226] lstm1x_h_conted_8 needs backward computation.
I0521 09:36:45.684541  3675 net.cpp:226] h_8_lstm1x_unit_8_1_split needs backward computation.
I0521 09:36:45.684545  3675 net.cpp:226] lstm1x_unit_8 needs backward computation.
I0521 09:36:45.684551  3675 net.cpp:226] lstm1x_gate_input_8 needs backward computation.
I0521 09:36:45.684556  3675 net.cpp:226] lstm1x_transform_8 needs backward computation.
I0521 09:36:45.684559  3675 net.cpp:226] lstm1x_h_conted_7 needs backward computation.
I0521 09:36:45.684564  3675 net.cpp:226] h_7_lstm1x_unit_7_1_split needs backward computation.
I0521 09:36:45.684568  3675 net.cpp:226] lstm1x_unit_7 needs backward computation.
I0521 09:36:45.684574  3675 net.cpp:226] lstm1x_gate_input_7 needs backward computation.
I0521 09:36:45.684578  3675 net.cpp:226] lstm1x_transform_7 needs backward computation.
I0521 09:36:45.684583  3675 net.cpp:226] lstm1x_h_conted_6 needs backward computation.
I0521 09:36:45.684588  3675 net.cpp:226] h_6_lstm1x_unit_6_1_split needs backward computation.
I0521 09:36:45.684592  3675 net.cpp:226] lstm1x_unit_6 needs backward computation.
I0521 09:36:45.684599  3675 net.cpp:226] lstm1x_gate_input_6 needs backward computation.
I0521 09:36:45.684603  3675 net.cpp:226] lstm1x_transform_6 needs backward computation.
I0521 09:36:45.684608  3675 net.cpp:226] lstm1x_h_conted_5 needs backward computation.
I0521 09:36:45.684613  3675 net.cpp:226] h_5_lstm1x_unit_5_1_split needs backward computation.
I0521 09:36:45.684625  3675 net.cpp:226] lstm1x_unit_5 needs backward computation.
I0521 09:36:45.684631  3675 net.cpp:226] lstm1x_gate_input_5 needs backward computation.
I0521 09:36:45.684636  3675 net.cpp:226] lstm1x_transform_5 needs backward computation.
I0521 09:36:45.684640  3675 net.cpp:226] lstm1x_h_conted_4 needs backward computation.
I0521 09:36:45.684645  3675 net.cpp:226] h_4_lstm1x_unit_4_1_split needs backward computation.
I0521 09:36:45.684649  3675 net.cpp:226] lstm1x_unit_4 needs backward computation.
I0521 09:36:45.684654  3675 net.cpp:226] lstm1x_gate_input_4 needs backward computation.
I0521 09:36:45.684659  3675 net.cpp:226] lstm1x_transform_4 needs backward computation.
I0521 09:36:45.684664  3675 net.cpp:226] lstm1x_h_conted_3 needs backward computation.
I0521 09:36:45.684669  3675 net.cpp:226] h_3_lstm1x_unit_3_1_split needs backward computation.
I0521 09:36:45.684672  3675 net.cpp:226] lstm1x_unit_3 needs backward computation.
I0521 09:36:45.684677  3675 net.cpp:226] lstm1x_gate_input_3 needs backward computation.
I0521 09:36:45.684682  3675 net.cpp:226] lstm1x_transform_3 needs backward computation.
I0521 09:36:45.684686  3675 net.cpp:226] lstm1x_h_conted_2 needs backward computation.
I0521 09:36:45.684693  3675 net.cpp:226] h_2_lstm1x_unit_2_1_split needs backward computation.
I0521 09:36:45.684697  3675 net.cpp:226] lstm1x_unit_2 needs backward computation.
I0521 09:36:45.684703  3675 net.cpp:226] lstm1x_gate_input_2 needs backward computation.
I0521 09:36:45.684707  3675 net.cpp:226] lstm1x_transform_2 needs backward computation.
I0521 09:36:45.684712  3675 net.cpp:226] lstm1x_h_conted_1 needs backward computation.
I0521 09:36:45.684717  3675 net.cpp:226] h_1_lstm1x_unit_1_1_split needs backward computation.
I0521 09:36:45.684721  3675 net.cpp:226] lstm1x_unit_1 needs backward computation.
I0521 09:36:45.684727  3675 net.cpp:226] lstm1x_gate_input_1 needs backward computation.
I0521 09:36:45.684731  3675 net.cpp:226] lstm1x_transform_1 needs backward computation.
I0521 09:36:45.684736  3675 net.cpp:228] lstm1x_h_conted_0 does not need backward computation.
I0521 09:36:45.684741  3675 net.cpp:226] lstm1x_W_xc_x_slice needs backward computation.
I0521 09:36:45.684746  3675 net.cpp:226] lstm1x_x_transform needs backward computation.
I0521 09:36:45.684751  3675 net.cpp:228] cont_16_lstm1x_cont_slice_15_split does not need backward computation.
I0521 09:36:45.684756  3675 net.cpp:228] cont_15_lstm1x_cont_slice_14_split does not need backward computation.
I0521 09:36:45.684761  3675 net.cpp:228] cont_14_lstm1x_cont_slice_13_split does not need backward computation.
I0521 09:36:45.684765  3675 net.cpp:228] cont_13_lstm1x_cont_slice_12_split does not need backward computation.
I0521 09:36:45.684770  3675 net.cpp:228] cont_12_lstm1x_cont_slice_11_split does not need backward computation.
I0521 09:36:45.684775  3675 net.cpp:228] cont_11_lstm1x_cont_slice_10_split does not need backward computation.
I0521 09:36:45.684780  3675 net.cpp:228] cont_10_lstm1x_cont_slice_9_split does not need backward computation.
I0521 09:36:45.684793  3675 net.cpp:228] cont_9_lstm1x_cont_slice_8_split does not need backward computation.
I0521 09:36:45.684798  3675 net.cpp:228] cont_8_lstm1x_cont_slice_7_split does not need backward computation.
I0521 09:36:45.684806  3675 net.cpp:228] cont_7_lstm1x_cont_slice_6_split does not need backward computation.
I0521 09:36:45.684811  3675 net.cpp:228] cont_6_lstm1x_cont_slice_5_split does not need backward computation.
I0521 09:36:45.684815  3675 net.cpp:228] cont_5_lstm1x_cont_slice_4_split does not need backward computation.
I0521 09:36:45.684820  3675 net.cpp:228] cont_4_lstm1x_cont_slice_3_split does not need backward computation.
I0521 09:36:45.684824  3675 net.cpp:228] cont_3_lstm1x_cont_slice_2_split does not need backward computation.
I0521 09:36:45.684829  3675 net.cpp:228] cont_2_lstm1x_cont_slice_1_split does not need backward computation.
I0521 09:36:45.684834  3675 net.cpp:228] cont_1_lstm1x_cont_slice_0_split does not need backward computation.
I0521 09:36:45.684851  3675 net.cpp:228] lstm1x_cont_slice does not need backward computation.
I0521 09:36:45.684856  3675 net.cpp:228] lstm1x_ does not need backward computation.
I0521 09:36:45.684860  3675 net.cpp:228] lstm1x_ does not need backward computation.
I0521 09:36:45.684864  3675 net.cpp:270] This network produces output c_T
I0521 09:36:45.684870  3675 net.cpp:270] This network produces output h_pseudoloss
I0521 09:36:45.685155  3675 net.cpp:283] Network initialization done.
I0521 09:36:45.685387  3675 recurrent_layer.cpp:150] Adding parameter 0: W_xc
I0521 09:36:45.685397  3675 recurrent_layer.cpp:150] Adding parameter 1: b_c
I0521 09:36:45.685401  3675 recurrent_layer.cpp:150] Adding parameter 2: W_hc
I0521 09:36:45.685796  3675 net.cpp:150] Setting up lstm1x
I0521 09:36:45.685811  3675 net.cpp:157] Top shape: 16 128 100 (204800)
I0521 09:36:45.685815  3675 net.cpp:165] Memory required for data: 1841688064
I0521 09:36:45.685824  3675 layer_factory.hpp:77] Creating layer merge_lstm_rlstmx
I0521 09:36:45.685835  3675 net.cpp:100] Creating Layer merge_lstm_rlstmx
I0521 09:36:45.685840  3675 net.cpp:434] merge_lstm_rlstmx <- lstm1x
I0521 09:36:45.685847  3675 net.cpp:434] merge_lstm_rlstmx <- rlstmx
I0521 09:36:45.685853  3675 net.cpp:408] merge_lstm_rlstmx -> merge_lstm_rlstmx
I0521 09:36:45.685886  3675 net.cpp:150] Setting up merge_lstm_rlstmx
I0521 09:36:45.685892  3675 net.cpp:157] Top shape: 16 128 200 (409600)
I0521 09:36:45.685896  3675 net.cpp:165] Memory required for data: 1843326464
I0521 09:36:45.685899  3675 layer_factory.hpp:77] Creating layer fc1x
I0521 09:36:45.685907  3675 net.cpp:100] Creating Layer fc1x
I0521 09:36:45.685911  3675 net.cpp:434] fc1x <- merge_lstm_rlstmx
I0521 09:36:45.685917  3675 net.cpp:408] fc1x -> fc1x
I0521 09:36:45.686137  3675 net.cpp:150] Setting up fc1x
I0521 09:36:45.686147  3675 net.cpp:157] Top shape: 16 128 66 (135168)
I0521 09:36:45.686151  3675 net.cpp:165] Memory required for data: 1843867136
I0521 09:36:45.686158  3675 layer_factory.hpp:77] Creating layer ctcloss
I0521 09:36:45.686167  3675 net.cpp:100] Creating Layer ctcloss
I0521 09:36:45.686170  3675 net.cpp:434] ctcloss <- fc1x
I0521 09:36:45.686175  3675 net.cpp:434] ctcloss <- label
I0521 09:36:45.686182  3675 net.cpp:408] ctcloss -> ctcloss
I0521 09:36:45.686205  3675 net.cpp:150] Setting up ctcloss
I0521 09:36:45.686210  3675 net.cpp:157] Top shape: (1)
I0521 09:36:45.686213  3675 net.cpp:160]     with loss weight 1
I0521 09:36:45.686224  3675 net.cpp:165] Memory required for data: 1843867140
I0521 09:36:45.686228  3675 net.cpp:226] ctcloss needs backward computation.
I0521 09:36:45.686233  3675 net.cpp:226] fc1x needs backward computation.
I0521 09:36:45.686236  3675 net.cpp:226] merge_lstm_rlstmx needs backward computation.
I0521 09:36:45.686240  3675 net.cpp:226] lstm1x needs backward computation.
I0521 09:36:45.686244  3675 net.cpp:226] lstm-reverse2 needs backward computation.
I0521 09:36:45.686249  3675 net.cpp:226] lstm2x needs backward computation.
I0521 09:36:45.686254  3675 net.cpp:226] lstm-reverse1 needs backward computation.
I0521 09:36:45.686259  3675 net.cpp:226] permuted_data_permuted_data_0_split needs backward computation.
I0521 09:36:45.686262  3675 net.cpp:226] permuted_data needs backward computation.
I0521 09:36:45.686266  3675 net.cpp:226] dropout needs backward computation.
I0521 09:36:45.686270  3675 net.cpp:226] last_relu needs backward computation.
I0521 09:36:45.686275  3675 net.cpp:226] last_scale needs backward computation.
I0521 09:36:45.686277  3675 net.cpp:226] last_bn needs backward computation.
I0521 09:36:45.686281  3675 net.cpp:226] layer_128_4_sum needs backward computation.
I0521 09:36:45.686286  3675 net.cpp:226] layer_128_4_conv3 needs backward computation.
I0521 09:36:45.686291  3675 net.cpp:226] layer_128_4_relu3 needs backward computation.
I0521 09:36:45.686295  3675 net.cpp:226] layer_128_4_scale3 needs backward computation.
I0521 09:36:45.686300  3675 net.cpp:226] layer_128_4_bn3 needs backward computation.
I0521 09:36:45.686303  3675 net.cpp:226] layer_128_4_conv2 needs backward computation.
I0521 09:36:45.686323  3675 net.cpp:226] layer_128_4_relu2 needs backward computation.
I0521 09:36:45.686327  3675 net.cpp:226] layer_128_4_scale2 needs backward computation.
I0521 09:36:45.686331  3675 net.cpp:226] layer_128_4_bn2 needs backward computation.
I0521 09:36:45.686336  3675 net.cpp:226] layer_128_4_conv1 needs backward computation.
I0521 09:36:45.686341  3675 net.cpp:226] layer_128_4_relu1 needs backward computation.
I0521 09:36:45.686344  3675 net.cpp:226] layer_128_4_scale1 needs backward computation.
I0521 09:36:45.686348  3675 net.cpp:226] layer_128_4_bn1 needs backward computation.
I0521 09:36:45.686352  3675 net.cpp:226] layer_128_3_sum_layer_128_3_sum_0_split needs backward computation.
I0521 09:36:45.686357  3675 net.cpp:226] layer_128_3_sum needs backward computation.
I0521 09:36:45.686362  3675 net.cpp:226] layer_128_3_conv3 needs backward computation.
I0521 09:36:45.686367  3675 net.cpp:226] layer_128_3_relu3 needs backward computation.
I0521 09:36:45.686370  3675 net.cpp:226] layer_128_3_scale3 needs backward computation.
I0521 09:36:45.686374  3675 net.cpp:226] layer_128_3_bn3 needs backward computation.
I0521 09:36:45.686378  3675 net.cpp:226] layer_128_3_conv2 needs backward computation.
I0521 09:36:45.686383  3675 net.cpp:226] layer_128_3_relu2 needs backward computation.
I0521 09:36:45.686388  3675 net.cpp:226] layer_128_3_scale2 needs backward computation.
I0521 09:36:45.686391  3675 net.cpp:226] layer_128_3_bn2 needs backward computation.
I0521 09:36:45.686395  3675 net.cpp:226] layer_128_3_conv1 needs backward computation.
I0521 09:36:45.686399  3675 net.cpp:226] layer_128_3_relu1 needs backward computation.
I0521 09:36:45.686403  3675 net.cpp:226] layer_128_3_scale1 needs backward computation.
I0521 09:36:45.686408  3675 net.cpp:226] layer_128_3_bn1 needs backward computation.
I0521 09:36:45.686412  3675 net.cpp:226] layer_128_2_sum_layer_128_2_sum_0_split needs backward computation.
I0521 09:36:45.686416  3675 net.cpp:226] layer_128_2_sum needs backward computation.
I0521 09:36:45.686422  3675 net.cpp:226] layer_128_2_conv3 needs backward computation.
I0521 09:36:45.686426  3675 net.cpp:226] layer_128_2_relu3 needs backward computation.
I0521 09:36:45.686430  3675 net.cpp:226] layer_128_2_scale3 needs backward computation.
I0521 09:36:45.686434  3675 net.cpp:226] layer_128_2_bn3 needs backward computation.
I0521 09:36:45.686437  3675 net.cpp:226] layer_128_2_conv2 needs backward computation.
I0521 09:36:45.686442  3675 net.cpp:226] layer_128_2_relu2 needs backward computation.
I0521 09:36:45.686445  3675 net.cpp:226] layer_128_2_scale2 needs backward computation.
I0521 09:36:45.686450  3675 net.cpp:226] layer_128_2_bn2 needs backward computation.
I0521 09:36:45.687422  3675 net.cpp:226] layer_128_2_conv1 needs backward computation.
I0521 09:36:45.687433  3675 net.cpp:226] layer_128_2_relu1 needs backward computation.
I0521 09:36:45.687438  3675 net.cpp:226] layer_128_2_scale1 needs backward computation.
I0521 09:36:45.687440  3675 net.cpp:226] layer_128_2_bn1 needs backward computation.
I0521 09:36:45.687445  3675 net.cpp:226] layer_128_1_sum_layer_128_1_sum_0_split needs backward computation.
I0521 09:36:45.687449  3675 net.cpp:226] layer_128_1_sum needs backward computation.
I0521 09:36:45.687454  3675 net.cpp:226] layer_128_1_conv_expand needs backward computation.
I0521 09:36:45.687458  3675 net.cpp:226] layer_128_1_conv3 needs backward computation.
I0521 09:36:45.687463  3675 net.cpp:226] layer_128_1_relu3 needs backward computation.
I0521 09:36:45.687467  3675 net.cpp:226] layer_128_1_scale3 needs backward computation.
I0521 09:36:45.687470  3675 net.cpp:226] layer_128_1_bn3 needs backward computation.
I0521 09:36:45.687474  3675 net.cpp:226] layer_128_1_conv2 needs backward computation.
I0521 09:36:45.687479  3675 net.cpp:226] layer_128_1_relu2 needs backward computation.
I0521 09:36:45.687482  3675 net.cpp:226] layer_128_1_scale2 needs backward computation.
I0521 09:36:45.687486  3675 net.cpp:226] layer_128_1_bn2 needs backward computation.
I0521 09:36:45.687501  3675 net.cpp:226] layer_128_1_conv1 needs backward computation.
I0521 09:36:45.687506  3675 net.cpp:226] layer_128_1_bn1_layer_128_1_relu1_0_split needs backward computation.
I0521 09:36:45.687510  3675 net.cpp:226] layer_128_1_relu1 needs backward computation.
I0521 09:36:45.687513  3675 net.cpp:226] layer_128_1_scale1 needs backward computation.
I0521 09:36:45.687517  3675 net.cpp:226] layer_128_1_bn1 needs backward computation.
I0521 09:36:45.687521  3675 net.cpp:226] layer_64_3_sum needs backward computation.
I0521 09:36:45.687526  3675 net.cpp:226] layer_64_3_conv3 needs backward computation.
I0521 09:36:45.687530  3675 net.cpp:226] layer_64_3_relu3 needs backward computation.
I0521 09:36:45.687535  3675 net.cpp:226] layer_64_3_scale3 needs backward computation.
I0521 09:36:45.687538  3675 net.cpp:226] layer_64_3_bn3 needs backward computation.
I0521 09:36:45.687541  3675 net.cpp:226] layer_64_3_conv2 needs backward computation.
I0521 09:36:45.687546  3675 net.cpp:226] layer_64_3_relu2 needs backward computation.
I0521 09:36:45.687549  3675 net.cpp:226] layer_64_3_scale2 needs backward computation.
I0521 09:36:45.687553  3675 net.cpp:226] layer_64_3_bn2 needs backward computation.
I0521 09:36:45.687556  3675 net.cpp:226] layer_64_3_conv1 needs backward computation.
I0521 09:36:45.687561  3675 net.cpp:226] layer_64_3_relu1 needs backward computation.
I0521 09:36:45.687566  3675 net.cpp:226] layer_64_3_scale1 needs backward computation.
I0521 09:36:45.687568  3675 net.cpp:226] layer_64_3_bn1 needs backward computation.
I0521 09:36:45.687573  3675 net.cpp:226] layer_64_2_sum_layer_64_2_sum_0_split needs backward computation.
I0521 09:36:45.687577  3675 net.cpp:226] layer_64_2_sum needs backward computation.
I0521 09:36:45.687582  3675 net.cpp:226] layer_64_2_conv3 needs backward computation.
I0521 09:36:45.687585  3675 net.cpp:226] layer_64_2_relu3 needs backward computation.
I0521 09:36:45.687589  3675 net.cpp:226] layer_64_2_scale3 needs backward computation.
I0521 09:36:45.687593  3675 net.cpp:226] layer_64_2_bn3 needs backward computation.
I0521 09:36:45.687597  3675 net.cpp:226] layer_64_2_conv2 needs backward computation.
I0521 09:36:45.687602  3675 net.cpp:226] layer_64_2_relu2 needs backward computation.
I0521 09:36:45.687605  3675 net.cpp:226] layer_64_2_scale2 needs backward computation.
I0521 09:36:45.687608  3675 net.cpp:226] layer_64_2_bn2 needs backward computation.
I0521 09:36:45.687613  3675 net.cpp:226] layer_64_2_conv1 needs backward computation.
I0521 09:36:45.687616  3675 net.cpp:226] layer_64_2_relu1 needs backward computation.
I0521 09:36:45.687620  3675 net.cpp:226] layer_64_2_scale1 needs backward computation.
I0521 09:36:45.687624  3675 net.cpp:226] layer_64_2_bn1 needs backward computation.
I0521 09:36:45.687628  3675 net.cpp:226] layer_64_1_sum_layer_64_1_sum_0_split needs backward computation.
I0521 09:36:45.687633  3675 net.cpp:226] layer_64_1_sum needs backward computation.
I0521 09:36:45.687638  3675 net.cpp:226] layer_64_1_conv_expand needs backward computation.
I0521 09:36:45.687642  3675 net.cpp:226] layer_64_1_conv3 needs backward computation.
I0521 09:36:45.687646  3675 net.cpp:226] layer_64_1_relu3 needs backward computation.
I0521 09:36:45.687650  3675 net.cpp:226] layer_64_1_scale3 needs backward computation.
I0521 09:36:45.687654  3675 net.cpp:226] layer_64_1_bn3 needs backward computation.
I0521 09:36:45.687657  3675 net.cpp:226] layer_64_1_conv2 needs backward computation.
I0521 09:36:45.687661  3675 net.cpp:226] layer_64_1_conv1_layer_64_1_relu2_0_split needs backward computation.
I0521 09:36:45.687665  3675 net.cpp:226] layer_64_1_relu2 needs backward computation.
I0521 09:36:45.687669  3675 net.cpp:226] layer_64_1_scale2 needs backward computation.
I0521 09:36:45.687674  3675 net.cpp:226] layer_64_1_bn2 needs backward computation.
I0521 09:36:45.687677  3675 net.cpp:226] layer_64_1_conv1 needs backward computation.
I0521 09:36:45.687681  3675 net.cpp:226] conv1_pool needs backward computation.
I0521 09:36:45.687685  3675 net.cpp:226] conv1_relu needs backward computation.
I0521 09:36:45.687695  3675 net.cpp:226] conv1_scale needs backward computation.
I0521 09:36:45.687700  3675 net.cpp:226] conv1_bn needs backward computation.
I0521 09:36:45.687703  3675 net.cpp:226] conv1 needs backward computation.
I0521 09:36:45.687707  3675 net.cpp:226] data_scale needs backward computation.
I0521 09:36:45.687711  3675 net.cpp:226] data_bn needs backward computation.
I0521 09:36:45.687716  3675 net.cpp:228] indicator_indicator_0_split does not need backward computation.
I0521 09:36:45.687721  3675 net.cpp:228] indicator does not need backward computation.
I0521 09:36:45.687724  3675 net.cpp:228] data does not need backward computation.
I0521 09:36:45.687727  3675 net.cpp:270] This network produces output ctcloss
I0521 09:36:45.687808  3675 net.cpp:283] Network initialization done.
I0521 09:36:45.688969  3675 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: ./jobs/Resnet_LSTM_CTC/train.prototxt
I0521 09:36:45.688987  3675 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I0521 09:36:45.688995  3675 solver.cpp:196] Creating test net (#0) specified by net file: ./jobs/Resnet_LSTM_CTC/train.prototxt
I0521 09:36:45.689133  3675 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I0521 09:36:45.689750  3675 net.cpp:58] Initializing net from parameters: 
state {
  phase: TEST
}
layer {
  name: "data"
  type: "HDF5Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  hdf5_data_param {
    source: "/home/zhuyipin/DATASET/ccpd/bbox_caffe_data/testing.list"
    batch_size: 128
  }
}
layer {
  name: "indicator"
  type: "ContinuationIndicator"
  top: "indicator"
  continuation_indicator_param {
    time_step: 16
    batch_size: 128
  }
}
layer {
  name: "data_bn"
  type: "BatchNorm"
  bottom: "data"
  top: "data_bn"
}
layer {
  name: "data_scale"
  type: "Scale"
  bottom: "data_bn"
  top: "data_bn"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data_bn"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    pad: 3
    kernel_size: 7
    stride: 2
    weight_filler {
      type: "msra"
      variance_norm: FAN_OUT
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv1_bn"
  type: "BatchNorm"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "conv1_scale"
  type: "Scale"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv1_relu"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "conv1_pool"
  type: "Pooling"
  bottom: "conv1"
  top: "conv1_pool"
  pooling_param {
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "layer_64_1_conv1"
  type: "Convolution"
  bottom: "conv1_pool"
  top: "layer_64_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_64_1_bn2"
  type: "BatchNorm"
  bottom: "layer_64_1_conv1"
  top: "layer_64_1_conv1"
}
layer {
  name: "layer_64_1_scale2"
  type: "Scale"
  bottom: "layer_64_1_conv1"
  top: "layer_64_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_64_1_relu2"
  type: "ReLU"
  bottom: "layer_64_1_conv1"
  top: "layer_64_1_conv1"
}
layer {
  name: "layer_64_1_conv2"
  type: "Convolution"
  bottom: "layer_64_1_conv1"
  top: "layer_64_1_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_64_1_bn3"
  type: "BatchNorm"
  bottom: "layer_64_1_conv2"
  top: "layer_64_1_conv2"
}
layer {
  name: "layer_64_1_scale3"
  type: "Scale"
  bottom: "layer_64_1_conv2"
  top: "layer_64_1_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_64_1_relu3"
  type: "ReLU"
  bottom: "layer_64_1_conv2"
  top: "layer_64_1_conv2"
}
layer {
  name: "layer_64_1_conv3"
  type: "Convolution"
  bottom: "layer_64_1_conv2"
  top: "layer_64_1_conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_64_1_conv_expand"
  type: "Convolution"
  bottom: "layer_64_1_conv1"
  top: "layer_64_1_conv_expand"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_64_1_sum"
  type: "Eltwise"
  bottom: "layer_64_1_conv3"
  bottom: "layer_64_1_conv_expand"
  top: "layer_64_1_sum"
}
layer {
  name: "layer_64_2_bn1"
  type: "BatchNorm"
  bottom: "layer_64_1_sum"
  top: "layer_64_2_bn1"
}
layer {
  name: "layer_64_2_scale1"
  type: "Scale"
  bottom: "layer_64_2_bn1"
  top: "layer_64_2_bn1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_64_2_relu1"
  type: "ReLU"
  bottom: "layer_64_2_bn1"
  top: "layer_64_2_bn1"
}
layer {
  name: "layer_64_2_conv1"
  type: "Convolution"
  bottom: "layer_64_2_bn1"
  top: "layer_64_2_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_64_2_bn2"
  type: "BatchNorm"
  bottom: "layer_64_2_conv1"
  top: "layer_64_2_conv1"
}
layer {
  name: "layer_64_2_scale2"
  type: "Scale"
  bottom: "layer_64_2_conv1"
  top: "layer_64_2_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_64_2_relu2"
  type: "ReLU"
  bottom: "layer_64_2_conv1"
  top: "layer_64_2_conv1"
}
layer {
  name: "layer_64_2_conv2"
  type: "Convolution"
  bottom: "layer_64_2_conv1"
  top: "layer_64_2_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_64_2_bn3"
  type: "BatchNorm"
  bottom: "layer_64_2_conv2"
  top: "layer_64_2_conv2"
}
layer {
  name: "layer_64_2_scale3"
  type: "Scale"
  bottom: "layer_64_2_conv2"
  top: "layer_64_2_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_64_2_relu3"
  type: "ReLU"
  bottom: "layer_64_2_conv2"
  top: "layer_64_2_conv2"
}
layer {
  name: "layer_64_2_conv3"
  type: "Convolution"
  bottom: "layer_64_2_conv2"
  top: "layer_64_2_conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_64_2_sum"
  type: "Eltwise"
  bottom: "layer_64_2_conv3"
  bottom: "layer_64_1_sum"
  top: "layer_64_2_sum"
}
layer {
  name: "layer_64_3_bn1"
  type: "BatchNorm"
  bottom: "layer_64_2_sum"
  top: "layer_64_3_bn1"
}
layer {
  name: "layer_64_3_scale1"
  type: "Scale"
  bottom: "layer_64_3_bn1"
  top: "layer_64_3_bn1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_64_3_relu1"
  type: "ReLU"
  bottom: "layer_64_3_bn1"
  top: "layer_64_3_bn1"
}
layer {
  name: "layer_64_3_conv1"
  type: "Convolution"
  bottom: "layer_64_3_bn1"
  top: "layer_64_3_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_64_3_bn2"
  type: "BatchNorm"
  bottom: "layer_64_3_conv1"
  top: "layer_64_3_conv1"
}
layer {
  name: "layer_64_3_scale2"
  type: "Scale"
  bottom: "layer_64_3_conv1"
  top: "layer_64_3_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_64_3_relu2"
  type: "ReLU"
  bottom: "layer_64_3_conv1"
  top: "layer_64_3_conv1"
}
layer {
  name: "layer_64_3_conv2"
  type: "Convolution"
  bottom: "layer_64_3_conv1"
  top: "layer_64_3_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_64_3_bn3"
  type: "BatchNorm"
  bottom: "layer_64_3_conv2"
  top: "layer_64_3_conv2"
}
layer {
  name: "layer_64_3_scale3"
  type: "Scale"
  bottom: "layer_64_3_conv2"
  top: "layer_64_3_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_64_3_relu3"
  type: "ReLU"
  bottom: "layer_64_3_conv2"
  top: "layer_64_3_conv2"
}
layer {
  name: "layer_64_3_conv3"
  type: "Convolution"
  bottom: "layer_64_3_conv2"
  top: "layer_64_3_conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_64_3_sum"
  type: "Eltwise"
  bottom: "layer_64_3_conv3"
  bottom: "layer_64_2_sum"
  top: "layer_64_3_sum"
}
layer {
  name: "layer_128_1_bn1"
  type: "BatchNorm"
  bottom: "layer_64_3_sum"
  top: "layer_128_1_bn1"
}
layer {
  name: "layer_128_1_scale1"
  type: "Scale"
  bottom: "layer_128_1_bn1"
  top: "layer_128_1_bn1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_128_1_relu1"
  type: "ReLU"
  bottom: "layer_128_1_bn1"
  top: "layer_128_1_bn1"
}
layer {
  name: "layer_128_1_conv1"
  type: "Convolution"
  bottom: "layer_128_1_bn1"
  top: "layer_128_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_128_1_bn2"
  type: "BatchNorm"
  bottom: "layer_128_1_conv1"
  top: "layer_128_1_conv1"
}
layer {
  name: "layer_128_1_scale2"
  type: "Scale"
  bottom: "layer_128_1_conv1"
  top: "layer_128_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_128_1_relu2"
  type: "ReLU"
  bottom: "layer_128_1_conv1"
  top: "layer_128_1_conv1"
}
layer {
  name: "layer_128_1_conv2"
  type: "Convolution"
  bottom: "layer_128_1_conv1"
  top: "layer_128_1_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_128_1_bn3"
  type: "BatchNorm"
  bottom: "layer_128_1_conv2"
  top: "layer_128_1_conv2"
}
layer {
  name: "layer_128_1_scale3"
  type: "Scale"
  bottom: "layer_128_1_conv2"
  top: "layer_128_1_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_128_1_relu3"
  type: "ReLU"
  bottom: "layer_128_1_conv2"
  top: "layer_128_1_conv2"
}
layer {
  name: "layer_128_1_conv3"
  type: "Convolution"
  bottom: "layer_128_1_conv2"
  top: "layer_128_1_conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_128_1_conv_expand"
  type: "Convolution"
  bottom: "layer_128_1_bn1"
  top: "layer_128_1_conv_expand"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_128_1_sum"
  type: "Eltwise"
  bottom: "layer_128_1_conv3"
  bottom: "layer_128_1_conv_expand"
  top: "layer_128_1_sum"
}
layer {
  name: "layer_128_2_bn1"
  type: "BatchNorm"
  bottom: "layer_128_1_sum"
  top: "layer_128_2_bn1"
}
layer {
  name: "layer_128_2_scale1"
  type: "Scale"
  bottom: "layer_128_2_bn1"
  top: "layer_128_2_bn1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_128_2_relu1"
  type: "ReLU"
  bottom: "layer_128_2_bn1"
  top: "layer_128_2_bn1"
}
layer {
  name: "layer_128_2_conv1"
  type: "Convolution"
  bottom: "layer_128_2_bn1"
  top: "layer_128_2_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_128_2_bn2"
  type: "BatchNorm"
  bottom: "layer_128_2_conv1"
  top: "layer_128_2_conv1"
}
layer {
  name: "layer_128_2_scale2"
  type: "Scale"
  bottom: "layer_128_2_conv1"
  top: "layer_128_2_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_128_2_relu2"
  type: "ReLU"
  bottom: "layer_128_2_conv1"
  top: "layer_128_2_conv1"
}
layer {
  name: "layer_128_2_conv2"
  type: "Convolution"
  bottom: "layer_128_2_conv1"
  top: "layer_128_2_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_128_2_bn3"
  type: "BatchNorm"
  bottom: "layer_128_2_conv2"
  top: "layer_128_2_conv2"
}
layer {
  name: "layer_128_2_scale3"
  type: "Scale"
  bottom: "layer_128_2_conv2"
  top: "layer_128_2_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_128_2_relu3"
  type: "ReLU"
  bottom: "layer_128_2_conv2"
  top: "layer_128_2_conv2"
}
layer {
  name: "layer_128_2_conv3"
  type: "Convolution"
  bottom: "layer_128_2_conv2"
  top: "layer_128_2_conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_128_2_sum"
  type: "Eltwise"
  bottom: "layer_128_2_conv3"
  bottom: "layer_128_1_sum"
  top: "layer_128_2_sum"
}
layer {
  name: "layer_128_3_bn1"
  type: "BatchNorm"
  bottom: "layer_128_2_sum"
  top: "layer_128_3_bn1"
}
layer {
  name: "layer_128_3_scale1"
  type: "Scale"
  bottom: "layer_128_3_bn1"
  top: "layer_128_3_bn1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_128_3_relu1"
  type: "ReLU"
  bottom: "layer_128_3_bn1"
  top: "layer_128_3_bn1"
}
layer {
  name: "layer_128_3_conv1"
  type: "Convolution"
  bottom: "layer_128_3_bn1"
  top: "layer_128_3_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_128_3_bn2"
  type: "BatchNorm"
  bottom: "layer_128_3_conv1"
  top: "layer_128_3_conv1"
}
layer {
  name: "layer_128_3_scale2"
  type: "Scale"
  bottom: "layer_128_3_conv1"
  top: "layer_128_3_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_128_3_relu2"
  type: "ReLU"
  bottom: "layer_128_3_conv1"
  top: "layer_128_3_conv1"
}
layer {
  name: "layer_128_3_conv2"
  type: "Convolution"
  bottom: "layer_128_3_conv1"
  top: "layer_128_3_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_128_3_bn3"
  type: "BatchNorm"
  bottom: "layer_128_3_conv2"
  top: "layer_128_3_conv2"
}
layer {
  name: "layer_128_3_scale3"
  type: "Scale"
  bottom: "layer_128_3_conv2"
  top: "layer_128_3_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_128_3_relu3"
  type: "ReLU"
  bottom: "layer_128_3_conv2"
  top: "layer_128_3_conv2"
}
layer {
  name: "layer_128_3_conv3"
  type: "Convolution"
  bottom: "layer_128_3_conv2"
  top: "layer_128_3_conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_128_3_sum"
  type: "Eltwise"
  bottom: "layer_128_3_conv3"
  bottom: "layer_128_2_sum"
  top: "layer_128_3_sum"
}
layer {
  name: "layer_128_4_bn1"
  type: "BatchNorm"
  bottom: "layer_128_3_sum"
  top: "layer_128_4_bn1"
}
layer {
  name: "layer_128_4_scale1"
  type: "Scale"
  bottom: "layer_128_4_bn1"
  top: "layer_128_4_bn1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_128_4_relu1"
  type: "ReLU"
  bottom: "layer_128_4_bn1"
  top: "layer_128_4_bn1"
}
layer {
  name: "layer_128_4_conv1"
  type: "Convolution"
  bottom: "layer_128_4_bn1"
  top: "layer_128_4_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_128_4_bn2"
  type: "BatchNorm"
  bottom: "layer_128_4_conv1"
  top: "layer_128_4_conv1"
}
layer {
  name: "layer_128_4_scale2"
  type: "Scale"
  bottom: "layer_128_4_conv1"
  top: "layer_128_4_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_128_4_relu2"
  type: "ReLU"
  bottom: "layer_128_4_conv1"
  top: "layer_128_4_conv1"
}
layer {
  name: "layer_128_4_conv2"
  type: "Convolution"
  bottom: "layer_128_4_conv1"
  top: "layer_128_4_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_128_4_bn3"
  type: "BatchNorm"
  bottom: "layer_128_4_conv2"
  top: "layer_128_4_conv2"
}
layer {
  name: "layer_128_4_scale3"
  type: "Scale"
  bottom: "layer_128_4_conv2"
  top: "layer_128_4_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_128_4_relu3"
  type: "ReLU"
  bottom: "layer_128_4_conv2"
  top: "layer_128_4_conv2"
}
layer {
  name: "layer_128_4_conv3"
  type: "Convolution"
  bottom: "layer_128_4_conv2"
  top: "layer_128_4_conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_128_4_sum"
  type: "Eltwise"
  bottom: "layer_128_4_conv3"
  bottom: "layer_128_3_sum"
  top: "layer_128_4_sum"
}
layer {
  name: "last_bn"
  type: "BatchNorm"
  bottom: "layer_128_4_sum"
  top: "layer_128_4_sum"
}
layer {
  name: "last_scale"
  type: "Scale"
  bottom: "layer_128_4_sum"
  top: "layer_128_4_sum"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "last_relu"
  type: "ReLU"
  bottom: "layer_128_4_sum"
  top: "layer_128_4_sum"
}
layer {
  name: "dropout"
  type: "Dropout"
  bottom: "layer_128_4_sum"
  top: "layer_128_4_sum"
  dropout_param {
    dropout_ratio: 0.7
  }
}
layer {
  name: "permuted_data"
  type: "Permute"
  bottom: "layer_128_4_sum"
  top: "permuted_data"
  permute_param {
    order: 3
    order: 0
    order: 1
    order: 2
  }
}
layer {
  name: "lstm-reverse1"
  type: "Reverse"
  bottom: "permuted_data"
  top: "rlstm_input"
  reverse_param {
    axis: 0
  }
}
layer {
  name: "lstm2x"
  type: "LSTM"
  bottom: "rlstm_input"
  bottom: "indicator"
  top: "lstm2x"
  recurrent_param {
    num_output: 100
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "lstm-reverse2"
  type: "Reverse"
  bottom: "lstm2x"
  top: "rlstmx"
  reverse_param {
    axis: 0
  }
}
layer {
  name: "lstm1x"
  type: "LSTM"
  bottom: "permuted_data"
  bottom: "indicator"
  top: "lstm1x"
  recurrent_param {
    num_output: 100
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "merge_lstm_rlstmx"
  type: "Concat"
  bottom: "lstm1x"
  bottom: "rlstmx"
  top: "merge_lstm_rlstmx"
  concat_param {
    axis: 2
  }
}
layer {
  name: "fc1x"
  type: "InnerProduct"
  bottom: "merge_lstm_rlstmx"
  top: "fc1x"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 66
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    axis: 2
  }
}
layer {
  name: "ctcloss"
  type: "WarpCTCLoss"
  bottom: "fc1x"
  bottom: "label"
  top: "ctcloss"
  loss_weight: 1
  ctc_loss_param {
    blank_index: 65
  }
}
layer {
  name: "acc"
  type: "CTCGreedyDecoder"
  bottom: "fc1x"
  bottom: "label"
  top: "acc"
  include {
    phase: TEST
  }
  ctc_decoder_param {
    blank_index: -1
  }
}
I0521 09:36:45.699075  3675 layer_factory.hpp:77] Creating layer data
I0521 09:36:45.699113  3675 net.cpp:100] Creating Layer data
I0521 09:36:45.699121  3675 net.cpp:408] data -> data
I0521 09:36:45.699172  3675 net.cpp:408] data -> label
I0521 09:36:45.699182  3675 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: /home/zhuyipin/DATASET/ccpd/bbox_caffe_data/testing.list
I0521 09:36:45.699625  3675 hdf5_data_layer.cpp:93] Number of HDF5 files: 1
I0521 09:36:45.725260  3675 net.cpp:150] Setting up data
I0521 09:36:45.725291  3675 net.cpp:157] Top shape: 128 3 32 128 (1572864)
I0521 09:36:45.725297  3675 net.cpp:157] Top shape: 128 7 (896)
I0521 09:36:45.725301  3675 net.cpp:165] Memory required for data: 6295040
I0521 09:36:45.725308  3675 layer_factory.hpp:77] Creating layer label_data_1_split
I0521 09:36:45.725322  3675 net.cpp:100] Creating Layer label_data_1_split
I0521 09:36:45.725329  3675 net.cpp:434] label_data_1_split <- label
I0521 09:36:45.725338  3675 net.cpp:408] label_data_1_split -> label_data_1_split_0
I0521 09:36:45.725350  3675 net.cpp:408] label_data_1_split -> label_data_1_split_1
I0521 09:36:45.725390  3675 net.cpp:150] Setting up label_data_1_split
I0521 09:36:45.725396  3675 net.cpp:157] Top shape: 128 7 (896)
I0521 09:36:45.725401  3675 net.cpp:157] Top shape: 128 7 (896)
I0521 09:36:45.725404  3675 net.cpp:165] Memory required for data: 6302208
I0521 09:36:45.725409  3675 layer_factory.hpp:77] Creating layer indicator
I0521 09:36:45.725416  3675 net.cpp:100] Creating Layer indicator
I0521 09:36:45.725421  3675 net.cpp:408] indicator -> indicator
I0521 09:36:45.725441  3675 net.cpp:150] Setting up indicator
I0521 09:36:45.725446  3675 net.cpp:157] Top shape: 16 128 (2048)
I0521 09:36:45.725450  3675 net.cpp:165] Memory required for data: 6310400
I0521 09:36:45.725453  3675 layer_factory.hpp:77] Creating layer indicator_indicator_0_split
I0521 09:36:45.725458  3675 net.cpp:100] Creating Layer indicator_indicator_0_split
I0521 09:36:45.725462  3675 net.cpp:434] indicator_indicator_0_split <- indicator
I0521 09:36:45.725467  3675 net.cpp:408] indicator_indicator_0_split -> indicator_indicator_0_split_0
I0521 09:36:45.725474  3675 net.cpp:408] indicator_indicator_0_split -> indicator_indicator_0_split_1
I0521 09:36:45.725502  3675 net.cpp:150] Setting up indicator_indicator_0_split
I0521 09:36:45.725507  3675 net.cpp:157] Top shape: 16 128 (2048)
I0521 09:36:45.725512  3675 net.cpp:157] Top shape: 16 128 (2048)
I0521 09:36:45.725515  3675 net.cpp:165] Memory required for data: 6326784
I0521 09:36:45.725518  3675 layer_factory.hpp:77] Creating layer data_bn
I0521 09:36:45.725525  3675 net.cpp:100] Creating Layer data_bn
I0521 09:36:45.725529  3675 net.cpp:434] data_bn <- data
I0521 09:36:45.725534  3675 net.cpp:408] data_bn -> data_bn
I0521 09:36:45.725754  3675 net.cpp:150] Setting up data_bn
I0521 09:36:45.725762  3675 net.cpp:157] Top shape: 128 3 32 128 (1572864)
I0521 09:36:45.725766  3675 net.cpp:165] Memory required for data: 12618240
I0521 09:36:45.725778  3675 layer_factory.hpp:77] Creating layer data_scale
I0521 09:36:45.725786  3675 net.cpp:100] Creating Layer data_scale
I0521 09:36:45.725793  3675 net.cpp:434] data_scale <- data_bn
I0521 09:36:45.725798  3675 net.cpp:395] data_scale -> data_bn (in-place)
I0521 09:36:45.725829  3675 layer_factory.hpp:77] Creating layer data_scale
I0521 09:36:45.725947  3675 net.cpp:150] Setting up data_scale
I0521 09:36:45.725955  3675 net.cpp:157] Top shape: 128 3 32 128 (1572864)
I0521 09:36:45.725957  3675 net.cpp:165] Memory required for data: 18909696
I0521 09:36:45.725965  3675 layer_factory.hpp:77] Creating layer conv1
I0521 09:36:45.725973  3675 net.cpp:100] Creating Layer conv1
I0521 09:36:45.725978  3675 net.cpp:434] conv1 <- data_bn
I0521 09:36:45.725984  3675 net.cpp:408] conv1 -> conv1
I0521 09:36:45.727771  3675 net.cpp:150] Setting up conv1
I0521 09:36:45.727802  3675 net.cpp:157] Top shape: 128 64 16 64 (8388608)
I0521 09:36:45.727807  3675 net.cpp:165] Memory required for data: 52464128
I0521 09:36:45.727818  3675 layer_factory.hpp:77] Creating layer conv1_bn
I0521 09:36:45.727828  3675 net.cpp:100] Creating Layer conv1_bn
I0521 09:36:45.727834  3675 net.cpp:434] conv1_bn <- conv1
I0521 09:36:45.727841  3675 net.cpp:395] conv1_bn -> conv1 (in-place)
I0521 09:36:45.728058  3675 net.cpp:150] Setting up conv1_bn
I0521 09:36:45.728065  3675 net.cpp:157] Top shape: 128 64 16 64 (8388608)
I0521 09:36:45.728070  3675 net.cpp:165] Memory required for data: 86018560
I0521 09:36:45.728080  3675 layer_factory.hpp:77] Creating layer conv1_scale
I0521 09:36:45.728091  3675 net.cpp:100] Creating Layer conv1_scale
I0521 09:36:45.728096  3675 net.cpp:434] conv1_scale <- conv1
I0521 09:36:45.728101  3675 net.cpp:395] conv1_scale -> conv1 (in-place)
I0521 09:36:45.728134  3675 layer_factory.hpp:77] Creating layer conv1_scale
I0521 09:36:45.728245  3675 net.cpp:150] Setting up conv1_scale
I0521 09:36:45.728253  3675 net.cpp:157] Top shape: 128 64 16 64 (8388608)
I0521 09:36:45.728257  3675 net.cpp:165] Memory required for data: 119572992
I0521 09:36:45.728262  3675 layer_factory.hpp:77] Creating layer conv1_relu
I0521 09:36:45.728271  3675 net.cpp:100] Creating Layer conv1_relu
I0521 09:36:45.728276  3675 net.cpp:434] conv1_relu <- conv1
I0521 09:36:45.728281  3675 net.cpp:395] conv1_relu -> conv1 (in-place)
I0521 09:36:45.728886  3675 net.cpp:150] Setting up conv1_relu
I0521 09:36:45.728904  3675 net.cpp:157] Top shape: 128 64 16 64 (8388608)
I0521 09:36:45.728907  3675 net.cpp:165] Memory required for data: 153127424
I0521 09:36:45.728912  3675 layer_factory.hpp:77] Creating layer conv1_pool
I0521 09:36:45.728922  3675 net.cpp:100] Creating Layer conv1_pool
I0521 09:36:45.728929  3675 net.cpp:434] conv1_pool <- conv1
I0521 09:36:45.728935  3675 net.cpp:408] conv1_pool -> conv1_pool
I0521 09:36:45.728987  3675 net.cpp:150] Setting up conv1_pool
I0521 09:36:45.728994  3675 net.cpp:157] Top shape: 128 64 8 32 (2097152)
I0521 09:36:45.728998  3675 net.cpp:165] Memory required for data: 161516032
I0521 09:36:45.729001  3675 layer_factory.hpp:77] Creating layer layer_64_1_conv1
I0521 09:36:45.729013  3675 net.cpp:100] Creating Layer layer_64_1_conv1
I0521 09:36:45.729018  3675 net.cpp:434] layer_64_1_conv1 <- conv1_pool
I0521 09:36:45.729025  3675 net.cpp:408] layer_64_1_conv1 -> layer_64_1_conv1
I0521 09:36:45.730875  3675 net.cpp:150] Setting up layer_64_1_conv1
I0521 09:36:45.730893  3675 net.cpp:157] Top shape: 128 64 8 32 (2097152)
I0521 09:36:45.730896  3675 net.cpp:165] Memory required for data: 169904640
I0521 09:36:45.730904  3675 layer_factory.hpp:77] Creating layer layer_64_1_bn2
I0521 09:36:45.730913  3675 net.cpp:100] Creating Layer layer_64_1_bn2
I0521 09:36:45.730921  3675 net.cpp:434] layer_64_1_bn2 <- layer_64_1_conv1
I0521 09:36:45.730927  3675 net.cpp:395] layer_64_1_bn2 -> layer_64_1_conv1 (in-place)
I0521 09:36:45.731123  3675 net.cpp:150] Setting up layer_64_1_bn2
I0521 09:36:45.731130  3675 net.cpp:157] Top shape: 128 64 8 32 (2097152)
I0521 09:36:45.731133  3675 net.cpp:165] Memory required for data: 178293248
I0521 09:36:45.731142  3675 layer_factory.hpp:77] Creating layer layer_64_1_scale2
I0521 09:36:45.731149  3675 net.cpp:100] Creating Layer layer_64_1_scale2
I0521 09:36:45.731156  3675 net.cpp:434] layer_64_1_scale2 <- layer_64_1_conv1
I0521 09:36:45.731161  3675 net.cpp:395] layer_64_1_scale2 -> layer_64_1_conv1 (in-place)
I0521 09:36:45.731194  3675 layer_factory.hpp:77] Creating layer layer_64_1_scale2
I0521 09:36:45.731302  3675 net.cpp:150] Setting up layer_64_1_scale2
I0521 09:36:45.731308  3675 net.cpp:157] Top shape: 128 64 8 32 (2097152)
I0521 09:36:45.731312  3675 net.cpp:165] Memory required for data: 186681856
I0521 09:36:45.731320  3675 layer_factory.hpp:77] Creating layer layer_64_1_relu2
I0521 09:36:45.731328  3675 net.cpp:100] Creating Layer layer_64_1_relu2
I0521 09:36:45.731333  3675 net.cpp:434] layer_64_1_relu2 <- layer_64_1_conv1
I0521 09:36:45.731338  3675 net.cpp:395] layer_64_1_relu2 -> layer_64_1_conv1 (in-place)
I0521 09:36:45.731703  3675 net.cpp:150] Setting up layer_64_1_relu2
I0521 09:36:45.731714  3675 net.cpp:157] Top shape: 128 64 8 32 (2097152)
I0521 09:36:45.731717  3675 net.cpp:165] Memory required for data: 195070464
I0521 09:36:45.731721  3675 layer_factory.hpp:77] Creating layer layer_64_1_conv1_layer_64_1_relu2_0_split
I0521 09:36:45.731750  3675 net.cpp:100] Creating Layer layer_64_1_conv1_layer_64_1_relu2_0_split
I0521 09:36:45.731756  3675 net.cpp:434] layer_64_1_conv1_layer_64_1_relu2_0_split <- layer_64_1_conv1
I0521 09:36:45.731762  3675 net.cpp:408] layer_64_1_conv1_layer_64_1_relu2_0_split -> layer_64_1_conv1_layer_64_1_relu2_0_split_0
I0521 09:36:45.731770  3675 net.cpp:408] layer_64_1_conv1_layer_64_1_relu2_0_split -> layer_64_1_conv1_layer_64_1_relu2_0_split_1
I0521 09:36:45.731813  3675 net.cpp:150] Setting up layer_64_1_conv1_layer_64_1_relu2_0_split
I0521 09:36:45.731820  3675 net.cpp:157] Top shape: 128 64 8 32 (2097152)
I0521 09:36:45.731825  3675 net.cpp:157] Top shape: 128 64 8 32 (2097152)
I0521 09:36:45.731828  3675 net.cpp:165] Memory required for data: 211847680
I0521 09:36:45.731833  3675 layer_factory.hpp:77] Creating layer layer_64_1_conv2
I0521 09:36:45.731847  3675 net.cpp:100] Creating Layer layer_64_1_conv2
I0521 09:36:45.731851  3675 net.cpp:434] layer_64_1_conv2 <- layer_64_1_conv1_layer_64_1_relu2_0_split_0
I0521 09:36:45.731858  3675 net.cpp:408] layer_64_1_conv2 -> layer_64_1_conv2
I0521 09:36:45.735350  3675 net.cpp:150] Setting up layer_64_1_conv2
I0521 09:36:45.735375  3675 net.cpp:157] Top shape: 128 64 8 32 (2097152)
I0521 09:36:45.735379  3675 net.cpp:165] Memory required for data: 220236288
I0521 09:36:45.735388  3675 layer_factory.hpp:77] Creating layer layer_64_1_bn3
I0521 09:36:45.735399  3675 net.cpp:100] Creating Layer layer_64_1_bn3
I0521 09:36:45.735404  3675 net.cpp:434] layer_64_1_bn3 <- layer_64_1_conv2
I0521 09:36:45.735410  3675 net.cpp:395] layer_64_1_bn3 -> layer_64_1_conv2 (in-place)
I0521 09:36:45.735612  3675 net.cpp:150] Setting up layer_64_1_bn3
I0521 09:36:45.735620  3675 net.cpp:157] Top shape: 128 64 8 32 (2097152)
I0521 09:36:45.735625  3675 net.cpp:165] Memory required for data: 228624896
I0521 09:36:45.735632  3675 layer_factory.hpp:77] Creating layer layer_64_1_scale3
I0521 09:36:45.735641  3675 net.cpp:100] Creating Layer layer_64_1_scale3
I0521 09:36:45.735648  3675 net.cpp:434] layer_64_1_scale3 <- layer_64_1_conv2
I0521 09:36:45.735656  3675 net.cpp:395] layer_64_1_scale3 -> layer_64_1_conv2 (in-place)
I0521 09:36:45.735692  3675 layer_factory.hpp:77] Creating layer layer_64_1_scale3
I0521 09:36:45.735805  3675 net.cpp:150] Setting up layer_64_1_scale3
I0521 09:36:45.735811  3675 net.cpp:157] Top shape: 128 64 8 32 (2097152)
I0521 09:36:45.735815  3675 net.cpp:165] Memory required for data: 237013504
I0521 09:36:45.735821  3675 layer_factory.hpp:77] Creating layer layer_64_1_relu3
I0521 09:36:45.735826  3675 net.cpp:100] Creating Layer layer_64_1_relu3
I0521 09:36:45.735831  3675 net.cpp:434] layer_64_1_relu3 <- layer_64_1_conv2
I0521 09:36:45.735836  3675 net.cpp:395] layer_64_1_relu3 -> layer_64_1_conv2 (in-place)
I0521 09:36:45.736357  3675 net.cpp:150] Setting up layer_64_1_relu3
I0521 09:36:45.736373  3675 net.cpp:157] Top shape: 128 64 8 32 (2097152)
I0521 09:36:45.736377  3675 net.cpp:165] Memory required for data: 245402112
I0521 09:36:45.736382  3675 layer_factory.hpp:77] Creating layer layer_64_1_conv3
I0521 09:36:45.736395  3675 net.cpp:100] Creating Layer layer_64_1_conv3
I0521 09:36:45.736402  3675 net.cpp:434] layer_64_1_conv3 <- layer_64_1_conv2
I0521 09:36:45.736409  3675 net.cpp:408] layer_64_1_conv3 -> layer_64_1_conv3
I0521 09:36:45.738165  3675 net.cpp:150] Setting up layer_64_1_conv3
I0521 09:36:45.738186  3675 net.cpp:157] Top shape: 128 256 8 32 (8388608)
I0521 09:36:45.738190  3675 net.cpp:165] Memory required for data: 278956544
I0521 09:36:45.738198  3675 layer_factory.hpp:77] Creating layer layer_64_1_conv_expand
I0521 09:36:45.738212  3675 net.cpp:100] Creating Layer layer_64_1_conv_expand
I0521 09:36:45.738217  3675 net.cpp:434] layer_64_1_conv_expand <- layer_64_1_conv1_layer_64_1_relu2_0_split_1
I0521 09:36:45.738226  3675 net.cpp:408] layer_64_1_conv_expand -> layer_64_1_conv_expand
I0521 09:36:45.740233  3675 net.cpp:150] Setting up layer_64_1_conv_expand
I0521 09:36:45.740260  3675 net.cpp:157] Top shape: 128 256 8 32 (8388608)
I0521 09:36:45.740295  3675 net.cpp:165] Memory required for data: 312510976
I0521 09:36:45.740305  3675 layer_factory.hpp:77] Creating layer layer_64_1_sum
I0521 09:36:45.740319  3675 net.cpp:100] Creating Layer layer_64_1_sum
I0521 09:36:45.740324  3675 net.cpp:434] layer_64_1_sum <- layer_64_1_conv3
I0521 09:36:45.740330  3675 net.cpp:434] layer_64_1_sum <- layer_64_1_conv_expand
I0521 09:36:45.740339  3675 net.cpp:408] layer_64_1_sum -> layer_64_1_sum
I0521 09:36:45.740373  3675 net.cpp:150] Setting up layer_64_1_sum
I0521 09:36:45.740381  3675 net.cpp:157] Top shape: 128 256 8 32 (8388608)
I0521 09:36:45.740383  3675 net.cpp:165] Memory required for data: 346065408
I0521 09:36:45.740387  3675 layer_factory.hpp:77] Creating layer layer_64_1_sum_layer_64_1_sum_0_split
I0521 09:36:45.740394  3675 net.cpp:100] Creating Layer layer_64_1_sum_layer_64_1_sum_0_split
I0521 09:36:45.740398  3675 net.cpp:434] layer_64_1_sum_layer_64_1_sum_0_split <- layer_64_1_sum
I0521 09:36:45.740403  3675 net.cpp:408] layer_64_1_sum_layer_64_1_sum_0_split -> layer_64_1_sum_layer_64_1_sum_0_split_0
I0521 09:36:45.740411  3675 net.cpp:408] layer_64_1_sum_layer_64_1_sum_0_split -> layer_64_1_sum_layer_64_1_sum_0_split_1
I0521 09:36:45.740444  3675 net.cpp:150] Setting up layer_64_1_sum_layer_64_1_sum_0_split
I0521 09:36:45.740453  3675 net.cpp:157] Top shape: 128 256 8 32 (8388608)
I0521 09:36:45.740458  3675 net.cpp:157] Top shape: 128 256 8 32 (8388608)
I0521 09:36:45.740460  3675 net.cpp:165] Memory required for data: 413174272
I0521 09:36:45.740464  3675 layer_factory.hpp:77] Creating layer layer_64_2_bn1
I0521 09:36:45.740471  3675 net.cpp:100] Creating Layer layer_64_2_bn1
I0521 09:36:45.740474  3675 net.cpp:434] layer_64_2_bn1 <- layer_64_1_sum_layer_64_1_sum_0_split_0
I0521 09:36:45.740479  3675 net.cpp:408] layer_64_2_bn1 -> layer_64_2_bn1
I0521 09:36:45.740667  3675 net.cpp:150] Setting up layer_64_2_bn1
I0521 09:36:45.740674  3675 net.cpp:157] Top shape: 128 256 8 32 (8388608)
I0521 09:36:45.740679  3675 net.cpp:165] Memory required for data: 446728704
I0521 09:36:45.740685  3675 layer_factory.hpp:77] Creating layer layer_64_2_scale1
I0521 09:36:45.740694  3675 net.cpp:100] Creating Layer layer_64_2_scale1
I0521 09:36:45.740697  3675 net.cpp:434] layer_64_2_scale1 <- layer_64_2_bn1
I0521 09:36:45.740702  3675 net.cpp:395] layer_64_2_scale1 -> layer_64_2_bn1 (in-place)
I0521 09:36:45.740736  3675 layer_factory.hpp:77] Creating layer layer_64_2_scale1
I0521 09:36:45.740845  3675 net.cpp:150] Setting up layer_64_2_scale1
I0521 09:36:45.740852  3675 net.cpp:157] Top shape: 128 256 8 32 (8388608)
I0521 09:36:45.740856  3675 net.cpp:165] Memory required for data: 480283136
I0521 09:36:45.740862  3675 layer_factory.hpp:77] Creating layer layer_64_2_relu1
I0521 09:36:45.740871  3675 net.cpp:100] Creating Layer layer_64_2_relu1
I0521 09:36:45.740877  3675 net.cpp:434] layer_64_2_relu1 <- layer_64_2_bn1
I0521 09:36:45.740881  3675 net.cpp:395] layer_64_2_relu1 -> layer_64_2_bn1 (in-place)
I0521 09:36:45.741405  3675 net.cpp:150] Setting up layer_64_2_relu1
I0521 09:36:45.741420  3675 net.cpp:157] Top shape: 128 256 8 32 (8388608)
I0521 09:36:45.741422  3675 net.cpp:165] Memory required for data: 513837568
I0521 09:36:45.741427  3675 layer_factory.hpp:77] Creating layer layer_64_2_conv1
I0521 09:36:45.741439  3675 net.cpp:100] Creating Layer layer_64_2_conv1
I0521 09:36:45.741443  3675 net.cpp:434] layer_64_2_conv1 <- layer_64_2_bn1
I0521 09:36:45.741451  3675 net.cpp:408] layer_64_2_conv1 -> layer_64_2_conv1
I0521 09:36:45.743299  3675 net.cpp:150] Setting up layer_64_2_conv1
I0521 09:36:45.743314  3675 net.cpp:157] Top shape: 128 64 8 32 (2097152)
I0521 09:36:45.743319  3675 net.cpp:165] Memory required for data: 522226176
I0521 09:36:45.743325  3675 layer_factory.hpp:77] Creating layer layer_64_2_bn2
I0521 09:36:45.743335  3675 net.cpp:100] Creating Layer layer_64_2_bn2
I0521 09:36:45.743341  3675 net.cpp:434] layer_64_2_bn2 <- layer_64_2_conv1
I0521 09:36:45.743347  3675 net.cpp:395] layer_64_2_bn2 -> layer_64_2_conv1 (in-place)
I0521 09:36:45.743561  3675 net.cpp:150] Setting up layer_64_2_bn2
I0521 09:36:45.743568  3675 net.cpp:157] Top shape: 128 64 8 32 (2097152)
I0521 09:36:45.743571  3675 net.cpp:165] Memory required for data: 530614784
I0521 09:36:45.743583  3675 layer_factory.hpp:77] Creating layer layer_64_2_scale2
I0521 09:36:45.743592  3675 net.cpp:100] Creating Layer layer_64_2_scale2
I0521 09:36:45.743597  3675 net.cpp:434] layer_64_2_scale2 <- layer_64_2_conv1
I0521 09:36:45.743602  3675 net.cpp:395] layer_64_2_scale2 -> layer_64_2_conv1 (in-place)
I0521 09:36:45.743634  3675 layer_factory.hpp:77] Creating layer layer_64_2_scale2
I0521 09:36:45.743739  3675 net.cpp:150] Setting up layer_64_2_scale2
I0521 09:36:45.743747  3675 net.cpp:157] Top shape: 128 64 8 32 (2097152)
I0521 09:36:45.743752  3675 net.cpp:165] Memory required for data: 539003392
I0521 09:36:45.743757  3675 layer_factory.hpp:77] Creating layer layer_64_2_relu2
I0521 09:36:45.743762  3675 net.cpp:100] Creating Layer layer_64_2_relu2
I0521 09:36:45.743767  3675 net.cpp:434] layer_64_2_relu2 <- layer_64_2_conv1
I0521 09:36:45.743772  3675 net.cpp:395] layer_64_2_relu2 -> layer_64_2_conv1 (in-place)
I0521 09:36:45.744122  3675 net.cpp:150] Setting up layer_64_2_relu2
I0521 09:36:45.744132  3675 net.cpp:157] Top shape: 128 64 8 32 (2097152)
I0521 09:36:45.744135  3675 net.cpp:165] Memory required for data: 547392000
I0521 09:36:45.744139  3675 layer_factory.hpp:77] Creating layer layer_64_2_conv2
I0521 09:36:45.744150  3675 net.cpp:100] Creating Layer layer_64_2_conv2
I0521 09:36:45.744155  3675 net.cpp:434] layer_64_2_conv2 <- layer_64_2_conv1
I0521 09:36:45.744163  3675 net.cpp:408] layer_64_2_conv2 -> layer_64_2_conv2
I0521 09:36:45.747701  3675 net.cpp:150] Setting up layer_64_2_conv2
I0521 09:36:45.747720  3675 net.cpp:157] Top shape: 128 64 8 32 (2097152)
I0521 09:36:45.747723  3675 net.cpp:165] Memory required for data: 555780608
I0521 09:36:45.747731  3675 layer_factory.hpp:77] Creating layer layer_64_2_bn3
I0521 09:36:45.747743  3675 net.cpp:100] Creating Layer layer_64_2_bn3
I0521 09:36:45.747747  3675 net.cpp:434] layer_64_2_bn3 <- layer_64_2_conv2
I0521 09:36:45.747756  3675 net.cpp:395] layer_64_2_bn3 -> layer_64_2_conv2 (in-place)
I0521 09:36:45.747956  3675 net.cpp:150] Setting up layer_64_2_bn3
I0521 09:36:45.747963  3675 net.cpp:157] Top shape: 128 64 8 32 (2097152)
I0521 09:36:45.747967  3675 net.cpp:165] Memory required for data: 564169216
I0521 09:36:45.747974  3675 layer_factory.hpp:77] Creating layer layer_64_2_scale3
I0521 09:36:45.747983  3675 net.cpp:100] Creating Layer layer_64_2_scale3
I0521 09:36:45.747988  3675 net.cpp:434] layer_64_2_scale3 <- layer_64_2_conv2
I0521 09:36:45.747993  3675 net.cpp:395] layer_64_2_scale3 -> layer_64_2_conv2 (in-place)
I0521 09:36:45.748024  3675 layer_factory.hpp:77] Creating layer layer_64_2_scale3
I0521 09:36:45.748129  3675 net.cpp:150] Setting up layer_64_2_scale3
I0521 09:36:45.748136  3675 net.cpp:157] Top shape: 128 64 8 32 (2097152)
I0521 09:36:45.748139  3675 net.cpp:165] Memory required for data: 572557824
I0521 09:36:45.748145  3675 layer_factory.hpp:77] Creating layer layer_64_2_relu3
I0521 09:36:45.748152  3675 net.cpp:100] Creating Layer layer_64_2_relu3
I0521 09:36:45.748155  3675 net.cpp:434] layer_64_2_relu3 <- layer_64_2_conv2
I0521 09:36:45.748162  3675 net.cpp:395] layer_64_2_relu3 -> layer_64_2_conv2 (in-place)
I0521 09:36:45.748646  3675 net.cpp:150] Setting up layer_64_2_relu3
I0521 09:36:45.748661  3675 net.cpp:157] Top shape: 128 64 8 32 (2097152)
I0521 09:36:45.748666  3675 net.cpp:165] Memory required for data: 580946432
I0521 09:36:45.748670  3675 layer_factory.hpp:77] Creating layer layer_64_2_conv3
I0521 09:36:45.748683  3675 net.cpp:100] Creating Layer layer_64_2_conv3
I0521 09:36:45.748689  3675 net.cpp:434] layer_64_2_conv3 <- layer_64_2_conv2
I0521 09:36:45.748697  3675 net.cpp:408] layer_64_2_conv3 -> layer_64_2_conv3
I0521 09:36:45.750931  3675 net.cpp:150] Setting up layer_64_2_conv3
I0521 09:36:45.750948  3675 net.cpp:157] Top shape: 128 256 8 32 (8388608)
I0521 09:36:45.750972  3675 net.cpp:165] Memory required for data: 614500864
I0521 09:36:45.750979  3675 layer_factory.hpp:77] Creating layer layer_64_2_sum
I0521 09:36:45.750986  3675 net.cpp:100] Creating Layer layer_64_2_sum
I0521 09:36:45.751000  3675 net.cpp:434] layer_64_2_sum <- layer_64_2_conv3
I0521 09:36:45.751005  3675 net.cpp:434] layer_64_2_sum <- layer_64_1_sum_layer_64_1_sum_0_split_1
I0521 09:36:45.751013  3675 net.cpp:408] layer_64_2_sum -> layer_64_2_sum
I0521 09:36:45.751039  3675 net.cpp:150] Setting up layer_64_2_sum
I0521 09:36:45.751046  3675 net.cpp:157] Top shape: 128 256 8 32 (8388608)
I0521 09:36:45.751049  3675 net.cpp:165] Memory required for data: 648055296
I0521 09:36:45.751054  3675 layer_factory.hpp:77] Creating layer layer_64_2_sum_layer_64_2_sum_0_split
I0521 09:36:45.751060  3675 net.cpp:100] Creating Layer layer_64_2_sum_layer_64_2_sum_0_split
I0521 09:36:45.751063  3675 net.cpp:434] layer_64_2_sum_layer_64_2_sum_0_split <- layer_64_2_sum
I0521 09:36:45.751068  3675 net.cpp:408] layer_64_2_sum_layer_64_2_sum_0_split -> layer_64_2_sum_layer_64_2_sum_0_split_0
I0521 09:36:45.751077  3675 net.cpp:408] layer_64_2_sum_layer_64_2_sum_0_split -> layer_64_2_sum_layer_64_2_sum_0_split_1
I0521 09:36:45.751111  3675 net.cpp:150] Setting up layer_64_2_sum_layer_64_2_sum_0_split
I0521 09:36:45.751121  3675 net.cpp:157] Top shape: 128 256 8 32 (8388608)
I0521 09:36:45.751125  3675 net.cpp:157] Top shape: 128 256 8 32 (8388608)
I0521 09:36:45.751128  3675 net.cpp:165] Memory required for data: 715164160
I0521 09:36:45.751132  3675 layer_factory.hpp:77] Creating layer layer_64_3_bn1
I0521 09:36:45.751138  3675 net.cpp:100] Creating Layer layer_64_3_bn1
I0521 09:36:45.751144  3675 net.cpp:434] layer_64_3_bn1 <- layer_64_2_sum_layer_64_2_sum_0_split_0
I0521 09:36:45.751149  3675 net.cpp:408] layer_64_3_bn1 -> layer_64_3_bn1
I0521 09:36:45.751330  3675 net.cpp:150] Setting up layer_64_3_bn1
I0521 09:36:45.751338  3675 net.cpp:157] Top shape: 128 256 8 32 (8388608)
I0521 09:36:45.751343  3675 net.cpp:165] Memory required for data: 748718592
I0521 09:36:45.751350  3675 layer_factory.hpp:77] Creating layer layer_64_3_scale1
I0521 09:36:45.751360  3675 net.cpp:100] Creating Layer layer_64_3_scale1
I0521 09:36:45.751366  3675 net.cpp:434] layer_64_3_scale1 <- layer_64_3_bn1
I0521 09:36:45.751371  3675 net.cpp:395] layer_64_3_scale1 -> layer_64_3_bn1 (in-place)
I0521 09:36:45.751404  3675 layer_factory.hpp:77] Creating layer layer_64_3_scale1
I0521 09:36:45.751503  3675 net.cpp:150] Setting up layer_64_3_scale1
I0521 09:36:45.751510  3675 net.cpp:157] Top shape: 128 256 8 32 (8388608)
I0521 09:36:45.751514  3675 net.cpp:165] Memory required for data: 782273024
I0521 09:36:45.751520  3675 layer_factory.hpp:77] Creating layer layer_64_3_relu1
I0521 09:36:45.751529  3675 net.cpp:100] Creating Layer layer_64_3_relu1
I0521 09:36:45.751534  3675 net.cpp:434] layer_64_3_relu1 <- layer_64_3_bn1
I0521 09:36:45.751539  3675 net.cpp:395] layer_64_3_relu1 -> layer_64_3_bn1 (in-place)
I0521 09:36:45.751901  3675 net.cpp:150] Setting up layer_64_3_relu1
I0521 09:36:45.751914  3675 net.cpp:157] Top shape: 128 256 8 32 (8388608)
I0521 09:36:45.751920  3675 net.cpp:165] Memory required for data: 815827456
I0521 09:36:45.751925  3675 layer_factory.hpp:77] Creating layer layer_64_3_conv1
I0521 09:36:45.751936  3675 net.cpp:100] Creating Layer layer_64_3_conv1
I0521 09:36:45.751942  3675 net.cpp:434] layer_64_3_conv1 <- layer_64_3_bn1
I0521 09:36:45.751951  3675 net.cpp:408] layer_64_3_conv1 -> layer_64_3_conv1
I0521 09:36:45.753751  3675 net.cpp:150] Setting up layer_64_3_conv1
I0521 09:36:45.753765  3675 net.cpp:157] Top shape: 128 64 8 32 (2097152)
I0521 09:36:45.753769  3675 net.cpp:165] Memory required for data: 824216064
I0521 09:36:45.753777  3675 layer_factory.hpp:77] Creating layer layer_64_3_bn2
I0521 09:36:45.753784  3675 net.cpp:100] Creating Layer layer_64_3_bn2
I0521 09:36:45.753790  3675 net.cpp:434] layer_64_3_bn2 <- layer_64_3_conv1
I0521 09:36:45.753796  3675 net.cpp:395] layer_64_3_bn2 -> layer_64_3_conv1 (in-place)
I0521 09:36:45.754014  3675 net.cpp:150] Setting up layer_64_3_bn2
I0521 09:36:45.754021  3675 net.cpp:157] Top shape: 128 64 8 32 (2097152)
I0521 09:36:45.754024  3675 net.cpp:165] Memory required for data: 832604672
I0521 09:36:45.754032  3675 layer_factory.hpp:77] Creating layer layer_64_3_scale2
I0521 09:36:45.754040  3675 net.cpp:100] Creating Layer layer_64_3_scale2
I0521 09:36:45.754045  3675 net.cpp:434] layer_64_3_scale2 <- layer_64_3_conv1
I0521 09:36:45.754050  3675 net.cpp:395] layer_64_3_scale2 -> layer_64_3_conv1 (in-place)
I0521 09:36:45.754082  3675 layer_factory.hpp:77] Creating layer layer_64_3_scale2
I0521 09:36:45.754189  3675 net.cpp:150] Setting up layer_64_3_scale2
I0521 09:36:45.754196  3675 net.cpp:157] Top shape: 128 64 8 32 (2097152)
I0521 09:36:45.754200  3675 net.cpp:165] Memory required for data: 840993280
I0521 09:36:45.754206  3675 layer_factory.hpp:77] Creating layer layer_64_3_relu2
I0521 09:36:45.754214  3675 net.cpp:100] Creating Layer layer_64_3_relu2
I0521 09:36:45.754217  3675 net.cpp:434] layer_64_3_relu2 <- layer_64_3_conv1
I0521 09:36:45.754222  3675 net.cpp:395] layer_64_3_relu2 -> layer_64_3_conv1 (in-place)
I0521 09:36:45.754741  3675 net.cpp:150] Setting up layer_64_3_relu2
I0521 09:36:45.754758  3675 net.cpp:157] Top shape: 128 64 8 32 (2097152)
I0521 09:36:45.754762  3675 net.cpp:165] Memory required for data: 849381888
I0521 09:36:45.754767  3675 layer_factory.hpp:77] Creating layer layer_64_3_conv2
I0521 09:36:45.754779  3675 net.cpp:100] Creating Layer layer_64_3_conv2
I0521 09:36:45.754783  3675 net.cpp:434] layer_64_3_conv2 <- layer_64_3_conv1
I0521 09:36:45.754791  3675 net.cpp:408] layer_64_3_conv2 -> layer_64_3_conv2
I0521 09:36:45.758744  3675 net.cpp:150] Setting up layer_64_3_conv2
I0521 09:36:45.758769  3675 net.cpp:157] Top shape: 128 64 8 32 (2097152)
I0521 09:36:45.758772  3675 net.cpp:165] Memory required for data: 857770496
I0521 09:36:45.758781  3675 layer_factory.hpp:77] Creating layer layer_64_3_bn3
I0521 09:36:45.758791  3675 net.cpp:100] Creating Layer layer_64_3_bn3
I0521 09:36:45.758796  3675 net.cpp:434] layer_64_3_bn3 <- layer_64_3_conv2
I0521 09:36:45.758803  3675 net.cpp:395] layer_64_3_bn3 -> layer_64_3_conv2 (in-place)
I0521 09:36:45.759006  3675 net.cpp:150] Setting up layer_64_3_bn3
I0521 09:36:45.759012  3675 net.cpp:157] Top shape: 128 64 8 32 (2097152)
I0521 09:36:45.759016  3675 net.cpp:165] Memory required for data: 866159104
I0521 09:36:45.759023  3675 layer_factory.hpp:77] Creating layer layer_64_3_scale3
I0521 09:36:45.759037  3675 net.cpp:100] Creating Layer layer_64_3_scale3
I0521 09:36:45.759040  3675 net.cpp:434] layer_64_3_scale3 <- layer_64_3_conv2
I0521 09:36:45.759045  3675 net.cpp:395] layer_64_3_scale3 -> layer_64_3_conv2 (in-place)
I0521 09:36:45.759078  3675 layer_factory.hpp:77] Creating layer layer_64_3_scale3
I0521 09:36:45.759186  3675 net.cpp:150] Setting up layer_64_3_scale3
I0521 09:36:45.759193  3675 net.cpp:157] Top shape: 128 64 8 32 (2097152)
I0521 09:36:45.759197  3675 net.cpp:165] Memory required for data: 874547712
I0521 09:36:45.759203  3675 layer_factory.hpp:77] Creating layer layer_64_3_relu3
I0521 09:36:45.759212  3675 net.cpp:100] Creating Layer layer_64_3_relu3
I0521 09:36:45.759215  3675 net.cpp:434] layer_64_3_relu3 <- layer_64_3_conv2
I0521 09:36:45.759220  3675 net.cpp:395] layer_64_3_relu3 -> layer_64_3_conv2 (in-place)
I0521 09:36:45.759582  3675 net.cpp:150] Setting up layer_64_3_relu3
I0521 09:36:45.759593  3675 net.cpp:157] Top shape: 128 64 8 32 (2097152)
I0521 09:36:45.759596  3675 net.cpp:165] Memory required for data: 882936320
I0521 09:36:45.759600  3675 layer_factory.hpp:77] Creating layer layer_64_3_conv3
I0521 09:36:45.759613  3675 net.cpp:100] Creating Layer layer_64_3_conv3
I0521 09:36:45.759619  3675 net.cpp:434] layer_64_3_conv3 <- layer_64_3_conv2
I0521 09:36:45.759625  3675 net.cpp:408] layer_64_3_conv3 -> layer_64_3_conv3
I0521 09:36:45.761464  3675 net.cpp:150] Setting up layer_64_3_conv3
I0521 09:36:45.761484  3675 net.cpp:157] Top shape: 128 256 8 32 (8388608)
I0521 09:36:45.761517  3675 net.cpp:165] Memory required for data: 916490752
I0521 09:36:45.761524  3675 layer_factory.hpp:77] Creating layer layer_64_3_sum
I0521 09:36:45.761533  3675 net.cpp:100] Creating Layer layer_64_3_sum
I0521 09:36:45.761540  3675 net.cpp:434] layer_64_3_sum <- layer_64_3_conv3
I0521 09:36:45.761546  3675 net.cpp:434] layer_64_3_sum <- layer_64_2_sum_layer_64_2_sum_0_split_1
I0521 09:36:45.761552  3675 net.cpp:408] layer_64_3_sum -> layer_64_3_sum
I0521 09:36:45.761579  3675 net.cpp:150] Setting up layer_64_3_sum
I0521 09:36:45.761586  3675 net.cpp:157] Top shape: 128 256 8 32 (8388608)
I0521 09:36:45.761590  3675 net.cpp:165] Memory required for data: 950045184
I0521 09:36:45.761593  3675 layer_factory.hpp:77] Creating layer layer_128_1_bn1
I0521 09:36:45.761600  3675 net.cpp:100] Creating Layer layer_128_1_bn1
I0521 09:36:45.761602  3675 net.cpp:434] layer_128_1_bn1 <- layer_64_3_sum
I0521 09:36:45.761610  3675 net.cpp:408] layer_128_1_bn1 -> layer_128_1_bn1
I0521 09:36:45.761801  3675 net.cpp:150] Setting up layer_128_1_bn1
I0521 09:36:45.761808  3675 net.cpp:157] Top shape: 128 256 8 32 (8388608)
I0521 09:36:45.761812  3675 net.cpp:165] Memory required for data: 983599616
I0521 09:36:45.761824  3675 layer_factory.hpp:77] Creating layer layer_128_1_scale1
I0521 09:36:45.761832  3675 net.cpp:100] Creating Layer layer_128_1_scale1
I0521 09:36:45.761837  3675 net.cpp:434] layer_128_1_scale1 <- layer_128_1_bn1
I0521 09:36:45.761842  3675 net.cpp:395] layer_128_1_scale1 -> layer_128_1_bn1 (in-place)
I0521 09:36:45.761873  3675 layer_factory.hpp:77] Creating layer layer_128_1_scale1
I0521 09:36:45.761976  3675 net.cpp:150] Setting up layer_128_1_scale1
I0521 09:36:45.761982  3675 net.cpp:157] Top shape: 128 256 8 32 (8388608)
I0521 09:36:45.761986  3675 net.cpp:165] Memory required for data: 1017154048
I0521 09:36:45.761991  3675 layer_factory.hpp:77] Creating layer layer_128_1_relu1
I0521 09:36:45.761999  3675 net.cpp:100] Creating Layer layer_128_1_relu1
I0521 09:36:45.762002  3675 net.cpp:434] layer_128_1_relu1 <- layer_128_1_bn1
I0521 09:36:45.762007  3675 net.cpp:395] layer_128_1_relu1 -> layer_128_1_bn1 (in-place)
I0521 09:36:45.762523  3675 net.cpp:150] Setting up layer_128_1_relu1
I0521 09:36:45.762537  3675 net.cpp:157] Top shape: 128 256 8 32 (8388608)
I0521 09:36:45.762542  3675 net.cpp:165] Memory required for data: 1050708480
I0521 09:36:45.762545  3675 layer_factory.hpp:77] Creating layer layer_128_1_bn1_layer_128_1_relu1_0_split
I0521 09:36:45.762552  3675 net.cpp:100] Creating Layer layer_128_1_bn1_layer_128_1_relu1_0_split
I0521 09:36:45.762557  3675 net.cpp:434] layer_128_1_bn1_layer_128_1_relu1_0_split <- layer_128_1_bn1
I0521 09:36:45.762563  3675 net.cpp:408] layer_128_1_bn1_layer_128_1_relu1_0_split -> layer_128_1_bn1_layer_128_1_relu1_0_split_0
I0521 09:36:45.762574  3675 net.cpp:408] layer_128_1_bn1_layer_128_1_relu1_0_split -> layer_128_1_bn1_layer_128_1_relu1_0_split_1
I0521 09:36:45.762619  3675 net.cpp:150] Setting up layer_128_1_bn1_layer_128_1_relu1_0_split
I0521 09:36:45.762625  3675 net.cpp:157] Top shape: 128 256 8 32 (8388608)
I0521 09:36:45.762630  3675 net.cpp:157] Top shape: 128 256 8 32 (8388608)
I0521 09:36:45.762634  3675 net.cpp:165] Memory required for data: 1117817344
I0521 09:36:45.762637  3675 layer_factory.hpp:77] Creating layer layer_128_1_conv1
I0521 09:36:45.762650  3675 net.cpp:100] Creating Layer layer_128_1_conv1
I0521 09:36:45.762656  3675 net.cpp:434] layer_128_1_conv1 <- layer_128_1_bn1_layer_128_1_relu1_0_split_0
I0521 09:36:45.762661  3675 net.cpp:408] layer_128_1_conv1 -> layer_128_1_conv1
I0521 09:36:45.764578  3675 net.cpp:150] Setting up layer_128_1_conv1
I0521 09:36:45.764593  3675 net.cpp:157] Top shape: 128 128 8 32 (4194304)
I0521 09:36:45.764597  3675 net.cpp:165] Memory required for data: 1134594560
I0521 09:36:45.764605  3675 layer_factory.hpp:77] Creating layer layer_128_1_bn2
I0521 09:36:45.764612  3675 net.cpp:100] Creating Layer layer_128_1_bn2
I0521 09:36:45.764617  3675 net.cpp:434] layer_128_1_bn2 <- layer_128_1_conv1
I0521 09:36:45.764639  3675 net.cpp:395] layer_128_1_bn2 -> layer_128_1_conv1 (in-place)
I0521 09:36:45.764834  3675 net.cpp:150] Setting up layer_128_1_bn2
I0521 09:36:45.764842  3675 net.cpp:157] Top shape: 128 128 8 32 (4194304)
I0521 09:36:45.764847  3675 net.cpp:165] Memory required for data: 1151371776
I0521 09:36:45.764853  3675 layer_factory.hpp:77] Creating layer layer_128_1_scale2
I0521 09:36:45.764861  3675 net.cpp:100] Creating Layer layer_128_1_scale2
I0521 09:36:45.764865  3675 net.cpp:434] layer_128_1_scale2 <- layer_128_1_conv1
I0521 09:36:45.764871  3675 net.cpp:395] layer_128_1_scale2 -> layer_128_1_conv1 (in-place)
I0521 09:36:45.764902  3675 layer_factory.hpp:77] Creating layer layer_128_1_scale2
I0521 09:36:45.765000  3675 net.cpp:150] Setting up layer_128_1_scale2
I0521 09:36:45.765008  3675 net.cpp:157] Top shape: 128 128 8 32 (4194304)
I0521 09:36:45.765012  3675 net.cpp:165] Memory required for data: 1168148992
I0521 09:36:45.765017  3675 layer_factory.hpp:77] Creating layer layer_128_1_relu2
I0521 09:36:45.765024  3675 net.cpp:100] Creating Layer layer_128_1_relu2
I0521 09:36:45.765029  3675 net.cpp:434] layer_128_1_relu2 <- layer_128_1_conv1
I0521 09:36:45.765033  3675 net.cpp:395] layer_128_1_relu2 -> layer_128_1_conv1 (in-place)
I0521 09:36:45.765533  3675 net.cpp:150] Setting up layer_128_1_relu2
I0521 09:36:45.765547  3675 net.cpp:157] Top shape: 128 128 8 32 (4194304)
I0521 09:36:45.765552  3675 net.cpp:165] Memory required for data: 1184926208
I0521 09:36:45.765556  3675 layer_factory.hpp:77] Creating layer layer_128_1_conv2
I0521 09:36:45.765568  3675 net.cpp:100] Creating Layer layer_128_1_conv2
I0521 09:36:45.765573  3675 net.cpp:434] layer_128_1_conv2 <- layer_128_1_conv1
I0521 09:36:45.765580  3675 net.cpp:408] layer_128_1_conv2 -> layer_128_1_conv2
I0521 09:36:45.770330  3675 net.cpp:150] Setting up layer_128_1_conv2
I0521 09:36:45.770349  3675 net.cpp:157] Top shape: 128 128 4 16 (1048576)
I0521 09:36:45.770354  3675 net.cpp:165] Memory required for data: 1189120512
I0521 09:36:45.770360  3675 layer_factory.hpp:77] Creating layer layer_128_1_bn3
I0521 09:36:45.770370  3675 net.cpp:100] Creating Layer layer_128_1_bn3
I0521 09:36:45.770375  3675 net.cpp:434] layer_128_1_bn3 <- layer_128_1_conv2
I0521 09:36:45.770380  3675 net.cpp:395] layer_128_1_bn3 -> layer_128_1_conv2 (in-place)
I0521 09:36:45.770583  3675 net.cpp:150] Setting up layer_128_1_bn3
I0521 09:36:45.770589  3675 net.cpp:157] Top shape: 128 128 4 16 (1048576)
I0521 09:36:45.770593  3675 net.cpp:165] Memory required for data: 1193314816
I0521 09:36:45.770601  3675 layer_factory.hpp:77] Creating layer layer_128_1_scale3
I0521 09:36:45.770608  3675 net.cpp:100] Creating Layer layer_128_1_scale3
I0521 09:36:45.770612  3675 net.cpp:434] layer_128_1_scale3 <- layer_128_1_conv2
I0521 09:36:45.770617  3675 net.cpp:395] layer_128_1_scale3 -> layer_128_1_conv2 (in-place)
I0521 09:36:45.770648  3675 layer_factory.hpp:77] Creating layer layer_128_1_scale3
I0521 09:36:45.770746  3675 net.cpp:150] Setting up layer_128_1_scale3
I0521 09:36:45.770753  3675 net.cpp:157] Top shape: 128 128 4 16 (1048576)
I0521 09:36:45.770756  3675 net.cpp:165] Memory required for data: 1197509120
I0521 09:36:45.770762  3675 layer_factory.hpp:77] Creating layer layer_128_1_relu3
I0521 09:36:45.770768  3675 net.cpp:100] Creating Layer layer_128_1_relu3
I0521 09:36:45.770771  3675 net.cpp:434] layer_128_1_relu3 <- layer_128_1_conv2
I0521 09:36:45.770776  3675 net.cpp:395] layer_128_1_relu3 -> layer_128_1_conv2 (in-place)
I0521 09:36:45.771106  3675 net.cpp:150] Setting up layer_128_1_relu3
I0521 09:36:45.771117  3675 net.cpp:157] Top shape: 128 128 4 16 (1048576)
I0521 09:36:45.771121  3675 net.cpp:165] Memory required for data: 1201703424
I0521 09:36:45.771124  3675 layer_factory.hpp:77] Creating layer layer_128_1_conv3
I0521 09:36:45.771136  3675 net.cpp:100] Creating Layer layer_128_1_conv3
I0521 09:36:45.771139  3675 net.cpp:434] layer_128_1_conv3 <- layer_128_1_conv2
I0521 09:36:45.771147  3675 net.cpp:408] layer_128_1_conv3 -> layer_128_1_conv3
I0521 09:36:45.773790  3675 net.cpp:150] Setting up layer_128_1_conv3
I0521 09:36:45.773811  3675 net.cpp:157] Top shape: 128 512 4 16 (4194304)
I0521 09:36:45.773815  3675 net.cpp:165] Memory required for data: 1218480640
I0521 09:36:45.773823  3675 layer_factory.hpp:77] Creating layer layer_128_1_conv_expand
I0521 09:36:45.773840  3675 net.cpp:100] Creating Layer layer_128_1_conv_expand
I0521 09:36:45.773847  3675 net.cpp:434] layer_128_1_conv_expand <- layer_128_1_bn1_layer_128_1_relu1_0_split_1
I0521 09:36:45.773854  3675 net.cpp:408] layer_128_1_conv_expand -> layer_128_1_conv_expand
I0521 09:36:45.777132  3675 net.cpp:150] Setting up layer_128_1_conv_expand
I0521 09:36:45.777149  3675 net.cpp:157] Top shape: 128 512 4 16 (4194304)
I0521 09:36:45.777153  3675 net.cpp:165] Memory required for data: 1235257856
I0521 09:36:45.777160  3675 layer_factory.hpp:77] Creating layer layer_128_1_sum
I0521 09:36:45.777168  3675 net.cpp:100] Creating Layer layer_128_1_sum
I0521 09:36:45.777173  3675 net.cpp:434] layer_128_1_sum <- layer_128_1_conv3
I0521 09:36:45.777179  3675 net.cpp:434] layer_128_1_sum <- layer_128_1_conv_expand
I0521 09:36:45.777186  3675 net.cpp:408] layer_128_1_sum -> layer_128_1_sum
I0521 09:36:45.777209  3675 net.cpp:150] Setting up layer_128_1_sum
I0521 09:36:45.777215  3675 net.cpp:157] Top shape: 128 512 4 16 (4194304)
I0521 09:36:45.777218  3675 net.cpp:165] Memory required for data: 1252035072
I0521 09:36:45.777222  3675 layer_factory.hpp:77] Creating layer layer_128_1_sum_layer_128_1_sum_0_split
I0521 09:36:45.777228  3675 net.cpp:100] Creating Layer layer_128_1_sum_layer_128_1_sum_0_split
I0521 09:36:45.777231  3675 net.cpp:434] layer_128_1_sum_layer_128_1_sum_0_split <- layer_128_1_sum
I0521 09:36:45.777237  3675 net.cpp:408] layer_128_1_sum_layer_128_1_sum_0_split -> layer_128_1_sum_layer_128_1_sum_0_split_0
I0521 09:36:45.777243  3675 net.cpp:408] layer_128_1_sum_layer_128_1_sum_0_split -> layer_128_1_sum_layer_128_1_sum_0_split_1
I0521 09:36:45.777276  3675 net.cpp:150] Setting up layer_128_1_sum_layer_128_1_sum_0_split
I0521 09:36:45.777281  3675 net.cpp:157] Top shape: 128 512 4 16 (4194304)
I0521 09:36:45.777285  3675 net.cpp:157] Top shape: 128 512 4 16 (4194304)
I0521 09:36:45.777288  3675 net.cpp:165] Memory required for data: 1285589504
I0521 09:36:45.777292  3675 layer_factory.hpp:77] Creating layer layer_128_2_bn1
I0521 09:36:45.777298  3675 net.cpp:100] Creating Layer layer_128_2_bn1
I0521 09:36:45.777304  3675 net.cpp:434] layer_128_2_bn1 <- layer_128_1_sum_layer_128_1_sum_0_split_0
I0521 09:36:45.777308  3675 net.cpp:408] layer_128_2_bn1 -> layer_128_2_bn1
I0521 09:36:45.777493  3675 net.cpp:150] Setting up layer_128_2_bn1
I0521 09:36:45.777498  3675 net.cpp:157] Top shape: 128 512 4 16 (4194304)
I0521 09:36:45.777501  3675 net.cpp:165] Memory required for data: 1302366720
I0521 09:36:45.777508  3675 layer_factory.hpp:77] Creating layer layer_128_2_scale1
I0521 09:36:45.777515  3675 net.cpp:100] Creating Layer layer_128_2_scale1
I0521 09:36:45.777520  3675 net.cpp:434] layer_128_2_scale1 <- layer_128_2_bn1
I0521 09:36:45.777525  3675 net.cpp:395] layer_128_2_scale1 -> layer_128_2_bn1 (in-place)
I0521 09:36:45.777555  3675 layer_factory.hpp:77] Creating layer layer_128_2_scale1
I0521 09:36:45.777650  3675 net.cpp:150] Setting up layer_128_2_scale1
I0521 09:36:45.777657  3675 net.cpp:157] Top shape: 128 512 4 16 (4194304)
I0521 09:36:45.777660  3675 net.cpp:165] Memory required for data: 1319143936
I0521 09:36:45.777665  3675 layer_factory.hpp:77] Creating layer layer_128_2_relu1
I0521 09:36:45.777673  3675 net.cpp:100] Creating Layer layer_128_2_relu1
I0521 09:36:45.777676  3675 net.cpp:434] layer_128_2_relu1 <- layer_128_2_bn1
I0521 09:36:45.777680  3675 net.cpp:395] layer_128_2_relu1 -> layer_128_2_bn1 (in-place)
I0521 09:36:45.778189  3675 net.cpp:150] Setting up layer_128_2_relu1
I0521 09:36:45.778205  3675 net.cpp:157] Top shape: 128 512 4 16 (4194304)
I0521 09:36:45.778209  3675 net.cpp:165] Memory required for data: 1335921152
I0521 09:36:45.778213  3675 layer_factory.hpp:77] Creating layer layer_128_2_conv1
I0521 09:36:45.778245  3675 net.cpp:100] Creating Layer layer_128_2_conv1
I0521 09:36:45.778251  3675 net.cpp:434] layer_128_2_conv1 <- layer_128_2_bn1
I0521 09:36:45.778259  3675 net.cpp:408] layer_128_2_conv1 -> layer_128_2_conv1
I0521 09:36:45.780599  3675 net.cpp:150] Setting up layer_128_2_conv1
I0521 09:36:45.780616  3675 net.cpp:157] Top shape: 128 128 4 16 (1048576)
I0521 09:36:45.780619  3675 net.cpp:165] Memory required for data: 1340115456
I0521 09:36:45.780627  3675 layer_factory.hpp:77] Creating layer layer_128_2_bn2
I0521 09:36:45.780634  3675 net.cpp:100] Creating Layer layer_128_2_bn2
I0521 09:36:45.780640  3675 net.cpp:434] layer_128_2_bn2 <- layer_128_2_conv1
I0521 09:36:45.780645  3675 net.cpp:395] layer_128_2_bn2 -> layer_128_2_conv1 (in-place)
I0521 09:36:45.780836  3675 net.cpp:150] Setting up layer_128_2_bn2
I0521 09:36:45.780846  3675 net.cpp:157] Top shape: 128 128 4 16 (1048576)
I0521 09:36:45.780849  3675 net.cpp:165] Memory required for data: 1344309760
I0521 09:36:45.780858  3675 layer_factory.hpp:77] Creating layer layer_128_2_scale2
I0521 09:36:45.780866  3675 net.cpp:100] Creating Layer layer_128_2_scale2
I0521 09:36:45.780871  3675 net.cpp:434] layer_128_2_scale2 <- layer_128_2_conv1
I0521 09:36:45.780877  3675 net.cpp:395] layer_128_2_scale2 -> layer_128_2_conv1 (in-place)
I0521 09:36:45.780911  3675 layer_factory.hpp:77] Creating layer layer_128_2_scale2
I0521 09:36:45.781010  3675 net.cpp:150] Setting up layer_128_2_scale2
I0521 09:36:45.781018  3675 net.cpp:157] Top shape: 128 128 4 16 (1048576)
I0521 09:36:45.781021  3675 net.cpp:165] Memory required for data: 1348504064
I0521 09:36:45.781028  3675 layer_factory.hpp:77] Creating layer layer_128_2_relu2
I0521 09:36:45.781034  3675 net.cpp:100] Creating Layer layer_128_2_relu2
I0521 09:36:45.781039  3675 net.cpp:434] layer_128_2_relu2 <- layer_128_2_conv1
I0521 09:36:45.781046  3675 net.cpp:395] layer_128_2_relu2 -> layer_128_2_conv1 (in-place)
I0521 09:36:45.781407  3675 net.cpp:150] Setting up layer_128_2_relu2
I0521 09:36:45.781424  3675 net.cpp:157] Top shape: 128 128 4 16 (1048576)
I0521 09:36:45.781427  3675 net.cpp:165] Memory required for data: 1352698368
I0521 09:36:45.781431  3675 layer_factory.hpp:77] Creating layer layer_128_2_conv2
I0521 09:36:45.781445  3675 net.cpp:100] Creating Layer layer_128_2_conv2
I0521 09:36:45.781450  3675 net.cpp:434] layer_128_2_conv2 <- layer_128_2_conv1
I0521 09:36:45.781457  3675 net.cpp:408] layer_128_2_conv2 -> layer_128_2_conv2
I0521 09:36:45.787278  3675 net.cpp:150] Setting up layer_128_2_conv2
I0521 09:36:45.787310  3675 net.cpp:157] Top shape: 128 128 4 16 (1048576)
I0521 09:36:45.787313  3675 net.cpp:165] Memory required for data: 1356892672
I0521 09:36:45.787323  3675 layer_factory.hpp:77] Creating layer layer_128_2_bn3
I0521 09:36:45.787335  3675 net.cpp:100] Creating Layer layer_128_2_bn3
I0521 09:36:45.787341  3675 net.cpp:434] layer_128_2_bn3 <- layer_128_2_conv2
I0521 09:36:45.787348  3675 net.cpp:395] layer_128_2_bn3 -> layer_128_2_conv2 (in-place)
I0521 09:36:45.787549  3675 net.cpp:150] Setting up layer_128_2_bn3
I0521 09:36:45.787557  3675 net.cpp:157] Top shape: 128 128 4 16 (1048576)
I0521 09:36:45.787560  3675 net.cpp:165] Memory required for data: 1361086976
I0521 09:36:45.787567  3675 layer_factory.hpp:77] Creating layer layer_128_2_scale3
I0521 09:36:45.787576  3675 net.cpp:100] Creating Layer layer_128_2_scale3
I0521 09:36:45.787581  3675 net.cpp:434] layer_128_2_scale3 <- layer_128_2_conv2
I0521 09:36:45.787587  3675 net.cpp:395] layer_128_2_scale3 -> layer_128_2_conv2 (in-place)
I0521 09:36:45.787618  3675 layer_factory.hpp:77] Creating layer layer_128_2_scale3
I0521 09:36:45.787714  3675 net.cpp:150] Setting up layer_128_2_scale3
I0521 09:36:45.787719  3675 net.cpp:157] Top shape: 128 128 4 16 (1048576)
I0521 09:36:45.787724  3675 net.cpp:165] Memory required for data: 1365281280
I0521 09:36:45.787729  3675 layer_factory.hpp:77] Creating layer layer_128_2_relu3
I0521 09:36:45.787734  3675 net.cpp:100] Creating Layer layer_128_2_relu3
I0521 09:36:45.787760  3675 net.cpp:434] layer_128_2_relu3 <- layer_128_2_conv2
I0521 09:36:45.787766  3675 net.cpp:395] layer_128_2_relu3 -> layer_128_2_conv2 (in-place)
I0521 09:36:45.788239  3675 net.cpp:150] Setting up layer_128_2_relu3
I0521 09:36:45.788254  3675 net.cpp:157] Top shape: 128 128 4 16 (1048576)
I0521 09:36:45.788265  3675 net.cpp:165] Memory required for data: 1369475584
I0521 09:36:45.788270  3675 layer_factory.hpp:77] Creating layer layer_128_2_conv3
I0521 09:36:45.788282  3675 net.cpp:100] Creating Layer layer_128_2_conv3
I0521 09:36:45.788286  3675 net.cpp:434] layer_128_2_conv3 <- layer_128_2_conv2
I0521 09:36:45.788293  3675 net.cpp:408] layer_128_2_conv3 -> layer_128_2_conv3
I0521 09:36:45.790591  3675 net.cpp:150] Setting up layer_128_2_conv3
I0521 09:36:45.790611  3675 net.cpp:157] Top shape: 128 512 4 16 (4194304)
I0521 09:36:45.790614  3675 net.cpp:165] Memory required for data: 1386252800
I0521 09:36:45.790622  3675 layer_factory.hpp:77] Creating layer layer_128_2_sum
I0521 09:36:45.790632  3675 net.cpp:100] Creating Layer layer_128_2_sum
I0521 09:36:45.790637  3675 net.cpp:434] layer_128_2_sum <- layer_128_2_conv3
I0521 09:36:45.790642  3675 net.cpp:434] layer_128_2_sum <- layer_128_1_sum_layer_128_1_sum_0_split_1
I0521 09:36:45.790647  3675 net.cpp:408] layer_128_2_sum -> layer_128_2_sum
I0521 09:36:45.790671  3675 net.cpp:150] Setting up layer_128_2_sum
I0521 09:36:45.790679  3675 net.cpp:157] Top shape: 128 512 4 16 (4194304)
I0521 09:36:45.790683  3675 net.cpp:165] Memory required for data: 1403030016
I0521 09:36:45.790686  3675 layer_factory.hpp:77] Creating layer layer_128_2_sum_layer_128_2_sum_0_split
I0521 09:36:45.790691  3675 net.cpp:100] Creating Layer layer_128_2_sum_layer_128_2_sum_0_split
I0521 09:36:45.790695  3675 net.cpp:434] layer_128_2_sum_layer_128_2_sum_0_split <- layer_128_2_sum
I0521 09:36:45.790701  3675 net.cpp:408] layer_128_2_sum_layer_128_2_sum_0_split -> layer_128_2_sum_layer_128_2_sum_0_split_0
I0521 09:36:45.790707  3675 net.cpp:408] layer_128_2_sum_layer_128_2_sum_0_split -> layer_128_2_sum_layer_128_2_sum_0_split_1
I0521 09:36:45.790740  3675 net.cpp:150] Setting up layer_128_2_sum_layer_128_2_sum_0_split
I0521 09:36:45.790750  3675 net.cpp:157] Top shape: 128 512 4 16 (4194304)
I0521 09:36:45.790755  3675 net.cpp:157] Top shape: 128 512 4 16 (4194304)
I0521 09:36:45.790757  3675 net.cpp:165] Memory required for data: 1436584448
I0521 09:36:45.790761  3675 layer_factory.hpp:77] Creating layer layer_128_3_bn1
I0521 09:36:45.790767  3675 net.cpp:100] Creating Layer layer_128_3_bn1
I0521 09:36:45.790771  3675 net.cpp:434] layer_128_3_bn1 <- layer_128_2_sum_layer_128_2_sum_0_split_0
I0521 09:36:45.790776  3675 net.cpp:408] layer_128_3_bn1 -> layer_128_3_bn1
I0521 09:36:45.790957  3675 net.cpp:150] Setting up layer_128_3_bn1
I0521 09:36:45.790964  3675 net.cpp:157] Top shape: 128 512 4 16 (4194304)
I0521 09:36:45.790967  3675 net.cpp:165] Memory required for data: 1453361664
I0521 09:36:45.790976  3675 layer_factory.hpp:77] Creating layer layer_128_3_scale1
I0521 09:36:45.790982  3675 net.cpp:100] Creating Layer layer_128_3_scale1
I0521 09:36:45.790985  3675 net.cpp:434] layer_128_3_scale1 <- layer_128_3_bn1
I0521 09:36:45.790989  3675 net.cpp:395] layer_128_3_scale1 -> layer_128_3_bn1 (in-place)
I0521 09:36:45.791023  3675 layer_factory.hpp:77] Creating layer layer_128_3_scale1
I0521 09:36:45.791121  3675 net.cpp:150] Setting up layer_128_3_scale1
I0521 09:36:45.791127  3675 net.cpp:157] Top shape: 128 512 4 16 (4194304)
I0521 09:36:45.791131  3675 net.cpp:165] Memory required for data: 1470138880
I0521 09:36:45.791136  3675 layer_factory.hpp:77] Creating layer layer_128_3_relu1
I0521 09:36:45.791142  3675 net.cpp:100] Creating Layer layer_128_3_relu1
I0521 09:36:45.791146  3675 net.cpp:434] layer_128_3_relu1 <- layer_128_3_bn1
I0521 09:36:45.791151  3675 net.cpp:395] layer_128_3_relu1 -> layer_128_3_bn1 (in-place)
I0521 09:36:45.791636  3675 net.cpp:150] Setting up layer_128_3_relu1
I0521 09:36:45.791651  3675 net.cpp:157] Top shape: 128 512 4 16 (4194304)
I0521 09:36:45.791676  3675 net.cpp:165] Memory required for data: 1486916096
I0521 09:36:45.791682  3675 layer_factory.hpp:77] Creating layer layer_128_3_conv1
I0521 09:36:45.791693  3675 net.cpp:100] Creating Layer layer_128_3_conv1
I0521 09:36:45.791697  3675 net.cpp:434] layer_128_3_conv1 <- layer_128_3_bn1
I0521 09:36:45.791707  3675 net.cpp:408] layer_128_3_conv1 -> layer_128_3_conv1
I0521 09:36:45.794064  3675 net.cpp:150] Setting up layer_128_3_conv1
I0521 09:36:45.794080  3675 net.cpp:157] Top shape: 128 128 4 16 (1048576)
I0521 09:36:45.794085  3675 net.cpp:165] Memory required for data: 1491110400
I0521 09:36:45.794091  3675 layer_factory.hpp:77] Creating layer layer_128_3_bn2
I0521 09:36:45.794100  3675 net.cpp:100] Creating Layer layer_128_3_bn2
I0521 09:36:45.794103  3675 net.cpp:434] layer_128_3_bn2 <- layer_128_3_conv1
I0521 09:36:45.794109  3675 net.cpp:395] layer_128_3_bn2 -> layer_128_3_conv1 (in-place)
I0521 09:36:45.794283  3675 net.cpp:150] Setting up layer_128_3_bn2
I0521 09:36:45.794291  3675 net.cpp:157] Top shape: 128 128 4 16 (1048576)
I0521 09:36:45.794294  3675 net.cpp:165] Memory required for data: 1495304704
I0521 09:36:45.794301  3675 layer_factory.hpp:77] Creating layer layer_128_3_scale2
I0521 09:36:45.794309  3675 net.cpp:100] Creating Layer layer_128_3_scale2
I0521 09:36:45.794312  3675 net.cpp:434] layer_128_3_scale2 <- layer_128_3_conv1
I0521 09:36:45.794317  3675 net.cpp:395] layer_128_3_scale2 -> layer_128_3_conv1 (in-place)
I0521 09:36:45.794347  3675 layer_factory.hpp:77] Creating layer layer_128_3_scale2
I0521 09:36:45.794445  3675 net.cpp:150] Setting up layer_128_3_scale2
I0521 09:36:45.794450  3675 net.cpp:157] Top shape: 128 128 4 16 (1048576)
I0521 09:36:45.794453  3675 net.cpp:165] Memory required for data: 1499499008
I0521 09:36:45.794459  3675 layer_factory.hpp:77] Creating layer layer_128_3_relu2
I0521 09:36:45.794466  3675 net.cpp:100] Creating Layer layer_128_3_relu2
I0521 09:36:45.794468  3675 net.cpp:434] layer_128_3_relu2 <- layer_128_3_conv1
I0521 09:36:45.794473  3675 net.cpp:395] layer_128_3_relu2 -> layer_128_3_conv1 (in-place)
I0521 09:36:45.794797  3675 net.cpp:150] Setting up layer_128_3_relu2
I0521 09:36:45.794806  3675 net.cpp:157] Top shape: 128 128 4 16 (1048576)
I0521 09:36:45.794811  3675 net.cpp:165] Memory required for data: 1503693312
I0521 09:36:45.794813  3675 layer_factory.hpp:77] Creating layer layer_128_3_conv2
I0521 09:36:45.794823  3675 net.cpp:100] Creating Layer layer_128_3_conv2
I0521 09:36:45.794828  3675 net.cpp:434] layer_128_3_conv2 <- layer_128_3_conv1
I0521 09:36:45.794834  3675 net.cpp:408] layer_128_3_conv2 -> layer_128_3_conv2
I0521 09:36:45.799105  3675 net.cpp:150] Setting up layer_128_3_conv2
I0521 09:36:45.799119  3675 net.cpp:157] Top shape: 128 128 4 16 (1048576)
I0521 09:36:45.799122  3675 net.cpp:165] Memory required for data: 1507887616
I0521 09:36:45.799127  3675 layer_factory.hpp:77] Creating layer layer_128_3_bn3
I0521 09:36:45.799136  3675 net.cpp:100] Creating Layer layer_128_3_bn3
I0521 09:36:45.799140  3675 net.cpp:434] layer_128_3_bn3 <- layer_128_3_conv2
I0521 09:36:45.799146  3675 net.cpp:395] layer_128_3_bn3 -> layer_128_3_conv2 (in-place)
I0521 09:36:45.799291  3675 net.cpp:150] Setting up layer_128_3_bn3
I0521 09:36:45.799298  3675 net.cpp:157] Top shape: 128 128 4 16 (1048576)
I0521 09:36:45.799299  3675 net.cpp:165] Memory required for data: 1512081920
I0521 09:36:45.799304  3675 layer_factory.hpp:77] Creating layer layer_128_3_scale3
I0521 09:36:45.799312  3675 net.cpp:100] Creating Layer layer_128_3_scale3
I0521 09:36:45.799315  3675 net.cpp:434] layer_128_3_scale3 <- layer_128_3_conv2
I0521 09:36:45.799319  3675 net.cpp:395] layer_128_3_scale3 -> layer_128_3_conv2 (in-place)
I0521 09:36:45.799345  3675 layer_factory.hpp:77] Creating layer layer_128_3_scale3
I0521 09:36:45.799425  3675 net.cpp:150] Setting up layer_128_3_scale3
I0521 09:36:45.799432  3675 net.cpp:157] Top shape: 128 128 4 16 (1048576)
I0521 09:36:45.799434  3675 net.cpp:165] Memory required for data: 1516276224
I0521 09:36:45.799440  3675 layer_factory.hpp:77] Creating layer layer_128_3_relu3
I0521 09:36:45.799464  3675 net.cpp:100] Creating Layer layer_128_3_relu3
I0521 09:36:45.799469  3675 net.cpp:434] layer_128_3_relu3 <- layer_128_3_conv2
I0521 09:36:45.799474  3675 net.cpp:395] layer_128_3_relu3 -> layer_128_3_conv2 (in-place)
I0521 09:36:45.799845  3675 net.cpp:150] Setting up layer_128_3_relu3
I0521 09:36:45.799856  3675 net.cpp:157] Top shape: 128 128 4 16 (1048576)
I0521 09:36:45.799860  3675 net.cpp:165] Memory required for data: 1520470528
I0521 09:36:45.799865  3675 layer_factory.hpp:77] Creating layer layer_128_3_conv3
I0521 09:36:45.799876  3675 net.cpp:100] Creating Layer layer_128_3_conv3
I0521 09:36:45.799881  3675 net.cpp:434] layer_128_3_conv3 <- layer_128_3_conv2
I0521 09:36:45.799890  3675 net.cpp:408] layer_128_3_conv3 -> layer_128_3_conv3
I0521 09:36:45.801512  3675 net.cpp:150] Setting up layer_128_3_conv3
I0521 09:36:45.801525  3675 net.cpp:157] Top shape: 128 512 4 16 (4194304)
I0521 09:36:45.801528  3675 net.cpp:165] Memory required for data: 1537247744
I0521 09:36:45.801534  3675 layer_factory.hpp:77] Creating layer layer_128_3_sum
I0521 09:36:45.801544  3675 net.cpp:100] Creating Layer layer_128_3_sum
I0521 09:36:45.801548  3675 net.cpp:434] layer_128_3_sum <- layer_128_3_conv3
I0521 09:36:45.801553  3675 net.cpp:434] layer_128_3_sum <- layer_128_2_sum_layer_128_2_sum_0_split_1
I0521 09:36:45.801558  3675 net.cpp:408] layer_128_3_sum -> layer_128_3_sum
I0521 09:36:45.801580  3675 net.cpp:150] Setting up layer_128_3_sum
I0521 09:36:45.801586  3675 net.cpp:157] Top shape: 128 512 4 16 (4194304)
I0521 09:36:45.801589  3675 net.cpp:165] Memory required for data: 1554024960
I0521 09:36:45.801594  3675 layer_factory.hpp:77] Creating layer layer_128_3_sum_layer_128_3_sum_0_split
I0521 09:36:45.801599  3675 net.cpp:100] Creating Layer layer_128_3_sum_layer_128_3_sum_0_split
I0521 09:36:45.801602  3675 net.cpp:434] layer_128_3_sum_layer_128_3_sum_0_split <- layer_128_3_sum
I0521 09:36:45.801609  3675 net.cpp:408] layer_128_3_sum_layer_128_3_sum_0_split -> layer_128_3_sum_layer_128_3_sum_0_split_0
I0521 09:36:45.801615  3675 net.cpp:408] layer_128_3_sum_layer_128_3_sum_0_split -> layer_128_3_sum_layer_128_3_sum_0_split_1
I0521 09:36:45.801643  3675 net.cpp:150] Setting up layer_128_3_sum_layer_128_3_sum_0_split
I0521 09:36:45.801650  3675 net.cpp:157] Top shape: 128 512 4 16 (4194304)
I0521 09:36:45.801653  3675 net.cpp:157] Top shape: 128 512 4 16 (4194304)
I0521 09:36:45.801656  3675 net.cpp:165] Memory required for data: 1587579392
I0521 09:36:45.801661  3675 layer_factory.hpp:77] Creating layer layer_128_4_bn1
I0521 09:36:45.801668  3675 net.cpp:100] Creating Layer layer_128_4_bn1
I0521 09:36:45.801674  3675 net.cpp:434] layer_128_4_bn1 <- layer_128_3_sum_layer_128_3_sum_0_split_0
I0521 09:36:45.801679  3675 net.cpp:408] layer_128_4_bn1 -> layer_128_4_bn1
I0521 09:36:45.801813  3675 net.cpp:150] Setting up layer_128_4_bn1
I0521 09:36:45.801820  3675 net.cpp:157] Top shape: 128 512 4 16 (4194304)
I0521 09:36:45.801822  3675 net.cpp:165] Memory required for data: 1604356608
I0521 09:36:45.801829  3675 layer_factory.hpp:77] Creating layer layer_128_4_scale1
I0521 09:36:45.801837  3675 net.cpp:100] Creating Layer layer_128_4_scale1
I0521 09:36:45.801842  3675 net.cpp:434] layer_128_4_scale1 <- layer_128_4_bn1
I0521 09:36:45.801851  3675 net.cpp:395] layer_128_4_scale1 -> layer_128_4_bn1 (in-place)
I0521 09:36:45.801875  3675 layer_factory.hpp:77] Creating layer layer_128_4_scale1
I0521 09:36:45.801947  3675 net.cpp:150] Setting up layer_128_4_scale1
I0521 09:36:45.801954  3675 net.cpp:157] Top shape: 128 512 4 16 (4194304)
I0521 09:36:45.801956  3675 net.cpp:165] Memory required for data: 1621133824
I0521 09:36:45.801962  3675 layer_factory.hpp:77] Creating layer layer_128_4_relu1
I0521 09:36:45.801970  3675 net.cpp:100] Creating Layer layer_128_4_relu1
I0521 09:36:45.801975  3675 net.cpp:434] layer_128_4_relu1 <- layer_128_4_bn1
I0521 09:36:45.801980  3675 net.cpp:395] layer_128_4_relu1 -> layer_128_4_bn1 (in-place)
I0521 09:36:45.802244  3675 net.cpp:150] Setting up layer_128_4_relu1
I0521 09:36:45.802263  3675 net.cpp:157] Top shape: 128 512 4 16 (4194304)
I0521 09:36:45.802268  3675 net.cpp:165] Memory required for data: 1637911040
I0521 09:36:45.802271  3675 layer_factory.hpp:77] Creating layer layer_128_4_conv1
I0521 09:36:45.802281  3675 net.cpp:100] Creating Layer layer_128_4_conv1
I0521 09:36:45.802286  3675 net.cpp:434] layer_128_4_conv1 <- layer_128_4_bn1
I0521 09:36:45.802294  3675 net.cpp:408] layer_128_4_conv1 -> layer_128_4_conv1
I0521 09:36:45.803903  3675 net.cpp:150] Setting up layer_128_4_conv1
I0521 09:36:45.803916  3675 net.cpp:157] Top shape: 128 128 4 16 (1048576)
I0521 09:36:45.803920  3675 net.cpp:165] Memory required for data: 1642105344
I0521 09:36:45.803926  3675 layer_factory.hpp:77] Creating layer layer_128_4_bn2
I0521 09:36:45.803934  3675 net.cpp:100] Creating Layer layer_128_4_bn2
I0521 09:36:45.803942  3675 net.cpp:434] layer_128_4_bn2 <- layer_128_4_conv1
I0521 09:36:45.803948  3675 net.cpp:395] layer_128_4_bn2 -> layer_128_4_conv1 (in-place)
I0521 09:36:45.804081  3675 net.cpp:150] Setting up layer_128_4_bn2
I0521 09:36:45.804087  3675 net.cpp:157] Top shape: 128 128 4 16 (1048576)
I0521 09:36:45.804090  3675 net.cpp:165] Memory required for data: 1646299648
I0521 09:36:45.804097  3675 layer_factory.hpp:77] Creating layer layer_128_4_scale2
I0521 09:36:45.804105  3675 net.cpp:100] Creating Layer layer_128_4_scale2
I0521 09:36:45.804109  3675 net.cpp:434] layer_128_4_scale2 <- layer_128_4_conv1
I0521 09:36:45.804117  3675 net.cpp:395] layer_128_4_scale2 -> layer_128_4_conv1 (in-place)
I0521 09:36:45.804143  3675 layer_factory.hpp:77] Creating layer layer_128_4_scale2
I0521 09:36:45.804231  3675 net.cpp:150] Setting up layer_128_4_scale2
I0521 09:36:45.804239  3675 net.cpp:157] Top shape: 128 128 4 16 (1048576)
I0521 09:36:45.804244  3675 net.cpp:165] Memory required for data: 1650493952
I0521 09:36:45.804250  3675 layer_factory.hpp:77] Creating layer layer_128_4_relu2
I0521 09:36:45.804256  3675 net.cpp:100] Creating Layer layer_128_4_relu2
I0521 09:36:45.804260  3675 net.cpp:434] layer_128_4_relu2 <- layer_128_4_conv1
I0521 09:36:45.804265  3675 net.cpp:395] layer_128_4_relu2 -> layer_128_4_conv1 (in-place)
I0521 09:36:45.804652  3675 net.cpp:150] Setting up layer_128_4_relu2
I0521 09:36:45.804663  3675 net.cpp:157] Top shape: 128 128 4 16 (1048576)
I0521 09:36:45.804667  3675 net.cpp:165] Memory required for data: 1654688256
I0521 09:36:45.804672  3675 layer_factory.hpp:77] Creating layer layer_128_4_conv2
I0521 09:36:45.804683  3675 net.cpp:100] Creating Layer layer_128_4_conv2
I0521 09:36:45.804688  3675 net.cpp:434] layer_128_4_conv2 <- layer_128_4_conv1
I0521 09:36:45.804695  3675 net.cpp:408] layer_128_4_conv2 -> layer_128_4_conv2
I0521 09:36:45.809938  3675 net.cpp:150] Setting up layer_128_4_conv2
I0521 09:36:45.809962  3675 net.cpp:157] Top shape: 128 128 4 16 (1048576)
I0521 09:36:45.809964  3675 net.cpp:165] Memory required for data: 1658882560
I0521 09:36:45.809984  3675 layer_factory.hpp:77] Creating layer layer_128_4_bn3
I0521 09:36:45.809995  3675 net.cpp:100] Creating Layer layer_128_4_bn3
I0521 09:36:45.810001  3675 net.cpp:434] layer_128_4_bn3 <- layer_128_4_conv2
I0521 09:36:45.810009  3675 net.cpp:395] layer_128_4_bn3 -> layer_128_4_conv2 (in-place)
I0521 09:36:45.810161  3675 net.cpp:150] Setting up layer_128_4_bn3
I0521 09:36:45.810168  3675 net.cpp:157] Top shape: 128 128 4 16 (1048576)
I0521 09:36:45.810170  3675 net.cpp:165] Memory required for data: 1663076864
I0521 09:36:45.810178  3675 layer_factory.hpp:77] Creating layer layer_128_4_scale3
I0521 09:36:45.810189  3675 net.cpp:100] Creating Layer layer_128_4_scale3
I0521 09:36:45.810192  3675 net.cpp:434] layer_128_4_scale3 <- layer_128_4_conv2
I0521 09:36:45.810199  3675 net.cpp:395] layer_128_4_scale3 -> layer_128_4_conv2 (in-place)
I0521 09:36:45.810225  3675 layer_factory.hpp:77] Creating layer layer_128_4_scale3
I0521 09:36:45.810297  3675 net.cpp:150] Setting up layer_128_4_scale3
I0521 09:36:45.810303  3675 net.cpp:157] Top shape: 128 128 4 16 (1048576)
I0521 09:36:45.810319  3675 net.cpp:165] Memory required for data: 1667271168
I0521 09:36:45.810325  3675 layer_factory.hpp:77] Creating layer layer_128_4_relu3
I0521 09:36:45.810333  3675 net.cpp:100] Creating Layer layer_128_4_relu3
I0521 09:36:45.810338  3675 net.cpp:434] layer_128_4_relu3 <- layer_128_4_conv2
I0521 09:36:45.810343  3675 net.cpp:395] layer_128_4_relu3 -> layer_128_4_conv2 (in-place)
I0521 09:36:45.810618  3675 net.cpp:150] Setting up layer_128_4_relu3
I0521 09:36:45.810629  3675 net.cpp:157] Top shape: 128 128 4 16 (1048576)
I0521 09:36:45.810633  3675 net.cpp:165] Memory required for data: 1671465472
I0521 09:36:45.810636  3675 layer_factory.hpp:77] Creating layer layer_128_4_conv3
I0521 09:36:45.810650  3675 net.cpp:100] Creating Layer layer_128_4_conv3
I0521 09:36:45.810655  3675 net.cpp:434] layer_128_4_conv3 <- layer_128_4_conv2
I0521 09:36:45.810662  3675 net.cpp:408] layer_128_4_conv3 -> layer_128_4_conv3
I0521 09:36:45.812314  3675 net.cpp:150] Setting up layer_128_4_conv3
I0521 09:36:45.812330  3675 net.cpp:157] Top shape: 128 512 4 16 (4194304)
I0521 09:36:45.812333  3675 net.cpp:165] Memory required for data: 1688242688
I0521 09:36:45.812340  3675 layer_factory.hpp:77] Creating layer layer_128_4_sum
I0521 09:36:45.812348  3675 net.cpp:100] Creating Layer layer_128_4_sum
I0521 09:36:45.812353  3675 net.cpp:434] layer_128_4_sum <- layer_128_4_conv3
I0521 09:36:45.812361  3675 net.cpp:434] layer_128_4_sum <- layer_128_3_sum_layer_128_3_sum_0_split_1
I0521 09:36:45.812369  3675 net.cpp:408] layer_128_4_sum -> layer_128_4_sum
I0521 09:36:45.812391  3675 net.cpp:150] Setting up layer_128_4_sum
I0521 09:36:45.812397  3675 net.cpp:157] Top shape: 128 512 4 16 (4194304)
I0521 09:36:45.812399  3675 net.cpp:165] Memory required for data: 1705019904
I0521 09:36:45.812403  3675 layer_factory.hpp:77] Creating layer last_bn
I0521 09:36:45.812412  3675 net.cpp:100] Creating Layer last_bn
I0521 09:36:45.812415  3675 net.cpp:434] last_bn <- layer_128_4_sum
I0521 09:36:45.812420  3675 net.cpp:395] last_bn -> layer_128_4_sum (in-place)
I0521 09:36:45.812551  3675 net.cpp:150] Setting up last_bn
I0521 09:36:45.812556  3675 net.cpp:157] Top shape: 128 512 4 16 (4194304)
I0521 09:36:45.812559  3675 net.cpp:165] Memory required for data: 1721797120
I0521 09:36:45.812567  3675 layer_factory.hpp:77] Creating layer last_scale
I0521 09:36:45.812573  3675 net.cpp:100] Creating Layer last_scale
I0521 09:36:45.812577  3675 net.cpp:434] last_scale <- layer_128_4_sum
I0521 09:36:45.812582  3675 net.cpp:395] last_scale -> layer_128_4_sum (in-place)
I0521 09:36:45.812608  3675 layer_factory.hpp:77] Creating layer last_scale
I0521 09:36:45.812680  3675 net.cpp:150] Setting up last_scale
I0521 09:36:45.812685  3675 net.cpp:157] Top shape: 128 512 4 16 (4194304)
I0521 09:36:45.812690  3675 net.cpp:165] Memory required for data: 1738574336
I0521 09:36:45.812695  3675 layer_factory.hpp:77] Creating layer last_relu
I0521 09:36:45.812700  3675 net.cpp:100] Creating Layer last_relu
I0521 09:36:45.812703  3675 net.cpp:434] last_relu <- layer_128_4_sum
I0521 09:36:45.812710  3675 net.cpp:395] last_relu -> layer_128_4_sum (in-place)
I0521 09:36:45.813102  3675 net.cpp:150] Setting up last_relu
I0521 09:36:45.813115  3675 net.cpp:157] Top shape: 128 512 4 16 (4194304)
I0521 09:36:45.813118  3675 net.cpp:165] Memory required for data: 1755351552
I0521 09:36:45.813123  3675 layer_factory.hpp:77] Creating layer dropout
I0521 09:36:45.813130  3675 net.cpp:100] Creating Layer dropout
I0521 09:36:45.813134  3675 net.cpp:434] dropout <- layer_128_4_sum
I0521 09:36:45.813140  3675 net.cpp:395] dropout -> layer_128_4_sum (in-place)
I0521 09:36:45.813164  3675 net.cpp:150] Setting up dropout
I0521 09:36:45.813169  3675 net.cpp:157] Top shape: 128 512 4 16 (4194304)
I0521 09:36:45.813172  3675 net.cpp:165] Memory required for data: 1772128768
I0521 09:36:45.813176  3675 layer_factory.hpp:77] Creating layer permuted_data
I0521 09:36:45.813184  3675 net.cpp:100] Creating Layer permuted_data
I0521 09:36:45.813189  3675 net.cpp:434] permuted_data <- layer_128_4_sum
I0521 09:36:45.813205  3675 net.cpp:408] permuted_data -> permuted_data
I0521 09:36:45.813275  3675 net.cpp:150] Setting up permuted_data
I0521 09:36:45.813280  3675 net.cpp:157] Top shape: 16 128 512 4 (4194304)
I0521 09:36:45.813284  3675 net.cpp:165] Memory required for data: 1788905984
I0521 09:36:45.813287  3675 layer_factory.hpp:77] Creating layer permuted_data_permuted_data_0_split
I0521 09:36:45.813294  3675 net.cpp:100] Creating Layer permuted_data_permuted_data_0_split
I0521 09:36:45.813298  3675 net.cpp:434] permuted_data_permuted_data_0_split <- permuted_data
I0521 09:36:45.813303  3675 net.cpp:408] permuted_data_permuted_data_0_split -> permuted_data_permuted_data_0_split_0
I0521 09:36:45.813310  3675 net.cpp:408] permuted_data_permuted_data_0_split -> permuted_data_permuted_data_0_split_1
I0521 09:36:45.813335  3675 net.cpp:150] Setting up permuted_data_permuted_data_0_split
I0521 09:36:45.813340  3675 net.cpp:157] Top shape: 16 128 512 4 (4194304)
I0521 09:36:45.813345  3675 net.cpp:157] Top shape: 16 128 512 4 (4194304)
I0521 09:36:45.813349  3675 net.cpp:165] Memory required for data: 1822460416
I0521 09:36:45.813351  3675 layer_factory.hpp:77] Creating layer lstm-reverse1
I0521 09:36:45.813360  3675 net.cpp:100] Creating Layer lstm-reverse1
I0521 09:36:45.813364  3675 net.cpp:434] lstm-reverse1 <- permuted_data_permuted_data_0_split_0
I0521 09:36:45.813370  3675 net.cpp:408] lstm-reverse1 -> rlstm_input
I0521 09:36:45.813386  3675 net.cpp:150] Setting up lstm-reverse1
I0521 09:36:45.813391  3675 net.cpp:157] Top shape: 16 128 512 4 (4194304)
I0521 09:36:45.813395  3675 net.cpp:165] Memory required for data: 1839237632
I0521 09:36:45.813398  3675 layer_factory.hpp:77] Creating layer lstm2x
I0521 09:36:45.813405  3675 net.cpp:100] Creating Layer lstm2x
I0521 09:36:45.813410  3675 net.cpp:434] lstm2x <- rlstm_input
I0521 09:36:45.813414  3675 net.cpp:434] lstm2x <- indicator_indicator_0_split_0
I0521 09:36:45.813419  3675 net.cpp:408] lstm2x -> lstm2x
I0521 09:36:45.813431  3675 recurrent_layer.cpp:20] Initializing recurrent layer: assuming input batch contains 16 timesteps of 128 independent streams.
I0521 09:36:45.813812  3675 net.cpp:58] Initializing net from parameters: 
layer {
  name: "lstm2x_"
  type: "Input"
  top: "x"
  top: "cont"
  input_param {
    shape {
      dim: 16
      dim: 128
      dim: 512
      dim: 4
    }
    shape {
      dim: 16
      dim: 128
    }
  }
}
layer {
  name: "lstm2x_"
  type: "Input"
  top: "c_0"
  top: "h_0"
  input_param {
    shape {
      dim: 1
      dim: 128
      dim: 100
    }
    shape {
      dim: 1
      dim: 128
      dim: 100
    }
  }
}
layer {
  name: "lstm2x_cont_slice"
  type: "Slice"
  bottom: "cont"
  top: "cont_1"
  top: "cont_2"
  top: "cont_3"
  top: "cont_4"
  top: "cont_5"
  top: "cont_6"
  top: "cont_7"
  top: "cont_8"
  top: "cont_9"
  top: "cont_10"
  top: "cont_11"
  top: "cont_12"
  top: "cont_13"
  top: "cont_14"
  top: "cont_15"
  top: "cont_16"
  slice_param {
    axis: 0
  }
}
layer {
  name: "lstm2x_x_transform"
  type: "InnerProduct"
  bottom: "x"
  top: "W_xc_x"
  param {
    name: "W_xc"
  }
  param {
    name: "b_c"
  }
  propagate_down: true
  inner_product_param {
    num_output: 400
    bias_term: true
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    axis: 2
  }
}
layer {
  name: "lstm2x_W_xc_x_slice"
  type: "Slice"
  bottom: "W_xc_x"
  top: "W_xc_x_1"
  top: "W_xc_x_2"
  top: "W_xc_x_3"
  top: "W_xc_x_4"
  top: "W_xc_x_5"
  top: "W_xc_x_6"
  top: "W_xc_x_7"
  top: "W_xc_x_8"
  top: "W_xc_x_9"
  top: "W_xc_x_10"
  top: "W_xc_x_11"
  top: "W_xc_x_12"
  top: "W_xc_x_13"
  top: "W_xc_x_14"
  top: "W_xc_x_15"
  top: "W_xc_x_16"
  slice_param {
    axis: 0
  }
}
layer {
  name: "lstm2x_h_conted_0"
  type: "Scale"
  bottom: "h_0"
  bottom: "cont_1"
  top: "h_conted_0"
  scale_param {
    axis: 0
  }
}
layer {
  name: "lstm2x_transform_1"
  type: "InnerProduct"
  bottom: "h_conted_0"
  top: "W_hc_h_0"
  param {
    name: "W_hc"
  }
  inner_product_param {
    num_output: 400
    bias_term: false
    weight_filler {
      type: "xavier"
    }
    axis: 2
  }
}
layer {
  name: "lstm2x_gate_input_1"
  type: "Eltwise"
  bottom: "W_hc_h_0"
  bottom: "W_xc_x_1"
  top: "gate_input_1"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "lstm2x_unit_1"
  type: "LSTMUnit"
  bottom: "c_0"
  bottom: "gate_input_1"
  bottom: "cont_1"
  top: "c_1"
  top: "h_1"
}
layer {
  name: "lstm2x_h_conted_1"
  type: "Scale"
  bottom: "h_1"
  bottom: "cont_2"
  top: "h_conted_1"
  scale_param {
    axis: 0
  }
}
layer {
  name: "lstm2x_transform_2"
  type: "InnerProduct"
  bottom: "h_conted_1"
  top: "W_hc_h_1"
  param {
    name: "W_hc"
  }
  inner_product_param {
    num_output: 400
    bias_term: false
    weight_filler {
      type: "xavier"
    }
    axis: 2
  }
}
layer {
  name: "lstm2x_gate_input_2"
  type: "Eltwise"
  bottom: "W_hc_h_1"
  bottom: "W_xc_x_2"
  top: "gate_input_2"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "lstm2x_unit_2"
  type: "LSTMUnit"
  bottom: "c_1"
  bottom: "gate_input_2"
  bottom: "cont_2"
  top: "c_2"
  top: "h_2"
}
layer {
  name: "lstm2x_h_conted_2"
  type: "Scale"
  bottom: "h_2"
  bottom: "cont_3"
  top: "h_conted_2"
  scale_param {
    axis: 0
  }
}
layer {
  name: "lstm2x_transform_3"
  type: "InnerProduct"
  bottom: "h_conted_2"
  top: "W_hc_h_2"
  param {
    name: "W_hc"
  }
  inner_product_param {
    num_output: 400
    bias_term: false
    weight_filler {
      type: "xavier"
    }
    axis: 2
  }
}
layer {
  name: "lstm2x_gate_input_3"
  type: "Eltwise"
  bottom: "W_hc_h_2"
  bottom: "W_xc_x_3"
  top: "gate_input_3"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "lstm2x_unit_3"
  type: "LSTMUnit"
  bottom: "c_2"
  bottom: "gate_input_3"
  bottom: "cont_3"
  top: "c_3"
  top: "h_3"
}
layer {
  name: "lstm2x_h_conted_3"
  type: "Scale"
  bottom: "h_3"
  bottom: "cont_4"
  top: "h_conted_3"
  scale_param {
    axis: 0
  }
}
layer {
  name: "lstm2x_transform_4"
  type: "InnerProduct"
  bottom: "h_conted_3"
  top: "W_hc_h_3"
  param {
    name: "W_hc"
  }
  inner_product_param {
    num_output: 400
    bias_term: false
    weight_filler {
      type: "xavier"
    }
    axis: 2
  }
}
layer {
  name: "lstm2x_gate_input_4"
  type: "Eltwise"
  bottom: "W_hc_h_3"
  bottom: "W_xc_x_4"
  top: "gate_input_4"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "lstm2x_unit_4"
  type: "LSTMUnit"
  bottom: "c_3"
  bottom: "gate_input_4"
  bottom: "cont_4"
  top: "c_4"
  top: "h_4"
}
layer {
  name: "lstm2x_h_conted_4"
  type: "Scale"
  bottom: "h_4"
  bottom: "cont_5"
  top: "h_conted_4"
  scale_param {
    axis: 0
  }
}
layer {
  name: "lstm2x_transform_5"
  type: "InnerProduct"
  bottom: "h_conted_4"
  top: "W_hc_h_4"
  param {
    name: "W_hc"
  }
  inner_product_param {
    num_output: 400
    bias_term: false
    weight_filler {
      type: "xavier"
    }
    axis: 2
  }
}
layer {
  name: "lstm2x_gate_input_5"
  type: "Eltwise"
  bottom: "W_hc_h_4"
  bottom: "W_xc_x_5"
  top: "gate_input_5"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "lstm2x_unit_5"
  type: "LSTMUnit"
  bottom: "c_4"
  bottom: "gate_input_5"
  bottom: "cont_5"
  top: "c_5"
  top: "h_5"
}
layer {
  name: "lstm2x_h_conted_5"
  type: "Scale"
  bottom: "h_5"
  bottom: "cont_6"
  top: "h_conted_5"
  scale_param {
    axis: 0
  }
}
layer {
  name: "lstm2x_transform_6"
  type: "InnerProduct"
  bottom: "h_conted_5"
  top: "W_hc_h_5"
  param {
    name: "W_hc"
  }
  inner_product_param {
    num_output: 400
    bias_term: false
    weight_filler {
      type: "xavier"
    }
    axis: 2
  }
}
layer {
  name: "lstm2x_gate_input_6"
  type: "Eltwise"
  bottom: "W_hc_h_5"
  bottom: "W_xc_x_6"
  top: "gate_input_6"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "lstm2x_unit_6"
  type: "LSTMUnit"
  bottom: "c_5"
  bottom: "gate_input_6"
  bottom: "cont_6"
  top: "c_6"
  top: "h_6"
}
layer {
  name: "lstm2x_h_conted_6"
  type: "Scale"
  bottom: "h_6"
  bottom: "cont_7"
  top: "h_conted_6"
  scale_param {
    axis: 0
  }
}
layer {
  name: "lstm2x_transform_7"
  type: "InnerProduct"
  bottom: "h_conted_6"
  top: "W_hc_h_6"
  param {
    name: "W_hc"
  }
  inner_product_param {
    num_output: 400
    bias_term: false
    weight_filler {
      type: "xavier"
    }
    axis: 2
  }
}
layer {
  name: "lstm2x_gate_input_7"
  type: "Eltwise"
  bottom: "W_hc_h_6"
  bottom: "W_xc_x_7"
  top: "gate_input_7"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "lstm2x_unit_7"
  type: "LSTMUnit"
  bottom: "c_6"
  bottom: "gate_input_7"
  bottom: "cont_7"
  top: "c_7"
  top: "h_7"
}
layer {
  name: "lstm2x_h_conted_7"
  type: "Scale"
  bottom: "h_7"
  bottom: "cont_8"
  top: "h_conted_7"
  scale_param {
    axis: 0
  }
}
layer {
  name: "lstm2x_transform_8"
  type: "InnerProduct"
  bottom: "h_conted_7"
  top: "W_hc_h_7"
  param {
    name: "W_hc"
  }
  inner_product_param {
    num_output: 400
    bias_term: false
    weight_filler {
      type: "xavier"
    }
    axis: 2
  }
}
layer {
  name: "lstm2x_gate_input_8"
  type: "Eltwise"
  bottom: "W_hc_h_7"
  bottom: "W_xc_x_8"
  top: "gate_input_8"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "lstm2x_unit_8"
  type: "LSTMUnit"
  bottom: "c_7"
  bottom: "gate_input_8"
  bottom: "cont_8"
  top: "c_8"
  top: "h_8"
}
layer {
  name: "lstm2x_h_conted_8"
  type: "Scale"
  bottom: "h_8"
  bottom: "cont_9"
  top: "h_conted_8"
  scale_param {
    axis: 0
  }
}
layer {
  name: "lstm2x_transform_9"
  type: "InnerProduct"
  bottom: "h_conted_8"
  top: "W_hc_h_8"
  param {
    name: "W_hc"
  }
  inner_product_param {
    num_output: 400
    bias_term: false
    weight_filler {
      type: "xavier"
    }
    axis: 2
  }
}
layer {
  name: "lstm2x_gate_input_9"
  type: "Eltwise"
  bottom: "W_hc_h_8"
  bottom: "W_xc_x_9"
  top: "gate_input_9"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "lstm2x_unit_9"
  type: "LSTMUnit"
  bottom: "c_8"
  bottom: "gate_input_9"
  bottom: "cont_9"
  top: "c_9"
  top: "h_9"
}
layer {
  name: "lstm2x_h_conted_9"
  type: "Scale"
  bottom: "h_9"
  bottom: "cont_10"
  top: "h_conted_9"
  scale_param {
    axis: 0
  }
}
layer {
  name: "lstm2x_transform_10"
  type: "InnerProduct"
  bottom: "h_conted_9"
  top: "W_hc_h_9"
  param {
    name: "W_hc"
  }
  inner_product_param {
    num_output: 400
    bias_term: false
    weight_filler {
      type: "xavier"
    }
    axis: 2
  }
}
layer {
  name: "lstm2x_gate_input_10"
  type: "Eltwise"
  bottom: "W_hc_h_9"
  bottom: "W_xc_x_10"
  top: "gate_input_10"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "lstm2x_unit_10"
  type: "LSTMUnit"
  bottom: "c_9"
  bottom: "gate_input_10"
  bottom: "cont_10"
  top: "c_10"
  top: "h_10"
}
layer {
  name: "lstm2x_h_conted_10"
  type: "Scale"
  bottom: "h_10"
  bottom: "cont_11"
  top: "h_conted_10"
  scale_param {
    axis: 0
  }
}
layer {
  name: "lstm2x_transform_11"
  type: "InnerProduct"
  bottom: "h_conted_10"
  top: "W_hc_h_10"
  param {
    name: "W_hc"
  }
  inner_product_param {
    num_output: 400
    bias_term: false
    weight_filler {
      type: "xavier"
    }
    axis: 2
  }
}
layer {
  name: "lstm2x_gate_input_11"
  type: "Eltwise"
  bottom: "W_hc_h_10"
  bottom: "W_xc_x_11"
  top: "gate_input_11"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "lstm2x_unit_11"
  type: "LSTMUnit"
  bottom: "c_10"
  bottom: "gate_input_11"
  bottom: "cont_11"
  top: "c_11"
  top: "h_11"
}
layer {
  name: "lstm2x_h_conted_11"
  type: "Scale"
  bottom: "h_11"
  bottom: "cont_12"
  top: "h_conted_11"
  scale_param {
    axis: 0
  }
}
layer {
  name: "lstm2x_transform_12"
  type: "InnerProduct"
  bottom: "h_conted_11"
  top: "W_hc_h_11"
  param {
    name: "W_hc"
  }
  inner_product_param {
    num_output: 400
    bias_term: false
    weight_filler {
      type: "xavier"
    }
    axis: 2
  }
}
layer {
  name: "lstm2x_gate_input_12"
  type: "Eltwise"
  bottom: "W_hc_h_11"
  bottom: "W_xc_x_12"
  top: "gate_input_12"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "lstm2x_unit_12"
  type: "LSTMUnit"
  bottom: "c_11"
  bottom: "gate_input_12"
  bottom: "cont_12"
  top: "c_12"
  top: "h_12"
}
layer {
  name: "lstm2x_h_conted_12"
  type: "Scale"
  bottom: "h_12"
  bottom: "cont_13"
  top: "h_conted_12"
  scale_param {
    axis: 0
  }
}
layer {
  name: "lstm2x_transform_13"
  type: "InnerProduct"
  bottom: "h_conted_12"
  top: "W_hc_h_12"
  param {
    name: "W_hc"
  }
  inner_product_param {
    num_output: 400
    bias_term: false
    weight_filler {
      type: "xavier"
    }
    axis: 2
  }
}
layer {
  name: "lstm2x_gate_input_13"
  type: "Eltwise"
  bottom: "W_hc_h_12"
  bottom: "W_xc_x_13"
  top: "gate_input_13"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "lstm2x_unit_13"
  type: "LSTMUnit"
  bottom: "c_12"
  bottom: "gate_input_13"
  bottom: "cont_13"
  top: "c_13"
  top: "h_13"
}
layer {
  name: "lstm2x_h_conted_13"
  type: "Scale"
  bottom: "h_13"
  bottom: "cont_14"
  top: "h_conted_13"
  scale_param {
    axis: 0
  }
}
layer {
  name: "lstm2x_transform_14"
  type: "InnerProduct"
  bottom: "h_conted_13"
  top: "W_hc_h_13"
  param {
    name: "W_hc"
  }
  inner_product_param {
    num_output: 400
    bias_term: false
    weight_filler {
      type: "xavier"
    }
    axis: 2
  }
}
layer {
  name: "lstm2x_gate_input_14"
  type: "Eltwise"
  bottom: "W_hc_h_13"
  bottom: "W_xc_x_14"
  top: "gate_input_14"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "lstm2x_unit_14"
  type: "LSTMUnit"
  bottom: "c_13"
  bottom: "gate_input_14"
  bottom: "cont_14"
  top: "c_14"
  top: "h_14"
}
layer {
  name: "lstm2x_h_conted_14"
  type: "Scale"
  bottom: "h_14"
  bottom: "cont_15"
  top: "h_conted_14"
  scale_param {
    axis: 0
  }
}
layer {
  name: "lstm2x_transform_15"
  type: "InnerProduct"
  bottom: "h_conted_14"
  top: "W_hc_h_14"
  param {
    name: "W_hc"
  }
  inner_product_param {
    num_output: 400
    bias_term: false
    weight_filler {
      type: "xavier"
    }
    axis: 2
  }
}
layer {
  name: "lstm2x_gate_input_15"
  type: "Eltwise"
  bottom: "W_hc_h_14"
  bottom: "W_xc_x_15"
  top: "gate_input_15"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "lstm2x_unit_15"
  type: "LSTMUnit"
  bottom: "c_14"
  bottom: "gate_input_15"
  bottom: "cont_15"
  top: "c_15"
  top: "h_15"
}
layer {
  name: "lstm2x_h_conted_15"
  type: "Scale"
  bottom: "h_15"
  bottom: "cont_16"
  top: "h_conted_15"
  scale_param {
    axis: 0
  }
}
layer {
  name: "lstm2x_transform_16"
  type: "InnerProduct"
  bottom: "h_conted_15"
  top: "W_hc_h_15"
  param {
    name: "W_hc"
  }
  inner_product_param {
    num_output: 400
    bias_term: false
    weight_filler {
      type: "xavier"
    }
    axis: 2
  }
}
layer {
  name: "lstm2x_gate_input_16"
  type: "Eltwise"
  bottom: "W_hc_h_15"
  bottom: "W_xc_x_16"
  top: "gate_input_16"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "lstm2x_unit_16"
  type: "LSTMUnit"
  bottom: "c_15"
  bottom: "gate_input_16"
  bottom: "cont_16"
  top: "c_16"
  top: "h_16"
}
layer {
  name: "lstm2x_"
  type: "Split"
  bottom: "c_16"
  top: "c_T"
}
layer {
  name: "lstm2x_h_concat"
  type: "Concat"
  bottom: "h_1"
  bottom: "h_2"
  bottom: "h_3"
  bottom: "h_4"
  bottom: "h_5"
  bottom: "h_6"
  bottom: "h_7"
  bottom: "h_8"
  bottom: "h_9"
  bottom: "h_10"
  bottom: "h_11"
  bottom: "h_12"
  bottom: "h_13"
  bottom: "h_14"
  bottom: "h_15"
  bottom: "h_16"
  top: "h"
  concat_param {
    axis: 0
  }
}
layer {
  name: "h_pseudoloss"
  type: "Reduction"
  bottom: "h"
  top: "h_pseudoloss"
  loss_weight: 1
}
I0521 09:36:45.814288  3675 layer_factory.hpp:77] Creating layer lstm2x_
I0521 09:36:45.814296  3675 net.cpp:100] Creating Layer lstm2x_
I0521 09:36:45.814301  3675 net.cpp:408] lstm2x_ -> x
I0521 09:36:45.814309  3675 net.cpp:408] lstm2x_ -> cont
I0521 09:36:45.814354  3675 net.cpp:150] Setting up lstm2x_
I0521 09:36:45.814360  3675 net.cpp:157] Top shape: 16 128 512 4 (4194304)
I0521 09:36:45.814364  3675 net.cpp:157] Top shape: 16 128 (2048)
I0521 09:36:45.814368  3675 net.cpp:165] Memory required for data: 16785408
I0521 09:36:45.814370  3675 layer_factory.hpp:77] Creating layer lstm2x_
I0521 09:36:45.814375  3675 net.cpp:100] Creating Layer lstm2x_
I0521 09:36:45.814386  3675 net.cpp:408] lstm2x_ -> c_0
I0521 09:36:45.814393  3675 net.cpp:408] lstm2x_ -> h_0
I0521 09:36:45.814429  3675 net.cpp:150] Setting up lstm2x_
I0521 09:36:45.814435  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.814438  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.814442  3675 net.cpp:165] Memory required for data: 16887808
I0521 09:36:45.814445  3675 layer_factory.hpp:77] Creating layer lstm2x_cont_slice
I0521 09:36:45.814452  3675 net.cpp:100] Creating Layer lstm2x_cont_slice
I0521 09:36:45.814460  3675 net.cpp:434] lstm2x_cont_slice <- cont
I0521 09:36:45.814465  3675 net.cpp:408] lstm2x_cont_slice -> cont_1
I0521 09:36:45.814472  3675 net.cpp:408] lstm2x_cont_slice -> cont_2
I0521 09:36:45.814477  3675 net.cpp:408] lstm2x_cont_slice -> cont_3
I0521 09:36:45.814481  3675 net.cpp:408] lstm2x_cont_slice -> cont_4
I0521 09:36:45.814487  3675 net.cpp:408] lstm2x_cont_slice -> cont_5
I0521 09:36:45.814493  3675 net.cpp:408] lstm2x_cont_slice -> cont_6
I0521 09:36:45.814499  3675 net.cpp:408] lstm2x_cont_slice -> cont_7
I0521 09:36:45.814507  3675 net.cpp:408] lstm2x_cont_slice -> cont_8
I0521 09:36:45.814512  3675 net.cpp:408] lstm2x_cont_slice -> cont_9
I0521 09:36:45.814517  3675 net.cpp:408] lstm2x_cont_slice -> cont_10
I0521 09:36:45.814522  3675 net.cpp:408] lstm2x_cont_slice -> cont_11
I0521 09:36:45.814528  3675 net.cpp:408] lstm2x_cont_slice -> cont_12
I0521 09:36:45.814534  3675 net.cpp:408] lstm2x_cont_slice -> cont_13
I0521 09:36:45.814540  3675 net.cpp:408] lstm2x_cont_slice -> cont_14
I0521 09:36:45.814546  3675 net.cpp:408] lstm2x_cont_slice -> cont_15
I0521 09:36:45.814551  3675 net.cpp:408] lstm2x_cont_slice -> cont_16
I0521 09:36:45.814687  3675 net.cpp:150] Setting up lstm2x_cont_slice
I0521 09:36:45.814692  3675 net.cpp:157] Top shape: 1 128 (128)
I0521 09:36:45.814694  3675 net.cpp:157] Top shape: 1 128 (128)
I0521 09:36:45.814698  3675 net.cpp:157] Top shape: 1 128 (128)
I0521 09:36:45.814702  3675 net.cpp:157] Top shape: 1 128 (128)
I0521 09:36:45.814705  3675 net.cpp:157] Top shape: 1 128 (128)
I0521 09:36:45.814709  3675 net.cpp:157] Top shape: 1 128 (128)
I0521 09:36:45.814713  3675 net.cpp:157] Top shape: 1 128 (128)
I0521 09:36:45.814718  3675 net.cpp:157] Top shape: 1 128 (128)
I0521 09:36:45.814720  3675 net.cpp:157] Top shape: 1 128 (128)
I0521 09:36:45.814724  3675 net.cpp:157] Top shape: 1 128 (128)
I0521 09:36:45.814728  3675 net.cpp:157] Top shape: 1 128 (128)
I0521 09:36:45.814731  3675 net.cpp:157] Top shape: 1 128 (128)
I0521 09:36:45.814735  3675 net.cpp:157] Top shape: 1 128 (128)
I0521 09:36:45.814739  3675 net.cpp:157] Top shape: 1 128 (128)
I0521 09:36:45.814743  3675 net.cpp:157] Top shape: 1 128 (128)
I0521 09:36:45.814746  3675 net.cpp:157] Top shape: 1 128 (128)
I0521 09:36:45.814750  3675 net.cpp:165] Memory required for data: 16896000
I0521 09:36:45.814754  3675 layer_factory.hpp:77] Creating layer cont_1_lstm2x_cont_slice_0_split
I0521 09:36:45.814759  3675 net.cpp:100] Creating Layer cont_1_lstm2x_cont_slice_0_split
I0521 09:36:45.814761  3675 net.cpp:434] cont_1_lstm2x_cont_slice_0_split <- cont_1
I0521 09:36:45.814766  3675 net.cpp:408] cont_1_lstm2x_cont_slice_0_split -> cont_1_lstm2x_cont_slice_0_split_0
I0521 09:36:45.814771  3675 net.cpp:408] cont_1_lstm2x_cont_slice_0_split -> cont_1_lstm2x_cont_slice_0_split_1
I0521 09:36:45.814797  3675 net.cpp:150] Setting up cont_1_lstm2x_cont_slice_0_split
I0521 09:36:45.814803  3675 net.cpp:157] Top shape: 1 128 (128)
I0521 09:36:45.814806  3675 net.cpp:157] Top shape: 1 128 (128)
I0521 09:36:45.814810  3675 net.cpp:165] Memory required for data: 16897024
I0521 09:36:45.814813  3675 layer_factory.hpp:77] Creating layer cont_2_lstm2x_cont_slice_1_split
I0521 09:36:45.814818  3675 net.cpp:100] Creating Layer cont_2_lstm2x_cont_slice_1_split
I0521 09:36:45.814822  3675 net.cpp:434] cont_2_lstm2x_cont_slice_1_split <- cont_2
I0521 09:36:45.814827  3675 net.cpp:408] cont_2_lstm2x_cont_slice_1_split -> cont_2_lstm2x_cont_slice_1_split_0
I0521 09:36:45.814843  3675 net.cpp:408] cont_2_lstm2x_cont_slice_1_split -> cont_2_lstm2x_cont_slice_1_split_1
I0521 09:36:45.814870  3675 net.cpp:150] Setting up cont_2_lstm2x_cont_slice_1_split
I0521 09:36:45.814877  3675 net.cpp:157] Top shape: 1 128 (128)
I0521 09:36:45.814880  3675 net.cpp:157] Top shape: 1 128 (128)
I0521 09:36:45.814883  3675 net.cpp:165] Memory required for data: 16898048
I0521 09:36:45.814887  3675 layer_factory.hpp:77] Creating layer cont_3_lstm2x_cont_slice_2_split
I0521 09:36:45.814893  3675 net.cpp:100] Creating Layer cont_3_lstm2x_cont_slice_2_split
I0521 09:36:45.814896  3675 net.cpp:434] cont_3_lstm2x_cont_slice_2_split <- cont_3
I0521 09:36:45.814900  3675 net.cpp:408] cont_3_lstm2x_cont_slice_2_split -> cont_3_lstm2x_cont_slice_2_split_0
I0521 09:36:45.814905  3675 net.cpp:408] cont_3_lstm2x_cont_slice_2_split -> cont_3_lstm2x_cont_slice_2_split_1
I0521 09:36:45.814927  3675 net.cpp:150] Setting up cont_3_lstm2x_cont_slice_2_split
I0521 09:36:45.814934  3675 net.cpp:157] Top shape: 1 128 (128)
I0521 09:36:45.814936  3675 net.cpp:157] Top shape: 1 128 (128)
I0521 09:36:45.814939  3675 net.cpp:165] Memory required for data: 16899072
I0521 09:36:45.814941  3675 layer_factory.hpp:77] Creating layer cont_4_lstm2x_cont_slice_3_split
I0521 09:36:45.814944  3675 net.cpp:100] Creating Layer cont_4_lstm2x_cont_slice_3_split
I0521 09:36:45.814946  3675 net.cpp:434] cont_4_lstm2x_cont_slice_3_split <- cont_4
I0521 09:36:45.814950  3675 net.cpp:408] cont_4_lstm2x_cont_slice_3_split -> cont_4_lstm2x_cont_slice_3_split_0
I0521 09:36:45.814954  3675 net.cpp:408] cont_4_lstm2x_cont_slice_3_split -> cont_4_lstm2x_cont_slice_3_split_1
I0521 09:36:45.814975  3675 net.cpp:150] Setting up cont_4_lstm2x_cont_slice_3_split
I0521 09:36:45.814978  3675 net.cpp:157] Top shape: 1 128 (128)
I0521 09:36:45.814980  3675 net.cpp:157] Top shape: 1 128 (128)
I0521 09:36:45.814982  3675 net.cpp:165] Memory required for data: 16900096
I0521 09:36:45.814985  3675 layer_factory.hpp:77] Creating layer cont_5_lstm2x_cont_slice_4_split
I0521 09:36:45.814990  3675 net.cpp:100] Creating Layer cont_5_lstm2x_cont_slice_4_split
I0521 09:36:45.814992  3675 net.cpp:434] cont_5_lstm2x_cont_slice_4_split <- cont_5
I0521 09:36:45.814996  3675 net.cpp:408] cont_5_lstm2x_cont_slice_4_split -> cont_5_lstm2x_cont_slice_4_split_0
I0521 09:36:45.814998  3675 net.cpp:408] cont_5_lstm2x_cont_slice_4_split -> cont_5_lstm2x_cont_slice_4_split_1
I0521 09:36:45.815018  3675 net.cpp:150] Setting up cont_5_lstm2x_cont_slice_4_split
I0521 09:36:45.815022  3675 net.cpp:157] Top shape: 1 128 (128)
I0521 09:36:45.815024  3675 net.cpp:157] Top shape: 1 128 (128)
I0521 09:36:45.815026  3675 net.cpp:165] Memory required for data: 16901120
I0521 09:36:45.815028  3675 layer_factory.hpp:77] Creating layer cont_6_lstm2x_cont_slice_5_split
I0521 09:36:45.815032  3675 net.cpp:100] Creating Layer cont_6_lstm2x_cont_slice_5_split
I0521 09:36:45.815034  3675 net.cpp:434] cont_6_lstm2x_cont_slice_5_split <- cont_6
I0521 09:36:45.815037  3675 net.cpp:408] cont_6_lstm2x_cont_slice_5_split -> cont_6_lstm2x_cont_slice_5_split_0
I0521 09:36:45.815042  3675 net.cpp:408] cont_6_lstm2x_cont_slice_5_split -> cont_6_lstm2x_cont_slice_5_split_1
I0521 09:36:45.815060  3675 net.cpp:150] Setting up cont_6_lstm2x_cont_slice_5_split
I0521 09:36:45.815064  3675 net.cpp:157] Top shape: 1 128 (128)
I0521 09:36:45.815068  3675 net.cpp:157] Top shape: 1 128 (128)
I0521 09:36:45.815069  3675 net.cpp:165] Memory required for data: 16902144
I0521 09:36:45.815071  3675 layer_factory.hpp:77] Creating layer cont_7_lstm2x_cont_slice_6_split
I0521 09:36:45.815075  3675 net.cpp:100] Creating Layer cont_7_lstm2x_cont_slice_6_split
I0521 09:36:45.815078  3675 net.cpp:434] cont_7_lstm2x_cont_slice_6_split <- cont_7
I0521 09:36:45.815081  3675 net.cpp:408] cont_7_lstm2x_cont_slice_6_split -> cont_7_lstm2x_cont_slice_6_split_0
I0521 09:36:45.815086  3675 net.cpp:408] cont_7_lstm2x_cont_slice_6_split -> cont_7_lstm2x_cont_slice_6_split_1
I0521 09:36:45.815114  3675 net.cpp:150] Setting up cont_7_lstm2x_cont_slice_6_split
I0521 09:36:45.815124  3675 net.cpp:157] Top shape: 1 128 (128)
I0521 09:36:45.815127  3675 net.cpp:157] Top shape: 1 128 (128)
I0521 09:36:45.815130  3675 net.cpp:165] Memory required for data: 16903168
I0521 09:36:45.815134  3675 layer_factory.hpp:77] Creating layer cont_8_lstm2x_cont_slice_7_split
I0521 09:36:45.815137  3675 net.cpp:100] Creating Layer cont_8_lstm2x_cont_slice_7_split
I0521 09:36:45.815140  3675 net.cpp:434] cont_8_lstm2x_cont_slice_7_split <- cont_8
I0521 09:36:45.815142  3675 net.cpp:408] cont_8_lstm2x_cont_slice_7_split -> cont_8_lstm2x_cont_slice_7_split_0
I0521 09:36:45.815146  3675 net.cpp:408] cont_8_lstm2x_cont_slice_7_split -> cont_8_lstm2x_cont_slice_7_split_1
I0521 09:36:45.815168  3675 net.cpp:150] Setting up cont_8_lstm2x_cont_slice_7_split
I0521 09:36:45.815171  3675 net.cpp:157] Top shape: 1 128 (128)
I0521 09:36:45.815173  3675 net.cpp:157] Top shape: 1 128 (128)
I0521 09:36:45.815176  3675 net.cpp:165] Memory required for data: 16904192
I0521 09:36:45.815177  3675 layer_factory.hpp:77] Creating layer cont_9_lstm2x_cont_slice_8_split
I0521 09:36:45.815181  3675 net.cpp:100] Creating Layer cont_9_lstm2x_cont_slice_8_split
I0521 09:36:45.815183  3675 net.cpp:434] cont_9_lstm2x_cont_slice_8_split <- cont_9
I0521 09:36:45.815186  3675 net.cpp:408] cont_9_lstm2x_cont_slice_8_split -> cont_9_lstm2x_cont_slice_8_split_0
I0521 09:36:45.815191  3675 net.cpp:408] cont_9_lstm2x_cont_slice_8_split -> cont_9_lstm2x_cont_slice_8_split_1
I0521 09:36:45.815210  3675 net.cpp:150] Setting up cont_9_lstm2x_cont_slice_8_split
I0521 09:36:45.815213  3675 net.cpp:157] Top shape: 1 128 (128)
I0521 09:36:45.815215  3675 net.cpp:157] Top shape: 1 128 (128)
I0521 09:36:45.815217  3675 net.cpp:165] Memory required for data: 16905216
I0521 09:36:45.815220  3675 layer_factory.hpp:77] Creating layer cont_10_lstm2x_cont_slice_9_split
I0521 09:36:45.815222  3675 net.cpp:100] Creating Layer cont_10_lstm2x_cont_slice_9_split
I0521 09:36:45.815225  3675 net.cpp:434] cont_10_lstm2x_cont_slice_9_split <- cont_10
I0521 09:36:45.815228  3675 net.cpp:408] cont_10_lstm2x_cont_slice_9_split -> cont_10_lstm2x_cont_slice_9_split_0
I0521 09:36:45.815232  3675 net.cpp:408] cont_10_lstm2x_cont_slice_9_split -> cont_10_lstm2x_cont_slice_9_split_1
I0521 09:36:45.815251  3675 net.cpp:150] Setting up cont_10_lstm2x_cont_slice_9_split
I0521 09:36:45.815254  3675 net.cpp:157] Top shape: 1 128 (128)
I0521 09:36:45.815256  3675 net.cpp:157] Top shape: 1 128 (128)
I0521 09:36:45.815258  3675 net.cpp:165] Memory required for data: 16906240
I0521 09:36:45.815261  3675 layer_factory.hpp:77] Creating layer cont_11_lstm2x_cont_slice_10_split
I0521 09:36:45.815263  3675 net.cpp:100] Creating Layer cont_11_lstm2x_cont_slice_10_split
I0521 09:36:45.815266  3675 net.cpp:434] cont_11_lstm2x_cont_slice_10_split <- cont_11
I0521 09:36:45.815269  3675 net.cpp:408] cont_11_lstm2x_cont_slice_10_split -> cont_11_lstm2x_cont_slice_10_split_0
I0521 09:36:45.815274  3675 net.cpp:408] cont_11_lstm2x_cont_slice_10_split -> cont_11_lstm2x_cont_slice_10_split_1
I0521 09:36:45.815292  3675 net.cpp:150] Setting up cont_11_lstm2x_cont_slice_10_split
I0521 09:36:45.815295  3675 net.cpp:157] Top shape: 1 128 (128)
I0521 09:36:45.815297  3675 net.cpp:157] Top shape: 1 128 (128)
I0521 09:36:45.815299  3675 net.cpp:165] Memory required for data: 16907264
I0521 09:36:45.815301  3675 layer_factory.hpp:77] Creating layer cont_12_lstm2x_cont_slice_11_split
I0521 09:36:45.815305  3675 net.cpp:100] Creating Layer cont_12_lstm2x_cont_slice_11_split
I0521 09:36:45.815307  3675 net.cpp:434] cont_12_lstm2x_cont_slice_11_split <- cont_12
I0521 09:36:45.815311  3675 net.cpp:408] cont_12_lstm2x_cont_slice_11_split -> cont_12_lstm2x_cont_slice_11_split_0
I0521 09:36:45.815315  3675 net.cpp:408] cont_12_lstm2x_cont_slice_11_split -> cont_12_lstm2x_cont_slice_11_split_1
I0521 09:36:45.815333  3675 net.cpp:150] Setting up cont_12_lstm2x_cont_slice_11_split
I0521 09:36:45.815336  3675 net.cpp:157] Top shape: 1 128 (128)
I0521 09:36:45.815338  3675 net.cpp:157] Top shape: 1 128 (128)
I0521 09:36:45.815346  3675 net.cpp:165] Memory required for data: 16908288
I0521 09:36:45.815347  3675 layer_factory.hpp:77] Creating layer cont_13_lstm2x_cont_slice_12_split
I0521 09:36:45.815351  3675 net.cpp:100] Creating Layer cont_13_lstm2x_cont_slice_12_split
I0521 09:36:45.815353  3675 net.cpp:434] cont_13_lstm2x_cont_slice_12_split <- cont_13
I0521 09:36:45.815356  3675 net.cpp:408] cont_13_lstm2x_cont_slice_12_split -> cont_13_lstm2x_cont_slice_12_split_0
I0521 09:36:45.815359  3675 net.cpp:408] cont_13_lstm2x_cont_slice_12_split -> cont_13_lstm2x_cont_slice_12_split_1
I0521 09:36:45.815379  3675 net.cpp:150] Setting up cont_13_lstm2x_cont_slice_12_split
I0521 09:36:45.815382  3675 net.cpp:157] Top shape: 1 128 (128)
I0521 09:36:45.815384  3675 net.cpp:157] Top shape: 1 128 (128)
I0521 09:36:45.815387  3675 net.cpp:165] Memory required for data: 16909312
I0521 09:36:45.815388  3675 layer_factory.hpp:77] Creating layer cont_14_lstm2x_cont_slice_13_split
I0521 09:36:45.815392  3675 net.cpp:100] Creating Layer cont_14_lstm2x_cont_slice_13_split
I0521 09:36:45.815395  3675 net.cpp:434] cont_14_lstm2x_cont_slice_13_split <- cont_14
I0521 09:36:45.815398  3675 net.cpp:408] cont_14_lstm2x_cont_slice_13_split -> cont_14_lstm2x_cont_slice_13_split_0
I0521 09:36:45.815402  3675 net.cpp:408] cont_14_lstm2x_cont_slice_13_split -> cont_14_lstm2x_cont_slice_13_split_1
I0521 09:36:45.815420  3675 net.cpp:150] Setting up cont_14_lstm2x_cont_slice_13_split
I0521 09:36:45.815423  3675 net.cpp:157] Top shape: 1 128 (128)
I0521 09:36:45.815426  3675 net.cpp:157] Top shape: 1 128 (128)
I0521 09:36:45.815428  3675 net.cpp:165] Memory required for data: 16910336
I0521 09:36:45.815430  3675 layer_factory.hpp:77] Creating layer cont_15_lstm2x_cont_slice_14_split
I0521 09:36:45.815433  3675 net.cpp:100] Creating Layer cont_15_lstm2x_cont_slice_14_split
I0521 09:36:45.815435  3675 net.cpp:434] cont_15_lstm2x_cont_slice_14_split <- cont_15
I0521 09:36:45.815438  3675 net.cpp:408] cont_15_lstm2x_cont_slice_14_split -> cont_15_lstm2x_cont_slice_14_split_0
I0521 09:36:45.815441  3675 net.cpp:408] cont_15_lstm2x_cont_slice_14_split -> cont_15_lstm2x_cont_slice_14_split_1
I0521 09:36:45.815461  3675 net.cpp:150] Setting up cont_15_lstm2x_cont_slice_14_split
I0521 09:36:45.815464  3675 net.cpp:157] Top shape: 1 128 (128)
I0521 09:36:45.815466  3675 net.cpp:157] Top shape: 1 128 (128)
I0521 09:36:45.815469  3675 net.cpp:165] Memory required for data: 16911360
I0521 09:36:45.815470  3675 layer_factory.hpp:77] Creating layer cont_16_lstm2x_cont_slice_15_split
I0521 09:36:45.815474  3675 net.cpp:100] Creating Layer cont_16_lstm2x_cont_slice_15_split
I0521 09:36:45.815476  3675 net.cpp:434] cont_16_lstm2x_cont_slice_15_split <- cont_16
I0521 09:36:45.815479  3675 net.cpp:408] cont_16_lstm2x_cont_slice_15_split -> cont_16_lstm2x_cont_slice_15_split_0
I0521 09:36:45.815484  3675 net.cpp:408] cont_16_lstm2x_cont_slice_15_split -> cont_16_lstm2x_cont_slice_15_split_1
I0521 09:36:45.815502  3675 net.cpp:150] Setting up cont_16_lstm2x_cont_slice_15_split
I0521 09:36:45.815505  3675 net.cpp:157] Top shape: 1 128 (128)
I0521 09:36:45.815508  3675 net.cpp:157] Top shape: 1 128 (128)
I0521 09:36:45.815510  3675 net.cpp:165] Memory required for data: 16912384
I0521 09:36:45.815512  3675 layer_factory.hpp:77] Creating layer lstm2x_x_transform
I0521 09:36:45.815517  3675 net.cpp:100] Creating Layer lstm2x_x_transform
I0521 09:36:45.815521  3675 net.cpp:434] lstm2x_x_transform <- x
I0521 09:36:45.815523  3675 net.cpp:408] lstm2x_x_transform -> W_xc_x
I0521 09:36:45.820017  3675 net.cpp:150] Setting up lstm2x_x_transform
I0521 09:36:45.820032  3675 net.cpp:157] Top shape: 16 128 400 (819200)
I0521 09:36:45.820036  3675 net.cpp:165] Memory required for data: 20189184
I0521 09:36:45.820046  3675 layer_factory.hpp:77] Creating layer lstm2x_W_xc_x_slice
I0521 09:36:45.820055  3675 net.cpp:100] Creating Layer lstm2x_W_xc_x_slice
I0521 09:36:45.820060  3675 net.cpp:434] lstm2x_W_xc_x_slice <- W_xc_x
I0521 09:36:45.820067  3675 net.cpp:408] lstm2x_W_xc_x_slice -> W_xc_x_1
I0521 09:36:45.820091  3675 net.cpp:408] lstm2x_W_xc_x_slice -> W_xc_x_2
I0521 09:36:45.820096  3675 net.cpp:408] lstm2x_W_xc_x_slice -> W_xc_x_3
I0521 09:36:45.820101  3675 net.cpp:408] lstm2x_W_xc_x_slice -> W_xc_x_4
I0521 09:36:45.820104  3675 net.cpp:408] lstm2x_W_xc_x_slice -> W_xc_x_5
I0521 09:36:45.820111  3675 net.cpp:408] lstm2x_W_xc_x_slice -> W_xc_x_6
I0521 09:36:45.820116  3675 net.cpp:408] lstm2x_W_xc_x_slice -> W_xc_x_7
I0521 09:36:45.820120  3675 net.cpp:408] lstm2x_W_xc_x_slice -> W_xc_x_8
I0521 09:36:45.820124  3675 net.cpp:408] lstm2x_W_xc_x_slice -> W_xc_x_9
I0521 09:36:45.820128  3675 net.cpp:408] lstm2x_W_xc_x_slice -> W_xc_x_10
I0521 09:36:45.820132  3675 net.cpp:408] lstm2x_W_xc_x_slice -> W_xc_x_11
I0521 09:36:45.820137  3675 net.cpp:408] lstm2x_W_xc_x_slice -> W_xc_x_12
I0521 09:36:45.820142  3675 net.cpp:408] lstm2x_W_xc_x_slice -> W_xc_x_13
I0521 09:36:45.820147  3675 net.cpp:408] lstm2x_W_xc_x_slice -> W_xc_x_14
I0521 09:36:45.820150  3675 net.cpp:408] lstm2x_W_xc_x_slice -> W_xc_x_15
I0521 09:36:45.820154  3675 net.cpp:408] lstm2x_W_xc_x_slice -> W_xc_x_16
I0521 09:36:45.820294  3675 net.cpp:150] Setting up lstm2x_W_xc_x_slice
I0521 09:36:45.820298  3675 net.cpp:157] Top shape: 1 128 400 (51200)
I0521 09:36:45.820300  3675 net.cpp:157] Top shape: 1 128 400 (51200)
I0521 09:36:45.820303  3675 net.cpp:157] Top shape: 1 128 400 (51200)
I0521 09:36:45.820307  3675 net.cpp:157] Top shape: 1 128 400 (51200)
I0521 09:36:45.820308  3675 net.cpp:157] Top shape: 1 128 400 (51200)
I0521 09:36:45.820312  3675 net.cpp:157] Top shape: 1 128 400 (51200)
I0521 09:36:45.820314  3675 net.cpp:157] Top shape: 1 128 400 (51200)
I0521 09:36:45.820317  3675 net.cpp:157] Top shape: 1 128 400 (51200)
I0521 09:36:45.820319  3675 net.cpp:157] Top shape: 1 128 400 (51200)
I0521 09:36:45.820322  3675 net.cpp:157] Top shape: 1 128 400 (51200)
I0521 09:36:45.820325  3675 net.cpp:157] Top shape: 1 128 400 (51200)
I0521 09:36:45.820327  3675 net.cpp:157] Top shape: 1 128 400 (51200)
I0521 09:36:45.820330  3675 net.cpp:157] Top shape: 1 128 400 (51200)
I0521 09:36:45.820333  3675 net.cpp:157] Top shape: 1 128 400 (51200)
I0521 09:36:45.820335  3675 net.cpp:157] Top shape: 1 128 400 (51200)
I0521 09:36:45.820338  3675 net.cpp:157] Top shape: 1 128 400 (51200)
I0521 09:36:45.820340  3675 net.cpp:165] Memory required for data: 23465984
I0521 09:36:45.820343  3675 layer_factory.hpp:77] Creating layer lstm2x_h_conted_0
I0521 09:36:45.820350  3675 net.cpp:100] Creating Layer lstm2x_h_conted_0
I0521 09:36:45.820353  3675 net.cpp:434] lstm2x_h_conted_0 <- h_0
I0521 09:36:45.820358  3675 net.cpp:434] lstm2x_h_conted_0 <- cont_1_lstm2x_cont_slice_0_split_0
I0521 09:36:45.820360  3675 net.cpp:408] lstm2x_h_conted_0 -> h_conted_0
I0521 09:36:45.820412  3675 net.cpp:150] Setting up lstm2x_h_conted_0
I0521 09:36:45.820415  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.820417  3675 net.cpp:165] Memory required for data: 23517184
I0521 09:36:45.820420  3675 layer_factory.hpp:77] Creating layer lstm2x_transform_1
I0521 09:36:45.820425  3675 net.cpp:100] Creating Layer lstm2x_transform_1
I0521 09:36:45.820428  3675 net.cpp:434] lstm2x_transform_1 <- h_conted_0
I0521 09:36:45.820431  3675 net.cpp:408] lstm2x_transform_1 -> W_hc_h_0
I0521 09:36:45.820637  3675 net.cpp:150] Setting up lstm2x_transform_1
I0521 09:36:45.820641  3675 net.cpp:157] Top shape: 1 128 400 (51200)
I0521 09:36:45.820642  3675 net.cpp:165] Memory required for data: 23721984
I0521 09:36:45.820647  3675 layer_factory.hpp:77] Creating layer lstm2x_gate_input_1
I0521 09:36:45.820650  3675 net.cpp:100] Creating Layer lstm2x_gate_input_1
I0521 09:36:45.820652  3675 net.cpp:434] lstm2x_gate_input_1 <- W_hc_h_0
I0521 09:36:45.820655  3675 net.cpp:434] lstm2x_gate_input_1 <- W_xc_x_1
I0521 09:36:45.820659  3675 net.cpp:408] lstm2x_gate_input_1 -> gate_input_1
I0521 09:36:45.820673  3675 net.cpp:150] Setting up lstm2x_gate_input_1
I0521 09:36:45.820677  3675 net.cpp:157] Top shape: 1 128 400 (51200)
I0521 09:36:45.820679  3675 net.cpp:165] Memory required for data: 23926784
I0521 09:36:45.820688  3675 layer_factory.hpp:77] Creating layer lstm2x_unit_1
I0521 09:36:45.820693  3675 net.cpp:100] Creating Layer lstm2x_unit_1
I0521 09:36:45.820695  3675 net.cpp:434] lstm2x_unit_1 <- c_0
I0521 09:36:45.820698  3675 net.cpp:434] lstm2x_unit_1 <- gate_input_1
I0521 09:36:45.820701  3675 net.cpp:434] lstm2x_unit_1 <- cont_1_lstm2x_cont_slice_0_split_1
I0521 09:36:45.820705  3675 net.cpp:408] lstm2x_unit_1 -> c_1
I0521 09:36:45.820709  3675 net.cpp:408] lstm2x_unit_1 -> h_1
I0521 09:36:45.820740  3675 net.cpp:150] Setting up lstm2x_unit_1
I0521 09:36:45.820744  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.820747  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.820749  3675 net.cpp:165] Memory required for data: 24029184
I0521 09:36:45.820751  3675 layer_factory.hpp:77] Creating layer h_1_lstm2x_unit_1_1_split
I0521 09:36:45.820756  3675 net.cpp:100] Creating Layer h_1_lstm2x_unit_1_1_split
I0521 09:36:45.820760  3675 net.cpp:434] h_1_lstm2x_unit_1_1_split <- h_1
I0521 09:36:45.820762  3675 net.cpp:408] h_1_lstm2x_unit_1_1_split -> h_1_lstm2x_unit_1_1_split_0
I0521 09:36:45.820766  3675 net.cpp:408] h_1_lstm2x_unit_1_1_split -> h_1_lstm2x_unit_1_1_split_1
I0521 09:36:45.820798  3675 net.cpp:150] Setting up h_1_lstm2x_unit_1_1_split
I0521 09:36:45.820802  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.820804  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.820807  3675 net.cpp:165] Memory required for data: 24131584
I0521 09:36:45.820809  3675 layer_factory.hpp:77] Creating layer lstm2x_h_conted_1
I0521 09:36:45.820812  3675 net.cpp:100] Creating Layer lstm2x_h_conted_1
I0521 09:36:45.820816  3675 net.cpp:434] lstm2x_h_conted_1 <- h_1_lstm2x_unit_1_1_split_0
I0521 09:36:45.820818  3675 net.cpp:434] lstm2x_h_conted_1 <- cont_2_lstm2x_cont_slice_1_split_0
I0521 09:36:45.820822  3675 net.cpp:408] lstm2x_h_conted_1 -> h_conted_1
I0521 09:36:45.820860  3675 net.cpp:150] Setting up lstm2x_h_conted_1
I0521 09:36:45.820863  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.820865  3675 net.cpp:165] Memory required for data: 24182784
I0521 09:36:45.820868  3675 layer_factory.hpp:77] Creating layer lstm2x_transform_2
I0521 09:36:45.820873  3675 net.cpp:100] Creating Layer lstm2x_transform_2
I0521 09:36:45.820874  3675 net.cpp:434] lstm2x_transform_2 <- h_conted_1
I0521 09:36:45.820880  3675 net.cpp:408] lstm2x_transform_2 -> W_hc_h_1
I0521 09:36:45.821079  3675 net.cpp:150] Setting up lstm2x_transform_2
I0521 09:36:45.821082  3675 net.cpp:157] Top shape: 1 128 400 (51200)
I0521 09:36:45.821085  3675 net.cpp:165] Memory required for data: 24387584
I0521 09:36:45.821087  3675 net.cpp:493] Sharing parameters 'W_hc' owned by layer 'lstm2x_transform_1', param index 0
I0521 09:36:45.821090  3675 layer_factory.hpp:77] Creating layer lstm2x_gate_input_2
I0521 09:36:45.821094  3675 net.cpp:100] Creating Layer lstm2x_gate_input_2
I0521 09:36:45.821096  3675 net.cpp:434] lstm2x_gate_input_2 <- W_hc_h_1
I0521 09:36:45.821099  3675 net.cpp:434] lstm2x_gate_input_2 <- W_xc_x_2
I0521 09:36:45.821102  3675 net.cpp:408] lstm2x_gate_input_2 -> gate_input_2
I0521 09:36:45.821116  3675 net.cpp:150] Setting up lstm2x_gate_input_2
I0521 09:36:45.821120  3675 net.cpp:157] Top shape: 1 128 400 (51200)
I0521 09:36:45.821121  3675 net.cpp:165] Memory required for data: 24592384
I0521 09:36:45.821125  3675 layer_factory.hpp:77] Creating layer lstm2x_unit_2
I0521 09:36:45.821127  3675 net.cpp:100] Creating Layer lstm2x_unit_2
I0521 09:36:45.821130  3675 net.cpp:434] lstm2x_unit_2 <- c_1
I0521 09:36:45.821132  3675 net.cpp:434] lstm2x_unit_2 <- gate_input_2
I0521 09:36:45.821135  3675 net.cpp:434] lstm2x_unit_2 <- cont_2_lstm2x_cont_slice_1_split_1
I0521 09:36:45.821139  3675 net.cpp:408] lstm2x_unit_2 -> c_2
I0521 09:36:45.821142  3675 net.cpp:408] lstm2x_unit_2 -> h_2
I0521 09:36:45.821171  3675 net.cpp:150] Setting up lstm2x_unit_2
I0521 09:36:45.821175  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.821177  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.821187  3675 net.cpp:165] Memory required for data: 24694784
I0521 09:36:45.821188  3675 layer_factory.hpp:77] Creating layer h_2_lstm2x_unit_2_1_split
I0521 09:36:45.821192  3675 net.cpp:100] Creating Layer h_2_lstm2x_unit_2_1_split
I0521 09:36:45.821195  3675 net.cpp:434] h_2_lstm2x_unit_2_1_split <- h_2
I0521 09:36:45.821198  3675 net.cpp:408] h_2_lstm2x_unit_2_1_split -> h_2_lstm2x_unit_2_1_split_0
I0521 09:36:45.821204  3675 net.cpp:408] h_2_lstm2x_unit_2_1_split -> h_2_lstm2x_unit_2_1_split_1
I0521 09:36:45.821233  3675 net.cpp:150] Setting up h_2_lstm2x_unit_2_1_split
I0521 09:36:45.821238  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.821241  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.821244  3675 net.cpp:165] Memory required for data: 24797184
I0521 09:36:45.821249  3675 layer_factory.hpp:77] Creating layer lstm2x_h_conted_2
I0521 09:36:45.821254  3675 net.cpp:100] Creating Layer lstm2x_h_conted_2
I0521 09:36:45.821255  3675 net.cpp:434] lstm2x_h_conted_2 <- h_2_lstm2x_unit_2_1_split_0
I0521 09:36:45.821259  3675 net.cpp:434] lstm2x_h_conted_2 <- cont_3_lstm2x_cont_slice_2_split_0
I0521 09:36:45.821264  3675 net.cpp:408] lstm2x_h_conted_2 -> h_conted_2
I0521 09:36:45.821305  3675 net.cpp:150] Setting up lstm2x_h_conted_2
I0521 09:36:45.821308  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.821311  3675 net.cpp:165] Memory required for data: 24848384
I0521 09:36:45.821313  3675 layer_factory.hpp:77] Creating layer lstm2x_transform_3
I0521 09:36:45.821319  3675 net.cpp:100] Creating Layer lstm2x_transform_3
I0521 09:36:45.821322  3675 net.cpp:434] lstm2x_transform_3 <- h_conted_2
I0521 09:36:45.821326  3675 net.cpp:408] lstm2x_transform_3 -> W_hc_h_2
I0521 09:36:45.821521  3675 net.cpp:150] Setting up lstm2x_transform_3
I0521 09:36:45.821525  3675 net.cpp:157] Top shape: 1 128 400 (51200)
I0521 09:36:45.821527  3675 net.cpp:165] Memory required for data: 25053184
I0521 09:36:45.821530  3675 net.cpp:493] Sharing parameters 'W_hc' owned by layer 'lstm2x_transform_1', param index 0
I0521 09:36:45.821533  3675 layer_factory.hpp:77] Creating layer lstm2x_gate_input_3
I0521 09:36:45.821537  3675 net.cpp:100] Creating Layer lstm2x_gate_input_3
I0521 09:36:45.821539  3675 net.cpp:434] lstm2x_gate_input_3 <- W_hc_h_2
I0521 09:36:45.821542  3675 net.cpp:434] lstm2x_gate_input_3 <- W_xc_x_3
I0521 09:36:45.821545  3675 net.cpp:408] lstm2x_gate_input_3 -> gate_input_3
I0521 09:36:45.821557  3675 net.cpp:150] Setting up lstm2x_gate_input_3
I0521 09:36:45.821560  3675 net.cpp:157] Top shape: 1 128 400 (51200)
I0521 09:36:45.821563  3675 net.cpp:165] Memory required for data: 25257984
I0521 09:36:45.821564  3675 layer_factory.hpp:77] Creating layer lstm2x_unit_3
I0521 09:36:45.821569  3675 net.cpp:100] Creating Layer lstm2x_unit_3
I0521 09:36:45.821573  3675 net.cpp:434] lstm2x_unit_3 <- c_2
I0521 09:36:45.821575  3675 net.cpp:434] lstm2x_unit_3 <- gate_input_3
I0521 09:36:45.821578  3675 net.cpp:434] lstm2x_unit_3 <- cont_3_lstm2x_cont_slice_2_split_1
I0521 09:36:45.821581  3675 net.cpp:408] lstm2x_unit_3 -> c_3
I0521 09:36:45.821585  3675 net.cpp:408] lstm2x_unit_3 -> h_3
I0521 09:36:45.821614  3675 net.cpp:150] Setting up lstm2x_unit_3
I0521 09:36:45.821616  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.821619  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.821621  3675 net.cpp:165] Memory required for data: 25360384
I0521 09:36:45.821624  3675 layer_factory.hpp:77] Creating layer h_3_lstm2x_unit_3_1_split
I0521 09:36:45.821631  3675 net.cpp:100] Creating Layer h_3_lstm2x_unit_3_1_split
I0521 09:36:45.821635  3675 net.cpp:434] h_3_lstm2x_unit_3_1_split <- h_3
I0521 09:36:45.821637  3675 net.cpp:408] h_3_lstm2x_unit_3_1_split -> h_3_lstm2x_unit_3_1_split_0
I0521 09:36:45.821641  3675 net.cpp:408] h_3_lstm2x_unit_3_1_split -> h_3_lstm2x_unit_3_1_split_1
I0521 09:36:45.821661  3675 net.cpp:150] Setting up h_3_lstm2x_unit_3_1_split
I0521 09:36:45.821666  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.821668  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.821677  3675 net.cpp:165] Memory required for data: 25462784
I0521 09:36:45.821681  3675 layer_factory.hpp:77] Creating layer lstm2x_h_conted_3
I0521 09:36:45.821684  3675 net.cpp:100] Creating Layer lstm2x_h_conted_3
I0521 09:36:45.821686  3675 net.cpp:434] lstm2x_h_conted_3 <- h_3_lstm2x_unit_3_1_split_0
I0521 09:36:45.821689  3675 net.cpp:434] lstm2x_h_conted_3 <- cont_4_lstm2x_cont_slice_3_split_0
I0521 09:36:45.821693  3675 net.cpp:408] lstm2x_h_conted_3 -> h_conted_3
I0521 09:36:45.821739  3675 net.cpp:150] Setting up lstm2x_h_conted_3
I0521 09:36:45.821743  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.821744  3675 net.cpp:165] Memory required for data: 25513984
I0521 09:36:45.821748  3675 layer_factory.hpp:77] Creating layer lstm2x_transform_4
I0521 09:36:45.821751  3675 net.cpp:100] Creating Layer lstm2x_transform_4
I0521 09:36:45.821753  3675 net.cpp:434] lstm2x_transform_4 <- h_conted_3
I0521 09:36:45.821758  3675 net.cpp:408] lstm2x_transform_4 -> W_hc_h_3
I0521 09:36:45.821949  3675 net.cpp:150] Setting up lstm2x_transform_4
I0521 09:36:45.821951  3675 net.cpp:157] Top shape: 1 128 400 (51200)
I0521 09:36:45.821954  3675 net.cpp:165] Memory required for data: 25718784
I0521 09:36:45.821956  3675 net.cpp:493] Sharing parameters 'W_hc' owned by layer 'lstm2x_transform_1', param index 0
I0521 09:36:45.821959  3675 layer_factory.hpp:77] Creating layer lstm2x_gate_input_4
I0521 09:36:45.821962  3675 net.cpp:100] Creating Layer lstm2x_gate_input_4
I0521 09:36:45.821964  3675 net.cpp:434] lstm2x_gate_input_4 <- W_hc_h_3
I0521 09:36:45.821967  3675 net.cpp:434] lstm2x_gate_input_4 <- W_xc_x_4
I0521 09:36:45.821970  3675 net.cpp:408] lstm2x_gate_input_4 -> gate_input_4
I0521 09:36:45.821985  3675 net.cpp:150] Setting up lstm2x_gate_input_4
I0521 09:36:45.821987  3675 net.cpp:157] Top shape: 1 128 400 (51200)
I0521 09:36:45.821990  3675 net.cpp:165] Memory required for data: 25923584
I0521 09:36:45.821991  3675 layer_factory.hpp:77] Creating layer lstm2x_unit_4
I0521 09:36:45.821995  3675 net.cpp:100] Creating Layer lstm2x_unit_4
I0521 09:36:45.821997  3675 net.cpp:434] lstm2x_unit_4 <- c_3
I0521 09:36:45.822000  3675 net.cpp:434] lstm2x_unit_4 <- gate_input_4
I0521 09:36:45.822002  3675 net.cpp:434] lstm2x_unit_4 <- cont_4_lstm2x_cont_slice_3_split_1
I0521 09:36:45.822005  3675 net.cpp:408] lstm2x_unit_4 -> c_4
I0521 09:36:45.822010  3675 net.cpp:408] lstm2x_unit_4 -> h_4
I0521 09:36:45.822037  3675 net.cpp:150] Setting up lstm2x_unit_4
I0521 09:36:45.822041  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.822043  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.822046  3675 net.cpp:165] Memory required for data: 26025984
I0521 09:36:45.822047  3675 layer_factory.hpp:77] Creating layer h_4_lstm2x_unit_4_1_split
I0521 09:36:45.822052  3675 net.cpp:100] Creating Layer h_4_lstm2x_unit_4_1_split
I0521 09:36:45.822053  3675 net.cpp:434] h_4_lstm2x_unit_4_1_split <- h_4
I0521 09:36:45.822057  3675 net.cpp:408] h_4_lstm2x_unit_4_1_split -> h_4_lstm2x_unit_4_1_split_0
I0521 09:36:45.822062  3675 net.cpp:408] h_4_lstm2x_unit_4_1_split -> h_4_lstm2x_unit_4_1_split_1
I0521 09:36:45.822082  3675 net.cpp:150] Setting up h_4_lstm2x_unit_4_1_split
I0521 09:36:45.822084  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.822088  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.822089  3675 net.cpp:165] Memory required for data: 26128384
I0521 09:36:45.822091  3675 layer_factory.hpp:77] Creating layer lstm2x_h_conted_4
I0521 09:36:45.822096  3675 net.cpp:100] Creating Layer lstm2x_h_conted_4
I0521 09:36:45.822098  3675 net.cpp:434] lstm2x_h_conted_4 <- h_4_lstm2x_unit_4_1_split_0
I0521 09:36:45.822101  3675 net.cpp:434] lstm2x_h_conted_4 <- cont_5_lstm2x_cont_slice_4_split_0
I0521 09:36:45.822104  3675 net.cpp:408] lstm2x_h_conted_4 -> h_conted_4
I0521 09:36:45.822141  3675 net.cpp:150] Setting up lstm2x_h_conted_4
I0521 09:36:45.822145  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.822147  3675 net.cpp:165] Memory required for data: 26179584
I0521 09:36:45.822155  3675 layer_factory.hpp:77] Creating layer lstm2x_transform_5
I0521 09:36:45.822158  3675 net.cpp:100] Creating Layer lstm2x_transform_5
I0521 09:36:45.822161  3675 net.cpp:434] lstm2x_transform_5 <- h_conted_4
I0521 09:36:45.822165  3675 net.cpp:408] lstm2x_transform_5 -> W_hc_h_4
I0521 09:36:45.822355  3675 net.cpp:150] Setting up lstm2x_transform_5
I0521 09:36:45.822360  3675 net.cpp:157] Top shape: 1 128 400 (51200)
I0521 09:36:45.822361  3675 net.cpp:165] Memory required for data: 26384384
I0521 09:36:45.822363  3675 net.cpp:493] Sharing parameters 'W_hc' owned by layer 'lstm2x_transform_1', param index 0
I0521 09:36:45.822366  3675 layer_factory.hpp:77] Creating layer lstm2x_gate_input_5
I0521 09:36:45.822369  3675 net.cpp:100] Creating Layer lstm2x_gate_input_5
I0521 09:36:45.822372  3675 net.cpp:434] lstm2x_gate_input_5 <- W_hc_h_4
I0521 09:36:45.822374  3675 net.cpp:434] lstm2x_gate_input_5 <- W_xc_x_5
I0521 09:36:45.822378  3675 net.cpp:408] lstm2x_gate_input_5 -> gate_input_5
I0521 09:36:45.822391  3675 net.cpp:150] Setting up lstm2x_gate_input_5
I0521 09:36:45.822396  3675 net.cpp:157] Top shape: 1 128 400 (51200)
I0521 09:36:45.822397  3675 net.cpp:165] Memory required for data: 26589184
I0521 09:36:45.822399  3675 layer_factory.hpp:77] Creating layer lstm2x_unit_5
I0521 09:36:45.822402  3675 net.cpp:100] Creating Layer lstm2x_unit_5
I0521 09:36:45.822405  3675 net.cpp:434] lstm2x_unit_5 <- c_4
I0521 09:36:45.822407  3675 net.cpp:434] lstm2x_unit_5 <- gate_input_5
I0521 09:36:45.822410  3675 net.cpp:434] lstm2x_unit_5 <- cont_5_lstm2x_cont_slice_4_split_1
I0521 09:36:45.822413  3675 net.cpp:408] lstm2x_unit_5 -> c_5
I0521 09:36:45.822417  3675 net.cpp:408] lstm2x_unit_5 -> h_5
I0521 09:36:45.822445  3675 net.cpp:150] Setting up lstm2x_unit_5
I0521 09:36:45.822448  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.822451  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.822453  3675 net.cpp:165] Memory required for data: 26691584
I0521 09:36:45.822455  3675 layer_factory.hpp:77] Creating layer h_5_lstm2x_unit_5_1_split
I0521 09:36:45.822459  3675 net.cpp:100] Creating Layer h_5_lstm2x_unit_5_1_split
I0521 09:36:45.822461  3675 net.cpp:434] h_5_lstm2x_unit_5_1_split <- h_5
I0521 09:36:45.822465  3675 net.cpp:408] h_5_lstm2x_unit_5_1_split -> h_5_lstm2x_unit_5_1_split_0
I0521 09:36:45.822468  3675 net.cpp:408] h_5_lstm2x_unit_5_1_split -> h_5_lstm2x_unit_5_1_split_1
I0521 09:36:45.822490  3675 net.cpp:150] Setting up h_5_lstm2x_unit_5_1_split
I0521 09:36:45.822494  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.822496  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.822499  3675 net.cpp:165] Memory required for data: 26793984
I0521 09:36:45.822500  3675 layer_factory.hpp:77] Creating layer lstm2x_h_conted_5
I0521 09:36:45.822504  3675 net.cpp:100] Creating Layer lstm2x_h_conted_5
I0521 09:36:45.822506  3675 net.cpp:434] lstm2x_h_conted_5 <- h_5_lstm2x_unit_5_1_split_0
I0521 09:36:45.822510  3675 net.cpp:434] lstm2x_h_conted_5 <- cont_6_lstm2x_cont_slice_5_split_0
I0521 09:36:45.822513  3675 net.cpp:408] lstm2x_h_conted_5 -> h_conted_5
I0521 09:36:45.822549  3675 net.cpp:150] Setting up lstm2x_h_conted_5
I0521 09:36:45.822553  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.822556  3675 net.cpp:165] Memory required for data: 26845184
I0521 09:36:45.822557  3675 layer_factory.hpp:77] Creating layer lstm2x_transform_6
I0521 09:36:45.822562  3675 net.cpp:100] Creating Layer lstm2x_transform_6
I0521 09:36:45.822564  3675 net.cpp:434] lstm2x_transform_6 <- h_conted_5
I0521 09:36:45.822568  3675 net.cpp:408] lstm2x_transform_6 -> W_hc_h_5
I0521 09:36:45.822779  3675 net.cpp:150] Setting up lstm2x_transform_6
I0521 09:36:45.822785  3675 net.cpp:157] Top shape: 1 128 400 (51200)
I0521 09:36:45.822788  3675 net.cpp:165] Memory required for data: 27049984
I0521 09:36:45.822793  3675 net.cpp:493] Sharing parameters 'W_hc' owned by layer 'lstm2x_transform_1', param index 0
I0521 09:36:45.822803  3675 layer_factory.hpp:77] Creating layer lstm2x_gate_input_6
I0521 09:36:45.822808  3675 net.cpp:100] Creating Layer lstm2x_gate_input_6
I0521 09:36:45.822811  3675 net.cpp:434] lstm2x_gate_input_6 <- W_hc_h_5
I0521 09:36:45.822815  3675 net.cpp:434] lstm2x_gate_input_6 <- W_xc_x_6
I0521 09:36:45.822820  3675 net.cpp:408] lstm2x_gate_input_6 -> gate_input_6
I0521 09:36:45.822839  3675 net.cpp:150] Setting up lstm2x_gate_input_6
I0521 09:36:45.822842  3675 net.cpp:157] Top shape: 1 128 400 (51200)
I0521 09:36:45.822845  3675 net.cpp:165] Memory required for data: 27254784
I0521 09:36:45.822847  3675 layer_factory.hpp:77] Creating layer lstm2x_unit_6
I0521 09:36:45.822851  3675 net.cpp:100] Creating Layer lstm2x_unit_6
I0521 09:36:45.822854  3675 net.cpp:434] lstm2x_unit_6 <- c_5
I0521 09:36:45.822856  3675 net.cpp:434] lstm2x_unit_6 <- gate_input_6
I0521 09:36:45.822860  3675 net.cpp:434] lstm2x_unit_6 <- cont_6_lstm2x_cont_slice_5_split_1
I0521 09:36:45.822862  3675 net.cpp:408] lstm2x_unit_6 -> c_6
I0521 09:36:45.822866  3675 net.cpp:408] lstm2x_unit_6 -> h_6
I0521 09:36:45.822898  3675 net.cpp:150] Setting up lstm2x_unit_6
I0521 09:36:45.822902  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.822904  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.822906  3675 net.cpp:165] Memory required for data: 27357184
I0521 09:36:45.822909  3675 layer_factory.hpp:77] Creating layer h_6_lstm2x_unit_6_1_split
I0521 09:36:45.822912  3675 net.cpp:100] Creating Layer h_6_lstm2x_unit_6_1_split
I0521 09:36:45.822916  3675 net.cpp:434] h_6_lstm2x_unit_6_1_split <- h_6
I0521 09:36:45.822918  3675 net.cpp:408] h_6_lstm2x_unit_6_1_split -> h_6_lstm2x_unit_6_1_split_0
I0521 09:36:45.822922  3675 net.cpp:408] h_6_lstm2x_unit_6_1_split -> h_6_lstm2x_unit_6_1_split_1
I0521 09:36:45.822942  3675 net.cpp:150] Setting up h_6_lstm2x_unit_6_1_split
I0521 09:36:45.822947  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.822948  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.822950  3675 net.cpp:165] Memory required for data: 27459584
I0521 09:36:45.822953  3675 layer_factory.hpp:77] Creating layer lstm2x_h_conted_6
I0521 09:36:45.822957  3675 net.cpp:100] Creating Layer lstm2x_h_conted_6
I0521 09:36:45.822960  3675 net.cpp:434] lstm2x_h_conted_6 <- h_6_lstm2x_unit_6_1_split_0
I0521 09:36:45.822963  3675 net.cpp:434] lstm2x_h_conted_6 <- cont_7_lstm2x_cont_slice_6_split_0
I0521 09:36:45.822966  3675 net.cpp:408] lstm2x_h_conted_6 -> h_conted_6
I0521 09:36:45.823005  3675 net.cpp:150] Setting up lstm2x_h_conted_6
I0521 09:36:45.823009  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.823010  3675 net.cpp:165] Memory required for data: 27510784
I0521 09:36:45.823014  3675 layer_factory.hpp:77] Creating layer lstm2x_transform_7
I0521 09:36:45.823019  3675 net.cpp:100] Creating Layer lstm2x_transform_7
I0521 09:36:45.823021  3675 net.cpp:434] lstm2x_transform_7 <- h_conted_6
I0521 09:36:45.823024  3675 net.cpp:408] lstm2x_transform_7 -> W_hc_h_6
I0521 09:36:45.823218  3675 net.cpp:150] Setting up lstm2x_transform_7
I0521 09:36:45.823222  3675 net.cpp:157] Top shape: 1 128 400 (51200)
I0521 09:36:45.823225  3675 net.cpp:165] Memory required for data: 27715584
I0521 09:36:45.823227  3675 net.cpp:493] Sharing parameters 'W_hc' owned by layer 'lstm2x_transform_1', param index 0
I0521 09:36:45.823230  3675 layer_factory.hpp:77] Creating layer lstm2x_gate_input_7
I0521 09:36:45.823233  3675 net.cpp:100] Creating Layer lstm2x_gate_input_7
I0521 09:36:45.823236  3675 net.cpp:434] lstm2x_gate_input_7 <- W_hc_h_6
I0521 09:36:45.823238  3675 net.cpp:434] lstm2x_gate_input_7 <- W_xc_x_7
I0521 09:36:45.823242  3675 net.cpp:408] lstm2x_gate_input_7 -> gate_input_7
I0521 09:36:45.823256  3675 net.cpp:150] Setting up lstm2x_gate_input_7
I0521 09:36:45.823259  3675 net.cpp:157] Top shape: 1 128 400 (51200)
I0521 09:36:45.823261  3675 net.cpp:165] Memory required for data: 27920384
I0521 09:36:45.823263  3675 layer_factory.hpp:77] Creating layer lstm2x_unit_7
I0521 09:36:45.823267  3675 net.cpp:100] Creating Layer lstm2x_unit_7
I0521 09:36:45.823276  3675 net.cpp:434] lstm2x_unit_7 <- c_6
I0521 09:36:45.823279  3675 net.cpp:434] lstm2x_unit_7 <- gate_input_7
I0521 09:36:45.823282  3675 net.cpp:434] lstm2x_unit_7 <- cont_7_lstm2x_cont_slice_6_split_1
I0521 09:36:45.823285  3675 net.cpp:408] lstm2x_unit_7 -> c_7
I0521 09:36:45.823290  3675 net.cpp:408] lstm2x_unit_7 -> h_7
I0521 09:36:45.823321  3675 net.cpp:150] Setting up lstm2x_unit_7
I0521 09:36:45.823324  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.823328  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.823329  3675 net.cpp:165] Memory required for data: 28022784
I0521 09:36:45.823331  3675 layer_factory.hpp:77] Creating layer h_7_lstm2x_unit_7_1_split
I0521 09:36:45.823336  3675 net.cpp:100] Creating Layer h_7_lstm2x_unit_7_1_split
I0521 09:36:45.823338  3675 net.cpp:434] h_7_lstm2x_unit_7_1_split <- h_7
I0521 09:36:45.823341  3675 net.cpp:408] h_7_lstm2x_unit_7_1_split -> h_7_lstm2x_unit_7_1_split_0
I0521 09:36:45.823345  3675 net.cpp:408] h_7_lstm2x_unit_7_1_split -> h_7_lstm2x_unit_7_1_split_1
I0521 09:36:45.823369  3675 net.cpp:150] Setting up h_7_lstm2x_unit_7_1_split
I0521 09:36:45.823371  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.823374  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.823376  3675 net.cpp:165] Memory required for data: 28125184
I0521 09:36:45.823379  3675 layer_factory.hpp:77] Creating layer lstm2x_h_conted_7
I0521 09:36:45.823384  3675 net.cpp:100] Creating Layer lstm2x_h_conted_7
I0521 09:36:45.823385  3675 net.cpp:434] lstm2x_h_conted_7 <- h_7_lstm2x_unit_7_1_split_0
I0521 09:36:45.823388  3675 net.cpp:434] lstm2x_h_conted_7 <- cont_8_lstm2x_cont_slice_7_split_0
I0521 09:36:45.823391  3675 net.cpp:408] lstm2x_h_conted_7 -> h_conted_7
I0521 09:36:45.823428  3675 net.cpp:150] Setting up lstm2x_h_conted_7
I0521 09:36:45.823432  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.823434  3675 net.cpp:165] Memory required for data: 28176384
I0521 09:36:45.823436  3675 layer_factory.hpp:77] Creating layer lstm2x_transform_8
I0521 09:36:45.823441  3675 net.cpp:100] Creating Layer lstm2x_transform_8
I0521 09:36:45.823443  3675 net.cpp:434] lstm2x_transform_8 <- h_conted_7
I0521 09:36:45.823447  3675 net.cpp:408] lstm2x_transform_8 -> W_hc_h_7
I0521 09:36:45.824288  3675 net.cpp:150] Setting up lstm2x_transform_8
I0521 09:36:45.824301  3675 net.cpp:157] Top shape: 1 128 400 (51200)
I0521 09:36:45.824303  3675 net.cpp:165] Memory required for data: 28381184
I0521 09:36:45.824308  3675 net.cpp:493] Sharing parameters 'W_hc' owned by layer 'lstm2x_transform_1', param index 0
I0521 09:36:45.824312  3675 layer_factory.hpp:77] Creating layer lstm2x_gate_input_8
I0521 09:36:45.824319  3675 net.cpp:100] Creating Layer lstm2x_gate_input_8
I0521 09:36:45.824323  3675 net.cpp:434] lstm2x_gate_input_8 <- W_hc_h_7
I0521 09:36:45.824327  3675 net.cpp:434] lstm2x_gate_input_8 <- W_xc_x_8
I0521 09:36:45.824333  3675 net.cpp:408] lstm2x_gate_input_8 -> gate_input_8
I0521 09:36:45.824357  3675 net.cpp:150] Setting up lstm2x_gate_input_8
I0521 09:36:45.824360  3675 net.cpp:157] Top shape: 1 128 400 (51200)
I0521 09:36:45.824363  3675 net.cpp:165] Memory required for data: 28585984
I0521 09:36:45.824368  3675 layer_factory.hpp:77] Creating layer lstm2x_unit_8
I0521 09:36:45.824373  3675 net.cpp:100] Creating Layer lstm2x_unit_8
I0521 09:36:45.824376  3675 net.cpp:434] lstm2x_unit_8 <- c_7
I0521 09:36:45.824380  3675 net.cpp:434] lstm2x_unit_8 <- gate_input_8
I0521 09:36:45.824384  3675 net.cpp:434] lstm2x_unit_8 <- cont_8_lstm2x_cont_slice_7_split_1
I0521 09:36:45.824389  3675 net.cpp:408] lstm2x_unit_8 -> c_8
I0521 09:36:45.824394  3675 net.cpp:408] lstm2x_unit_8 -> h_8
I0521 09:36:45.824424  3675 net.cpp:150] Setting up lstm2x_unit_8
I0521 09:36:45.824429  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.824431  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.824434  3675 net.cpp:165] Memory required for data: 28688384
I0521 09:36:45.824435  3675 layer_factory.hpp:77] Creating layer h_8_lstm2x_unit_8_1_split
I0521 09:36:45.824452  3675 net.cpp:100] Creating Layer h_8_lstm2x_unit_8_1_split
I0521 09:36:45.824455  3675 net.cpp:434] h_8_lstm2x_unit_8_1_split <- h_8
I0521 09:36:45.824458  3675 net.cpp:408] h_8_lstm2x_unit_8_1_split -> h_8_lstm2x_unit_8_1_split_0
I0521 09:36:45.824462  3675 net.cpp:408] h_8_lstm2x_unit_8_1_split -> h_8_lstm2x_unit_8_1_split_1
I0521 09:36:45.824486  3675 net.cpp:150] Setting up h_8_lstm2x_unit_8_1_split
I0521 09:36:45.824488  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.824491  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.824493  3675 net.cpp:165] Memory required for data: 28790784
I0521 09:36:45.824496  3675 layer_factory.hpp:77] Creating layer lstm2x_h_conted_8
I0521 09:36:45.824499  3675 net.cpp:100] Creating Layer lstm2x_h_conted_8
I0521 09:36:45.824501  3675 net.cpp:434] lstm2x_h_conted_8 <- h_8_lstm2x_unit_8_1_split_0
I0521 09:36:45.824504  3675 net.cpp:434] lstm2x_h_conted_8 <- cont_9_lstm2x_cont_slice_8_split_0
I0521 09:36:45.824508  3675 net.cpp:408] lstm2x_h_conted_8 -> h_conted_8
I0521 09:36:45.824556  3675 net.cpp:150] Setting up lstm2x_h_conted_8
I0521 09:36:45.824559  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.824561  3675 net.cpp:165] Memory required for data: 28841984
I0521 09:36:45.824563  3675 layer_factory.hpp:77] Creating layer lstm2x_transform_9
I0521 09:36:45.824568  3675 net.cpp:100] Creating Layer lstm2x_transform_9
I0521 09:36:45.824570  3675 net.cpp:434] lstm2x_transform_9 <- h_conted_8
I0521 09:36:45.824574  3675 net.cpp:408] lstm2x_transform_9 -> W_hc_h_8
I0521 09:36:45.824774  3675 net.cpp:150] Setting up lstm2x_transform_9
I0521 09:36:45.824777  3675 net.cpp:157] Top shape: 1 128 400 (51200)
I0521 09:36:45.824779  3675 net.cpp:165] Memory required for data: 29046784
I0521 09:36:45.824791  3675 net.cpp:493] Sharing parameters 'W_hc' owned by layer 'lstm2x_transform_1', param index 0
I0521 09:36:45.824795  3675 layer_factory.hpp:77] Creating layer lstm2x_gate_input_9
I0521 09:36:45.824800  3675 net.cpp:100] Creating Layer lstm2x_gate_input_9
I0521 09:36:45.824803  3675 net.cpp:434] lstm2x_gate_input_9 <- W_hc_h_8
I0521 09:36:45.824806  3675 net.cpp:434] lstm2x_gate_input_9 <- W_xc_x_9
I0521 09:36:45.824810  3675 net.cpp:408] lstm2x_gate_input_9 -> gate_input_9
I0521 09:36:45.824825  3675 net.cpp:150] Setting up lstm2x_gate_input_9
I0521 09:36:45.824828  3675 net.cpp:157] Top shape: 1 128 400 (51200)
I0521 09:36:45.824831  3675 net.cpp:165] Memory required for data: 29251584
I0521 09:36:45.824832  3675 layer_factory.hpp:77] Creating layer lstm2x_unit_9
I0521 09:36:45.824838  3675 net.cpp:100] Creating Layer lstm2x_unit_9
I0521 09:36:45.824841  3675 net.cpp:434] lstm2x_unit_9 <- c_8
I0521 09:36:45.824844  3675 net.cpp:434] lstm2x_unit_9 <- gate_input_9
I0521 09:36:45.824847  3675 net.cpp:434] lstm2x_unit_9 <- cont_9_lstm2x_cont_slice_8_split_1
I0521 09:36:45.824851  3675 net.cpp:408] lstm2x_unit_9 -> c_9
I0521 09:36:45.824859  3675 net.cpp:408] lstm2x_unit_9 -> h_9
I0521 09:36:45.824888  3675 net.cpp:150] Setting up lstm2x_unit_9
I0521 09:36:45.824892  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.824894  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.824898  3675 net.cpp:165] Memory required for data: 29353984
I0521 09:36:45.824899  3675 layer_factory.hpp:77] Creating layer h_9_lstm2x_unit_9_1_split
I0521 09:36:45.824903  3675 net.cpp:100] Creating Layer h_9_lstm2x_unit_9_1_split
I0521 09:36:45.824904  3675 net.cpp:434] h_9_lstm2x_unit_9_1_split <- h_9
I0521 09:36:45.824908  3675 net.cpp:408] h_9_lstm2x_unit_9_1_split -> h_9_lstm2x_unit_9_1_split_0
I0521 09:36:45.824913  3675 net.cpp:408] h_9_lstm2x_unit_9_1_split -> h_9_lstm2x_unit_9_1_split_1
I0521 09:36:45.824939  3675 net.cpp:150] Setting up h_9_lstm2x_unit_9_1_split
I0521 09:36:45.824942  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.824947  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.824950  3675 net.cpp:165] Memory required for data: 29456384
I0521 09:36:45.824961  3675 layer_factory.hpp:77] Creating layer lstm2x_h_conted_9
I0521 09:36:45.824967  3675 net.cpp:100] Creating Layer lstm2x_h_conted_9
I0521 09:36:45.824970  3675 net.cpp:434] lstm2x_h_conted_9 <- h_9_lstm2x_unit_9_1_split_0
I0521 09:36:45.824975  3675 net.cpp:434] lstm2x_h_conted_9 <- cont_10_lstm2x_cont_slice_9_split_0
I0521 09:36:45.824980  3675 net.cpp:408] lstm2x_h_conted_9 -> h_conted_9
I0521 09:36:45.825029  3675 net.cpp:150] Setting up lstm2x_h_conted_9
I0521 09:36:45.825033  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.825037  3675 net.cpp:165] Memory required for data: 29507584
I0521 09:36:45.825040  3675 layer_factory.hpp:77] Creating layer lstm2x_transform_10
I0521 09:36:45.825047  3675 net.cpp:100] Creating Layer lstm2x_transform_10
I0521 09:36:45.825052  3675 net.cpp:434] lstm2x_transform_10 <- h_conted_9
I0521 09:36:45.825057  3675 net.cpp:408] lstm2x_transform_10 -> W_hc_h_9
I0521 09:36:45.825258  3675 net.cpp:150] Setting up lstm2x_transform_10
I0521 09:36:45.825263  3675 net.cpp:157] Top shape: 1 128 400 (51200)
I0521 09:36:45.825264  3675 net.cpp:165] Memory required for data: 29712384
I0521 09:36:45.825268  3675 net.cpp:493] Sharing parameters 'W_hc' owned by layer 'lstm2x_transform_1', param index 0
I0521 09:36:45.825270  3675 layer_factory.hpp:77] Creating layer lstm2x_gate_input_10
I0521 09:36:45.825273  3675 net.cpp:100] Creating Layer lstm2x_gate_input_10
I0521 09:36:45.825276  3675 net.cpp:434] lstm2x_gate_input_10 <- W_hc_h_9
I0521 09:36:45.825279  3675 net.cpp:434] lstm2x_gate_input_10 <- W_xc_x_10
I0521 09:36:45.825284  3675 net.cpp:408] lstm2x_gate_input_10 -> gate_input_10
I0521 09:36:45.825297  3675 net.cpp:150] Setting up lstm2x_gate_input_10
I0521 09:36:45.825300  3675 net.cpp:157] Top shape: 1 128 400 (51200)
I0521 09:36:45.825302  3675 net.cpp:165] Memory required for data: 29917184
I0521 09:36:45.825304  3675 layer_factory.hpp:77] Creating layer lstm2x_unit_10
I0521 09:36:45.825309  3675 net.cpp:100] Creating Layer lstm2x_unit_10
I0521 09:36:45.825312  3675 net.cpp:434] lstm2x_unit_10 <- c_9
I0521 09:36:45.825314  3675 net.cpp:434] lstm2x_unit_10 <- gate_input_10
I0521 09:36:45.825317  3675 net.cpp:434] lstm2x_unit_10 <- cont_10_lstm2x_cont_slice_9_split_1
I0521 09:36:45.825321  3675 net.cpp:408] lstm2x_unit_10 -> c_10
I0521 09:36:45.825326  3675 net.cpp:408] lstm2x_unit_10 -> h_10
I0521 09:36:45.825354  3675 net.cpp:150] Setting up lstm2x_unit_10
I0521 09:36:45.825358  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.825361  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.825363  3675 net.cpp:165] Memory required for data: 30019584
I0521 09:36:45.825366  3675 layer_factory.hpp:77] Creating layer h_10_lstm2x_unit_10_1_split
I0521 09:36:45.825369  3675 net.cpp:100] Creating Layer h_10_lstm2x_unit_10_1_split
I0521 09:36:45.825372  3675 net.cpp:434] h_10_lstm2x_unit_10_1_split <- h_10
I0521 09:36:45.825376  3675 net.cpp:408] h_10_lstm2x_unit_10_1_split -> h_10_lstm2x_unit_10_1_split_0
I0521 09:36:45.825381  3675 net.cpp:408] h_10_lstm2x_unit_10_1_split -> h_10_lstm2x_unit_10_1_split_1
I0521 09:36:45.825400  3675 net.cpp:150] Setting up h_10_lstm2x_unit_10_1_split
I0521 09:36:45.825403  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.825407  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.825408  3675 net.cpp:165] Memory required for data: 30121984
I0521 09:36:45.825412  3675 layer_factory.hpp:77] Creating layer lstm2x_h_conted_10
I0521 09:36:45.825415  3675 net.cpp:100] Creating Layer lstm2x_h_conted_10
I0521 09:36:45.825418  3675 net.cpp:434] lstm2x_h_conted_10 <- h_10_lstm2x_unit_10_1_split_0
I0521 09:36:45.825422  3675 net.cpp:434] lstm2x_h_conted_10 <- cont_11_lstm2x_cont_slice_10_split_0
I0521 09:36:45.825425  3675 net.cpp:408] lstm2x_h_conted_10 -> h_conted_10
I0521 09:36:45.825464  3675 net.cpp:150] Setting up lstm2x_h_conted_10
I0521 09:36:45.825467  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.825469  3675 net.cpp:165] Memory required for data: 30173184
I0521 09:36:45.825479  3675 layer_factory.hpp:77] Creating layer lstm2x_transform_11
I0521 09:36:45.825484  3675 net.cpp:100] Creating Layer lstm2x_transform_11
I0521 09:36:45.825485  3675 net.cpp:434] lstm2x_transform_11 <- h_conted_10
I0521 09:36:45.825489  3675 net.cpp:408] lstm2x_transform_11 -> W_hc_h_10
I0521 09:36:45.825718  3675 net.cpp:150] Setting up lstm2x_transform_11
I0521 09:36:45.825726  3675 net.cpp:157] Top shape: 1 128 400 (51200)
I0521 09:36:45.825728  3675 net.cpp:165] Memory required for data: 30377984
I0521 09:36:45.825731  3675 net.cpp:493] Sharing parameters 'W_hc' owned by layer 'lstm2x_transform_1', param index 0
I0521 09:36:45.825733  3675 layer_factory.hpp:77] Creating layer lstm2x_gate_input_11
I0521 09:36:45.825737  3675 net.cpp:100] Creating Layer lstm2x_gate_input_11
I0521 09:36:45.825742  3675 net.cpp:434] lstm2x_gate_input_11 <- W_hc_h_10
I0521 09:36:45.825745  3675 net.cpp:434] lstm2x_gate_input_11 <- W_xc_x_11
I0521 09:36:45.825750  3675 net.cpp:408] lstm2x_gate_input_11 -> gate_input_11
I0521 09:36:45.825773  3675 net.cpp:150] Setting up lstm2x_gate_input_11
I0521 09:36:45.825779  3675 net.cpp:157] Top shape: 1 128 400 (51200)
I0521 09:36:45.825783  3675 net.cpp:165] Memory required for data: 30582784
I0521 09:36:45.825785  3675 layer_factory.hpp:77] Creating layer lstm2x_unit_11
I0521 09:36:45.825789  3675 net.cpp:100] Creating Layer lstm2x_unit_11
I0521 09:36:45.825793  3675 net.cpp:434] lstm2x_unit_11 <- c_10
I0521 09:36:45.825798  3675 net.cpp:434] lstm2x_unit_11 <- gate_input_11
I0521 09:36:45.825803  3675 net.cpp:434] lstm2x_unit_11 <- cont_11_lstm2x_cont_slice_10_split_1
I0521 09:36:45.825808  3675 net.cpp:408] lstm2x_unit_11 -> c_11
I0521 09:36:45.825814  3675 net.cpp:408] lstm2x_unit_11 -> h_11
I0521 09:36:45.825855  3675 net.cpp:150] Setting up lstm2x_unit_11
I0521 09:36:45.825860  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.825863  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.825866  3675 net.cpp:165] Memory required for data: 30685184
I0521 09:36:45.825870  3675 layer_factory.hpp:77] Creating layer h_11_lstm2x_unit_11_1_split
I0521 09:36:45.825876  3675 net.cpp:100] Creating Layer h_11_lstm2x_unit_11_1_split
I0521 09:36:45.825881  3675 net.cpp:434] h_11_lstm2x_unit_11_1_split <- h_11
I0521 09:36:45.825886  3675 net.cpp:408] h_11_lstm2x_unit_11_1_split -> h_11_lstm2x_unit_11_1_split_0
I0521 09:36:45.825892  3675 net.cpp:408] h_11_lstm2x_unit_11_1_split -> h_11_lstm2x_unit_11_1_split_1
I0521 09:36:45.825920  3675 net.cpp:150] Setting up h_11_lstm2x_unit_11_1_split
I0521 09:36:45.825925  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.825929  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.825933  3675 net.cpp:165] Memory required for data: 30787584
I0521 09:36:45.825937  3675 layer_factory.hpp:77] Creating layer lstm2x_h_conted_11
I0521 09:36:45.825943  3675 net.cpp:100] Creating Layer lstm2x_h_conted_11
I0521 09:36:45.825947  3675 net.cpp:434] lstm2x_h_conted_11 <- h_11_lstm2x_unit_11_1_split_0
I0521 09:36:45.825951  3675 net.cpp:434] lstm2x_h_conted_11 <- cont_12_lstm2x_cont_slice_11_split_0
I0521 09:36:45.825956  3675 net.cpp:408] lstm2x_h_conted_11 -> h_conted_11
I0521 09:36:45.826010  3675 net.cpp:150] Setting up lstm2x_h_conted_11
I0521 09:36:45.826014  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.826016  3675 net.cpp:165] Memory required for data: 30838784
I0521 09:36:45.826020  3675 layer_factory.hpp:77] Creating layer lstm2x_transform_12
I0521 09:36:45.826023  3675 net.cpp:100] Creating Layer lstm2x_transform_12
I0521 09:36:45.826026  3675 net.cpp:434] lstm2x_transform_12 <- h_conted_11
I0521 09:36:45.826031  3675 net.cpp:408] lstm2x_transform_12 -> W_hc_h_11
I0521 09:36:45.826372  3675 net.cpp:150] Setting up lstm2x_transform_12
I0521 09:36:45.826378  3675 net.cpp:157] Top shape: 1 128 400 (51200)
I0521 09:36:45.826382  3675 net.cpp:165] Memory required for data: 31043584
I0521 09:36:45.826386  3675 net.cpp:493] Sharing parameters 'W_hc' owned by layer 'lstm2x_transform_1', param index 0
I0521 09:36:45.826402  3675 layer_factory.hpp:77] Creating layer lstm2x_gate_input_12
I0521 09:36:45.826408  3675 net.cpp:100] Creating Layer lstm2x_gate_input_12
I0521 09:36:45.826412  3675 net.cpp:434] lstm2x_gate_input_12 <- W_hc_h_11
I0521 09:36:45.826416  3675 net.cpp:434] lstm2x_gate_input_12 <- W_xc_x_12
I0521 09:36:45.826421  3675 net.cpp:408] lstm2x_gate_input_12 -> gate_input_12
I0521 09:36:45.826442  3675 net.cpp:150] Setting up lstm2x_gate_input_12
I0521 09:36:45.826447  3675 net.cpp:157] Top shape: 1 128 400 (51200)
I0521 09:36:45.826449  3675 net.cpp:165] Memory required for data: 31248384
I0521 09:36:45.826453  3675 layer_factory.hpp:77] Creating layer lstm2x_unit_12
I0521 09:36:45.826458  3675 net.cpp:100] Creating Layer lstm2x_unit_12
I0521 09:36:45.826462  3675 net.cpp:434] lstm2x_unit_12 <- c_11
I0521 09:36:45.826467  3675 net.cpp:434] lstm2x_unit_12 <- gate_input_12
I0521 09:36:45.826470  3675 net.cpp:434] lstm2x_unit_12 <- cont_12_lstm2x_cont_slice_11_split_1
I0521 09:36:45.826475  3675 net.cpp:408] lstm2x_unit_12 -> c_12
I0521 09:36:45.826481  3675 net.cpp:408] lstm2x_unit_12 -> h_12
I0521 09:36:45.826524  3675 net.cpp:150] Setting up lstm2x_unit_12
I0521 09:36:45.826530  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.826534  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.826537  3675 net.cpp:165] Memory required for data: 31350784
I0521 09:36:45.826541  3675 layer_factory.hpp:77] Creating layer h_12_lstm2x_unit_12_1_split
I0521 09:36:45.826545  3675 net.cpp:100] Creating Layer h_12_lstm2x_unit_12_1_split
I0521 09:36:45.826550  3675 net.cpp:434] h_12_lstm2x_unit_12_1_split <- h_12
I0521 09:36:45.826555  3675 net.cpp:408] h_12_lstm2x_unit_12_1_split -> h_12_lstm2x_unit_12_1_split_0
I0521 09:36:45.826561  3675 net.cpp:408] h_12_lstm2x_unit_12_1_split -> h_12_lstm2x_unit_12_1_split_1
I0521 09:36:45.826591  3675 net.cpp:150] Setting up h_12_lstm2x_unit_12_1_split
I0521 09:36:45.826596  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.826601  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.826604  3675 net.cpp:165] Memory required for data: 31453184
I0521 09:36:45.826608  3675 layer_factory.hpp:77] Creating layer lstm2x_h_conted_12
I0521 09:36:45.826613  3675 net.cpp:100] Creating Layer lstm2x_h_conted_12
I0521 09:36:45.826617  3675 net.cpp:434] lstm2x_h_conted_12 <- h_12_lstm2x_unit_12_1_split_0
I0521 09:36:45.826622  3675 net.cpp:434] lstm2x_h_conted_12 <- cont_13_lstm2x_cont_slice_12_split_0
I0521 09:36:45.826628  3675 net.cpp:408] lstm2x_h_conted_12 -> h_conted_12
I0521 09:36:45.826679  3675 net.cpp:150] Setting up lstm2x_h_conted_12
I0521 09:36:45.826685  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.826689  3675 net.cpp:165] Memory required for data: 31504384
I0521 09:36:45.826691  3675 layer_factory.hpp:77] Creating layer lstm2x_transform_13
I0521 09:36:45.826699  3675 net.cpp:100] Creating Layer lstm2x_transform_13
I0521 09:36:45.826701  3675 net.cpp:434] lstm2x_transform_13 <- h_conted_12
I0521 09:36:45.826707  3675 net.cpp:408] lstm2x_transform_13 -> W_hc_h_12
I0521 09:36:45.826969  3675 net.cpp:150] Setting up lstm2x_transform_13
I0521 09:36:45.826977  3675 net.cpp:157] Top shape: 1 128 400 (51200)
I0521 09:36:45.826979  3675 net.cpp:165] Memory required for data: 31709184
I0521 09:36:45.826983  3675 net.cpp:493] Sharing parameters 'W_hc' owned by layer 'lstm2x_transform_1', param index 0
I0521 09:36:45.826987  3675 layer_factory.hpp:77] Creating layer lstm2x_gate_input_13
I0521 09:36:45.826992  3675 net.cpp:100] Creating Layer lstm2x_gate_input_13
I0521 09:36:45.826995  3675 net.cpp:434] lstm2x_gate_input_13 <- W_hc_h_12
I0521 09:36:45.827000  3675 net.cpp:434] lstm2x_gate_input_13 <- W_xc_x_13
I0521 09:36:45.827004  3675 net.cpp:408] lstm2x_gate_input_13 -> gate_input_13
I0521 09:36:45.827023  3675 net.cpp:150] Setting up lstm2x_gate_input_13
I0521 09:36:45.827028  3675 net.cpp:157] Top shape: 1 128 400 (51200)
I0521 09:36:45.827031  3675 net.cpp:165] Memory required for data: 31913984
I0521 09:36:45.827034  3675 layer_factory.hpp:77] Creating layer lstm2x_unit_13
I0521 09:36:45.827049  3675 net.cpp:100] Creating Layer lstm2x_unit_13
I0521 09:36:45.827052  3675 net.cpp:434] lstm2x_unit_13 <- c_12
I0521 09:36:45.827056  3675 net.cpp:434] lstm2x_unit_13 <- gate_input_13
I0521 09:36:45.827059  3675 net.cpp:434] lstm2x_unit_13 <- cont_13_lstm2x_cont_slice_12_split_1
I0521 09:36:45.827064  3675 net.cpp:408] lstm2x_unit_13 -> c_13
I0521 09:36:45.827070  3675 net.cpp:408] lstm2x_unit_13 -> h_13
I0521 09:36:45.827107  3675 net.cpp:150] Setting up lstm2x_unit_13
I0521 09:36:45.827111  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.827116  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.827119  3675 net.cpp:165] Memory required for data: 32016384
I0521 09:36:45.827122  3675 layer_factory.hpp:77] Creating layer h_13_lstm2x_unit_13_1_split
I0521 09:36:45.827127  3675 net.cpp:100] Creating Layer h_13_lstm2x_unit_13_1_split
I0521 09:36:45.827131  3675 net.cpp:434] h_13_lstm2x_unit_13_1_split <- h_13
I0521 09:36:45.827136  3675 net.cpp:408] h_13_lstm2x_unit_13_1_split -> h_13_lstm2x_unit_13_1_split_0
I0521 09:36:45.827142  3675 net.cpp:408] h_13_lstm2x_unit_13_1_split -> h_13_lstm2x_unit_13_1_split_1
I0521 09:36:45.827168  3675 net.cpp:150] Setting up h_13_lstm2x_unit_13_1_split
I0521 09:36:45.827172  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.827177  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.827179  3675 net.cpp:165] Memory required for data: 32118784
I0521 09:36:45.827183  3675 layer_factory.hpp:77] Creating layer lstm2x_h_conted_13
I0521 09:36:45.827190  3675 net.cpp:100] Creating Layer lstm2x_h_conted_13
I0521 09:36:45.827194  3675 net.cpp:434] lstm2x_h_conted_13 <- h_13_lstm2x_unit_13_1_split_0
I0521 09:36:45.827199  3675 net.cpp:434] lstm2x_h_conted_13 <- cont_14_lstm2x_cont_slice_13_split_0
I0521 09:36:45.827204  3675 net.cpp:408] lstm2x_h_conted_13 -> h_conted_13
I0521 09:36:45.827257  3675 net.cpp:150] Setting up lstm2x_h_conted_13
I0521 09:36:45.827262  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.827265  3675 net.cpp:165] Memory required for data: 32169984
I0521 09:36:45.827268  3675 layer_factory.hpp:77] Creating layer lstm2x_transform_14
I0521 09:36:45.827275  3675 net.cpp:100] Creating Layer lstm2x_transform_14
I0521 09:36:45.827280  3675 net.cpp:434] lstm2x_transform_14 <- h_conted_13
I0521 09:36:45.827284  3675 net.cpp:408] lstm2x_transform_14 -> W_hc_h_13
I0521 09:36:45.827634  3675 net.cpp:150] Setting up lstm2x_transform_14
I0521 09:36:45.827641  3675 net.cpp:157] Top shape: 1 128 400 (51200)
I0521 09:36:45.827644  3675 net.cpp:165] Memory required for data: 32374784
I0521 09:36:45.827648  3675 net.cpp:493] Sharing parameters 'W_hc' owned by layer 'lstm2x_transform_1', param index 0
I0521 09:36:45.827652  3675 layer_factory.hpp:77] Creating layer lstm2x_gate_input_14
I0521 09:36:45.827657  3675 net.cpp:100] Creating Layer lstm2x_gate_input_14
I0521 09:36:45.827661  3675 net.cpp:434] lstm2x_gate_input_14 <- W_hc_h_13
I0521 09:36:45.827668  3675 net.cpp:434] lstm2x_gate_input_14 <- W_xc_x_14
I0521 09:36:45.827673  3675 net.cpp:408] lstm2x_gate_input_14 -> gate_input_14
I0521 09:36:45.827697  3675 net.cpp:150] Setting up lstm2x_gate_input_14
I0521 09:36:45.827700  3675 net.cpp:157] Top shape: 1 128 400 (51200)
I0521 09:36:45.827703  3675 net.cpp:165] Memory required for data: 32579584
I0521 09:36:45.827708  3675 layer_factory.hpp:77] Creating layer lstm2x_unit_14
I0521 09:36:45.827713  3675 net.cpp:100] Creating Layer lstm2x_unit_14
I0521 09:36:45.827716  3675 net.cpp:434] lstm2x_unit_14 <- c_13
I0521 09:36:45.827720  3675 net.cpp:434] lstm2x_unit_14 <- gate_input_14
I0521 09:36:45.827724  3675 net.cpp:434] lstm2x_unit_14 <- cont_14_lstm2x_cont_slice_13_split_1
I0521 09:36:45.827729  3675 net.cpp:408] lstm2x_unit_14 -> c_14
I0521 09:36:45.827735  3675 net.cpp:408] lstm2x_unit_14 -> h_14
I0521 09:36:45.827776  3675 net.cpp:150] Setting up lstm2x_unit_14
I0521 09:36:45.827781  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.827785  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.827797  3675 net.cpp:165] Memory required for data: 32681984
I0521 09:36:45.827801  3675 layer_factory.hpp:77] Creating layer h_14_lstm2x_unit_14_1_split
I0521 09:36:45.827806  3675 net.cpp:100] Creating Layer h_14_lstm2x_unit_14_1_split
I0521 09:36:45.827809  3675 net.cpp:434] h_14_lstm2x_unit_14_1_split <- h_14
I0521 09:36:45.827814  3675 net.cpp:408] h_14_lstm2x_unit_14_1_split -> h_14_lstm2x_unit_14_1_split_0
I0521 09:36:45.827821  3675 net.cpp:408] h_14_lstm2x_unit_14_1_split -> h_14_lstm2x_unit_14_1_split_1
I0521 09:36:45.827849  3675 net.cpp:150] Setting up h_14_lstm2x_unit_14_1_split
I0521 09:36:45.827853  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.827857  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.827860  3675 net.cpp:165] Memory required for data: 32784384
I0521 09:36:45.827863  3675 layer_factory.hpp:77] Creating layer lstm2x_h_conted_14
I0521 09:36:45.827872  3675 net.cpp:100] Creating Layer lstm2x_h_conted_14
I0521 09:36:45.827877  3675 net.cpp:434] lstm2x_h_conted_14 <- h_14_lstm2x_unit_14_1_split_0
I0521 09:36:45.827881  3675 net.cpp:434] lstm2x_h_conted_14 <- cont_15_lstm2x_cont_slice_14_split_0
I0521 09:36:45.827888  3675 net.cpp:408] lstm2x_h_conted_14 -> h_conted_14
I0521 09:36:45.827944  3675 net.cpp:150] Setting up lstm2x_h_conted_14
I0521 09:36:45.827949  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.827951  3675 net.cpp:165] Memory required for data: 32835584
I0521 09:36:45.827955  3675 layer_factory.hpp:77] Creating layer lstm2x_transform_15
I0521 09:36:45.827961  3675 net.cpp:100] Creating Layer lstm2x_transform_15
I0521 09:36:45.827965  3675 net.cpp:434] lstm2x_transform_15 <- h_conted_14
I0521 09:36:45.827970  3675 net.cpp:408] lstm2x_transform_15 -> W_hc_h_14
I0521 09:36:45.828312  3675 net.cpp:150] Setting up lstm2x_transform_15
I0521 09:36:45.828318  3675 net.cpp:157] Top shape: 1 128 400 (51200)
I0521 09:36:45.828321  3675 net.cpp:165] Memory required for data: 33040384
I0521 09:36:45.828325  3675 net.cpp:493] Sharing parameters 'W_hc' owned by layer 'lstm2x_transform_1', param index 0
I0521 09:36:45.828330  3675 layer_factory.hpp:77] Creating layer lstm2x_gate_input_15
I0521 09:36:45.828335  3675 net.cpp:100] Creating Layer lstm2x_gate_input_15
I0521 09:36:45.828338  3675 net.cpp:434] lstm2x_gate_input_15 <- W_hc_h_14
I0521 09:36:45.828341  3675 net.cpp:434] lstm2x_gate_input_15 <- W_xc_x_15
I0521 09:36:45.828346  3675 net.cpp:408] lstm2x_gate_input_15 -> gate_input_15
I0521 09:36:45.828361  3675 net.cpp:150] Setting up lstm2x_gate_input_15
I0521 09:36:45.828366  3675 net.cpp:157] Top shape: 1 128 400 (51200)
I0521 09:36:45.828367  3675 net.cpp:165] Memory required for data: 33245184
I0521 09:36:45.828371  3675 layer_factory.hpp:77] Creating layer lstm2x_unit_15
I0521 09:36:45.828379  3675 net.cpp:100] Creating Layer lstm2x_unit_15
I0521 09:36:45.828382  3675 net.cpp:434] lstm2x_unit_15 <- c_14
I0521 09:36:45.828387  3675 net.cpp:434] lstm2x_unit_15 <- gate_input_15
I0521 09:36:45.828390  3675 net.cpp:434] lstm2x_unit_15 <- cont_15_lstm2x_cont_slice_14_split_1
I0521 09:36:45.828394  3675 net.cpp:408] lstm2x_unit_15 -> c_15
I0521 09:36:45.828399  3675 net.cpp:408] lstm2x_unit_15 -> h_15
I0521 09:36:45.828433  3675 net.cpp:150] Setting up lstm2x_unit_15
I0521 09:36:45.828436  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.828440  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.828442  3675 net.cpp:165] Memory required for data: 33347584
I0521 09:36:45.828445  3675 layer_factory.hpp:77] Creating layer h_15_lstm2x_unit_15_1_split
I0521 09:36:45.828449  3675 net.cpp:100] Creating Layer h_15_lstm2x_unit_15_1_split
I0521 09:36:45.828452  3675 net.cpp:434] h_15_lstm2x_unit_15_1_split <- h_15
I0521 09:36:45.828456  3675 net.cpp:408] h_15_lstm2x_unit_15_1_split -> h_15_lstm2x_unit_15_1_split_0
I0521 09:36:45.828464  3675 net.cpp:408] h_15_lstm2x_unit_15_1_split -> h_15_lstm2x_unit_15_1_split_1
I0521 09:36:45.828485  3675 net.cpp:150] Setting up h_15_lstm2x_unit_15_1_split
I0521 09:36:45.828498  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.828502  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.828505  3675 net.cpp:165] Memory required for data: 33449984
I0521 09:36:45.828507  3675 layer_factory.hpp:77] Creating layer lstm2x_h_conted_15
I0521 09:36:45.828516  3675 net.cpp:100] Creating Layer lstm2x_h_conted_15
I0521 09:36:45.828519  3675 net.cpp:434] lstm2x_h_conted_15 <- h_15_lstm2x_unit_15_1_split_0
I0521 09:36:45.828522  3675 net.cpp:434] lstm2x_h_conted_15 <- cont_16_lstm2x_cont_slice_15_split_0
I0521 09:36:45.828527  3675 net.cpp:408] lstm2x_h_conted_15 -> h_conted_15
I0521 09:36:45.828573  3675 net.cpp:150] Setting up lstm2x_h_conted_15
I0521 09:36:45.828577  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.828580  3675 net.cpp:165] Memory required for data: 33501184
I0521 09:36:45.828583  3675 layer_factory.hpp:77] Creating layer lstm2x_transform_16
I0521 09:36:45.828588  3675 net.cpp:100] Creating Layer lstm2x_transform_16
I0521 09:36:45.828590  3675 net.cpp:434] lstm2x_transform_16 <- h_conted_15
I0521 09:36:45.828595  3675 net.cpp:408] lstm2x_transform_16 -> W_hc_h_15
I0521 09:36:45.828881  3675 net.cpp:150] Setting up lstm2x_transform_16
I0521 09:36:45.828888  3675 net.cpp:157] Top shape: 1 128 400 (51200)
I0521 09:36:45.828891  3675 net.cpp:165] Memory required for data: 33705984
I0521 09:36:45.828893  3675 net.cpp:493] Sharing parameters 'W_hc' owned by layer 'lstm2x_transform_1', param index 0
I0521 09:36:45.828896  3675 layer_factory.hpp:77] Creating layer lstm2x_gate_input_16
I0521 09:36:45.828902  3675 net.cpp:100] Creating Layer lstm2x_gate_input_16
I0521 09:36:45.828903  3675 net.cpp:434] lstm2x_gate_input_16 <- W_hc_h_15
I0521 09:36:45.828907  3675 net.cpp:434] lstm2x_gate_input_16 <- W_xc_x_16
I0521 09:36:45.828910  3675 net.cpp:408] lstm2x_gate_input_16 -> gate_input_16
I0521 09:36:45.828924  3675 net.cpp:150] Setting up lstm2x_gate_input_16
I0521 09:36:45.828927  3675 net.cpp:157] Top shape: 1 128 400 (51200)
I0521 09:36:45.828929  3675 net.cpp:165] Memory required for data: 33910784
I0521 09:36:45.828933  3675 layer_factory.hpp:77] Creating layer lstm2x_unit_16
I0521 09:36:45.828938  3675 net.cpp:100] Creating Layer lstm2x_unit_16
I0521 09:36:45.828939  3675 net.cpp:434] lstm2x_unit_16 <- c_15
I0521 09:36:45.828943  3675 net.cpp:434] lstm2x_unit_16 <- gate_input_16
I0521 09:36:45.828945  3675 net.cpp:434] lstm2x_unit_16 <- cont_16_lstm2x_cont_slice_15_split_1
I0521 09:36:45.828948  3675 net.cpp:408] lstm2x_unit_16 -> c_16
I0521 09:36:45.828953  3675 net.cpp:408] lstm2x_unit_16 -> h_16
I0521 09:36:45.828981  3675 net.cpp:150] Setting up lstm2x_unit_16
I0521 09:36:45.828985  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.828989  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.828990  3675 net.cpp:165] Memory required for data: 34013184
I0521 09:36:45.828992  3675 layer_factory.hpp:77] Creating layer lstm2x_
I0521 09:36:45.828995  3675 net.cpp:100] Creating Layer lstm2x_
I0521 09:36:45.828997  3675 net.cpp:434] lstm2x_ <- c_16
I0521 09:36:45.829000  3675 net.cpp:408] lstm2x_ -> c_T
I0521 09:36:45.829013  3675 net.cpp:150] Setting up lstm2x_
I0521 09:36:45.829016  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.829020  3675 net.cpp:165] Memory required for data: 34064384
I0521 09:36:45.829021  3675 layer_factory.hpp:77] Creating layer lstm2x_h_concat
I0521 09:36:45.829027  3675 net.cpp:100] Creating Layer lstm2x_h_concat
I0521 09:36:45.829030  3675 net.cpp:434] lstm2x_h_concat <- h_1_lstm2x_unit_1_1_split_1
I0521 09:36:45.829033  3675 net.cpp:434] lstm2x_h_concat <- h_2_lstm2x_unit_2_1_split_1
I0521 09:36:45.829036  3675 net.cpp:434] lstm2x_h_concat <- h_3_lstm2x_unit_3_1_split_1
I0521 09:36:45.829039  3675 net.cpp:434] lstm2x_h_concat <- h_4_lstm2x_unit_4_1_split_1
I0521 09:36:45.829041  3675 net.cpp:434] lstm2x_h_concat <- h_5_lstm2x_unit_5_1_split_1
I0521 09:36:45.829044  3675 net.cpp:434] lstm2x_h_concat <- h_6_lstm2x_unit_6_1_split_1
I0521 09:36:45.829047  3675 net.cpp:434] lstm2x_h_concat <- h_7_lstm2x_unit_7_1_split_1
I0521 09:36:45.829058  3675 net.cpp:434] lstm2x_h_concat <- h_8_lstm2x_unit_8_1_split_1
I0521 09:36:45.829061  3675 net.cpp:434] lstm2x_h_concat <- h_9_lstm2x_unit_9_1_split_1
I0521 09:36:45.829064  3675 net.cpp:434] lstm2x_h_concat <- h_10_lstm2x_unit_10_1_split_1
I0521 09:36:45.829066  3675 net.cpp:434] lstm2x_h_concat <- h_11_lstm2x_unit_11_1_split_1
I0521 09:36:45.829069  3675 net.cpp:434] lstm2x_h_concat <- h_12_lstm2x_unit_12_1_split_1
I0521 09:36:45.829071  3675 net.cpp:434] lstm2x_h_concat <- h_13_lstm2x_unit_13_1_split_1
I0521 09:36:45.829074  3675 net.cpp:434] lstm2x_h_concat <- h_14_lstm2x_unit_14_1_split_1
I0521 09:36:45.829077  3675 net.cpp:434] lstm2x_h_concat <- h_15_lstm2x_unit_15_1_split_1
I0521 09:36:45.829079  3675 net.cpp:434] lstm2x_h_concat <- h_16
I0521 09:36:45.829083  3675 net.cpp:408] lstm2x_h_concat -> h
I0521 09:36:45.829099  3675 net.cpp:150] Setting up lstm2x_h_concat
I0521 09:36:45.829102  3675 net.cpp:157] Top shape: 16 128 100 (204800)
I0521 09:36:45.829104  3675 net.cpp:165] Memory required for data: 34883584
I0521 09:36:45.829107  3675 layer_factory.hpp:77] Creating layer h_pseudoloss
I0521 09:36:45.829113  3675 net.cpp:100] Creating Layer h_pseudoloss
I0521 09:36:45.829115  3675 net.cpp:434] h_pseudoloss <- h
I0521 09:36:45.829118  3675 net.cpp:408] h_pseudoloss -> h_pseudoloss
I0521 09:36:45.829929  3675 net.cpp:150] Setting up h_pseudoloss
I0521 09:36:45.829939  3675 net.cpp:157] Top shape: (1)
I0521 09:36:45.829942  3675 net.cpp:160]     with loss weight 1
I0521 09:36:45.829952  3675 net.cpp:165] Memory required for data: 34883588
I0521 09:36:45.829954  3675 net.cpp:226] h_pseudoloss needs backward computation.
I0521 09:36:45.829957  3675 net.cpp:226] lstm2x_h_concat needs backward computation.
I0521 09:36:45.829963  3675 net.cpp:228] lstm2x_ does not need backward computation.
I0521 09:36:45.829967  3675 net.cpp:226] lstm2x_unit_16 needs backward computation.
I0521 09:36:45.829972  3675 net.cpp:226] lstm2x_gate_input_16 needs backward computation.
I0521 09:36:45.829973  3675 net.cpp:226] lstm2x_transform_16 needs backward computation.
I0521 09:36:45.829977  3675 net.cpp:226] lstm2x_h_conted_15 needs backward computation.
I0521 09:36:45.829979  3675 net.cpp:226] h_15_lstm2x_unit_15_1_split needs backward computation.
I0521 09:36:45.829982  3675 net.cpp:226] lstm2x_unit_15 needs backward computation.
I0521 09:36:45.829985  3675 net.cpp:226] lstm2x_gate_input_15 needs backward computation.
I0521 09:36:45.829988  3675 net.cpp:226] lstm2x_transform_15 needs backward computation.
I0521 09:36:45.829991  3675 net.cpp:226] lstm2x_h_conted_14 needs backward computation.
I0521 09:36:45.829994  3675 net.cpp:226] h_14_lstm2x_unit_14_1_split needs backward computation.
I0521 09:36:45.829996  3675 net.cpp:226] lstm2x_unit_14 needs backward computation.
I0521 09:36:45.830000  3675 net.cpp:226] lstm2x_gate_input_14 needs backward computation.
I0521 09:36:45.830003  3675 net.cpp:226] lstm2x_transform_14 needs backward computation.
I0521 09:36:45.830005  3675 net.cpp:226] lstm2x_h_conted_13 needs backward computation.
I0521 09:36:45.830009  3675 net.cpp:226] h_13_lstm2x_unit_13_1_split needs backward computation.
I0521 09:36:45.830013  3675 net.cpp:226] lstm2x_unit_13 needs backward computation.
I0521 09:36:45.830018  3675 net.cpp:226] lstm2x_gate_input_13 needs backward computation.
I0521 09:36:45.830022  3675 net.cpp:226] lstm2x_transform_13 needs backward computation.
I0521 09:36:45.830026  3675 net.cpp:226] lstm2x_h_conted_12 needs backward computation.
I0521 09:36:45.830030  3675 net.cpp:226] h_12_lstm2x_unit_12_1_split needs backward computation.
I0521 09:36:45.830034  3675 net.cpp:226] lstm2x_unit_12 needs backward computation.
I0521 09:36:45.830039  3675 net.cpp:226] lstm2x_gate_input_12 needs backward computation.
I0521 09:36:45.830044  3675 net.cpp:226] lstm2x_transform_12 needs backward computation.
I0521 09:36:45.830047  3675 net.cpp:226] lstm2x_h_conted_11 needs backward computation.
I0521 09:36:45.830051  3675 net.cpp:226] h_11_lstm2x_unit_11_1_split needs backward computation.
I0521 09:36:45.830066  3675 net.cpp:226] lstm2x_unit_11 needs backward computation.
I0521 09:36:45.830071  3675 net.cpp:226] lstm2x_gate_input_11 needs backward computation.
I0521 09:36:45.830075  3675 net.cpp:226] lstm2x_transform_11 needs backward computation.
I0521 09:36:45.830078  3675 net.cpp:226] lstm2x_h_conted_10 needs backward computation.
I0521 09:36:45.830083  3675 net.cpp:226] h_10_lstm2x_unit_10_1_split needs backward computation.
I0521 09:36:45.830087  3675 net.cpp:226] lstm2x_unit_10 needs backward computation.
I0521 09:36:45.830092  3675 net.cpp:226] lstm2x_gate_input_10 needs backward computation.
I0521 09:36:45.830096  3675 net.cpp:226] lstm2x_transform_10 needs backward computation.
I0521 09:36:45.830099  3675 net.cpp:226] lstm2x_h_conted_9 needs backward computation.
I0521 09:36:45.830102  3675 net.cpp:226] h_9_lstm2x_unit_9_1_split needs backward computation.
I0521 09:36:45.830106  3675 net.cpp:226] lstm2x_unit_9 needs backward computation.
I0521 09:36:45.830108  3675 net.cpp:226] lstm2x_gate_input_9 needs backward computation.
I0521 09:36:45.830111  3675 net.cpp:226] lstm2x_transform_9 needs backward computation.
I0521 09:36:45.830114  3675 net.cpp:226] lstm2x_h_conted_8 needs backward computation.
I0521 09:36:45.830119  3675 net.cpp:226] h_8_lstm2x_unit_8_1_split needs backward computation.
I0521 09:36:45.830122  3675 net.cpp:226] lstm2x_unit_8 needs backward computation.
I0521 09:36:45.830127  3675 net.cpp:226] lstm2x_gate_input_8 needs backward computation.
I0521 09:36:45.830129  3675 net.cpp:226] lstm2x_transform_8 needs backward computation.
I0521 09:36:45.830132  3675 net.cpp:226] lstm2x_h_conted_7 needs backward computation.
I0521 09:36:45.830135  3675 net.cpp:226] h_7_lstm2x_unit_7_1_split needs backward computation.
I0521 09:36:45.830138  3675 net.cpp:226] lstm2x_unit_7 needs backward computation.
I0521 09:36:45.830142  3675 net.cpp:226] lstm2x_gate_input_7 needs backward computation.
I0521 09:36:45.830145  3675 net.cpp:226] lstm2x_transform_7 needs backward computation.
I0521 09:36:45.830148  3675 net.cpp:226] lstm2x_h_conted_6 needs backward computation.
I0521 09:36:45.830152  3675 net.cpp:226] h_6_lstm2x_unit_6_1_split needs backward computation.
I0521 09:36:45.830154  3675 net.cpp:226] lstm2x_unit_6 needs backward computation.
I0521 09:36:45.830158  3675 net.cpp:226] lstm2x_gate_input_6 needs backward computation.
I0521 09:36:45.830162  3675 net.cpp:226] lstm2x_transform_6 needs backward computation.
I0521 09:36:45.830163  3675 net.cpp:226] lstm2x_h_conted_5 needs backward computation.
I0521 09:36:45.830168  3675 net.cpp:226] h_5_lstm2x_unit_5_1_split needs backward computation.
I0521 09:36:45.830169  3675 net.cpp:226] lstm2x_unit_5 needs backward computation.
I0521 09:36:45.830174  3675 net.cpp:226] lstm2x_gate_input_5 needs backward computation.
I0521 09:36:45.830178  3675 net.cpp:226] lstm2x_transform_5 needs backward computation.
I0521 09:36:45.830180  3675 net.cpp:226] lstm2x_h_conted_4 needs backward computation.
I0521 09:36:45.830183  3675 net.cpp:226] h_4_lstm2x_unit_4_1_split needs backward computation.
I0521 09:36:45.830185  3675 net.cpp:226] lstm2x_unit_4 needs backward computation.
I0521 09:36:45.830189  3675 net.cpp:226] lstm2x_gate_input_4 needs backward computation.
I0521 09:36:45.830191  3675 net.cpp:226] lstm2x_transform_4 needs backward computation.
I0521 09:36:45.830194  3675 net.cpp:226] lstm2x_h_conted_3 needs backward computation.
I0521 09:36:45.830199  3675 net.cpp:226] h_3_lstm2x_unit_3_1_split needs backward computation.
I0521 09:36:45.830201  3675 net.cpp:226] lstm2x_unit_3 needs backward computation.
I0521 09:36:45.830204  3675 net.cpp:226] lstm2x_gate_input_3 needs backward computation.
I0521 09:36:45.830207  3675 net.cpp:226] lstm2x_transform_3 needs backward computation.
I0521 09:36:45.830209  3675 net.cpp:226] lstm2x_h_conted_2 needs backward computation.
I0521 09:36:45.830214  3675 net.cpp:226] h_2_lstm2x_unit_2_1_split needs backward computation.
I0521 09:36:45.830215  3675 net.cpp:226] lstm2x_unit_2 needs backward computation.
I0521 09:36:45.830224  3675 net.cpp:226] lstm2x_gate_input_2 needs backward computation.
I0521 09:36:45.830226  3675 net.cpp:226] lstm2x_transform_2 needs backward computation.
I0521 09:36:45.830229  3675 net.cpp:226] lstm2x_h_conted_1 needs backward computation.
I0521 09:36:45.830232  3675 net.cpp:226] h_1_lstm2x_unit_1_1_split needs backward computation.
I0521 09:36:45.830236  3675 net.cpp:226] lstm2x_unit_1 needs backward computation.
I0521 09:36:45.830240  3675 net.cpp:226] lstm2x_gate_input_1 needs backward computation.
I0521 09:36:45.830243  3675 net.cpp:226] lstm2x_transform_1 needs backward computation.
I0521 09:36:45.830246  3675 net.cpp:228] lstm2x_h_conted_0 does not need backward computation.
I0521 09:36:45.830250  3675 net.cpp:226] lstm2x_W_xc_x_slice needs backward computation.
I0521 09:36:45.830252  3675 net.cpp:226] lstm2x_x_transform needs backward computation.
I0521 09:36:45.830255  3675 net.cpp:228] cont_16_lstm2x_cont_slice_15_split does not need backward computation.
I0521 09:36:45.830258  3675 net.cpp:228] cont_15_lstm2x_cont_slice_14_split does not need backward computation.
I0521 09:36:45.830262  3675 net.cpp:228] cont_14_lstm2x_cont_slice_13_split does not need backward computation.
I0521 09:36:45.830265  3675 net.cpp:228] cont_13_lstm2x_cont_slice_12_split does not need backward computation.
I0521 09:36:45.830268  3675 net.cpp:228] cont_12_lstm2x_cont_slice_11_split does not need backward computation.
I0521 09:36:45.830271  3675 net.cpp:228] cont_11_lstm2x_cont_slice_10_split does not need backward computation.
I0521 09:36:45.830274  3675 net.cpp:228] cont_10_lstm2x_cont_slice_9_split does not need backward computation.
I0521 09:36:45.830278  3675 net.cpp:228] cont_9_lstm2x_cont_slice_8_split does not need backward computation.
I0521 09:36:45.830281  3675 net.cpp:228] cont_8_lstm2x_cont_slice_7_split does not need backward computation.
I0521 09:36:45.830284  3675 net.cpp:228] cont_7_lstm2x_cont_slice_6_split does not need backward computation.
I0521 09:36:45.830287  3675 net.cpp:228] cont_6_lstm2x_cont_slice_5_split does not need backward computation.
I0521 09:36:45.830291  3675 net.cpp:228] cont_5_lstm2x_cont_slice_4_split does not need backward computation.
I0521 09:36:45.830293  3675 net.cpp:228] cont_4_lstm2x_cont_slice_3_split does not need backward computation.
I0521 09:36:45.830296  3675 net.cpp:228] cont_3_lstm2x_cont_slice_2_split does not need backward computation.
I0521 09:36:45.830299  3675 net.cpp:228] cont_2_lstm2x_cont_slice_1_split does not need backward computation.
I0521 09:36:45.830302  3675 net.cpp:228] cont_1_lstm2x_cont_slice_0_split does not need backward computation.
I0521 09:36:45.830307  3675 net.cpp:228] lstm2x_cont_slice does not need backward computation.
I0521 09:36:45.830312  3675 net.cpp:228] lstm2x_ does not need backward computation.
I0521 09:36:45.830314  3675 net.cpp:228] lstm2x_ does not need backward computation.
I0521 09:36:45.830317  3675 net.cpp:270] This network produces output c_T
I0521 09:36:45.830319  3675 net.cpp:270] This network produces output h_pseudoloss
I0521 09:36:45.830827  3675 net.cpp:283] Network initialization done.
I0521 09:36:45.831017  3675 recurrent_layer.cpp:150] Adding parameter 0: W_xc
I0521 09:36:45.831024  3675 recurrent_layer.cpp:150] Adding parameter 1: b_c
I0521 09:36:45.831028  3675 recurrent_layer.cpp:150] Adding parameter 2: W_hc
I0521 09:36:45.831322  3675 net.cpp:150] Setting up lstm2x
I0521 09:36:45.831334  3675 net.cpp:157] Top shape: 16 128 100 (204800)
I0521 09:36:45.831336  3675 net.cpp:165] Memory required for data: 1840056832
I0521 09:36:45.831343  3675 layer_factory.hpp:77] Creating layer lstm-reverse2
I0521 09:36:45.831349  3675 net.cpp:100] Creating Layer lstm-reverse2
I0521 09:36:45.831353  3675 net.cpp:434] lstm-reverse2 <- lstm2x
I0521 09:36:45.831358  3675 net.cpp:408] lstm-reverse2 -> rlstmx
I0521 09:36:45.831379  3675 net.cpp:150] Setting up lstm-reverse2
I0521 09:36:45.831382  3675 net.cpp:157] Top shape: 16 128 100 (204800)
I0521 09:36:45.831385  3675 net.cpp:165] Memory required for data: 1840876032
I0521 09:36:45.831396  3675 layer_factory.hpp:77] Creating layer lstm1x
I0521 09:36:45.831403  3675 net.cpp:100] Creating Layer lstm1x
I0521 09:36:45.831405  3675 net.cpp:434] lstm1x <- permuted_data_permuted_data_0_split_1
I0521 09:36:45.831409  3675 net.cpp:434] lstm1x <- indicator_indicator_0_split_1
I0521 09:36:45.831413  3675 net.cpp:408] lstm1x -> lstm1x
I0521 09:36:45.831418  3675 recurrent_layer.cpp:20] Initializing recurrent layer: assuming input batch contains 16 timesteps of 128 independent streams.
I0521 09:36:45.831785  3675 net.cpp:58] Initializing net from parameters: 
layer {
  name: "lstm1x_"
  type: "Input"
  top: "x"
  top: "cont"
  input_param {
    shape {
      dim: 16
      dim: 128
      dim: 512
      dim: 4
    }
    shape {
      dim: 16
      dim: 128
    }
  }
}
layer {
  name: "lstm1x_"
  type: "Input"
  top: "c_0"
  top: "h_0"
  input_param {
    shape {
      dim: 1
      dim: 128
      dim: 100
    }
    shape {
      dim: 1
      dim: 128
      dim: 100
    }
  }
}
layer {
  name: "lstm1x_cont_slice"
  type: "Slice"
  bottom: "cont"
  top: "cont_1"
  top: "cont_2"
  top: "cont_3"
  top: "cont_4"
  top: "cont_5"
  top: "cont_6"
  top: "cont_7"
  top: "cont_8"
  top: "cont_9"
  top: "cont_10"
  top: "cont_11"
  top: "cont_12"
  top: "cont_13"
  top: "cont_14"
  top: "cont_15"
  top: "cont_16"
  slice_param {
    axis: 0
  }
}
layer {
  name: "lstm1x_x_transform"
  type: "InnerProduct"
  bottom: "x"
  top: "W_xc_x"
  param {
    name: "W_xc"
  }
  param {
    name: "b_c"
  }
  propagate_down: true
  inner_product_param {
    num_output: 400
    bias_term: true
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    axis: 2
  }
}
layer {
  name: "lstm1x_W_xc_x_slice"
  type: "Slice"
  bottom: "W_xc_x"
  top: "W_xc_x_1"
  top: "W_xc_x_2"
  top: "W_xc_x_3"
  top: "W_xc_x_4"
  top: "W_xc_x_5"
  top: "W_xc_x_6"
  top: "W_xc_x_7"
  top: "W_xc_x_8"
  top: "W_xc_x_9"
  top: "W_xc_x_10"
  top: "W_xc_x_11"
  top: "W_xc_x_12"
  top: "W_xc_x_13"
  top: "W_xc_x_14"
  top: "W_xc_x_15"
  top: "W_xc_x_16"
  slice_param {
    axis: 0
  }
}
layer {
  name: "lstm1x_h_conted_0"
  type: "Scale"
  bottom: "h_0"
  bottom: "cont_1"
  top: "h_conted_0"
  scale_param {
    axis: 0
  }
}
layer {
  name: "lstm1x_transform_1"
  type: "InnerProduct"
  bottom: "h_conted_0"
  top: "W_hc_h_0"
  param {
    name: "W_hc"
  }
  inner_product_param {
    num_output: 400
    bias_term: false
    weight_filler {
      type: "xavier"
    }
    axis: 2
  }
}
layer {
  name: "lstm1x_gate_input_1"
  type: "Eltwise"
  bottom: "W_hc_h_0"
  bottom: "W_xc_x_1"
  top: "gate_input_1"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "lstm1x_unit_1"
  type: "LSTMUnit"
  bottom: "c_0"
  bottom: "gate_input_1"
  bottom: "cont_1"
  top: "c_1"
  top: "h_1"
}
layer {
  name: "lstm1x_h_conted_1"
  type: "Scale"
  bottom: "h_1"
  bottom: "cont_2"
  top: "h_conted_1"
  scale_param {
    axis: 0
  }
}
layer {
  name: "lstm1x_transform_2"
  type: "InnerProduct"
  bottom: "h_conted_1"
  top: "W_hc_h_1"
  param {
    name: "W_hc"
  }
  inner_product_param {
    num_output: 400
    bias_term: false
    weight_filler {
      type: "xavier"
    }
    axis: 2
  }
}
layer {
  name: "lstm1x_gate_input_2"
  type: "Eltwise"
  bottom: "W_hc_h_1"
  bottom: "W_xc_x_2"
  top: "gate_input_2"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "lstm1x_unit_2"
  type: "LSTMUnit"
  bottom: "c_1"
  bottom: "gate_input_2"
  bottom: "cont_2"
  top: "c_2"
  top: "h_2"
}
layer {
  name: "lstm1x_h_conted_2"
  type: "Scale"
  bottom: "h_2"
  bottom: "cont_3"
  top: "h_conted_2"
  scale_param {
    axis: 0
  }
}
layer {
  name: "lstm1x_transform_3"
  type: "InnerProduct"
  bottom: "h_conted_2"
  top: "W_hc_h_2"
  param {
    name: "W_hc"
  }
  inner_product_param {
    num_output: 400
    bias_term: false
    weight_filler {
      type: "xavier"
    }
    axis: 2
  }
}
layer {
  name: "lstm1x_gate_input_3"
  type: "Eltwise"
  bottom: "W_hc_h_2"
  bottom: "W_xc_x_3"
  top: "gate_input_3"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "lstm1x_unit_3"
  type: "LSTMUnit"
  bottom: "c_2"
  bottom: "gate_input_3"
  bottom: "cont_3"
  top: "c_3"
  top: "h_3"
}
layer {
  name: "lstm1x_h_conted_3"
  type: "Scale"
  bottom: "h_3"
  bottom: "cont_4"
  top: "h_conted_3"
  scale_param {
    axis: 0
  }
}
layer {
  name: "lstm1x_transform_4"
  type: "InnerProduct"
  bottom: "h_conted_3"
  top: "W_hc_h_3"
  param {
    name: "W_hc"
  }
  inner_product_param {
    num_output: 400
    bias_term: false
    weight_filler {
      type: "xavier"
    }
    axis: 2
  }
}
layer {
  name: "lstm1x_gate_input_4"
  type: "Eltwise"
  bottom: "W_hc_h_3"
  bottom: "W_xc_x_4"
  top: "gate_input_4"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "lstm1x_unit_4"
  type: "LSTMUnit"
  bottom: "c_3"
  bottom: "gate_input_4"
  bottom: "cont_4"
  top: "c_4"
  top: "h_4"
}
layer {
  name: "lstm1x_h_conted_4"
  type: "Scale"
  bottom: "h_4"
  bottom: "cont_5"
  top: "h_conted_4"
  scale_param {
    axis: 0
  }
}
layer {
  name: "lstm1x_transform_5"
  type: "InnerProduct"
  bottom: "h_conted_4"
  top: "W_hc_h_4"
  param {
    name: "W_hc"
  }
  inner_product_param {
    num_output: 400
    bias_term: false
    weight_filler {
      type: "xavier"
    }
    axis: 2
  }
}
layer {
  name: "lstm1x_gate_input_5"
  type: "Eltwise"
  bottom: "W_hc_h_4"
  bottom: "W_xc_x_5"
  top: "gate_input_5"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "lstm1x_unit_5"
  type: "LSTMUnit"
  bottom: "c_4"
  bottom: "gate_input_5"
  bottom: "cont_5"
  top: "c_5"
  top: "h_5"
}
layer {
  name: "lstm1x_h_conted_5"
  type: "Scale"
  bottom: "h_5"
  bottom: "cont_6"
  top: "h_conted_5"
  scale_param {
    axis: 0
  }
}
layer {
  name: "lstm1x_transform_6"
  type: "InnerProduct"
  bottom: "h_conted_5"
  top: "W_hc_h_5"
  param {
    name: "W_hc"
  }
  inner_product_param {
    num_output: 400
    bias_term: false
    weight_filler {
      type: "xavier"
    }
    axis: 2
  }
}
layer {
  name: "lstm1x_gate_input_6"
  type: "Eltwise"
  bottom: "W_hc_h_5"
  bottom: "W_xc_x_6"
  top: "gate_input_6"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "lstm1x_unit_6"
  type: "LSTMUnit"
  bottom: "c_5"
  bottom: "gate_input_6"
  bottom: "cont_6"
  top: "c_6"
  top: "h_6"
}
layer {
  name: "lstm1x_h_conted_6"
  type: "Scale"
  bottom: "h_6"
  bottom: "cont_7"
  top: "h_conted_6"
  scale_param {
    axis: 0
  }
}
layer {
  name: "lstm1x_transform_7"
  type: "InnerProduct"
  bottom: "h_conted_6"
  top: "W_hc_h_6"
  param {
    name: "W_hc"
  }
  inner_product_param {
    num_output: 400
    bias_term: false
    weight_filler {
      type: "xavier"
    }
    axis: 2
  }
}
layer {
  name: "lstm1x_gate_input_7"
  type: "Eltwise"
  bottom: "W_hc_h_6"
  bottom: "W_xc_x_7"
  top: "gate_input_7"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "lstm1x_unit_7"
  type: "LSTMUnit"
  bottom: "c_6"
  bottom: "gate_input_7"
  bottom: "cont_7"
  top: "c_7"
  top: "h_7"
}
layer {
  name: "lstm1x_h_conted_7"
  type: "Scale"
  bottom: "h_7"
  bottom: "cont_8"
  top: "h_conted_7"
  scale_param {
    axis: 0
  }
}
layer {
  name: "lstm1x_transform_8"
  type: "InnerProduct"
  bottom: "h_conted_7"
  top: "W_hc_h_7"
  param {
    name: "W_hc"
  }
  inner_product_param {
    num_output: 400
    bias_term: false
    weight_filler {
      type: "xavier"
    }
    axis: 2
  }
}
layer {
  name: "lstm1x_gate_input_8"
  type: "Eltwise"
  bottom: "W_hc_h_7"
  bottom: "W_xc_x_8"
  top: "gate_input_8"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "lstm1x_unit_8"
  type: "LSTMUnit"
  bottom: "c_7"
  bottom: "gate_input_8"
  bottom: "cont_8"
  top: "c_8"
  top: "h_8"
}
layer {
  name: "lstm1x_h_conted_8"
  type: "Scale"
  bottom: "h_8"
  bottom: "cont_9"
  top: "h_conted_8"
  scale_param {
    axis: 0
  }
}
layer {
  name: "lstm1x_transform_9"
  type: "InnerProduct"
  bottom: "h_conted_8"
  top: "W_hc_h_8"
  param {
    name: "W_hc"
  }
  inner_product_param {
    num_output: 400
    bias_term: false
    weight_filler {
      type: "xavier"
    }
    axis: 2
  }
}
layer {
  name: "lstm1x_gate_input_9"
  type: "Eltwise"
  bottom: "W_hc_h_8"
  bottom: "W_xc_x_9"
  top: "gate_input_9"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "lstm1x_unit_9"
  type: "LSTMUnit"
  bottom: "c_8"
  bottom: "gate_input_9"
  bottom: "cont_9"
  top: "c_9"
  top: "h_9"
}
layer {
  name: "lstm1x_h_conted_9"
  type: "Scale"
  bottom: "h_9"
  bottom: "cont_10"
  top: "h_conted_9"
  scale_param {
    axis: 0
  }
}
layer {
  name: "lstm1x_transform_10"
  type: "InnerProduct"
  bottom: "h_conted_9"
  top: "W_hc_h_9"
  param {
    name: "W_hc"
  }
  inner_product_param {
    num_output: 400
    bias_term: false
    weight_filler {
      type: "xavier"
    }
    axis: 2
  }
}
layer {
  name: "lstm1x_gate_input_10"
  type: "Eltwise"
  bottom: "W_hc_h_9"
  bottom: "W_xc_x_10"
  top: "gate_input_10"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "lstm1x_unit_10"
  type: "LSTMUnit"
  bottom: "c_9"
  bottom: "gate_input_10"
  bottom: "cont_10"
  top: "c_10"
  top: "h_10"
}
layer {
  name: "lstm1x_h_conted_10"
  type: "Scale"
  bottom: "h_10"
  bottom: "cont_11"
  top: "h_conted_10"
  scale_param {
    axis: 0
  }
}
layer {
  name: "lstm1x_transform_11"
  type: "InnerProduct"
  bottom: "h_conted_10"
  top: "W_hc_h_10"
  param {
    name: "W_hc"
  }
  inner_product_param {
    num_output: 400
    bias_term: false
    weight_filler {
      type: "xavier"
    }
    axis: 2
  }
}
layer {
  name: "lstm1x_gate_input_11"
  type: "Eltwise"
  bottom: "W_hc_h_10"
  bottom: "W_xc_x_11"
  top: "gate_input_11"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "lstm1x_unit_11"
  type: "LSTMUnit"
  bottom: "c_10"
  bottom: "gate_input_11"
  bottom: "cont_11"
  top: "c_11"
  top: "h_11"
}
layer {
  name: "lstm1x_h_conted_11"
  type: "Scale"
  bottom: "h_11"
  bottom: "cont_12"
  top: "h_conted_11"
  scale_param {
    axis: 0
  }
}
layer {
  name: "lstm1x_transform_12"
  type: "InnerProduct"
  bottom: "h_conted_11"
  top: "W_hc_h_11"
  param {
    name: "W_hc"
  }
  inner_product_param {
    num_output: 400
    bias_term: false
    weight_filler {
      type: "xavier"
    }
    axis: 2
  }
}
layer {
  name: "lstm1x_gate_input_12"
  type: "Eltwise"
  bottom: "W_hc_h_11"
  bottom: "W_xc_x_12"
  top: "gate_input_12"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "lstm1x_unit_12"
  type: "LSTMUnit"
  bottom: "c_11"
  bottom: "gate_input_12"
  bottom: "cont_12"
  top: "c_12"
  top: "h_12"
}
layer {
  name: "lstm1x_h_conted_12"
  type: "Scale"
  bottom: "h_12"
  bottom: "cont_13"
  top: "h_conted_12"
  scale_param {
    axis: 0
  }
}
layer {
  name: "lstm1x_transform_13"
  type: "InnerProduct"
  bottom: "h_conted_12"
  top: "W_hc_h_12"
  param {
    name: "W_hc"
  }
  inner_product_param {
    num_output: 400
    bias_term: false
    weight_filler {
      type: "xavier"
    }
    axis: 2
  }
}
layer {
  name: "lstm1x_gate_input_13"
  type: "Eltwise"
  bottom: "W_hc_h_12"
  bottom: "W_xc_x_13"
  top: "gate_input_13"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "lstm1x_unit_13"
  type: "LSTMUnit"
  bottom: "c_12"
  bottom: "gate_input_13"
  bottom: "cont_13"
  top: "c_13"
  top: "h_13"
}
layer {
  name: "lstm1x_h_conted_13"
  type: "Scale"
  bottom: "h_13"
  bottom: "cont_14"
  top: "h_conted_13"
  scale_param {
    axis: 0
  }
}
layer {
  name: "lstm1x_transform_14"
  type: "InnerProduct"
  bottom: "h_conted_13"
  top: "W_hc_h_13"
  param {
    name: "W_hc"
  }
  inner_product_param {
    num_output: 400
    bias_term: false
    weight_filler {
      type: "xavier"
    }
    axis: 2
  }
}
layer {
  name: "lstm1x_gate_input_14"
  type: "Eltwise"
  bottom: "W_hc_h_13"
  bottom: "W_xc_x_14"
  top: "gate_input_14"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "lstm1x_unit_14"
  type: "LSTMUnit"
  bottom: "c_13"
  bottom: "gate_input_14"
  bottom: "cont_14"
  top: "c_14"
  top: "h_14"
}
layer {
  name: "lstm1x_h_conted_14"
  type: "Scale"
  bottom: "h_14"
  bottom: "cont_15"
  top: "h_conted_14"
  scale_param {
    axis: 0
  }
}
layer {
  name: "lstm1x_transform_15"
  type: "InnerProduct"
  bottom: "h_conted_14"
  top: "W_hc_h_14"
  param {
    name: "W_hc"
  }
  inner_product_param {
    num_output: 400
    bias_term: false
    weight_filler {
      type: "xavier"
    }
    axis: 2
  }
}
layer {
  name: "lstm1x_gate_input_15"
  type: "Eltwise"
  bottom: "W_hc_h_14"
  bottom: "W_xc_x_15"
  top: "gate_input_15"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "lstm1x_unit_15"
  type: "LSTMUnit"
  bottom: "c_14"
  bottom: "gate_input_15"
  bottom: "cont_15"
  top: "c_15"
  top: "h_15"
}
layer {
  name: "lstm1x_h_conted_15"
  type: "Scale"
  bottom: "h_15"
  bottom: "cont_16"
  top: "h_conted_15"
  scale_param {
    axis: 0
  }
}
layer {
  name: "lstm1x_transform_16"
  type: "InnerProduct"
  bottom: "h_conted_15"
  top: "W_hc_h_15"
  param {
    name: "W_hc"
  }
  inner_product_param {
    num_output: 400
    bias_term: false
    weight_filler {
      type: "xavier"
    }
    axis: 2
  }
}
layer {
  name: "lstm1x_gate_input_16"
  type: "Eltwise"
  bottom: "W_hc_h_15"
  bottom: "W_xc_x_16"
  top: "gate_input_16"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "lstm1x_unit_16"
  type: "LSTMUnit"
  bottom: "c_15"
  bottom: "gate_input_16"
  bottom: "cont_16"
  top: "c_16"
  top: "h_16"
}
layer {
  name: "lstm1x_"
  type: "Split"
  bottom: "c_16"
  top: "c_T"
}
layer {
  name: "lstm1x_h_concat"
  type: "Concat"
  bottom: "h_1"
  bottom: "h_2"
  bottom: "h_3"
  bottom: "h_4"
  bottom: "h_5"
  bottom: "h_6"
  bottom: "h_7"
  bottom: "h_8"
  bottom: "h_9"
  bottom: "h_10"
  bottom: "h_11"
  bottom: "h_12"
  bottom: "h_13"
  bottom: "h_14"
  bottom: "h_15"
  bottom: "h_16"
  top: "h"
  concat_param {
    axis: 0
  }
}
layer {
  name: "h_pseudoloss"
  type: "Reduction"
  bottom: "h"
  top: "h_pseudoloss"
  loss_weight: 1
}
I0521 09:36:45.832195  3675 layer_factory.hpp:77] Creating layer lstm1x_
I0521 09:36:45.832204  3675 net.cpp:100] Creating Layer lstm1x_
I0521 09:36:45.832208  3675 net.cpp:408] lstm1x_ -> x
I0521 09:36:45.832216  3675 net.cpp:408] lstm1x_ -> cont
I0521 09:36:45.832273  3675 net.cpp:150] Setting up lstm1x_
I0521 09:36:45.832278  3675 net.cpp:157] Top shape: 16 128 512 4 (4194304)
I0521 09:36:45.832283  3675 net.cpp:157] Top shape: 16 128 (2048)
I0521 09:36:45.832286  3675 net.cpp:165] Memory required for data: 16785408
I0521 09:36:45.832290  3675 layer_factory.hpp:77] Creating layer lstm1x_
I0521 09:36:45.832296  3675 net.cpp:100] Creating Layer lstm1x_
I0521 09:36:45.832300  3675 net.cpp:408] lstm1x_ -> c_0
I0521 09:36:45.832306  3675 net.cpp:408] lstm1x_ -> h_0
I0521 09:36:45.832342  3675 net.cpp:150] Setting up lstm1x_
I0521 09:36:45.832347  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.832352  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.832355  3675 net.cpp:165] Memory required for data: 16887808
I0521 09:36:45.832360  3675 layer_factory.hpp:77] Creating layer lstm1x_cont_slice
I0521 09:36:45.832365  3675 net.cpp:100] Creating Layer lstm1x_cont_slice
I0521 09:36:45.832367  3675 net.cpp:434] lstm1x_cont_slice <- cont
I0521 09:36:45.832371  3675 net.cpp:408] lstm1x_cont_slice -> cont_1
I0521 09:36:45.832377  3675 net.cpp:408] lstm1x_cont_slice -> cont_2
I0521 09:36:45.832382  3675 net.cpp:408] lstm1x_cont_slice -> cont_3
I0521 09:36:45.832387  3675 net.cpp:408] lstm1x_cont_slice -> cont_4
I0521 09:36:45.832391  3675 net.cpp:408] lstm1x_cont_slice -> cont_5
I0521 09:36:45.832396  3675 net.cpp:408] lstm1x_cont_slice -> cont_6
I0521 09:36:45.832401  3675 net.cpp:408] lstm1x_cont_slice -> cont_7
I0521 09:36:45.832404  3675 net.cpp:408] lstm1x_cont_slice -> cont_8
I0521 09:36:45.832408  3675 net.cpp:408] lstm1x_cont_slice -> cont_9
I0521 09:36:45.832412  3675 net.cpp:408] lstm1x_cont_slice -> cont_10
I0521 09:36:45.832417  3675 net.cpp:408] lstm1x_cont_slice -> cont_11
I0521 09:36:45.832420  3675 net.cpp:408] lstm1x_cont_slice -> cont_12
I0521 09:36:45.832425  3675 net.cpp:408] lstm1x_cont_slice -> cont_13
I0521 09:36:45.832429  3675 net.cpp:408] lstm1x_cont_slice -> cont_14
I0521 09:36:45.832433  3675 net.cpp:408] lstm1x_cont_slice -> cont_15
I0521 09:36:45.832445  3675 net.cpp:408] lstm1x_cont_slice -> cont_16
I0521 09:36:45.832582  3675 net.cpp:150] Setting up lstm1x_cont_slice
I0521 09:36:45.832587  3675 net.cpp:157] Top shape: 1 128 (128)
I0521 09:36:45.832589  3675 net.cpp:157] Top shape: 1 128 (128)
I0521 09:36:45.832592  3675 net.cpp:157] Top shape: 1 128 (128)
I0521 09:36:45.832594  3675 net.cpp:157] Top shape: 1 128 (128)
I0521 09:36:45.832597  3675 net.cpp:157] Top shape: 1 128 (128)
I0521 09:36:45.832599  3675 net.cpp:157] Top shape: 1 128 (128)
I0521 09:36:45.832602  3675 net.cpp:157] Top shape: 1 128 (128)
I0521 09:36:45.832604  3675 net.cpp:157] Top shape: 1 128 (128)
I0521 09:36:45.832607  3675 net.cpp:157] Top shape: 1 128 (128)
I0521 09:36:45.832609  3675 net.cpp:157] Top shape: 1 128 (128)
I0521 09:36:45.832612  3675 net.cpp:157] Top shape: 1 128 (128)
I0521 09:36:45.832614  3675 net.cpp:157] Top shape: 1 128 (128)
I0521 09:36:45.832617  3675 net.cpp:157] Top shape: 1 128 (128)
I0521 09:36:45.832619  3675 net.cpp:157] Top shape: 1 128 (128)
I0521 09:36:45.832623  3675 net.cpp:157] Top shape: 1 128 (128)
I0521 09:36:45.832624  3675 net.cpp:157] Top shape: 1 128 (128)
I0521 09:36:45.832626  3675 net.cpp:165] Memory required for data: 16896000
I0521 09:36:45.832629  3675 layer_factory.hpp:77] Creating layer cont_1_lstm1x_cont_slice_0_split
I0521 09:36:45.832633  3675 net.cpp:100] Creating Layer cont_1_lstm1x_cont_slice_0_split
I0521 09:36:45.832636  3675 net.cpp:434] cont_1_lstm1x_cont_slice_0_split <- cont_1
I0521 09:36:45.832639  3675 net.cpp:408] cont_1_lstm1x_cont_slice_0_split -> cont_1_lstm1x_cont_slice_0_split_0
I0521 09:36:45.832644  3675 net.cpp:408] cont_1_lstm1x_cont_slice_0_split -> cont_1_lstm1x_cont_slice_0_split_1
I0521 09:36:45.832665  3675 net.cpp:150] Setting up cont_1_lstm1x_cont_slice_0_split
I0521 09:36:45.832669  3675 net.cpp:157] Top shape: 1 128 (128)
I0521 09:36:45.832670  3675 net.cpp:157] Top shape: 1 128 (128)
I0521 09:36:45.832672  3675 net.cpp:165] Memory required for data: 16897024
I0521 09:36:45.832675  3675 layer_factory.hpp:77] Creating layer cont_2_lstm1x_cont_slice_1_split
I0521 09:36:45.832680  3675 net.cpp:100] Creating Layer cont_2_lstm1x_cont_slice_1_split
I0521 09:36:45.832684  3675 net.cpp:434] cont_2_lstm1x_cont_slice_1_split <- cont_2
I0521 09:36:45.832686  3675 net.cpp:408] cont_2_lstm1x_cont_slice_1_split -> cont_2_lstm1x_cont_slice_1_split_0
I0521 09:36:45.832690  3675 net.cpp:408] cont_2_lstm1x_cont_slice_1_split -> cont_2_lstm1x_cont_slice_1_split_1
I0521 09:36:45.832711  3675 net.cpp:150] Setting up cont_2_lstm1x_cont_slice_1_split
I0521 09:36:45.832715  3675 net.cpp:157] Top shape: 1 128 (128)
I0521 09:36:45.832716  3675 net.cpp:157] Top shape: 1 128 (128)
I0521 09:36:45.832718  3675 net.cpp:165] Memory required for data: 16898048
I0521 09:36:45.832720  3675 layer_factory.hpp:77] Creating layer cont_3_lstm1x_cont_slice_2_split
I0521 09:36:45.832725  3675 net.cpp:100] Creating Layer cont_3_lstm1x_cont_slice_2_split
I0521 09:36:45.832726  3675 net.cpp:434] cont_3_lstm1x_cont_slice_2_split <- cont_3
I0521 09:36:45.832731  3675 net.cpp:408] cont_3_lstm1x_cont_slice_2_split -> cont_3_lstm1x_cont_slice_2_split_0
I0521 09:36:45.832734  3675 net.cpp:408] cont_3_lstm1x_cont_slice_2_split -> cont_3_lstm1x_cont_slice_2_split_1
I0521 09:36:45.832759  3675 net.cpp:150] Setting up cont_3_lstm1x_cont_slice_2_split
I0521 09:36:45.832762  3675 net.cpp:157] Top shape: 1 128 (128)
I0521 09:36:45.832764  3675 net.cpp:157] Top shape: 1 128 (128)
I0521 09:36:45.832767  3675 net.cpp:165] Memory required for data: 16899072
I0521 09:36:45.832769  3675 layer_factory.hpp:77] Creating layer cont_4_lstm1x_cont_slice_3_split
I0521 09:36:45.832772  3675 net.cpp:100] Creating Layer cont_4_lstm1x_cont_slice_3_split
I0521 09:36:45.832774  3675 net.cpp:434] cont_4_lstm1x_cont_slice_3_split <- cont_4
I0521 09:36:45.832778  3675 net.cpp:408] cont_4_lstm1x_cont_slice_3_split -> cont_4_lstm1x_cont_slice_3_split_0
I0521 09:36:45.832793  3675 net.cpp:408] cont_4_lstm1x_cont_slice_3_split -> cont_4_lstm1x_cont_slice_3_split_1
I0521 09:36:45.832824  3675 net.cpp:150] Setting up cont_4_lstm1x_cont_slice_3_split
I0521 09:36:45.832828  3675 net.cpp:157] Top shape: 1 128 (128)
I0521 09:36:45.832830  3675 net.cpp:157] Top shape: 1 128 (128)
I0521 09:36:45.832832  3675 net.cpp:165] Memory required for data: 16900096
I0521 09:36:45.832835  3675 layer_factory.hpp:77] Creating layer cont_5_lstm1x_cont_slice_4_split
I0521 09:36:45.832839  3675 net.cpp:100] Creating Layer cont_5_lstm1x_cont_slice_4_split
I0521 09:36:45.832840  3675 net.cpp:434] cont_5_lstm1x_cont_slice_4_split <- cont_5
I0521 09:36:45.832845  3675 net.cpp:408] cont_5_lstm1x_cont_slice_4_split -> cont_5_lstm1x_cont_slice_4_split_0
I0521 09:36:45.832849  3675 net.cpp:408] cont_5_lstm1x_cont_slice_4_split -> cont_5_lstm1x_cont_slice_4_split_1
I0521 09:36:45.832870  3675 net.cpp:150] Setting up cont_5_lstm1x_cont_slice_4_split
I0521 09:36:45.832872  3675 net.cpp:157] Top shape: 1 128 (128)
I0521 09:36:45.832875  3675 net.cpp:157] Top shape: 1 128 (128)
I0521 09:36:45.832876  3675 net.cpp:165] Memory required for data: 16901120
I0521 09:36:45.832878  3675 layer_factory.hpp:77] Creating layer cont_6_lstm1x_cont_slice_5_split
I0521 09:36:45.832882  3675 net.cpp:100] Creating Layer cont_6_lstm1x_cont_slice_5_split
I0521 09:36:45.832885  3675 net.cpp:434] cont_6_lstm1x_cont_slice_5_split <- cont_6
I0521 09:36:45.832887  3675 net.cpp:408] cont_6_lstm1x_cont_slice_5_split -> cont_6_lstm1x_cont_slice_5_split_0
I0521 09:36:45.832891  3675 net.cpp:408] cont_6_lstm1x_cont_slice_5_split -> cont_6_lstm1x_cont_slice_5_split_1
I0521 09:36:45.832913  3675 net.cpp:150] Setting up cont_6_lstm1x_cont_slice_5_split
I0521 09:36:45.832917  3675 net.cpp:157] Top shape: 1 128 (128)
I0521 09:36:45.832922  3675 net.cpp:157] Top shape: 1 128 (128)
I0521 09:36:45.832926  3675 net.cpp:165] Memory required for data: 16902144
I0521 09:36:45.832928  3675 layer_factory.hpp:77] Creating layer cont_7_lstm1x_cont_slice_6_split
I0521 09:36:45.832933  3675 net.cpp:100] Creating Layer cont_7_lstm1x_cont_slice_6_split
I0521 09:36:45.832937  3675 net.cpp:434] cont_7_lstm1x_cont_slice_6_split <- cont_7
I0521 09:36:45.832942  3675 net.cpp:408] cont_7_lstm1x_cont_slice_6_split -> cont_7_lstm1x_cont_slice_6_split_0
I0521 09:36:45.832948  3675 net.cpp:408] cont_7_lstm1x_cont_slice_6_split -> cont_7_lstm1x_cont_slice_6_split_1
I0521 09:36:45.832969  3675 net.cpp:150] Setting up cont_7_lstm1x_cont_slice_6_split
I0521 09:36:45.832973  3675 net.cpp:157] Top shape: 1 128 (128)
I0521 09:36:45.832974  3675 net.cpp:157] Top shape: 1 128 (128)
I0521 09:36:45.832976  3675 net.cpp:165] Memory required for data: 16903168
I0521 09:36:45.832978  3675 layer_factory.hpp:77] Creating layer cont_8_lstm1x_cont_slice_7_split
I0521 09:36:45.832983  3675 net.cpp:100] Creating Layer cont_8_lstm1x_cont_slice_7_split
I0521 09:36:45.832985  3675 net.cpp:434] cont_8_lstm1x_cont_slice_7_split <- cont_8
I0521 09:36:45.832988  3675 net.cpp:408] cont_8_lstm1x_cont_slice_7_split -> cont_8_lstm1x_cont_slice_7_split_0
I0521 09:36:45.832993  3675 net.cpp:408] cont_8_lstm1x_cont_slice_7_split -> cont_8_lstm1x_cont_slice_7_split_1
I0521 09:36:45.833011  3675 net.cpp:150] Setting up cont_8_lstm1x_cont_slice_7_split
I0521 09:36:45.833014  3675 net.cpp:157] Top shape: 1 128 (128)
I0521 09:36:45.833016  3675 net.cpp:157] Top shape: 1 128 (128)
I0521 09:36:45.833019  3675 net.cpp:165] Memory required for data: 16904192
I0521 09:36:45.833021  3675 layer_factory.hpp:77] Creating layer cont_9_lstm1x_cont_slice_8_split
I0521 09:36:45.833024  3675 net.cpp:100] Creating Layer cont_9_lstm1x_cont_slice_8_split
I0521 09:36:45.833026  3675 net.cpp:434] cont_9_lstm1x_cont_slice_8_split <- cont_9
I0521 09:36:45.833029  3675 net.cpp:408] cont_9_lstm1x_cont_slice_8_split -> cont_9_lstm1x_cont_slice_8_split_0
I0521 09:36:45.833034  3675 net.cpp:408] cont_9_lstm1x_cont_slice_8_split -> cont_9_lstm1x_cont_slice_8_split_1
I0521 09:36:45.833052  3675 net.cpp:150] Setting up cont_9_lstm1x_cont_slice_8_split
I0521 09:36:45.833055  3675 net.cpp:157] Top shape: 1 128 (128)
I0521 09:36:45.833058  3675 net.cpp:157] Top shape: 1 128 (128)
I0521 09:36:45.833066  3675 net.cpp:165] Memory required for data: 16905216
I0521 09:36:45.833068  3675 layer_factory.hpp:77] Creating layer cont_10_lstm1x_cont_slice_9_split
I0521 09:36:45.833072  3675 net.cpp:100] Creating Layer cont_10_lstm1x_cont_slice_9_split
I0521 09:36:45.833075  3675 net.cpp:434] cont_10_lstm1x_cont_slice_9_split <- cont_10
I0521 09:36:45.833078  3675 net.cpp:408] cont_10_lstm1x_cont_slice_9_split -> cont_10_lstm1x_cont_slice_9_split_0
I0521 09:36:45.833081  3675 net.cpp:408] cont_10_lstm1x_cont_slice_9_split -> cont_10_lstm1x_cont_slice_9_split_1
I0521 09:36:45.833101  3675 net.cpp:150] Setting up cont_10_lstm1x_cont_slice_9_split
I0521 09:36:45.833104  3675 net.cpp:157] Top shape: 1 128 (128)
I0521 09:36:45.833106  3675 net.cpp:157] Top shape: 1 128 (128)
I0521 09:36:45.833108  3675 net.cpp:165] Memory required for data: 16906240
I0521 09:36:45.833112  3675 layer_factory.hpp:77] Creating layer cont_11_lstm1x_cont_slice_10_split
I0521 09:36:45.833113  3675 net.cpp:100] Creating Layer cont_11_lstm1x_cont_slice_10_split
I0521 09:36:45.833117  3675 net.cpp:434] cont_11_lstm1x_cont_slice_10_split <- cont_11
I0521 09:36:45.833119  3675 net.cpp:408] cont_11_lstm1x_cont_slice_10_split -> cont_11_lstm1x_cont_slice_10_split_0
I0521 09:36:45.833123  3675 net.cpp:408] cont_11_lstm1x_cont_slice_10_split -> cont_11_lstm1x_cont_slice_10_split_1
I0521 09:36:45.833143  3675 net.cpp:150] Setting up cont_11_lstm1x_cont_slice_10_split
I0521 09:36:45.833145  3675 net.cpp:157] Top shape: 1 128 (128)
I0521 09:36:45.833148  3675 net.cpp:157] Top shape: 1 128 (128)
I0521 09:36:45.833150  3675 net.cpp:165] Memory required for data: 16907264
I0521 09:36:45.833153  3675 layer_factory.hpp:77] Creating layer cont_12_lstm1x_cont_slice_11_split
I0521 09:36:45.833155  3675 net.cpp:100] Creating Layer cont_12_lstm1x_cont_slice_11_split
I0521 09:36:45.833158  3675 net.cpp:434] cont_12_lstm1x_cont_slice_11_split <- cont_12
I0521 09:36:45.833163  3675 net.cpp:408] cont_12_lstm1x_cont_slice_11_split -> cont_12_lstm1x_cont_slice_11_split_0
I0521 09:36:45.833165  3675 net.cpp:408] cont_12_lstm1x_cont_slice_11_split -> cont_12_lstm1x_cont_slice_11_split_1
I0521 09:36:45.833185  3675 net.cpp:150] Setting up cont_12_lstm1x_cont_slice_11_split
I0521 09:36:45.833189  3675 net.cpp:157] Top shape: 1 128 (128)
I0521 09:36:45.833191  3675 net.cpp:157] Top shape: 1 128 (128)
I0521 09:36:45.833194  3675 net.cpp:165] Memory required for data: 16908288
I0521 09:36:45.833195  3675 layer_factory.hpp:77] Creating layer cont_13_lstm1x_cont_slice_12_split
I0521 09:36:45.833199  3675 net.cpp:100] Creating Layer cont_13_lstm1x_cont_slice_12_split
I0521 09:36:45.833200  3675 net.cpp:434] cont_13_lstm1x_cont_slice_12_split <- cont_13
I0521 09:36:45.833204  3675 net.cpp:408] cont_13_lstm1x_cont_slice_12_split -> cont_13_lstm1x_cont_slice_12_split_0
I0521 09:36:45.833207  3675 net.cpp:408] cont_13_lstm1x_cont_slice_12_split -> cont_13_lstm1x_cont_slice_12_split_1
I0521 09:36:45.833227  3675 net.cpp:150] Setting up cont_13_lstm1x_cont_slice_12_split
I0521 09:36:45.833230  3675 net.cpp:157] Top shape: 1 128 (128)
I0521 09:36:45.833232  3675 net.cpp:157] Top shape: 1 128 (128)
I0521 09:36:45.833235  3675 net.cpp:165] Memory required for data: 16909312
I0521 09:36:45.833237  3675 layer_factory.hpp:77] Creating layer cont_14_lstm1x_cont_slice_13_split
I0521 09:36:45.833240  3675 net.cpp:100] Creating Layer cont_14_lstm1x_cont_slice_13_split
I0521 09:36:45.833242  3675 net.cpp:434] cont_14_lstm1x_cont_slice_13_split <- cont_14
I0521 09:36:45.833247  3675 net.cpp:408] cont_14_lstm1x_cont_slice_13_split -> cont_14_lstm1x_cont_slice_13_split_0
I0521 09:36:45.833250  3675 net.cpp:408] cont_14_lstm1x_cont_slice_13_split -> cont_14_lstm1x_cont_slice_13_split_1
I0521 09:36:45.833271  3675 net.cpp:150] Setting up cont_14_lstm1x_cont_slice_13_split
I0521 09:36:45.833273  3675 net.cpp:157] Top shape: 1 128 (128)
I0521 09:36:45.833276  3675 net.cpp:157] Top shape: 1 128 (128)
I0521 09:36:45.833277  3675 net.cpp:165] Memory required for data: 16910336
I0521 09:36:45.833286  3675 layer_factory.hpp:77] Creating layer cont_15_lstm1x_cont_slice_14_split
I0521 09:36:45.833288  3675 net.cpp:100] Creating Layer cont_15_lstm1x_cont_slice_14_split
I0521 09:36:45.833290  3675 net.cpp:434] cont_15_lstm1x_cont_slice_14_split <- cont_15
I0521 09:36:45.833293  3675 net.cpp:408] cont_15_lstm1x_cont_slice_14_split -> cont_15_lstm1x_cont_slice_14_split_0
I0521 09:36:45.833297  3675 net.cpp:408] cont_15_lstm1x_cont_slice_14_split -> cont_15_lstm1x_cont_slice_14_split_1
I0521 09:36:45.833317  3675 net.cpp:150] Setting up cont_15_lstm1x_cont_slice_14_split
I0521 09:36:45.833323  3675 net.cpp:157] Top shape: 1 128 (128)
I0521 09:36:45.833326  3675 net.cpp:157] Top shape: 1 128 (128)
I0521 09:36:45.833329  3675 net.cpp:165] Memory required for data: 16911360
I0521 09:36:45.833333  3675 layer_factory.hpp:77] Creating layer cont_16_lstm1x_cont_slice_15_split
I0521 09:36:45.833339  3675 net.cpp:100] Creating Layer cont_16_lstm1x_cont_slice_15_split
I0521 09:36:45.833345  3675 net.cpp:434] cont_16_lstm1x_cont_slice_15_split <- cont_16
I0521 09:36:45.833353  3675 net.cpp:408] cont_16_lstm1x_cont_slice_15_split -> cont_16_lstm1x_cont_slice_15_split_0
I0521 09:36:45.833362  3675 net.cpp:408] cont_16_lstm1x_cont_slice_15_split -> cont_16_lstm1x_cont_slice_15_split_1
I0521 09:36:45.833401  3675 net.cpp:150] Setting up cont_16_lstm1x_cont_slice_15_split
I0521 09:36:45.833406  3675 net.cpp:157] Top shape: 1 128 (128)
I0521 09:36:45.833413  3675 net.cpp:157] Top shape: 1 128 (128)
I0521 09:36:45.833417  3675 net.cpp:165] Memory required for data: 16912384
I0521 09:36:45.833421  3675 layer_factory.hpp:77] Creating layer lstm1x_x_transform
I0521 09:36:45.833433  3675 net.cpp:100] Creating Layer lstm1x_x_transform
I0521 09:36:45.833439  3675 net.cpp:434] lstm1x_x_transform <- x
I0521 09:36:45.833446  3675 net.cpp:408] lstm1x_x_transform -> W_xc_x
I0521 09:36:45.838376  3675 net.cpp:150] Setting up lstm1x_x_transform
I0521 09:36:45.838398  3675 net.cpp:157] Top shape: 16 128 400 (819200)
I0521 09:36:45.838402  3675 net.cpp:165] Memory required for data: 20189184
I0521 09:36:45.838413  3675 layer_factory.hpp:77] Creating layer lstm1x_W_xc_x_slice
I0521 09:36:45.838423  3675 net.cpp:100] Creating Layer lstm1x_W_xc_x_slice
I0521 09:36:45.838428  3675 net.cpp:434] lstm1x_W_xc_x_slice <- W_xc_x
I0521 09:36:45.838433  3675 net.cpp:408] lstm1x_W_xc_x_slice -> W_xc_x_1
I0521 09:36:45.838440  3675 net.cpp:408] lstm1x_W_xc_x_slice -> W_xc_x_2
I0521 09:36:45.838444  3675 net.cpp:408] lstm1x_W_xc_x_slice -> W_xc_x_3
I0521 09:36:45.838449  3675 net.cpp:408] lstm1x_W_xc_x_slice -> W_xc_x_4
I0521 09:36:45.838454  3675 net.cpp:408] lstm1x_W_xc_x_slice -> W_xc_x_5
I0521 09:36:45.838459  3675 net.cpp:408] lstm1x_W_xc_x_slice -> W_xc_x_6
I0521 09:36:45.838462  3675 net.cpp:408] lstm1x_W_xc_x_slice -> W_xc_x_7
I0521 09:36:45.838466  3675 net.cpp:408] lstm1x_W_xc_x_slice -> W_xc_x_8
I0521 09:36:45.838470  3675 net.cpp:408] lstm1x_W_xc_x_slice -> W_xc_x_9
I0521 09:36:45.838474  3675 net.cpp:408] lstm1x_W_xc_x_slice -> W_xc_x_10
I0521 09:36:45.838477  3675 net.cpp:408] lstm1x_W_xc_x_slice -> W_xc_x_11
I0521 09:36:45.838481  3675 net.cpp:408] lstm1x_W_xc_x_slice -> W_xc_x_12
I0521 09:36:45.838490  3675 net.cpp:408] lstm1x_W_xc_x_slice -> W_xc_x_13
I0521 09:36:45.838495  3675 net.cpp:408] lstm1x_W_xc_x_slice -> W_xc_x_14
I0521 09:36:45.838498  3675 net.cpp:408] lstm1x_W_xc_x_slice -> W_xc_x_15
I0521 09:36:45.838502  3675 net.cpp:408] lstm1x_W_xc_x_slice -> W_xc_x_16
I0521 09:36:45.838644  3675 net.cpp:150] Setting up lstm1x_W_xc_x_slice
I0521 09:36:45.838647  3675 net.cpp:157] Top shape: 1 128 400 (51200)
I0521 09:36:45.838650  3675 net.cpp:157] Top shape: 1 128 400 (51200)
I0521 09:36:45.838654  3675 net.cpp:157] Top shape: 1 128 400 (51200)
I0521 09:36:45.838656  3675 net.cpp:157] Top shape: 1 128 400 (51200)
I0521 09:36:45.838659  3675 net.cpp:157] Top shape: 1 128 400 (51200)
I0521 09:36:45.838661  3675 net.cpp:157] Top shape: 1 128 400 (51200)
I0521 09:36:45.838665  3675 net.cpp:157] Top shape: 1 128 400 (51200)
I0521 09:36:45.838680  3675 net.cpp:157] Top shape: 1 128 400 (51200)
I0521 09:36:45.838682  3675 net.cpp:157] Top shape: 1 128 400 (51200)
I0521 09:36:45.838685  3675 net.cpp:157] Top shape: 1 128 400 (51200)
I0521 09:36:45.838687  3675 net.cpp:157] Top shape: 1 128 400 (51200)
I0521 09:36:45.838690  3675 net.cpp:157] Top shape: 1 128 400 (51200)
I0521 09:36:45.838693  3675 net.cpp:157] Top shape: 1 128 400 (51200)
I0521 09:36:45.838696  3675 net.cpp:157] Top shape: 1 128 400 (51200)
I0521 09:36:45.838698  3675 net.cpp:157] Top shape: 1 128 400 (51200)
I0521 09:36:45.838701  3675 net.cpp:157] Top shape: 1 128 400 (51200)
I0521 09:36:45.838703  3675 net.cpp:165] Memory required for data: 23465984
I0521 09:36:45.838706  3675 layer_factory.hpp:77] Creating layer lstm1x_h_conted_0
I0521 09:36:45.838711  3675 net.cpp:100] Creating Layer lstm1x_h_conted_0
I0521 09:36:45.838714  3675 net.cpp:434] lstm1x_h_conted_0 <- h_0
I0521 09:36:45.838717  3675 net.cpp:434] lstm1x_h_conted_0 <- cont_1_lstm1x_cont_slice_0_split_0
I0521 09:36:45.838722  3675 net.cpp:408] lstm1x_h_conted_0 -> h_conted_0
I0521 09:36:45.838773  3675 net.cpp:150] Setting up lstm1x_h_conted_0
I0521 09:36:45.838776  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.838778  3675 net.cpp:165] Memory required for data: 23517184
I0521 09:36:45.838780  3675 layer_factory.hpp:77] Creating layer lstm1x_transform_1
I0521 09:36:45.838786  3675 net.cpp:100] Creating Layer lstm1x_transform_1
I0521 09:36:45.838788  3675 net.cpp:434] lstm1x_transform_1 <- h_conted_0
I0521 09:36:45.838793  3675 net.cpp:408] lstm1x_transform_1 -> W_hc_h_0
I0521 09:36:45.839016  3675 net.cpp:150] Setting up lstm1x_transform_1
I0521 09:36:45.839023  3675 net.cpp:157] Top shape: 1 128 400 (51200)
I0521 09:36:45.839026  3675 net.cpp:165] Memory required for data: 23721984
I0521 09:36:45.839032  3675 layer_factory.hpp:77] Creating layer lstm1x_gate_input_1
I0521 09:36:45.839041  3675 net.cpp:100] Creating Layer lstm1x_gate_input_1
I0521 09:36:45.839046  3675 net.cpp:434] lstm1x_gate_input_1 <- W_hc_h_0
I0521 09:36:45.839049  3675 net.cpp:434] lstm1x_gate_input_1 <- W_xc_x_1
I0521 09:36:45.839054  3675 net.cpp:408] lstm1x_gate_input_1 -> gate_input_1
I0521 09:36:45.839072  3675 net.cpp:150] Setting up lstm1x_gate_input_1
I0521 09:36:45.839076  3675 net.cpp:157] Top shape: 1 128 400 (51200)
I0521 09:36:45.839078  3675 net.cpp:165] Memory required for data: 23926784
I0521 09:36:45.839080  3675 layer_factory.hpp:77] Creating layer lstm1x_unit_1
I0521 09:36:45.839085  3675 net.cpp:100] Creating Layer lstm1x_unit_1
I0521 09:36:45.839087  3675 net.cpp:434] lstm1x_unit_1 <- c_0
I0521 09:36:45.839090  3675 net.cpp:434] lstm1x_unit_1 <- gate_input_1
I0521 09:36:45.839093  3675 net.cpp:434] lstm1x_unit_1 <- cont_1_lstm1x_cont_slice_0_split_1
I0521 09:36:45.839097  3675 net.cpp:408] lstm1x_unit_1 -> c_1
I0521 09:36:45.839102  3675 net.cpp:408] lstm1x_unit_1 -> h_1
I0521 09:36:45.839131  3675 net.cpp:150] Setting up lstm1x_unit_1
I0521 09:36:45.839134  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.839138  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.839139  3675 net.cpp:165] Memory required for data: 24029184
I0521 09:36:45.839141  3675 layer_factory.hpp:77] Creating layer h_1_lstm1x_unit_1_1_split
I0521 09:36:45.839146  3675 net.cpp:100] Creating Layer h_1_lstm1x_unit_1_1_split
I0521 09:36:45.839148  3675 net.cpp:434] h_1_lstm1x_unit_1_1_split <- h_1
I0521 09:36:45.839152  3675 net.cpp:408] h_1_lstm1x_unit_1_1_split -> h_1_lstm1x_unit_1_1_split_0
I0521 09:36:45.839156  3675 net.cpp:408] h_1_lstm1x_unit_1_1_split -> h_1_lstm1x_unit_1_1_split_1
I0521 09:36:45.839177  3675 net.cpp:150] Setting up h_1_lstm1x_unit_1_1_split
I0521 09:36:45.839180  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.839184  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.839185  3675 net.cpp:165] Memory required for data: 24131584
I0521 09:36:45.839187  3675 layer_factory.hpp:77] Creating layer lstm1x_h_conted_1
I0521 09:36:45.839192  3675 net.cpp:100] Creating Layer lstm1x_h_conted_1
I0521 09:36:45.839201  3675 net.cpp:434] lstm1x_h_conted_1 <- h_1_lstm1x_unit_1_1_split_0
I0521 09:36:45.839205  3675 net.cpp:434] lstm1x_h_conted_1 <- cont_2_lstm1x_cont_slice_1_split_0
I0521 09:36:45.839208  3675 net.cpp:408] lstm1x_h_conted_1 -> h_conted_1
I0521 09:36:45.839247  3675 net.cpp:150] Setting up lstm1x_h_conted_1
I0521 09:36:45.839251  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.839253  3675 net.cpp:165] Memory required for data: 24182784
I0521 09:36:45.839256  3675 layer_factory.hpp:77] Creating layer lstm1x_transform_2
I0521 09:36:45.839259  3675 net.cpp:100] Creating Layer lstm1x_transform_2
I0521 09:36:45.839262  3675 net.cpp:434] lstm1x_transform_2 <- h_conted_1
I0521 09:36:45.839265  3675 net.cpp:408] lstm1x_transform_2 -> W_hc_h_1
I0521 09:36:45.839459  3675 net.cpp:150] Setting up lstm1x_transform_2
I0521 09:36:45.839462  3675 net.cpp:157] Top shape: 1 128 400 (51200)
I0521 09:36:45.839464  3675 net.cpp:165] Memory required for data: 24387584
I0521 09:36:45.839468  3675 net.cpp:493] Sharing parameters 'W_hc' owned by layer 'lstm1x_transform_1', param index 0
I0521 09:36:45.839470  3675 layer_factory.hpp:77] Creating layer lstm1x_gate_input_2
I0521 09:36:45.839473  3675 net.cpp:100] Creating Layer lstm1x_gate_input_2
I0521 09:36:45.839476  3675 net.cpp:434] lstm1x_gate_input_2 <- W_hc_h_1
I0521 09:36:45.839479  3675 net.cpp:434] lstm1x_gate_input_2 <- W_xc_x_2
I0521 09:36:45.839483  3675 net.cpp:408] lstm1x_gate_input_2 -> gate_input_2
I0521 09:36:45.839495  3675 net.cpp:150] Setting up lstm1x_gate_input_2
I0521 09:36:45.839499  3675 net.cpp:157] Top shape: 1 128 400 (51200)
I0521 09:36:45.839501  3675 net.cpp:165] Memory required for data: 24592384
I0521 09:36:45.839504  3675 layer_factory.hpp:77] Creating layer lstm1x_unit_2
I0521 09:36:45.839507  3675 net.cpp:100] Creating Layer lstm1x_unit_2
I0521 09:36:45.839509  3675 net.cpp:434] lstm1x_unit_2 <- c_1
I0521 09:36:45.839512  3675 net.cpp:434] lstm1x_unit_2 <- gate_input_2
I0521 09:36:45.839515  3675 net.cpp:434] lstm1x_unit_2 <- cont_2_lstm1x_cont_slice_1_split_1
I0521 09:36:45.839519  3675 net.cpp:408] lstm1x_unit_2 -> c_2
I0521 09:36:45.839522  3675 net.cpp:408] lstm1x_unit_2 -> h_2
I0521 09:36:45.839550  3675 net.cpp:150] Setting up lstm1x_unit_2
I0521 09:36:45.839553  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.839555  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.839558  3675 net.cpp:165] Memory required for data: 24694784
I0521 09:36:45.839560  3675 layer_factory.hpp:77] Creating layer h_2_lstm1x_unit_2_1_split
I0521 09:36:45.839565  3675 net.cpp:100] Creating Layer h_2_lstm1x_unit_2_1_split
I0521 09:36:45.839566  3675 net.cpp:434] h_2_lstm1x_unit_2_1_split <- h_2
I0521 09:36:45.839570  3675 net.cpp:408] h_2_lstm1x_unit_2_1_split -> h_2_lstm1x_unit_2_1_split_0
I0521 09:36:45.839574  3675 net.cpp:408] h_2_lstm1x_unit_2_1_split -> h_2_lstm1x_unit_2_1_split_1
I0521 09:36:45.839593  3675 net.cpp:150] Setting up h_2_lstm1x_unit_2_1_split
I0521 09:36:45.839596  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.839599  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.839601  3675 net.cpp:165] Memory required for data: 24797184
I0521 09:36:45.839604  3675 layer_factory.hpp:77] Creating layer lstm1x_h_conted_2
I0521 09:36:45.839608  3675 net.cpp:100] Creating Layer lstm1x_h_conted_2
I0521 09:36:45.839610  3675 net.cpp:434] lstm1x_h_conted_2 <- h_2_lstm1x_unit_2_1_split_0
I0521 09:36:45.839613  3675 net.cpp:434] lstm1x_h_conted_2 <- cont_3_lstm1x_cont_slice_2_split_0
I0521 09:36:45.839617  3675 net.cpp:408] lstm1x_h_conted_2 -> h_conted_2
I0521 09:36:45.839654  3675 net.cpp:150] Setting up lstm1x_h_conted_2
I0521 09:36:45.839658  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.839659  3675 net.cpp:165] Memory required for data: 24848384
I0521 09:36:45.839661  3675 layer_factory.hpp:77] Creating layer lstm1x_transform_3
I0521 09:36:45.839668  3675 net.cpp:100] Creating Layer lstm1x_transform_3
I0521 09:36:45.839671  3675 net.cpp:434] lstm1x_transform_3 <- h_conted_2
I0521 09:36:45.839686  3675 net.cpp:408] lstm1x_transform_3 -> W_hc_h_2
I0521 09:36:45.839884  3675 net.cpp:150] Setting up lstm1x_transform_3
I0521 09:36:45.839887  3675 net.cpp:157] Top shape: 1 128 400 (51200)
I0521 09:36:45.839890  3675 net.cpp:165] Memory required for data: 25053184
I0521 09:36:45.839892  3675 net.cpp:493] Sharing parameters 'W_hc' owned by layer 'lstm1x_transform_1', param index 0
I0521 09:36:45.839895  3675 layer_factory.hpp:77] Creating layer lstm1x_gate_input_3
I0521 09:36:45.839900  3675 net.cpp:100] Creating Layer lstm1x_gate_input_3
I0521 09:36:45.839902  3675 net.cpp:434] lstm1x_gate_input_3 <- W_hc_h_2
I0521 09:36:45.839905  3675 net.cpp:434] lstm1x_gate_input_3 <- W_xc_x_3
I0521 09:36:45.839908  3675 net.cpp:408] lstm1x_gate_input_3 -> gate_input_3
I0521 09:36:45.839921  3675 net.cpp:150] Setting up lstm1x_gate_input_3
I0521 09:36:45.839924  3675 net.cpp:157] Top shape: 1 128 400 (51200)
I0521 09:36:45.839926  3675 net.cpp:165] Memory required for data: 25257984
I0521 09:36:45.839928  3675 layer_factory.hpp:77] Creating layer lstm1x_unit_3
I0521 09:36:45.839932  3675 net.cpp:100] Creating Layer lstm1x_unit_3
I0521 09:36:45.839936  3675 net.cpp:434] lstm1x_unit_3 <- c_2
I0521 09:36:45.839938  3675 net.cpp:434] lstm1x_unit_3 <- gate_input_3
I0521 09:36:45.839941  3675 net.cpp:434] lstm1x_unit_3 <- cont_3_lstm1x_cont_slice_2_split_1
I0521 09:36:45.839943  3675 net.cpp:408] lstm1x_unit_3 -> c_3
I0521 09:36:45.839947  3675 net.cpp:408] lstm1x_unit_3 -> h_3
I0521 09:36:45.839974  3675 net.cpp:150] Setting up lstm1x_unit_3
I0521 09:36:45.839977  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.839980  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.839982  3675 net.cpp:165] Memory required for data: 25360384
I0521 09:36:45.839985  3675 layer_factory.hpp:77] Creating layer h_3_lstm1x_unit_3_1_split
I0521 09:36:45.839988  3675 net.cpp:100] Creating Layer h_3_lstm1x_unit_3_1_split
I0521 09:36:45.839992  3675 net.cpp:434] h_3_lstm1x_unit_3_1_split <- h_3
I0521 09:36:45.839995  3675 net.cpp:408] h_3_lstm1x_unit_3_1_split -> h_3_lstm1x_unit_3_1_split_0
I0521 09:36:45.839999  3675 net.cpp:408] h_3_lstm1x_unit_3_1_split -> h_3_lstm1x_unit_3_1_split_1
I0521 09:36:45.840021  3675 net.cpp:150] Setting up h_3_lstm1x_unit_3_1_split
I0521 09:36:45.840024  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.840028  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.840029  3675 net.cpp:165] Memory required for data: 25462784
I0521 09:36:45.840031  3675 layer_factory.hpp:77] Creating layer lstm1x_h_conted_3
I0521 09:36:45.840034  3675 net.cpp:100] Creating Layer lstm1x_h_conted_3
I0521 09:36:45.840037  3675 net.cpp:434] lstm1x_h_conted_3 <- h_3_lstm1x_unit_3_1_split_0
I0521 09:36:45.840040  3675 net.cpp:434] lstm1x_h_conted_3 <- cont_4_lstm1x_cont_slice_3_split_0
I0521 09:36:45.840044  3675 net.cpp:408] lstm1x_h_conted_3 -> h_conted_3
I0521 09:36:45.840080  3675 net.cpp:150] Setting up lstm1x_h_conted_3
I0521 09:36:45.840083  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.840085  3675 net.cpp:165] Memory required for data: 25513984
I0521 09:36:45.840087  3675 layer_factory.hpp:77] Creating layer lstm1x_transform_4
I0521 09:36:45.840091  3675 net.cpp:100] Creating Layer lstm1x_transform_4
I0521 09:36:45.840093  3675 net.cpp:434] lstm1x_transform_4 <- h_conted_3
I0521 09:36:45.840096  3675 net.cpp:408] lstm1x_transform_4 -> W_hc_h_3
I0521 09:36:45.840288  3675 net.cpp:150] Setting up lstm1x_transform_4
I0521 09:36:45.840292  3675 net.cpp:157] Top shape: 1 128 400 (51200)
I0521 09:36:45.840294  3675 net.cpp:165] Memory required for data: 25718784
I0521 09:36:45.840296  3675 net.cpp:493] Sharing parameters 'W_hc' owned by layer 'lstm1x_transform_1', param index 0
I0521 09:36:45.840299  3675 layer_factory.hpp:77] Creating layer lstm1x_gate_input_4
I0521 09:36:45.840302  3675 net.cpp:100] Creating Layer lstm1x_gate_input_4
I0521 09:36:45.840304  3675 net.cpp:434] lstm1x_gate_input_4 <- W_hc_h_3
I0521 09:36:45.840307  3675 net.cpp:434] lstm1x_gate_input_4 <- W_xc_x_4
I0521 09:36:45.840317  3675 net.cpp:408] lstm1x_gate_input_4 -> gate_input_4
I0521 09:36:45.840329  3675 net.cpp:150] Setting up lstm1x_gate_input_4
I0521 09:36:45.840333  3675 net.cpp:157] Top shape: 1 128 400 (51200)
I0521 09:36:45.840337  3675 net.cpp:165] Memory required for data: 25923584
I0521 09:36:45.840340  3675 layer_factory.hpp:77] Creating layer lstm1x_unit_4
I0521 09:36:45.840346  3675 net.cpp:100] Creating Layer lstm1x_unit_4
I0521 09:36:45.840349  3675 net.cpp:434] lstm1x_unit_4 <- c_3
I0521 09:36:45.840353  3675 net.cpp:434] lstm1x_unit_4 <- gate_input_4
I0521 09:36:45.840358  3675 net.cpp:434] lstm1x_unit_4 <- cont_4_lstm1x_cont_slice_3_split_1
I0521 09:36:45.840361  3675 net.cpp:408] lstm1x_unit_4 -> c_4
I0521 09:36:45.840366  3675 net.cpp:408] lstm1x_unit_4 -> h_4
I0521 09:36:45.840395  3675 net.cpp:150] Setting up lstm1x_unit_4
I0521 09:36:45.840400  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.840404  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.840407  3675 net.cpp:165] Memory required for data: 26025984
I0521 09:36:45.840410  3675 layer_factory.hpp:77] Creating layer h_4_lstm1x_unit_4_1_split
I0521 09:36:45.840415  3675 net.cpp:100] Creating Layer h_4_lstm1x_unit_4_1_split
I0521 09:36:45.840417  3675 net.cpp:434] h_4_lstm1x_unit_4_1_split <- h_4
I0521 09:36:45.840423  3675 net.cpp:408] h_4_lstm1x_unit_4_1_split -> h_4_lstm1x_unit_4_1_split_0
I0521 09:36:45.840430  3675 net.cpp:408] h_4_lstm1x_unit_4_1_split -> h_4_lstm1x_unit_4_1_split_1
I0521 09:36:45.840456  3675 net.cpp:150] Setting up h_4_lstm1x_unit_4_1_split
I0521 09:36:45.840459  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.840461  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.840463  3675 net.cpp:165] Memory required for data: 26128384
I0521 09:36:45.840466  3675 layer_factory.hpp:77] Creating layer lstm1x_h_conted_4
I0521 09:36:45.840471  3675 net.cpp:100] Creating Layer lstm1x_h_conted_4
I0521 09:36:45.840473  3675 net.cpp:434] lstm1x_h_conted_4 <- h_4_lstm1x_unit_4_1_split_0
I0521 09:36:45.840476  3675 net.cpp:434] lstm1x_h_conted_4 <- cont_5_lstm1x_cont_slice_4_split_0
I0521 09:36:45.840479  3675 net.cpp:408] lstm1x_h_conted_4 -> h_conted_4
I0521 09:36:45.840517  3675 net.cpp:150] Setting up lstm1x_h_conted_4
I0521 09:36:45.840520  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.840523  3675 net.cpp:165] Memory required for data: 26179584
I0521 09:36:45.840524  3675 layer_factory.hpp:77] Creating layer lstm1x_transform_5
I0521 09:36:45.840528  3675 net.cpp:100] Creating Layer lstm1x_transform_5
I0521 09:36:45.840531  3675 net.cpp:434] lstm1x_transform_5 <- h_conted_4
I0521 09:36:45.840534  3675 net.cpp:408] lstm1x_transform_5 -> W_hc_h_4
I0521 09:36:45.840724  3675 net.cpp:150] Setting up lstm1x_transform_5
I0521 09:36:45.840728  3675 net.cpp:157] Top shape: 1 128 400 (51200)
I0521 09:36:45.840730  3675 net.cpp:165] Memory required for data: 26384384
I0521 09:36:45.840734  3675 net.cpp:493] Sharing parameters 'W_hc' owned by layer 'lstm1x_transform_1', param index 0
I0521 09:36:45.840735  3675 layer_factory.hpp:77] Creating layer lstm1x_gate_input_5
I0521 09:36:45.840739  3675 net.cpp:100] Creating Layer lstm1x_gate_input_5
I0521 09:36:45.840741  3675 net.cpp:434] lstm1x_gate_input_5 <- W_hc_h_4
I0521 09:36:45.840744  3675 net.cpp:434] lstm1x_gate_input_5 <- W_xc_x_5
I0521 09:36:45.840746  3675 net.cpp:408] lstm1x_gate_input_5 -> gate_input_5
I0521 09:36:45.840760  3675 net.cpp:150] Setting up lstm1x_gate_input_5
I0521 09:36:45.840764  3675 net.cpp:157] Top shape: 1 128 400 (51200)
I0521 09:36:45.840765  3675 net.cpp:165] Memory required for data: 26589184
I0521 09:36:45.840767  3675 layer_factory.hpp:77] Creating layer lstm1x_unit_5
I0521 09:36:45.840770  3675 net.cpp:100] Creating Layer lstm1x_unit_5
I0521 09:36:45.840773  3675 net.cpp:434] lstm1x_unit_5 <- c_4
I0521 09:36:45.840775  3675 net.cpp:434] lstm1x_unit_5 <- gate_input_5
I0521 09:36:45.840778  3675 net.cpp:434] lstm1x_unit_5 <- cont_5_lstm1x_cont_slice_4_split_1
I0521 09:36:45.840801  3675 net.cpp:408] lstm1x_unit_5 -> c_5
I0521 09:36:45.840806  3675 net.cpp:408] lstm1x_unit_5 -> h_5
I0521 09:36:45.840834  3675 net.cpp:150] Setting up lstm1x_unit_5
I0521 09:36:45.840838  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.840842  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.840843  3675 net.cpp:165] Memory required for data: 26691584
I0521 09:36:45.840845  3675 layer_factory.hpp:77] Creating layer h_5_lstm1x_unit_5_1_split
I0521 09:36:45.840850  3675 net.cpp:100] Creating Layer h_5_lstm1x_unit_5_1_split
I0521 09:36:45.840852  3675 net.cpp:434] h_5_lstm1x_unit_5_1_split <- h_5
I0521 09:36:45.840855  3675 net.cpp:408] h_5_lstm1x_unit_5_1_split -> h_5_lstm1x_unit_5_1_split_0
I0521 09:36:45.840860  3675 net.cpp:408] h_5_lstm1x_unit_5_1_split -> h_5_lstm1x_unit_5_1_split_1
I0521 09:36:45.840880  3675 net.cpp:150] Setting up h_5_lstm1x_unit_5_1_split
I0521 09:36:45.840883  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.840886  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.840888  3675 net.cpp:165] Memory required for data: 26793984
I0521 09:36:45.840890  3675 layer_factory.hpp:77] Creating layer lstm1x_h_conted_5
I0521 09:36:45.840895  3675 net.cpp:100] Creating Layer lstm1x_h_conted_5
I0521 09:36:45.840898  3675 net.cpp:434] lstm1x_h_conted_5 <- h_5_lstm1x_unit_5_1_split_0
I0521 09:36:45.840900  3675 net.cpp:434] lstm1x_h_conted_5 <- cont_6_lstm1x_cont_slice_5_split_0
I0521 09:36:45.840904  3675 net.cpp:408] lstm1x_h_conted_5 -> h_conted_5
I0521 09:36:45.840943  3675 net.cpp:150] Setting up lstm1x_h_conted_5
I0521 09:36:45.840946  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.840948  3675 net.cpp:165] Memory required for data: 26845184
I0521 09:36:45.840951  3675 layer_factory.hpp:77] Creating layer lstm1x_transform_6
I0521 09:36:45.840955  3675 net.cpp:100] Creating Layer lstm1x_transform_6
I0521 09:36:45.840957  3675 net.cpp:434] lstm1x_transform_6 <- h_conted_5
I0521 09:36:45.840961  3675 net.cpp:408] lstm1x_transform_6 -> W_hc_h_5
I0521 09:36:45.841248  3675 net.cpp:150] Setting up lstm1x_transform_6
I0521 09:36:45.841253  3675 net.cpp:157] Top shape: 1 128 400 (51200)
I0521 09:36:45.841255  3675 net.cpp:165] Memory required for data: 27049984
I0521 09:36:45.841257  3675 net.cpp:493] Sharing parameters 'W_hc' owned by layer 'lstm1x_transform_1', param index 0
I0521 09:36:45.841260  3675 layer_factory.hpp:77] Creating layer lstm1x_gate_input_6
I0521 09:36:45.841264  3675 net.cpp:100] Creating Layer lstm1x_gate_input_6
I0521 09:36:45.841266  3675 net.cpp:434] lstm1x_gate_input_6 <- W_hc_h_5
I0521 09:36:45.841269  3675 net.cpp:434] lstm1x_gate_input_6 <- W_xc_x_6
I0521 09:36:45.841272  3675 net.cpp:408] lstm1x_gate_input_6 -> gate_input_6
I0521 09:36:45.841286  3675 net.cpp:150] Setting up lstm1x_gate_input_6
I0521 09:36:45.841290  3675 net.cpp:157] Top shape: 1 128 400 (51200)
I0521 09:36:45.841293  3675 net.cpp:165] Memory required for data: 27254784
I0521 09:36:45.841296  3675 layer_factory.hpp:77] Creating layer lstm1x_unit_6
I0521 09:36:45.841301  3675 net.cpp:100] Creating Layer lstm1x_unit_6
I0521 09:36:45.841305  3675 net.cpp:434] lstm1x_unit_6 <- c_5
I0521 09:36:45.841308  3675 net.cpp:434] lstm1x_unit_6 <- gate_input_6
I0521 09:36:45.841312  3675 net.cpp:434] lstm1x_unit_6 <- cont_6_lstm1x_cont_slice_5_split_1
I0521 09:36:45.841317  3675 net.cpp:408] lstm1x_unit_6 -> c_6
I0521 09:36:45.841322  3675 net.cpp:408] lstm1x_unit_6 -> h_6
I0521 09:36:45.841358  3675 net.cpp:150] Setting up lstm1x_unit_6
I0521 09:36:45.841363  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.841365  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.841368  3675 net.cpp:165] Memory required for data: 27357184
I0521 09:36:45.841370  3675 layer_factory.hpp:77] Creating layer h_6_lstm1x_unit_6_1_split
I0521 09:36:45.841375  3675 net.cpp:100] Creating Layer h_6_lstm1x_unit_6_1_split
I0521 09:36:45.841377  3675 net.cpp:434] h_6_lstm1x_unit_6_1_split <- h_6
I0521 09:36:45.841382  3675 net.cpp:408] h_6_lstm1x_unit_6_1_split -> h_6_lstm1x_unit_6_1_split_0
I0521 09:36:45.841395  3675 net.cpp:408] h_6_lstm1x_unit_6_1_split -> h_6_lstm1x_unit_6_1_split_1
I0521 09:36:45.841416  3675 net.cpp:150] Setting up h_6_lstm1x_unit_6_1_split
I0521 09:36:45.841420  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.841423  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.841425  3675 net.cpp:165] Memory required for data: 27459584
I0521 09:36:45.841428  3675 layer_factory.hpp:77] Creating layer lstm1x_h_conted_6
I0521 09:36:45.841433  3675 net.cpp:100] Creating Layer lstm1x_h_conted_6
I0521 09:36:45.841434  3675 net.cpp:434] lstm1x_h_conted_6 <- h_6_lstm1x_unit_6_1_split_0
I0521 09:36:45.841437  3675 net.cpp:434] lstm1x_h_conted_6 <- cont_7_lstm1x_cont_slice_6_split_0
I0521 09:36:45.841440  3675 net.cpp:408] lstm1x_h_conted_6 -> h_conted_6
I0521 09:36:45.841480  3675 net.cpp:150] Setting up lstm1x_h_conted_6
I0521 09:36:45.841485  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.841486  3675 net.cpp:165] Memory required for data: 27510784
I0521 09:36:45.841488  3675 layer_factory.hpp:77] Creating layer lstm1x_transform_7
I0521 09:36:45.841492  3675 net.cpp:100] Creating Layer lstm1x_transform_7
I0521 09:36:45.841495  3675 net.cpp:434] lstm1x_transform_7 <- h_conted_6
I0521 09:36:45.841501  3675 net.cpp:408] lstm1x_transform_7 -> W_hc_h_6
I0521 09:36:45.841781  3675 net.cpp:150] Setting up lstm1x_transform_7
I0521 09:36:45.841794  3675 net.cpp:157] Top shape: 1 128 400 (51200)
I0521 09:36:45.841796  3675 net.cpp:165] Memory required for data: 27715584
I0521 09:36:45.841804  3675 net.cpp:493] Sharing parameters 'W_hc' owned by layer 'lstm1x_transform_1', param index 0
I0521 09:36:45.841807  3675 layer_factory.hpp:77] Creating layer lstm1x_gate_input_7
I0521 09:36:45.841814  3675 net.cpp:100] Creating Layer lstm1x_gate_input_7
I0521 09:36:45.841817  3675 net.cpp:434] lstm1x_gate_input_7 <- W_hc_h_6
I0521 09:36:45.841821  3675 net.cpp:434] lstm1x_gate_input_7 <- W_xc_x_7
I0521 09:36:45.841826  3675 net.cpp:408] lstm1x_gate_input_7 -> gate_input_7
I0521 09:36:45.841852  3675 net.cpp:150] Setting up lstm1x_gate_input_7
I0521 09:36:45.841857  3675 net.cpp:157] Top shape: 1 128 400 (51200)
I0521 09:36:45.841861  3675 net.cpp:165] Memory required for data: 27920384
I0521 09:36:45.841863  3675 layer_factory.hpp:77] Creating layer lstm1x_unit_7
I0521 09:36:45.841869  3675 net.cpp:100] Creating Layer lstm1x_unit_7
I0521 09:36:45.841872  3675 net.cpp:434] lstm1x_unit_7 <- c_6
I0521 09:36:45.841876  3675 net.cpp:434] lstm1x_unit_7 <- gate_input_7
I0521 09:36:45.841878  3675 net.cpp:434] lstm1x_unit_7 <- cont_7_lstm1x_cont_slice_6_split_1
I0521 09:36:45.841882  3675 net.cpp:408] lstm1x_unit_7 -> c_7
I0521 09:36:45.841886  3675 net.cpp:408] lstm1x_unit_7 -> h_7
I0521 09:36:45.841917  3675 net.cpp:150] Setting up lstm1x_unit_7
I0521 09:36:45.841920  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.841922  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.841925  3675 net.cpp:165] Memory required for data: 28022784
I0521 09:36:45.841928  3675 layer_factory.hpp:77] Creating layer h_7_lstm1x_unit_7_1_split
I0521 09:36:45.841933  3675 net.cpp:100] Creating Layer h_7_lstm1x_unit_7_1_split
I0521 09:36:45.841934  3675 net.cpp:434] h_7_lstm1x_unit_7_1_split <- h_7
I0521 09:36:45.841938  3675 net.cpp:408] h_7_lstm1x_unit_7_1_split -> h_7_lstm1x_unit_7_1_split_0
I0521 09:36:45.841943  3675 net.cpp:408] h_7_lstm1x_unit_7_1_split -> h_7_lstm1x_unit_7_1_split_1
I0521 09:36:45.841964  3675 net.cpp:150] Setting up h_7_lstm1x_unit_7_1_split
I0521 09:36:45.841967  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.841970  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.841972  3675 net.cpp:165] Memory required for data: 28125184
I0521 09:36:45.841974  3675 layer_factory.hpp:77] Creating layer lstm1x_h_conted_7
I0521 09:36:45.841979  3675 net.cpp:100] Creating Layer lstm1x_h_conted_7
I0521 09:36:45.841980  3675 net.cpp:434] lstm1x_h_conted_7 <- h_7_lstm1x_unit_7_1_split_0
I0521 09:36:45.841994  3675 net.cpp:434] lstm1x_h_conted_7 <- cont_8_lstm1x_cont_slice_7_split_0
I0521 09:36:45.841997  3675 net.cpp:408] lstm1x_h_conted_7 -> h_conted_7
I0521 09:36:45.842041  3675 net.cpp:150] Setting up lstm1x_h_conted_7
I0521 09:36:45.842043  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.842046  3675 net.cpp:165] Memory required for data: 28176384
I0521 09:36:45.842048  3675 layer_factory.hpp:77] Creating layer lstm1x_transform_8
I0521 09:36:45.842052  3675 net.cpp:100] Creating Layer lstm1x_transform_8
I0521 09:36:45.842054  3675 net.cpp:434] lstm1x_transform_8 <- h_conted_7
I0521 09:36:45.842058  3675 net.cpp:408] lstm1x_transform_8 -> W_hc_h_7
I0521 09:36:45.842258  3675 net.cpp:150] Setting up lstm1x_transform_8
I0521 09:36:45.842262  3675 net.cpp:157] Top shape: 1 128 400 (51200)
I0521 09:36:45.842264  3675 net.cpp:165] Memory required for data: 28381184
I0521 09:36:45.842267  3675 net.cpp:493] Sharing parameters 'W_hc' owned by layer 'lstm1x_transform_1', param index 0
I0521 09:36:45.842269  3675 layer_factory.hpp:77] Creating layer lstm1x_gate_input_8
I0521 09:36:45.842273  3675 net.cpp:100] Creating Layer lstm1x_gate_input_8
I0521 09:36:45.842275  3675 net.cpp:434] lstm1x_gate_input_8 <- W_hc_h_7
I0521 09:36:45.842278  3675 net.cpp:434] lstm1x_gate_input_8 <- W_xc_x_8
I0521 09:36:45.842281  3675 net.cpp:408] lstm1x_gate_input_8 -> gate_input_8
I0521 09:36:45.842296  3675 net.cpp:150] Setting up lstm1x_gate_input_8
I0521 09:36:45.842299  3675 net.cpp:157] Top shape: 1 128 400 (51200)
I0521 09:36:45.842303  3675 net.cpp:165] Memory required for data: 28585984
I0521 09:36:45.842306  3675 layer_factory.hpp:77] Creating layer lstm1x_unit_8
I0521 09:36:45.842311  3675 net.cpp:100] Creating Layer lstm1x_unit_8
I0521 09:36:45.842314  3675 net.cpp:434] lstm1x_unit_8 <- c_7
I0521 09:36:45.842319  3675 net.cpp:434] lstm1x_unit_8 <- gate_input_8
I0521 09:36:45.842322  3675 net.cpp:434] lstm1x_unit_8 <- cont_8_lstm1x_cont_slice_7_split_1
I0521 09:36:45.842327  3675 net.cpp:408] lstm1x_unit_8 -> c_8
I0521 09:36:45.842332  3675 net.cpp:408] lstm1x_unit_8 -> h_8
I0521 09:36:45.842368  3675 net.cpp:150] Setting up lstm1x_unit_8
I0521 09:36:45.842372  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.842376  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.842380  3675 net.cpp:165] Memory required for data: 28688384
I0521 09:36:45.842382  3675 layer_factory.hpp:77] Creating layer h_8_lstm1x_unit_8_1_split
I0521 09:36:45.842387  3675 net.cpp:100] Creating Layer h_8_lstm1x_unit_8_1_split
I0521 09:36:45.842391  3675 net.cpp:434] h_8_lstm1x_unit_8_1_split <- h_8
I0521 09:36:45.842396  3675 net.cpp:408] h_8_lstm1x_unit_8_1_split -> h_8_lstm1x_unit_8_1_split_0
I0521 09:36:45.842401  3675 net.cpp:408] h_8_lstm1x_unit_8_1_split -> h_8_lstm1x_unit_8_1_split_1
I0521 09:36:45.842429  3675 net.cpp:150] Setting up h_8_lstm1x_unit_8_1_split
I0521 09:36:45.842433  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.842437  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.842440  3675 net.cpp:165] Memory required for data: 28790784
I0521 09:36:45.842443  3675 layer_factory.hpp:77] Creating layer lstm1x_h_conted_8
I0521 09:36:45.842448  3675 net.cpp:100] Creating Layer lstm1x_h_conted_8
I0521 09:36:45.842451  3675 net.cpp:434] lstm1x_h_conted_8 <- h_8_lstm1x_unit_8_1_split_0
I0521 09:36:45.842461  3675 net.cpp:434] lstm1x_h_conted_8 <- cont_9_lstm1x_cont_slice_8_split_0
I0521 09:36:45.842466  3675 net.cpp:408] lstm1x_h_conted_8 -> h_conted_8
I0521 09:36:45.842512  3675 net.cpp:150] Setting up lstm1x_h_conted_8
I0521 09:36:45.842517  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.842520  3675 net.cpp:165] Memory required for data: 28841984
I0521 09:36:45.842523  3675 layer_factory.hpp:77] Creating layer lstm1x_transform_9
I0521 09:36:45.842530  3675 net.cpp:100] Creating Layer lstm1x_transform_9
I0521 09:36:45.842533  3675 net.cpp:434] lstm1x_transform_9 <- h_conted_8
I0521 09:36:45.842538  3675 net.cpp:408] lstm1x_transform_9 -> W_hc_h_8
I0521 09:36:45.842762  3675 net.cpp:150] Setting up lstm1x_transform_9
I0521 09:36:45.842767  3675 net.cpp:157] Top shape: 1 128 400 (51200)
I0521 09:36:45.842769  3675 net.cpp:165] Memory required for data: 29046784
I0521 09:36:45.842772  3675 net.cpp:493] Sharing parameters 'W_hc' owned by layer 'lstm1x_transform_1', param index 0
I0521 09:36:45.842774  3675 layer_factory.hpp:77] Creating layer lstm1x_gate_input_9
I0521 09:36:45.842777  3675 net.cpp:100] Creating Layer lstm1x_gate_input_9
I0521 09:36:45.842780  3675 net.cpp:434] lstm1x_gate_input_9 <- W_hc_h_8
I0521 09:36:45.842783  3675 net.cpp:434] lstm1x_gate_input_9 <- W_xc_x_9
I0521 09:36:45.842787  3675 net.cpp:408] lstm1x_gate_input_9 -> gate_input_9
I0521 09:36:45.842800  3675 net.cpp:150] Setting up lstm1x_gate_input_9
I0521 09:36:45.842803  3675 net.cpp:157] Top shape: 1 128 400 (51200)
I0521 09:36:45.842805  3675 net.cpp:165] Memory required for data: 29251584
I0521 09:36:45.842808  3675 layer_factory.hpp:77] Creating layer lstm1x_unit_9
I0521 09:36:45.842815  3675 net.cpp:100] Creating Layer lstm1x_unit_9
I0521 09:36:45.842823  3675 net.cpp:434] lstm1x_unit_9 <- c_8
I0521 09:36:45.842828  3675 net.cpp:434] lstm1x_unit_9 <- gate_input_9
I0521 09:36:45.842831  3675 net.cpp:434] lstm1x_unit_9 <- cont_9_lstm1x_cont_slice_8_split_1
I0521 09:36:45.842835  3675 net.cpp:408] lstm1x_unit_9 -> c_9
I0521 09:36:45.842844  3675 net.cpp:408] lstm1x_unit_9 -> h_9
I0521 09:36:45.842872  3675 net.cpp:150] Setting up lstm1x_unit_9
I0521 09:36:45.842876  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.842880  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.842881  3675 net.cpp:165] Memory required for data: 29353984
I0521 09:36:45.842885  3675 layer_factory.hpp:77] Creating layer h_9_lstm1x_unit_9_1_split
I0521 09:36:45.842887  3675 net.cpp:100] Creating Layer h_9_lstm1x_unit_9_1_split
I0521 09:36:45.842890  3675 net.cpp:434] h_9_lstm1x_unit_9_1_split <- h_9
I0521 09:36:45.842893  3675 net.cpp:408] h_9_lstm1x_unit_9_1_split -> h_9_lstm1x_unit_9_1_split_0
I0521 09:36:45.842897  3675 net.cpp:408] h_9_lstm1x_unit_9_1_split -> h_9_lstm1x_unit_9_1_split_1
I0521 09:36:45.842921  3675 net.cpp:150] Setting up h_9_lstm1x_unit_9_1_split
I0521 09:36:45.842926  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.842931  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.842933  3675 net.cpp:165] Memory required for data: 29456384
I0521 09:36:45.842936  3675 layer_factory.hpp:77] Creating layer lstm1x_h_conted_9
I0521 09:36:45.842941  3675 net.cpp:100] Creating Layer lstm1x_h_conted_9
I0521 09:36:45.842945  3675 net.cpp:434] lstm1x_h_conted_9 <- h_9_lstm1x_unit_9_1_split_0
I0521 09:36:45.842949  3675 net.cpp:434] lstm1x_h_conted_9 <- cont_10_lstm1x_cont_slice_9_split_0
I0521 09:36:45.842954  3675 net.cpp:408] lstm1x_h_conted_9 -> h_conted_9
I0521 09:36:45.843001  3675 net.cpp:150] Setting up lstm1x_h_conted_9
I0521 09:36:45.843006  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.843008  3675 net.cpp:165] Memory required for data: 29507584
I0521 09:36:45.843010  3675 layer_factory.hpp:77] Creating layer lstm1x_transform_10
I0521 09:36:45.843017  3675 net.cpp:100] Creating Layer lstm1x_transform_10
I0521 09:36:45.843020  3675 net.cpp:434] lstm1x_transform_10 <- h_conted_9
I0521 09:36:45.843025  3675 net.cpp:408] lstm1x_transform_10 -> W_hc_h_9
I0521 09:36:45.843267  3675 net.cpp:150] Setting up lstm1x_transform_10
I0521 09:36:45.843271  3675 net.cpp:157] Top shape: 1 128 400 (51200)
I0521 09:36:45.843273  3675 net.cpp:165] Memory required for data: 29712384
I0521 09:36:45.843276  3675 net.cpp:493] Sharing parameters 'W_hc' owned by layer 'lstm1x_transform_1', param index 0
I0521 09:36:45.843278  3675 layer_factory.hpp:77] Creating layer lstm1x_gate_input_10
I0521 09:36:45.843283  3675 net.cpp:100] Creating Layer lstm1x_gate_input_10
I0521 09:36:45.843286  3675 net.cpp:434] lstm1x_gate_input_10 <- W_hc_h_9
I0521 09:36:45.843288  3675 net.cpp:434] lstm1x_gate_input_10 <- W_xc_x_10
I0521 09:36:45.843291  3675 net.cpp:408] lstm1x_gate_input_10 -> gate_input_10
I0521 09:36:45.843317  3675 net.cpp:150] Setting up lstm1x_gate_input_10
I0521 09:36:45.843319  3675 net.cpp:157] Top shape: 1 128 400 (51200)
I0521 09:36:45.843322  3675 net.cpp:165] Memory required for data: 29917184
I0521 09:36:45.843324  3675 layer_factory.hpp:77] Creating layer lstm1x_unit_10
I0521 09:36:45.843329  3675 net.cpp:100] Creating Layer lstm1x_unit_10
I0521 09:36:45.843331  3675 net.cpp:434] lstm1x_unit_10 <- c_9
I0521 09:36:45.843334  3675 net.cpp:434] lstm1x_unit_10 <- gate_input_10
I0521 09:36:45.843338  3675 net.cpp:434] lstm1x_unit_10 <- cont_10_lstm1x_cont_slice_9_split_1
I0521 09:36:45.843340  3675 net.cpp:408] lstm1x_unit_10 -> c_10
I0521 09:36:45.843344  3675 net.cpp:408] lstm1x_unit_10 -> h_10
I0521 09:36:45.843372  3675 net.cpp:150] Setting up lstm1x_unit_10
I0521 09:36:45.843375  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.843379  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.843380  3675 net.cpp:165] Memory required for data: 30019584
I0521 09:36:45.843382  3675 layer_factory.hpp:77] Creating layer h_10_lstm1x_unit_10_1_split
I0521 09:36:45.843387  3675 net.cpp:100] Creating Layer h_10_lstm1x_unit_10_1_split
I0521 09:36:45.843389  3675 net.cpp:434] h_10_lstm1x_unit_10_1_split <- h_10
I0521 09:36:45.843394  3675 net.cpp:408] h_10_lstm1x_unit_10_1_split -> h_10_lstm1x_unit_10_1_split_0
I0521 09:36:45.843397  3675 net.cpp:408] h_10_lstm1x_unit_10_1_split -> h_10_lstm1x_unit_10_1_split_1
I0521 09:36:45.843417  3675 net.cpp:150] Setting up h_10_lstm1x_unit_10_1_split
I0521 09:36:45.843422  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.843425  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.843427  3675 net.cpp:165] Memory required for data: 30121984
I0521 09:36:45.843430  3675 layer_factory.hpp:77] Creating layer lstm1x_h_conted_10
I0521 09:36:45.843432  3675 net.cpp:100] Creating Layer lstm1x_h_conted_10
I0521 09:36:45.843436  3675 net.cpp:434] lstm1x_h_conted_10 <- h_10_lstm1x_unit_10_1_split_0
I0521 09:36:45.843438  3675 net.cpp:434] lstm1x_h_conted_10 <- cont_11_lstm1x_cont_slice_10_split_0
I0521 09:36:45.843441  3675 net.cpp:408] lstm1x_h_conted_10 -> h_conted_10
I0521 09:36:45.843479  3675 net.cpp:150] Setting up lstm1x_h_conted_10
I0521 09:36:45.843483  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.843485  3675 net.cpp:165] Memory required for data: 30173184
I0521 09:36:45.843487  3675 layer_factory.hpp:77] Creating layer lstm1x_transform_11
I0521 09:36:45.843492  3675 net.cpp:100] Creating Layer lstm1x_transform_11
I0521 09:36:45.843494  3675 net.cpp:434] lstm1x_transform_11 <- h_conted_10
I0521 09:36:45.843500  3675 net.cpp:408] lstm1x_transform_11 -> W_hc_h_10
I0521 09:36:45.843732  3675 net.cpp:150] Setting up lstm1x_transform_11
I0521 09:36:45.843736  3675 net.cpp:157] Top shape: 1 128 400 (51200)
I0521 09:36:45.843739  3675 net.cpp:165] Memory required for data: 30377984
I0521 09:36:45.843740  3675 net.cpp:493] Sharing parameters 'W_hc' owned by layer 'lstm1x_transform_1', param index 0
I0521 09:36:45.843744  3675 layer_factory.hpp:77] Creating layer lstm1x_gate_input_11
I0521 09:36:45.843746  3675 net.cpp:100] Creating Layer lstm1x_gate_input_11
I0521 09:36:45.843750  3675 net.cpp:434] lstm1x_gate_input_11 <- W_hc_h_10
I0521 09:36:45.843751  3675 net.cpp:434] lstm1x_gate_input_11 <- W_xc_x_11
I0521 09:36:45.843755  3675 net.cpp:408] lstm1x_gate_input_11 -> gate_input_11
I0521 09:36:45.843768  3675 net.cpp:150] Setting up lstm1x_gate_input_11
I0521 09:36:45.843771  3675 net.cpp:157] Top shape: 1 128 400 (51200)
I0521 09:36:45.843773  3675 net.cpp:165] Memory required for data: 30582784
I0521 09:36:45.843776  3675 layer_factory.hpp:77] Creating layer lstm1x_unit_11
I0521 09:36:45.843780  3675 net.cpp:100] Creating Layer lstm1x_unit_11
I0521 09:36:45.843781  3675 net.cpp:434] lstm1x_unit_11 <- c_10
I0521 09:36:45.843786  3675 net.cpp:434] lstm1x_unit_11 <- gate_input_11
I0521 09:36:45.843787  3675 net.cpp:434] lstm1x_unit_11 <- cont_11_lstm1x_cont_slice_10_split_1
I0521 09:36:45.843791  3675 net.cpp:408] lstm1x_unit_11 -> c_11
I0521 09:36:45.843801  3675 net.cpp:408] lstm1x_unit_11 -> h_11
I0521 09:36:45.843830  3675 net.cpp:150] Setting up lstm1x_unit_11
I0521 09:36:45.843833  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.843837  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.843838  3675 net.cpp:165] Memory required for data: 30685184
I0521 09:36:45.843840  3675 layer_factory.hpp:77] Creating layer h_11_lstm1x_unit_11_1_split
I0521 09:36:45.843843  3675 net.cpp:100] Creating Layer h_11_lstm1x_unit_11_1_split
I0521 09:36:45.843847  3675 net.cpp:434] h_11_lstm1x_unit_11_1_split <- h_11
I0521 09:36:45.843849  3675 net.cpp:408] h_11_lstm1x_unit_11_1_split -> h_11_lstm1x_unit_11_1_split_0
I0521 09:36:45.843853  3675 net.cpp:408] h_11_lstm1x_unit_11_1_split -> h_11_lstm1x_unit_11_1_split_1
I0521 09:36:45.843876  3675 net.cpp:150] Setting up h_11_lstm1x_unit_11_1_split
I0521 09:36:45.843879  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.843883  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.843884  3675 net.cpp:165] Memory required for data: 30787584
I0521 09:36:45.843886  3675 layer_factory.hpp:77] Creating layer lstm1x_h_conted_11
I0521 09:36:45.843890  3675 net.cpp:100] Creating Layer lstm1x_h_conted_11
I0521 09:36:45.843892  3675 net.cpp:434] lstm1x_h_conted_11 <- h_11_lstm1x_unit_11_1_split_0
I0521 09:36:45.843895  3675 net.cpp:434] lstm1x_h_conted_11 <- cont_12_lstm1x_cont_slice_11_split_0
I0521 09:36:45.843900  3675 net.cpp:408] lstm1x_h_conted_11 -> h_conted_11
I0521 09:36:45.843937  3675 net.cpp:150] Setting up lstm1x_h_conted_11
I0521 09:36:45.843940  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.843942  3675 net.cpp:165] Memory required for data: 30838784
I0521 09:36:45.843945  3675 layer_factory.hpp:77] Creating layer lstm1x_transform_12
I0521 09:36:45.843950  3675 net.cpp:100] Creating Layer lstm1x_transform_12
I0521 09:36:45.843951  3675 net.cpp:434] lstm1x_transform_12 <- h_conted_11
I0521 09:36:45.843955  3675 net.cpp:408] lstm1x_transform_12 -> W_hc_h_11
I0521 09:36:45.844151  3675 net.cpp:150] Setting up lstm1x_transform_12
I0521 09:36:45.844156  3675 net.cpp:157] Top shape: 1 128 400 (51200)
I0521 09:36:45.844159  3675 net.cpp:165] Memory required for data: 31043584
I0521 09:36:45.844162  3675 net.cpp:493] Sharing parameters 'W_hc' owned by layer 'lstm1x_transform_1', param index 0
I0521 09:36:45.844166  3675 layer_factory.hpp:77] Creating layer lstm1x_gate_input_12
I0521 09:36:45.844171  3675 net.cpp:100] Creating Layer lstm1x_gate_input_12
I0521 09:36:45.844173  3675 net.cpp:434] lstm1x_gate_input_12 <- W_hc_h_11
I0521 09:36:45.844177  3675 net.cpp:434] lstm1x_gate_input_12 <- W_xc_x_12
I0521 09:36:45.844183  3675 net.cpp:408] lstm1x_gate_input_12 -> gate_input_12
I0521 09:36:45.844197  3675 net.cpp:150] Setting up lstm1x_gate_input_12
I0521 09:36:45.844202  3675 net.cpp:157] Top shape: 1 128 400 (51200)
I0521 09:36:45.844204  3675 net.cpp:165] Memory required for data: 31248384
I0521 09:36:45.844208  3675 layer_factory.hpp:77] Creating layer lstm1x_unit_12
I0521 09:36:45.844211  3675 net.cpp:100] Creating Layer lstm1x_unit_12
I0521 09:36:45.844214  3675 net.cpp:434] lstm1x_unit_12 <- c_11
I0521 09:36:45.844218  3675 net.cpp:434] lstm1x_unit_12 <- gate_input_12
I0521 09:36:45.844223  3675 net.cpp:434] lstm1x_unit_12 <- cont_12_lstm1x_cont_slice_11_split_1
I0521 09:36:45.844228  3675 net.cpp:408] lstm1x_unit_12 -> c_12
I0521 09:36:45.844231  3675 net.cpp:408] lstm1x_unit_12 -> h_12
I0521 09:36:45.844265  3675 net.cpp:150] Setting up lstm1x_unit_12
I0521 09:36:45.844269  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.844272  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.844274  3675 net.cpp:165] Memory required for data: 31350784
I0521 09:36:45.844276  3675 layer_factory.hpp:77] Creating layer h_12_lstm1x_unit_12_1_split
I0521 09:36:45.844280  3675 net.cpp:100] Creating Layer h_12_lstm1x_unit_12_1_split
I0521 09:36:45.844282  3675 net.cpp:434] h_12_lstm1x_unit_12_1_split <- h_12
I0521 09:36:45.844291  3675 net.cpp:408] h_12_lstm1x_unit_12_1_split -> h_12_lstm1x_unit_12_1_split_0
I0521 09:36:45.844296  3675 net.cpp:408] h_12_lstm1x_unit_12_1_split -> h_12_lstm1x_unit_12_1_split_1
I0521 09:36:45.844317  3675 net.cpp:150] Setting up h_12_lstm1x_unit_12_1_split
I0521 09:36:45.844321  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.844323  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.844326  3675 net.cpp:165] Memory required for data: 31453184
I0521 09:36:45.844327  3675 layer_factory.hpp:77] Creating layer lstm1x_h_conted_12
I0521 09:36:45.844332  3675 net.cpp:100] Creating Layer lstm1x_h_conted_12
I0521 09:36:45.844334  3675 net.cpp:434] lstm1x_h_conted_12 <- h_12_lstm1x_unit_12_1_split_0
I0521 09:36:45.844337  3675 net.cpp:434] lstm1x_h_conted_12 <- cont_13_lstm1x_cont_slice_12_split_0
I0521 09:36:45.844341  3675 net.cpp:408] lstm1x_h_conted_12 -> h_conted_12
I0521 09:36:45.844378  3675 net.cpp:150] Setting up lstm1x_h_conted_12
I0521 09:36:45.844382  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.844383  3675 net.cpp:165] Memory required for data: 31504384
I0521 09:36:45.844385  3675 layer_factory.hpp:77] Creating layer lstm1x_transform_13
I0521 09:36:45.844390  3675 net.cpp:100] Creating Layer lstm1x_transform_13
I0521 09:36:45.844393  3675 net.cpp:434] lstm1x_transform_13 <- h_conted_12
I0521 09:36:45.844396  3675 net.cpp:408] lstm1x_transform_13 -> W_hc_h_12
I0521 09:36:45.845263  3675 net.cpp:150] Setting up lstm1x_transform_13
I0521 09:36:45.845278  3675 net.cpp:157] Top shape: 1 128 400 (51200)
I0521 09:36:45.845280  3675 net.cpp:165] Memory required for data: 31709184
I0521 09:36:45.845284  3675 net.cpp:493] Sharing parameters 'W_hc' owned by layer 'lstm1x_transform_1', param index 0
I0521 09:36:45.845288  3675 layer_factory.hpp:77] Creating layer lstm1x_gate_input_13
I0521 09:36:45.845293  3675 net.cpp:100] Creating Layer lstm1x_gate_input_13
I0521 09:36:45.845295  3675 net.cpp:434] lstm1x_gate_input_13 <- W_hc_h_12
I0521 09:36:45.845300  3675 net.cpp:434] lstm1x_gate_input_13 <- W_xc_x_13
I0521 09:36:45.845304  3675 net.cpp:408] lstm1x_gate_input_13 -> gate_input_13
I0521 09:36:45.845324  3675 net.cpp:150] Setting up lstm1x_gate_input_13
I0521 09:36:45.845326  3675 net.cpp:157] Top shape: 1 128 400 (51200)
I0521 09:36:45.845329  3675 net.cpp:165] Memory required for data: 31913984
I0521 09:36:45.845330  3675 layer_factory.hpp:77] Creating layer lstm1x_unit_13
I0521 09:36:45.845335  3675 net.cpp:100] Creating Layer lstm1x_unit_13
I0521 09:36:45.845337  3675 net.cpp:434] lstm1x_unit_13 <- c_12
I0521 09:36:45.845341  3675 net.cpp:434] lstm1x_unit_13 <- gate_input_13
I0521 09:36:45.845343  3675 net.cpp:434] lstm1x_unit_13 <- cont_13_lstm1x_cont_slice_12_split_1
I0521 09:36:45.845347  3675 net.cpp:408] lstm1x_unit_13 -> c_13
I0521 09:36:45.845351  3675 net.cpp:408] lstm1x_unit_13 -> h_13
I0521 09:36:45.845379  3675 net.cpp:150] Setting up lstm1x_unit_13
I0521 09:36:45.845383  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.845386  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.845387  3675 net.cpp:165] Memory required for data: 32016384
I0521 09:36:45.845391  3675 layer_factory.hpp:77] Creating layer h_13_lstm1x_unit_13_1_split
I0521 09:36:45.845394  3675 net.cpp:100] Creating Layer h_13_lstm1x_unit_13_1_split
I0521 09:36:45.845397  3675 net.cpp:434] h_13_lstm1x_unit_13_1_split <- h_13
I0521 09:36:45.845401  3675 net.cpp:408] h_13_lstm1x_unit_13_1_split -> h_13_lstm1x_unit_13_1_split_0
I0521 09:36:45.845404  3675 net.cpp:408] h_13_lstm1x_unit_13_1_split -> h_13_lstm1x_unit_13_1_split_1
I0521 09:36:45.845425  3675 net.cpp:150] Setting up h_13_lstm1x_unit_13_1_split
I0521 09:36:45.845428  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.845432  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.845433  3675 net.cpp:165] Memory required for data: 32118784
I0521 09:36:45.845435  3675 layer_factory.hpp:77] Creating layer lstm1x_h_conted_13
I0521 09:36:45.845439  3675 net.cpp:100] Creating Layer lstm1x_h_conted_13
I0521 09:36:45.845453  3675 net.cpp:434] lstm1x_h_conted_13 <- h_13_lstm1x_unit_13_1_split_0
I0521 09:36:45.845456  3675 net.cpp:434] lstm1x_h_conted_13 <- cont_14_lstm1x_cont_slice_13_split_0
I0521 09:36:45.845460  3675 net.cpp:408] lstm1x_h_conted_13 -> h_conted_13
I0521 09:36:45.845504  3675 net.cpp:150] Setting up lstm1x_h_conted_13
I0521 09:36:45.845506  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.845508  3675 net.cpp:165] Memory required for data: 32169984
I0521 09:36:45.845510  3675 layer_factory.hpp:77] Creating layer lstm1x_transform_14
I0521 09:36:45.845516  3675 net.cpp:100] Creating Layer lstm1x_transform_14
I0521 09:36:45.845518  3675 net.cpp:434] lstm1x_transform_14 <- h_conted_13
I0521 09:36:45.845522  3675 net.cpp:408] lstm1x_transform_14 -> W_hc_h_13
I0521 09:36:45.845721  3675 net.cpp:150] Setting up lstm1x_transform_14
I0521 09:36:45.845726  3675 net.cpp:157] Top shape: 1 128 400 (51200)
I0521 09:36:45.845727  3675 net.cpp:165] Memory required for data: 32374784
I0521 09:36:45.845729  3675 net.cpp:493] Sharing parameters 'W_hc' owned by layer 'lstm1x_transform_1', param index 0
I0521 09:36:45.845732  3675 layer_factory.hpp:77] Creating layer lstm1x_gate_input_14
I0521 09:36:45.845736  3675 net.cpp:100] Creating Layer lstm1x_gate_input_14
I0521 09:36:45.845738  3675 net.cpp:434] lstm1x_gate_input_14 <- W_hc_h_13
I0521 09:36:45.845741  3675 net.cpp:434] lstm1x_gate_input_14 <- W_xc_x_14
I0521 09:36:45.845744  3675 net.cpp:408] lstm1x_gate_input_14 -> gate_input_14
I0521 09:36:45.845758  3675 net.cpp:150] Setting up lstm1x_gate_input_14
I0521 09:36:45.845762  3675 net.cpp:157] Top shape: 1 128 400 (51200)
I0521 09:36:45.845763  3675 net.cpp:165] Memory required for data: 32579584
I0521 09:36:45.845765  3675 layer_factory.hpp:77] Creating layer lstm1x_unit_14
I0521 09:36:45.845769  3675 net.cpp:100] Creating Layer lstm1x_unit_14
I0521 09:36:45.845772  3675 net.cpp:434] lstm1x_unit_14 <- c_13
I0521 09:36:45.845774  3675 net.cpp:434] lstm1x_unit_14 <- gate_input_14
I0521 09:36:45.845777  3675 net.cpp:434] lstm1x_unit_14 <- cont_14_lstm1x_cont_slice_13_split_1
I0521 09:36:45.845780  3675 net.cpp:408] lstm1x_unit_14 -> c_14
I0521 09:36:45.845784  3675 net.cpp:408] lstm1x_unit_14 -> h_14
I0521 09:36:45.845813  3675 net.cpp:150] Setting up lstm1x_unit_14
I0521 09:36:45.845815  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.845818  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.845820  3675 net.cpp:165] Memory required for data: 32681984
I0521 09:36:45.845822  3675 layer_factory.hpp:77] Creating layer h_14_lstm1x_unit_14_1_split
I0521 09:36:45.845827  3675 net.cpp:100] Creating Layer h_14_lstm1x_unit_14_1_split
I0521 09:36:45.845830  3675 net.cpp:434] h_14_lstm1x_unit_14_1_split <- h_14
I0521 09:36:45.845834  3675 net.cpp:408] h_14_lstm1x_unit_14_1_split -> h_14_lstm1x_unit_14_1_split_0
I0521 09:36:45.845837  3675 net.cpp:408] h_14_lstm1x_unit_14_1_split -> h_14_lstm1x_unit_14_1_split_1
I0521 09:36:45.845858  3675 net.cpp:150] Setting up h_14_lstm1x_unit_14_1_split
I0521 09:36:45.845862  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.845865  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.845867  3675 net.cpp:165] Memory required for data: 32784384
I0521 09:36:45.845870  3675 layer_factory.hpp:77] Creating layer lstm1x_h_conted_14
I0521 09:36:45.845872  3675 net.cpp:100] Creating Layer lstm1x_h_conted_14
I0521 09:36:45.845875  3675 net.cpp:434] lstm1x_h_conted_14 <- h_14_lstm1x_unit_14_1_split_0
I0521 09:36:45.845878  3675 net.cpp:434] lstm1x_h_conted_14 <- cont_15_lstm1x_cont_slice_14_split_0
I0521 09:36:45.845881  3675 net.cpp:408] lstm1x_h_conted_14 -> h_conted_14
I0521 09:36:45.845921  3675 net.cpp:150] Setting up lstm1x_h_conted_14
I0521 09:36:45.845924  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.845927  3675 net.cpp:165] Memory required for data: 32835584
I0521 09:36:45.845929  3675 layer_factory.hpp:77] Creating layer lstm1x_transform_15
I0521 09:36:45.845934  3675 net.cpp:100] Creating Layer lstm1x_transform_15
I0521 09:36:45.845942  3675 net.cpp:434] lstm1x_transform_15 <- h_conted_14
I0521 09:36:45.845947  3675 net.cpp:408] lstm1x_transform_15 -> W_hc_h_14
I0521 09:36:45.846139  3675 net.cpp:150] Setting up lstm1x_transform_15
I0521 09:36:45.846143  3675 net.cpp:157] Top shape: 1 128 400 (51200)
I0521 09:36:45.846145  3675 net.cpp:165] Memory required for data: 33040384
I0521 09:36:45.846149  3675 net.cpp:493] Sharing parameters 'W_hc' owned by layer 'lstm1x_transform_1', param index 0
I0521 09:36:45.846151  3675 layer_factory.hpp:77] Creating layer lstm1x_gate_input_15
I0521 09:36:45.846155  3675 net.cpp:100] Creating Layer lstm1x_gate_input_15
I0521 09:36:45.846158  3675 net.cpp:434] lstm1x_gate_input_15 <- W_hc_h_14
I0521 09:36:45.846160  3675 net.cpp:434] lstm1x_gate_input_15 <- W_xc_x_15
I0521 09:36:45.846163  3675 net.cpp:408] lstm1x_gate_input_15 -> gate_input_15
I0521 09:36:45.846177  3675 net.cpp:150] Setting up lstm1x_gate_input_15
I0521 09:36:45.846180  3675 net.cpp:157] Top shape: 1 128 400 (51200)
I0521 09:36:45.846182  3675 net.cpp:165] Memory required for data: 33245184
I0521 09:36:45.846184  3675 layer_factory.hpp:77] Creating layer lstm1x_unit_15
I0521 09:36:45.846189  3675 net.cpp:100] Creating Layer lstm1x_unit_15
I0521 09:36:45.846191  3675 net.cpp:434] lstm1x_unit_15 <- c_14
I0521 09:36:45.846194  3675 net.cpp:434] lstm1x_unit_15 <- gate_input_15
I0521 09:36:45.846197  3675 net.cpp:434] lstm1x_unit_15 <- cont_15_lstm1x_cont_slice_14_split_1
I0521 09:36:45.846200  3675 net.cpp:408] lstm1x_unit_15 -> c_15
I0521 09:36:45.846204  3675 net.cpp:408] lstm1x_unit_15 -> h_15
I0521 09:36:45.846233  3675 net.cpp:150] Setting up lstm1x_unit_15
I0521 09:36:45.846236  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.846240  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.846241  3675 net.cpp:165] Memory required for data: 33347584
I0521 09:36:45.846243  3675 layer_factory.hpp:77] Creating layer h_15_lstm1x_unit_15_1_split
I0521 09:36:45.846247  3675 net.cpp:100] Creating Layer h_15_lstm1x_unit_15_1_split
I0521 09:36:45.846249  3675 net.cpp:434] h_15_lstm1x_unit_15_1_split <- h_15
I0521 09:36:45.846252  3675 net.cpp:408] h_15_lstm1x_unit_15_1_split -> h_15_lstm1x_unit_15_1_split_0
I0521 09:36:45.846256  3675 net.cpp:408] h_15_lstm1x_unit_15_1_split -> h_15_lstm1x_unit_15_1_split_1
I0521 09:36:45.846278  3675 net.cpp:150] Setting up h_15_lstm1x_unit_15_1_split
I0521 09:36:45.846282  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.846284  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.846287  3675 net.cpp:165] Memory required for data: 33449984
I0521 09:36:45.846289  3675 layer_factory.hpp:77] Creating layer lstm1x_h_conted_15
I0521 09:36:45.846293  3675 net.cpp:100] Creating Layer lstm1x_h_conted_15
I0521 09:36:45.846297  3675 net.cpp:434] lstm1x_h_conted_15 <- h_15_lstm1x_unit_15_1_split_0
I0521 09:36:45.846298  3675 net.cpp:434] lstm1x_h_conted_15 <- cont_16_lstm1x_cont_slice_15_split_0
I0521 09:36:45.846303  3675 net.cpp:408] lstm1x_h_conted_15 -> h_conted_15
I0521 09:36:45.846341  3675 net.cpp:150] Setting up lstm1x_h_conted_15
I0521 09:36:45.846344  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.846346  3675 net.cpp:165] Memory required for data: 33501184
I0521 09:36:45.846349  3675 layer_factory.hpp:77] Creating layer lstm1x_transform_16
I0521 09:36:45.846354  3675 net.cpp:100] Creating Layer lstm1x_transform_16
I0521 09:36:45.846357  3675 net.cpp:434] lstm1x_transform_16 <- h_conted_15
I0521 09:36:45.846360  3675 net.cpp:408] lstm1x_transform_16 -> W_hc_h_15
I0521 09:36:45.846570  3675 net.cpp:150] Setting up lstm1x_transform_16
I0521 09:36:45.846576  3675 net.cpp:157] Top shape: 1 128 400 (51200)
I0521 09:36:45.846578  3675 net.cpp:165] Memory required for data: 33705984
I0521 09:36:45.846581  3675 net.cpp:493] Sharing parameters 'W_hc' owned by layer 'lstm1x_transform_1', param index 0
I0521 09:36:45.846585  3675 layer_factory.hpp:77] Creating layer lstm1x_gate_input_16
I0521 09:36:45.846588  3675 net.cpp:100] Creating Layer lstm1x_gate_input_16
I0521 09:36:45.846601  3675 net.cpp:434] lstm1x_gate_input_16 <- W_hc_h_15
I0521 09:36:45.846603  3675 net.cpp:434] lstm1x_gate_input_16 <- W_xc_x_16
I0521 09:36:45.846608  3675 net.cpp:408] lstm1x_gate_input_16 -> gate_input_16
I0521 09:36:45.846622  3675 net.cpp:150] Setting up lstm1x_gate_input_16
I0521 09:36:45.846626  3675 net.cpp:157] Top shape: 1 128 400 (51200)
I0521 09:36:45.846628  3675 net.cpp:165] Memory required for data: 33910784
I0521 09:36:45.846630  3675 layer_factory.hpp:77] Creating layer lstm1x_unit_16
I0521 09:36:45.846634  3675 net.cpp:100] Creating Layer lstm1x_unit_16
I0521 09:36:45.846637  3675 net.cpp:434] lstm1x_unit_16 <- c_15
I0521 09:36:45.846640  3675 net.cpp:434] lstm1x_unit_16 <- gate_input_16
I0521 09:36:45.846642  3675 net.cpp:434] lstm1x_unit_16 <- cont_16_lstm1x_cont_slice_15_split_1
I0521 09:36:45.846645  3675 net.cpp:408] lstm1x_unit_16 -> c_16
I0521 09:36:45.846650  3675 net.cpp:408] lstm1x_unit_16 -> h_16
I0521 09:36:45.846681  3675 net.cpp:150] Setting up lstm1x_unit_16
I0521 09:36:45.846685  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.846688  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.846690  3675 net.cpp:165] Memory required for data: 34013184
I0521 09:36:45.846693  3675 layer_factory.hpp:77] Creating layer lstm1x_
I0521 09:36:45.846695  3675 net.cpp:100] Creating Layer lstm1x_
I0521 09:36:45.846698  3675 net.cpp:434] lstm1x_ <- c_16
I0521 09:36:45.846701  3675 net.cpp:408] lstm1x_ -> c_T
I0521 09:36:45.846714  3675 net.cpp:150] Setting up lstm1x_
I0521 09:36:45.846719  3675 net.cpp:157] Top shape: 1 128 100 (12800)
I0521 09:36:45.846720  3675 net.cpp:165] Memory required for data: 34064384
I0521 09:36:45.846722  3675 layer_factory.hpp:77] Creating layer lstm1x_h_concat
I0521 09:36:45.846729  3675 net.cpp:100] Creating Layer lstm1x_h_concat
I0521 09:36:45.846732  3675 net.cpp:434] lstm1x_h_concat <- h_1_lstm1x_unit_1_1_split_1
I0521 09:36:45.846735  3675 net.cpp:434] lstm1x_h_concat <- h_2_lstm1x_unit_2_1_split_1
I0521 09:36:45.846738  3675 net.cpp:434] lstm1x_h_concat <- h_3_lstm1x_unit_3_1_split_1
I0521 09:36:45.846740  3675 net.cpp:434] lstm1x_h_concat <- h_4_lstm1x_unit_4_1_split_1
I0521 09:36:45.846743  3675 net.cpp:434] lstm1x_h_concat <- h_5_lstm1x_unit_5_1_split_1
I0521 09:36:45.846746  3675 net.cpp:434] lstm1x_h_concat <- h_6_lstm1x_unit_6_1_split_1
I0521 09:36:45.846748  3675 net.cpp:434] lstm1x_h_concat <- h_7_lstm1x_unit_7_1_split_1
I0521 09:36:45.846751  3675 net.cpp:434] lstm1x_h_concat <- h_8_lstm1x_unit_8_1_split_1
I0521 09:36:45.846753  3675 net.cpp:434] lstm1x_h_concat <- h_9_lstm1x_unit_9_1_split_1
I0521 09:36:45.846757  3675 net.cpp:434] lstm1x_h_concat <- h_10_lstm1x_unit_10_1_split_1
I0521 09:36:45.846760  3675 net.cpp:434] lstm1x_h_concat <- h_11_lstm1x_unit_11_1_split_1
I0521 09:36:45.846762  3675 net.cpp:434] lstm1x_h_concat <- h_12_lstm1x_unit_12_1_split_1
I0521 09:36:45.846765  3675 net.cpp:434] lstm1x_h_concat <- h_13_lstm1x_unit_13_1_split_1
I0521 09:36:45.846767  3675 net.cpp:434] lstm1x_h_concat <- h_14_lstm1x_unit_14_1_split_1
I0521 09:36:45.846770  3675 net.cpp:434] lstm1x_h_concat <- h_15_lstm1x_unit_15_1_split_1
I0521 09:36:45.846772  3675 net.cpp:434] lstm1x_h_concat <- h_16
I0521 09:36:45.846776  3675 net.cpp:408] lstm1x_h_concat -> h
I0521 09:36:45.846792  3675 net.cpp:150] Setting up lstm1x_h_concat
I0521 09:36:45.846796  3675 net.cpp:157] Top shape: 16 128 100 (204800)
I0521 09:36:45.846797  3675 net.cpp:165] Memory required for data: 34883584
I0521 09:36:45.846799  3675 layer_factory.hpp:77] Creating layer h_pseudoloss
I0521 09:36:45.846804  3675 net.cpp:100] Creating Layer h_pseudoloss
I0521 09:36:45.846807  3675 net.cpp:434] h_pseudoloss <- h
I0521 09:36:45.846809  3675 net.cpp:408] h_pseudoloss -> h_pseudoloss
I0521 09:36:45.846966  3675 net.cpp:150] Setting up h_pseudoloss
I0521 09:36:45.846972  3675 net.cpp:157] Top shape: (1)
I0521 09:36:45.846974  3675 net.cpp:160]     with loss weight 1
I0521 09:36:45.846983  3675 net.cpp:165] Memory required for data: 34883588
I0521 09:36:45.846987  3675 net.cpp:226] h_pseudoloss needs backward computation.
I0521 09:36:45.846998  3675 net.cpp:226] lstm1x_h_concat needs backward computation.
I0521 09:36:45.847005  3675 net.cpp:228] lstm1x_ does not need backward computation.
I0521 09:36:45.847007  3675 net.cpp:226] lstm1x_unit_16 needs backward computation.
I0521 09:36:45.847012  3675 net.cpp:226] lstm1x_gate_input_16 needs backward computation.
I0521 09:36:45.847013  3675 net.cpp:226] lstm1x_transform_16 needs backward computation.
I0521 09:36:45.847016  3675 net.cpp:226] lstm1x_h_conted_15 needs backward computation.
I0521 09:36:45.847019  3675 net.cpp:226] h_15_lstm1x_unit_15_1_split needs backward computation.
I0521 09:36:45.847023  3675 net.cpp:226] lstm1x_unit_15 needs backward computation.
I0521 09:36:45.847025  3675 net.cpp:226] lstm1x_gate_input_15 needs backward computation.
I0521 09:36:45.847028  3675 net.cpp:226] lstm1x_transform_15 needs backward computation.
I0521 09:36:45.847030  3675 net.cpp:226] lstm1x_h_conted_14 needs backward computation.
I0521 09:36:45.847034  3675 net.cpp:226] h_14_lstm1x_unit_14_1_split needs backward computation.
I0521 09:36:45.850051  3675 net.cpp:226] lstm1x_unit_14 needs backward computation.
I0521 09:36:45.850059  3675 net.cpp:226] lstm1x_gate_input_14 needs backward computation.
I0521 09:36:45.850064  3675 net.cpp:226] lstm1x_transform_14 needs backward computation.
I0521 09:36:45.850067  3675 net.cpp:226] lstm1x_h_conted_13 needs backward computation.
I0521 09:36:45.850072  3675 net.cpp:226] h_13_lstm1x_unit_13_1_split needs backward computation.
I0521 09:36:45.850076  3675 net.cpp:226] lstm1x_unit_13 needs backward computation.
I0521 09:36:45.850083  3675 net.cpp:226] lstm1x_gate_input_13 needs backward computation.
I0521 09:36:45.850086  3675 net.cpp:226] lstm1x_transform_13 needs backward computation.
I0521 09:36:45.850090  3675 net.cpp:226] lstm1x_h_conted_12 needs backward computation.
I0521 09:36:45.850092  3675 net.cpp:226] h_12_lstm1x_unit_12_1_split needs backward computation.
I0521 09:36:45.850095  3675 net.cpp:226] lstm1x_unit_12 needs backward computation.
I0521 09:36:45.850098  3675 net.cpp:226] lstm1x_gate_input_12 needs backward computation.
I0521 09:36:45.850101  3675 net.cpp:226] lstm1x_transform_12 needs backward computation.
I0521 09:36:45.850103  3675 net.cpp:226] lstm1x_h_conted_11 needs backward computation.
I0521 09:36:45.850106  3675 net.cpp:226] h_11_lstm1x_unit_11_1_split needs backward computation.
I0521 09:36:45.850109  3675 net.cpp:226] lstm1x_unit_11 needs backward computation.
I0521 09:36:45.850113  3675 net.cpp:226] lstm1x_gate_input_11 needs backward computation.
I0521 09:36:45.850116  3675 net.cpp:226] lstm1x_transform_11 needs backward computation.
I0521 09:36:45.850118  3675 net.cpp:226] lstm1x_h_conted_10 needs backward computation.
I0521 09:36:45.850121  3675 net.cpp:226] h_10_lstm1x_unit_10_1_split needs backward computation.
I0521 09:36:45.850124  3675 net.cpp:226] lstm1x_unit_10 needs backward computation.
I0521 09:36:45.850127  3675 net.cpp:226] lstm1x_gate_input_10 needs backward computation.
I0521 09:36:45.850131  3675 net.cpp:226] lstm1x_transform_10 needs backward computation.
I0521 09:36:45.850133  3675 net.cpp:226] lstm1x_h_conted_9 needs backward computation.
I0521 09:36:45.850137  3675 net.cpp:226] h_9_lstm1x_unit_9_1_split needs backward computation.
I0521 09:36:45.850142  3675 net.cpp:226] lstm1x_unit_9 needs backward computation.
I0521 09:36:45.850144  3675 net.cpp:226] lstm1x_gate_input_9 needs backward computation.
I0521 09:36:45.850147  3675 net.cpp:226] lstm1x_transform_9 needs backward computation.
I0521 09:36:45.850149  3675 net.cpp:226] lstm1x_h_conted_8 needs backward computation.
I0521 09:36:45.850153  3675 net.cpp:226] h_8_lstm1x_unit_8_1_split needs backward computation.
I0521 09:36:45.850157  3675 net.cpp:226] lstm1x_unit_8 needs backward computation.
I0521 09:36:45.850159  3675 net.cpp:226] lstm1x_gate_input_8 needs backward computation.
I0521 09:36:45.850163  3675 net.cpp:226] lstm1x_transform_8 needs backward computation.
I0521 09:36:45.850167  3675 net.cpp:226] lstm1x_h_conted_7 needs backward computation.
I0521 09:36:45.850178  3675 net.cpp:226] h_7_lstm1x_unit_7_1_split needs backward computation.
I0521 09:36:45.850180  3675 net.cpp:226] lstm1x_unit_7 needs backward computation.
I0521 09:36:45.850184  3675 net.cpp:226] lstm1x_gate_input_7 needs backward computation.
I0521 09:36:45.850188  3675 net.cpp:226] lstm1x_transform_7 needs backward computation.
I0521 09:36:45.850190  3675 net.cpp:226] lstm1x_h_conted_6 needs backward computation.
I0521 09:36:45.850193  3675 net.cpp:226] h_6_lstm1x_unit_6_1_split needs backward computation.
I0521 09:36:45.850196  3675 net.cpp:226] lstm1x_unit_6 needs backward computation.
I0521 09:36:45.850200  3675 net.cpp:226] lstm1x_gate_input_6 needs backward computation.
I0521 09:36:45.850203  3675 net.cpp:226] lstm1x_transform_6 needs backward computation.
I0521 09:36:45.850206  3675 net.cpp:226] lstm1x_h_conted_5 needs backward computation.
I0521 09:36:45.850209  3675 net.cpp:226] h_5_lstm1x_unit_5_1_split needs backward computation.
I0521 09:36:45.850212  3675 net.cpp:226] lstm1x_unit_5 needs backward computation.
I0521 09:36:45.850215  3675 net.cpp:226] lstm1x_gate_input_5 needs backward computation.
I0521 09:36:45.850219  3675 net.cpp:226] lstm1x_transform_5 needs backward computation.
I0521 09:36:45.850221  3675 net.cpp:226] lstm1x_h_conted_4 needs backward computation.
I0521 09:36:45.850225  3675 net.cpp:226] h_4_lstm1x_unit_4_1_split needs backward computation.
I0521 09:36:45.850229  3675 net.cpp:226] lstm1x_unit_4 needs backward computation.
I0521 09:36:45.850231  3675 net.cpp:226] lstm1x_gate_input_4 needs backward computation.
I0521 09:36:45.850234  3675 net.cpp:226] lstm1x_transform_4 needs backward computation.
I0521 09:36:45.850236  3675 net.cpp:226] lstm1x_h_conted_3 needs backward computation.
I0521 09:36:45.850239  3675 net.cpp:226] h_3_lstm1x_unit_3_1_split needs backward computation.
I0521 09:36:45.850242  3675 net.cpp:226] lstm1x_unit_3 needs backward computation.
I0521 09:36:45.850245  3675 net.cpp:226] lstm1x_gate_input_3 needs backward computation.
I0521 09:36:45.850248  3675 net.cpp:226] lstm1x_transform_3 needs backward computation.
I0521 09:36:45.850251  3675 net.cpp:226] lstm1x_h_conted_2 needs backward computation.
I0521 09:36:45.850255  3675 net.cpp:226] h_2_lstm1x_unit_2_1_split needs backward computation.
I0521 09:36:45.850257  3675 net.cpp:226] lstm1x_unit_2 needs backward computation.
I0521 09:36:45.850263  3675 net.cpp:226] lstm1x_gate_input_2 needs backward computation.
I0521 09:36:45.850266  3675 net.cpp:226] lstm1x_transform_2 needs backward computation.
I0521 09:36:45.850270  3675 net.cpp:226] lstm1x_h_conted_1 needs backward computation.
I0521 09:36:45.850272  3675 net.cpp:226] h_1_lstm1x_unit_1_1_split needs backward computation.
I0521 09:36:45.850275  3675 net.cpp:226] lstm1x_unit_1 needs backward computation.
I0521 09:36:45.850278  3675 net.cpp:226] lstm1x_gate_input_1 needs backward computation.
I0521 09:36:45.850281  3675 net.cpp:226] lstm1x_transform_1 needs backward computation.
I0521 09:36:45.850284  3675 net.cpp:228] lstm1x_h_conted_0 does not need backward computation.
I0521 09:36:45.850288  3675 net.cpp:226] lstm1x_W_xc_x_slice needs backward computation.
I0521 09:36:45.850291  3675 net.cpp:226] lstm1x_x_transform needs backward computation.
I0521 09:36:45.850294  3675 net.cpp:228] cont_16_lstm1x_cont_slice_15_split does not need backward computation.
I0521 09:36:45.850298  3675 net.cpp:228] cont_15_lstm1x_cont_slice_14_split does not need backward computation.
I0521 09:36:45.850301  3675 net.cpp:228] cont_14_lstm1x_cont_slice_13_split does not need backward computation.
I0521 09:36:45.850304  3675 net.cpp:228] cont_13_lstm1x_cont_slice_12_split does not need backward computation.
I0521 09:36:45.850307  3675 net.cpp:228] cont_12_lstm1x_cont_slice_11_split does not need backward computation.
I0521 09:36:45.850311  3675 net.cpp:228] cont_11_lstm1x_cont_slice_10_split does not need backward computation.
I0521 09:36:45.850313  3675 net.cpp:228] cont_10_lstm1x_cont_slice_9_split does not need backward computation.
I0521 09:36:45.850320  3675 net.cpp:228] cont_9_lstm1x_cont_slice_8_split does not need backward computation.
I0521 09:36:45.850323  3675 net.cpp:228] cont_8_lstm1x_cont_slice_7_split does not need backward computation.
I0521 09:36:45.850327  3675 net.cpp:228] cont_7_lstm1x_cont_slice_6_split does not need backward computation.
I0521 09:36:45.850329  3675 net.cpp:228] cont_6_lstm1x_cont_slice_5_split does not need backward computation.
I0521 09:36:45.850333  3675 net.cpp:228] cont_5_lstm1x_cont_slice_4_split does not need backward computation.
I0521 09:36:45.850337  3675 net.cpp:228] cont_4_lstm1x_cont_slice_3_split does not need backward computation.
I0521 09:36:45.850340  3675 net.cpp:228] cont_3_lstm1x_cont_slice_2_split does not need backward computation.
I0521 09:36:45.850343  3675 net.cpp:228] cont_2_lstm1x_cont_slice_1_split does not need backward computation.
I0521 09:36:45.850347  3675 net.cpp:228] cont_1_lstm1x_cont_slice_0_split does not need backward computation.
I0521 09:36:45.855947  3675 net.cpp:228] lstm1x_cont_slice does not need backward computation.
I0521 09:36:45.855960  3675 net.cpp:228] lstm1x_ does not need backward computation.
I0521 09:36:45.855964  3675 net.cpp:228] lstm1x_ does not need backward computation.
I0521 09:36:45.855967  3675 net.cpp:270] This network produces output c_T
I0521 09:36:45.855973  3675 net.cpp:270] This network produces output h_pseudoloss
I0521 09:36:45.856253  3675 net.cpp:283] Network initialization done.
I0521 09:36:45.856464  3675 recurrent_layer.cpp:150] Adding parameter 0: W_xc
I0521 09:36:45.856469  3675 recurrent_layer.cpp:150] Adding parameter 1: b_c
I0521 09:36:45.856472  3675 recurrent_layer.cpp:150] Adding parameter 2: W_hc
I0521 09:36:45.856920  3675 net.cpp:150] Setting up lstm1x
I0521 09:36:45.856935  3675 net.cpp:157] Top shape: 16 128 100 (204800)
I0521 09:36:45.856937  3675 net.cpp:165] Memory required for data: 1841695232
I0521 09:36:45.856946  3675 layer_factory.hpp:77] Creating layer merge_lstm_rlstmx
I0521 09:36:45.856956  3675 net.cpp:100] Creating Layer merge_lstm_rlstmx
I0521 09:36:45.856961  3675 net.cpp:434] merge_lstm_rlstmx <- lstm1x
I0521 09:36:45.856966  3675 net.cpp:434] merge_lstm_rlstmx <- rlstmx
I0521 09:36:45.856971  3675 net.cpp:408] merge_lstm_rlstmx -> merge_lstm_rlstmx
I0521 09:36:45.857000  3675 net.cpp:150] Setting up merge_lstm_rlstmx
I0521 09:36:45.857003  3675 net.cpp:157] Top shape: 16 128 200 (409600)
I0521 09:36:45.857005  3675 net.cpp:165] Memory required for data: 1843333632
I0521 09:36:45.857008  3675 layer_factory.hpp:77] Creating layer fc1x
I0521 09:36:45.857014  3675 net.cpp:100] Creating Layer fc1x
I0521 09:36:45.857017  3675 net.cpp:434] fc1x <- merge_lstm_rlstmx
I0521 09:36:45.857023  3675 net.cpp:408] fc1x -> fc1x
I0521 09:36:45.857194  3675 net.cpp:150] Setting up fc1x
I0521 09:36:45.857199  3675 net.cpp:157] Top shape: 16 128 66 (135168)
I0521 09:36:45.857203  3675 net.cpp:165] Memory required for data: 1843874304
I0521 09:36:45.857208  3675 layer_factory.hpp:77] Creating layer fc1x_fc1x_0_split
I0521 09:36:45.857214  3675 net.cpp:100] Creating Layer fc1x_fc1x_0_split
I0521 09:36:45.857220  3675 net.cpp:434] fc1x_fc1x_0_split <- fc1x
I0521 09:36:45.857228  3675 net.cpp:408] fc1x_fc1x_0_split -> fc1x_fc1x_0_split_0
I0521 09:36:45.857237  3675 net.cpp:408] fc1x_fc1x_0_split -> fc1x_fc1x_0_split_1
I0521 09:36:45.857283  3675 net.cpp:150] Setting up fc1x_fc1x_0_split
I0521 09:36:45.857290  3675 net.cpp:157] Top shape: 16 128 66 (135168)
I0521 09:36:45.857297  3675 net.cpp:157] Top shape: 16 128 66 (135168)
I0521 09:36:45.857302  3675 net.cpp:165] Memory required for data: 1844955648
I0521 09:36:45.857307  3675 layer_factory.hpp:77] Creating layer ctcloss
I0521 09:36:45.857317  3675 net.cpp:100] Creating Layer ctcloss
I0521 09:36:45.857322  3675 net.cpp:434] ctcloss <- fc1x_fc1x_0_split_0
I0521 09:36:45.857329  3675 net.cpp:434] ctcloss <- label_data_1_split_0
I0521 09:36:45.857337  3675 net.cpp:408] ctcloss -> ctcloss
I0521 09:36:45.857395  3675 net.cpp:150] Setting up ctcloss
I0521 09:36:45.857403  3675 net.cpp:157] Top shape: (1)
I0521 09:36:45.857435  3675 net.cpp:160]     with loss weight 1
I0521 09:36:45.857453  3675 net.cpp:165] Memory required for data: 1844955652
I0521 09:36:45.857460  3675 layer_factory.hpp:77] Creating layer acc
I0521 09:36:45.857477  3675 net.cpp:100] Creating Layer acc
I0521 09:36:45.857483  3675 net.cpp:434] acc <- fc1x_fc1x_0_split_1
I0521 09:36:45.857491  3675 net.cpp:434] acc <- label_data_1_split_1
I0521 09:36:45.857499  3675 net.cpp:408] acc -> acc
I0521 09:36:45.857559  3675 net.cpp:150] Setting up acc
I0521 09:36:45.857566  3675 net.cpp:157] Top shape: 1 2 1 1 (2)
I0521 09:36:45.857571  3675 net.cpp:165] Memory required for data: 1844955660
I0521 09:36:45.857576  3675 net.cpp:228] acc does not need backward computation.
I0521 09:36:45.857583  3675 net.cpp:226] ctcloss needs backward computation.
I0521 09:36:45.857591  3675 net.cpp:226] fc1x_fc1x_0_split needs backward computation.
I0521 09:36:45.857597  3675 net.cpp:226] fc1x needs backward computation.
I0521 09:36:45.857602  3675 net.cpp:226] merge_lstm_rlstmx needs backward computation.
I0521 09:36:45.857609  3675 net.cpp:226] lstm1x needs backward computation.
I0521 09:36:45.857615  3675 net.cpp:226] lstm-reverse2 needs backward computation.
I0521 09:36:45.857620  3675 net.cpp:226] lstm2x needs backward computation.
I0521 09:36:45.857627  3675 net.cpp:226] lstm-reverse1 needs backward computation.
I0521 09:36:45.857632  3675 net.cpp:226] permuted_data_permuted_data_0_split needs backward computation.
I0521 09:36:45.857640  3675 net.cpp:226] permuted_data needs backward computation.
I0521 09:36:45.857646  3675 net.cpp:226] dropout needs backward computation.
I0521 09:36:45.857651  3675 net.cpp:226] last_relu needs backward computation.
I0521 09:36:45.857656  3675 net.cpp:226] last_scale needs backward computation.
I0521 09:36:45.857661  3675 net.cpp:226] last_bn needs backward computation.
I0521 09:36:45.857666  3675 net.cpp:226] layer_128_4_sum needs backward computation.
I0521 09:36:45.857671  3675 net.cpp:226] layer_128_4_conv3 needs backward computation.
I0521 09:36:45.857677  3675 net.cpp:226] layer_128_4_relu3 needs backward computation.
I0521 09:36:45.857682  3675 net.cpp:226] layer_128_4_scale3 needs backward computation.
I0521 09:36:45.857686  3675 net.cpp:226] layer_128_4_bn3 needs backward computation.
I0521 09:36:45.857692  3675 net.cpp:226] layer_128_4_conv2 needs backward computation.
I0521 09:36:45.857697  3675 net.cpp:226] layer_128_4_relu2 needs backward computation.
I0521 09:36:45.857702  3675 net.cpp:226] layer_128_4_scale2 needs backward computation.
I0521 09:36:45.857707  3675 net.cpp:226] layer_128_4_bn2 needs backward computation.
I0521 09:36:45.857712  3675 net.cpp:226] layer_128_4_conv1 needs backward computation.
I0521 09:36:45.857717  3675 net.cpp:226] layer_128_4_relu1 needs backward computation.
I0521 09:36:45.857722  3675 net.cpp:226] layer_128_4_scale1 needs backward computation.
I0521 09:36:45.857725  3675 net.cpp:226] layer_128_4_bn1 needs backward computation.
I0521 09:36:45.857731  3675 net.cpp:226] layer_128_3_sum_layer_128_3_sum_0_split needs backward computation.
I0521 09:36:45.857735  3675 net.cpp:226] layer_128_3_sum needs backward computation.
I0521 09:36:45.857743  3675 net.cpp:226] layer_128_3_conv3 needs backward computation.
I0521 09:36:45.857749  3675 net.cpp:226] layer_128_3_relu3 needs backward computation.
I0521 09:36:45.857754  3675 net.cpp:226] layer_128_3_scale3 needs backward computation.
I0521 09:36:45.857759  3675 net.cpp:226] layer_128_3_bn3 needs backward computation.
I0521 09:36:45.857764  3675 net.cpp:226] layer_128_3_conv2 needs backward computation.
I0521 09:36:45.857769  3675 net.cpp:226] layer_128_3_relu2 needs backward computation.
I0521 09:36:45.857774  3675 net.cpp:226] layer_128_3_scale2 needs backward computation.
I0521 09:36:45.857780  3675 net.cpp:226] layer_128_3_bn2 needs backward computation.
I0521 09:36:45.857785  3675 net.cpp:226] layer_128_3_conv1 needs backward computation.
I0521 09:36:45.857790  3675 net.cpp:226] layer_128_3_relu1 needs backward computation.
I0521 09:36:45.857811  3675 net.cpp:226] layer_128_3_scale1 needs backward computation.
I0521 09:36:45.857818  3675 net.cpp:226] layer_128_3_bn1 needs backward computation.
I0521 09:36:45.857823  3675 net.cpp:226] layer_128_2_sum_layer_128_2_sum_0_split needs backward computation.
I0521 09:36:45.857828  3675 net.cpp:226] layer_128_2_sum needs backward computation.
I0521 09:36:45.857836  3675 net.cpp:226] layer_128_2_conv3 needs backward computation.
I0521 09:36:45.857843  3675 net.cpp:226] layer_128_2_relu3 needs backward computation.
I0521 09:36:45.857848  3675 net.cpp:226] layer_128_2_scale3 needs backward computation.
I0521 09:36:45.857853  3675 net.cpp:226] layer_128_2_bn3 needs backward computation.
I0521 09:36:45.857858  3675 net.cpp:226] layer_128_2_conv2 needs backward computation.
I0521 09:36:45.857864  3675 net.cpp:226] layer_128_2_relu2 needs backward computation.
I0521 09:36:45.857869  3675 net.cpp:226] layer_128_2_scale2 needs backward computation.
I0521 09:36:45.857874  3675 net.cpp:226] layer_128_2_bn2 needs backward computation.
I0521 09:36:45.857879  3675 net.cpp:226] layer_128_2_conv1 needs backward computation.
I0521 09:36:45.857885  3675 net.cpp:226] layer_128_2_relu1 needs backward computation.
I0521 09:36:45.857890  3675 net.cpp:226] layer_128_2_scale1 needs backward computation.
I0521 09:36:45.857895  3675 net.cpp:226] layer_128_2_bn1 needs backward computation.
I0521 09:36:45.857901  3675 net.cpp:226] layer_128_1_sum_layer_128_1_sum_0_split needs backward computation.
I0521 09:36:45.857906  3675 net.cpp:226] layer_128_1_sum needs backward computation.
I0521 09:36:45.857913  3675 net.cpp:226] layer_128_1_conv_expand needs backward computation.
I0521 09:36:45.857918  3675 net.cpp:226] layer_128_1_conv3 needs backward computation.
I0521 09:36:45.857924  3675 net.cpp:226] layer_128_1_relu3 needs backward computation.
I0521 09:36:45.857929  3675 net.cpp:226] layer_128_1_scale3 needs backward computation.
I0521 09:36:45.857934  3675 net.cpp:226] layer_128_1_bn3 needs backward computation.
I0521 09:36:45.857939  3675 net.cpp:226] layer_128_1_conv2 needs backward computation.
I0521 09:36:45.857945  3675 net.cpp:226] layer_128_1_relu2 needs backward computation.
I0521 09:36:45.857950  3675 net.cpp:226] layer_128_1_scale2 needs backward computation.
I0521 09:36:45.857956  3675 net.cpp:226] layer_128_1_bn2 needs backward computation.
I0521 09:36:45.857960  3675 net.cpp:226] layer_128_1_conv1 needs backward computation.
I0521 09:36:45.857966  3675 net.cpp:226] layer_128_1_bn1_layer_128_1_relu1_0_split needs backward computation.
I0521 09:36:45.857971  3675 net.cpp:226] layer_128_1_relu1 needs backward computation.
I0521 09:36:45.857977  3675 net.cpp:226] layer_128_1_scale1 needs backward computation.
I0521 09:36:45.857982  3675 net.cpp:226] layer_128_1_bn1 needs backward computation.
I0521 09:36:45.857987  3675 net.cpp:226] layer_64_3_sum needs backward computation.
I0521 09:36:45.857993  3675 net.cpp:226] layer_64_3_conv3 needs backward computation.
I0521 09:36:45.858000  3675 net.cpp:226] layer_64_3_relu3 needs backward computation.
I0521 09:36:45.858005  3675 net.cpp:226] layer_64_3_scale3 needs backward computation.
I0521 09:36:45.858009  3675 net.cpp:226] layer_64_3_bn3 needs backward computation.
I0521 09:36:45.858014  3675 net.cpp:226] layer_64_3_conv2 needs backward computation.
I0521 09:36:45.858021  3675 net.cpp:226] layer_64_3_relu2 needs backward computation.
I0521 09:36:45.858026  3675 net.cpp:226] layer_64_3_scale2 needs backward computation.
I0521 09:36:45.858031  3675 net.cpp:226] layer_64_3_bn2 needs backward computation.
I0521 09:36:45.858036  3675 net.cpp:226] layer_64_3_conv1 needs backward computation.
I0521 09:36:45.858042  3675 net.cpp:226] layer_64_3_relu1 needs backward computation.
I0521 09:36:45.858047  3675 net.cpp:226] layer_64_3_scale1 needs backward computation.
I0521 09:36:45.858052  3675 net.cpp:226] layer_64_3_bn1 needs backward computation.
I0521 09:36:45.858058  3675 net.cpp:226] layer_64_2_sum_layer_64_2_sum_0_split needs backward computation.
I0521 09:36:45.858064  3675 net.cpp:226] layer_64_2_sum needs backward computation.
I0521 09:36:45.858083  3675 net.cpp:226] layer_64_2_conv3 needs backward computation.
I0521 09:36:45.858090  3675 net.cpp:226] layer_64_2_relu3 needs backward computation.
I0521 09:36:45.858094  3675 net.cpp:226] layer_64_2_scale3 needs backward computation.
I0521 09:36:45.858100  3675 net.cpp:226] layer_64_2_bn3 needs backward computation.
I0521 09:36:45.858105  3675 net.cpp:226] layer_64_2_conv2 needs backward computation.
I0521 09:36:45.858111  3675 net.cpp:226] layer_64_2_relu2 needs backward computation.
I0521 09:36:45.858116  3675 net.cpp:226] layer_64_2_scale2 needs backward computation.
I0521 09:36:45.858122  3675 net.cpp:226] layer_64_2_bn2 needs backward computation.
I0521 09:36:45.858126  3675 net.cpp:226] layer_64_2_conv1 needs backward computation.
I0521 09:36:45.858132  3675 net.cpp:226] layer_64_2_relu1 needs backward computation.
I0521 09:36:45.858139  3675 net.cpp:226] layer_64_2_scale1 needs backward computation.
I0521 09:36:45.858142  3675 net.cpp:226] layer_64_2_bn1 needs backward computation.
I0521 09:36:45.858148  3675 net.cpp:226] layer_64_1_sum_layer_64_1_sum_0_split needs backward computation.
I0521 09:36:45.858155  3675 net.cpp:226] layer_64_1_sum needs backward computation.
I0521 09:36:45.858161  3675 net.cpp:226] layer_64_1_conv_expand needs backward computation.
I0521 09:36:45.858166  3675 net.cpp:226] layer_64_1_conv3 needs backward computation.
I0521 09:36:45.858173  3675 net.cpp:226] layer_64_1_relu3 needs backward computation.
I0521 09:36:45.858178  3675 net.cpp:226] layer_64_1_scale3 needs backward computation.
I0521 09:36:45.858183  3675 net.cpp:226] layer_64_1_bn3 needs backward computation.
I0521 09:36:45.858187  3675 net.cpp:226] layer_64_1_conv2 needs backward computation.
I0521 09:36:45.858193  3675 net.cpp:226] layer_64_1_conv1_layer_64_1_relu2_0_split needs backward computation.
I0521 09:36:45.858199  3675 net.cpp:226] layer_64_1_relu2 needs backward computation.
I0521 09:36:45.858204  3675 net.cpp:226] layer_64_1_scale2 needs backward computation.
I0521 09:36:45.858209  3675 net.cpp:226] layer_64_1_bn2 needs backward computation.
I0521 09:36:45.858216  3675 net.cpp:226] layer_64_1_conv1 needs backward computation.
I0521 09:36:45.858222  3675 net.cpp:226] conv1_pool needs backward computation.
I0521 09:36:45.858227  3675 net.cpp:226] conv1_relu needs backward computation.
I0521 09:36:45.858232  3675 net.cpp:226] conv1_scale needs backward computation.
I0521 09:36:45.858237  3675 net.cpp:226] conv1_bn needs backward computation.
I0521 09:36:45.858242  3675 net.cpp:226] conv1 needs backward computation.
I0521 09:36:45.858247  3675 net.cpp:226] data_scale needs backward computation.
I0521 09:36:45.858252  3675 net.cpp:226] data_bn needs backward computation.
I0521 09:36:45.858258  3675 net.cpp:228] indicator_indicator_0_split does not need backward computation.
I0521 09:36:45.858263  3675 net.cpp:228] indicator does not need backward computation.
I0521 09:36:45.858269  3675 net.cpp:228] label_data_1_split does not need backward computation.
I0521 09:36:45.858275  3675 net.cpp:228] data does not need backward computation.
I0521 09:36:45.858278  3675 net.cpp:270] This network produces output acc
I0521 09:36:45.858283  3675 net.cpp:270] This network produces output ctcloss
I0521 09:36:45.858367  3675 net.cpp:283] Network initialization done.
I0521 09:36:45.858850  3675 solver.cpp:75] Solver scaffolding done.
I0521 09:36:45.864723  3675 caffe.cpp:251] Starting Optimization
I0521 09:36:45.864740  3675 solver.cpp:294] Solving 
I0521 09:36:45.864745  3675 solver.cpp:295] Learning Rate Policy: step
I0521 09:36:46.102800  3675 solver.cpp:243] Iteration 0, loss = 53.7792
I0521 09:36:46.102840  3675 solver.cpp:259]     Train net output #0: ctcloss = 53.7792 (* 1 = 53.7792 loss)
I0521 09:36:46.102861  3675 sgd_solver.cpp:138] Iteration 0, lr = 0.0001
I0521 09:36:49.955240  3675 solver.cpp:243] Iteration 20, loss = 27.6152
I0521 09:36:49.955276  3675 solver.cpp:259]     Train net output #0: ctcloss = 27.6152 (* 1 = 27.6152 loss)
I0521 09:36:49.955317  3675 sgd_solver.cpp:138] Iteration 20, lr = 0.0001
I0521 09:36:53.753479  3675 solver.cpp:243] Iteration 40, loss = 25.0552
I0521 09:36:53.753515  3675 solver.cpp:259]     Train net output #0: ctcloss = 25.0552 (* 1 = 25.0552 loss)
I0521 09:36:53.753521  3675 sgd_solver.cpp:138] Iteration 40, lr = 0.0001
I0521 09:36:57.535431  3675 solver.cpp:243] Iteration 60, loss = 23.1631
I0521 09:36:57.535465  3675 solver.cpp:259]     Train net output #0: ctcloss = 23.1631 (* 1 = 23.1631 loss)
I0521 09:36:57.535470  3675 sgd_solver.cpp:138] Iteration 60, lr = 0.0001
I0521 09:37:01.010816  3675 solver.cpp:243] Iteration 80, loss = 22.4614
I0521 09:37:01.010848  3675 solver.cpp:259]     Train net output #0: ctcloss = 22.4614 (* 1 = 22.4614 loss)
I0521 09:37:01.010854  3675 sgd_solver.cpp:138] Iteration 80, lr = 0.0001
I0521 09:37:04.807889  3675 solver.cpp:243] Iteration 100, loss = 22.3063
I0521 09:37:04.807921  3675 solver.cpp:259]     Train net output #0: ctcloss = 22.3063 (* 1 = 22.3063 loss)
I0521 09:37:04.807927  3675 sgd_solver.cpp:138] Iteration 100, lr = 0.0001
I0521 09:37:08.607722  3675 solver.cpp:243] Iteration 120, loss = 21.5789
I0521 09:37:08.607755  3675 solver.cpp:259]     Train net output #0: ctcloss = 21.5789 (* 1 = 21.5789 loss)
I0521 09:37:08.607761  3675 sgd_solver.cpp:138] Iteration 120, lr = 0.0001
I0521 09:37:12.409492  3675 solver.cpp:243] Iteration 140, loss = 20.7758
I0521 09:37:12.409525  3675 solver.cpp:259]     Train net output #0: ctcloss = 20.7758 (* 1 = 20.7758 loss)
I0521 09:37:12.409533  3675 sgd_solver.cpp:138] Iteration 140, lr = 0.0001
I0521 09:37:16.202009  3675 solver.cpp:243] Iteration 160, loss = 19.6353
I0521 09:37:16.202152  3675 solver.cpp:259]     Train net output #0: ctcloss = 19.6353 (* 1 = 19.6353 loss)
I0521 09:37:16.202159  3675 sgd_solver.cpp:138] Iteration 160, lr = 0.0001
I0521 09:37:20.019274  3675 solver.cpp:243] Iteration 180, loss = 17.5455
I0521 09:37:20.019307  3675 solver.cpp:259]     Train net output #0: ctcloss = 17.5455 (* 1 = 17.5455 loss)
I0521 09:37:20.019315  3675 sgd_solver.cpp:138] Iteration 180, lr = 0.0001
I0521 09:37:23.822484  3675 solver.cpp:243] Iteration 200, loss = 16.4365
I0521 09:37:23.822515  3675 solver.cpp:259]     Train net output #0: ctcloss = 16.4365 (* 1 = 16.4365 loss)
I0521 09:37:23.822521  3675 sgd_solver.cpp:138] Iteration 200, lr = 0.0001
I0521 09:37:27.363114  3675 solver.cpp:243] Iteration 220, loss = 13.2693
I0521 09:37:27.363145  3675 solver.cpp:259]     Train net output #0: ctcloss = 13.2693 (* 1 = 13.2693 loss)
I0521 09:37:27.363168  3675 sgd_solver.cpp:138] Iteration 220, lr = 0.0001
I0521 09:37:30.908222  3675 solver.cpp:243] Iteration 240, loss = 10.3836
I0521 09:37:30.908253  3675 solver.cpp:259]     Train net output #0: ctcloss = 10.3836 (* 1 = 10.3836 loss)
I0521 09:37:30.908259  3675 sgd_solver.cpp:138] Iteration 240, lr = 0.0001
I0521 09:37:34.451580  3675 solver.cpp:243] Iteration 260, loss = 9.14752
I0521 09:37:34.451611  3675 solver.cpp:259]     Train net output #0: ctcloss = 9.14752 (* 1 = 9.14752 loss)
I0521 09:37:34.451617  3675 sgd_solver.cpp:138] Iteration 260, lr = 0.0001
I0521 09:37:37.996327  3675 solver.cpp:243] Iteration 280, loss = 8.00181
I0521 09:37:37.996358  3675 solver.cpp:259]     Train net output #0: ctcloss = 8.00181 (* 1 = 8.00181 loss)
I0521 09:37:37.996364  3675 sgd_solver.cpp:138] Iteration 280, lr = 0.0001
I0521 09:37:41.540743  3675 solver.cpp:243] Iteration 300, loss = 7.4979
I0521 09:37:41.540773  3675 solver.cpp:259]     Train net output #0: ctcloss = 7.4979 (* 1 = 7.4979 loss)
I0521 09:37:41.540796  3675 sgd_solver.cpp:138] Iteration 300, lr = 0.0001
I0521 09:37:45.084414  3675 solver.cpp:243] Iteration 320, loss = 5.36826
I0521 09:37:45.084445  3675 solver.cpp:259]     Train net output #0: ctcloss = 5.36826 (* 1 = 5.36826 loss)
I0521 09:37:45.084467  3675 sgd_solver.cpp:138] Iteration 320, lr = 0.0001
I0521 09:37:48.629393  3675 solver.cpp:243] Iteration 340, loss = 6.22731
I0521 09:37:48.636832  3675 solver.cpp:259]     Train net output #0: ctcloss = 6.22731 (* 1 = 6.22731 loss)
I0521 09:37:48.636847  3675 sgd_solver.cpp:138] Iteration 340, lr = 0.0001
I0521 09:37:52.187870  3675 solver.cpp:243] Iteration 360, loss = 5.08268
I0521 09:37:52.187902  3675 solver.cpp:259]     Train net output #0: ctcloss = 5.08268 (* 1 = 5.08268 loss)
I0521 09:37:52.187908  3675 sgd_solver.cpp:138] Iteration 360, lr = 0.0001
I0521 09:37:55.741416  3675 solver.cpp:243] Iteration 380, loss = 4.61887
I0521 09:37:55.741447  3675 solver.cpp:259]     Train net output #0: ctcloss = 4.61887 (* 1 = 4.61887 loss)
I0521 09:37:55.741452  3675 sgd_solver.cpp:138] Iteration 380, lr = 0.0001
I0521 09:37:59.282940  3675 solver.cpp:243] Iteration 400, loss = 4.46562
I0521 09:37:59.282974  3675 solver.cpp:259]     Train net output #0: ctcloss = 4.46562 (* 1 = 4.46562 loss)
I0521 09:37:59.282995  3675 sgd_solver.cpp:138] Iteration 400, lr = 0.0001
I0521 09:38:02.835465  3675 solver.cpp:243] Iteration 420, loss = 4.14712
I0521 09:38:02.835496  3675 solver.cpp:259]     Train net output #0: ctcloss = 4.14712 (* 1 = 4.14712 loss)
I0521 09:38:02.835518  3675 sgd_solver.cpp:138] Iteration 420, lr = 0.0001
I0521 09:38:06.387959  3675 solver.cpp:243] Iteration 440, loss = 4.12956
I0521 09:38:06.387991  3675 solver.cpp:259]     Train net output #0: ctcloss = 4.12956 (* 1 = 4.12956 loss)
I0521 09:38:06.388000  3675 sgd_solver.cpp:138] Iteration 440, lr = 0.0001
I0521 09:38:09.937508  3675 solver.cpp:243] Iteration 460, loss = 3.63234
I0521 09:38:09.937539  3675 solver.cpp:259]     Train net output #0: ctcloss = 3.63234 (* 1 = 3.63234 loss)
I0521 09:38:09.937546  3675 sgd_solver.cpp:138] Iteration 460, lr = 0.0001
I0521 09:38:13.487000  3675 solver.cpp:243] Iteration 480, loss = 3.1102
I0521 09:38:13.487027  3675 solver.cpp:259]     Train net output #0: ctcloss = 3.1102 (* 1 = 3.1102 loss)
I0521 09:38:13.487033  3675 sgd_solver.cpp:138] Iteration 480, lr = 0.0001
I0521 09:38:17.040750  3675 solver.cpp:243] Iteration 500, loss = 2.91733
I0521 09:38:17.040781  3675 solver.cpp:259]     Train net output #0: ctcloss = 2.91733 (* 1 = 2.91733 loss)
I0521 09:38:17.040788  3675 sgd_solver.cpp:138] Iteration 500, lr = 0.0001
I0521 09:38:20.589164  3675 solver.cpp:243] Iteration 520, loss = 2.98716
I0521 09:38:20.589285  3675 solver.cpp:259]     Train net output #0: ctcloss = 2.98716 (* 1 = 2.98716 loss)
I0521 09:38:20.589293  3675 sgd_solver.cpp:138] Iteration 520, lr = 0.0001
I0521 09:38:24.136091  3675 solver.cpp:243] Iteration 540, loss = 3.11143
I0521 09:38:24.136122  3675 solver.cpp:259]     Train net output #0: ctcloss = 3.11143 (* 1 = 3.11143 loss)
I0521 09:38:24.136128  3675 sgd_solver.cpp:138] Iteration 540, lr = 0.0001
I0521 09:38:27.686974  3675 solver.cpp:243] Iteration 560, loss = 2.50935
I0521 09:38:27.687003  3675 solver.cpp:259]     Train net output #0: ctcloss = 2.50935 (* 1 = 2.50935 loss)
I0521 09:38:27.687008  3675 sgd_solver.cpp:138] Iteration 560, lr = 0.0001
I0521 09:38:31.236660  3675 solver.cpp:243] Iteration 580, loss = 3.14508
I0521 09:38:31.236690  3675 solver.cpp:259]     Train net output #0: ctcloss = 3.14508 (* 1 = 3.14508 loss)
I0521 09:38:31.236696  3675 sgd_solver.cpp:138] Iteration 580, lr = 0.0001
I0521 09:38:34.773517  3675 solver.cpp:243] Iteration 600, loss = 2.45023
I0521 09:38:34.773548  3675 solver.cpp:259]     Train net output #0: ctcloss = 2.45023 (* 1 = 2.45023 loss)
I0521 09:38:34.773553  3675 sgd_solver.cpp:138] Iteration 600, lr = 0.0001
I0521 09:38:38.305825  3675 solver.cpp:243] Iteration 620, loss = 2.65921
I0521 09:38:38.305856  3675 solver.cpp:259]     Train net output #0: ctcloss = 2.65921 (* 1 = 2.65921 loss)
I0521 09:38:38.305861  3675 sgd_solver.cpp:138] Iteration 620, lr = 0.0001
I0521 09:38:41.836552  3675 solver.cpp:243] Iteration 640, loss = 2.52941
I0521 09:38:41.836588  3675 solver.cpp:259]     Train net output #0: ctcloss = 2.52941 (* 1 = 2.52941 loss)
I0521 09:38:41.836594  3675 sgd_solver.cpp:138] Iteration 640, lr = 0.0001
I0521 09:38:45.383823  3675 solver.cpp:243] Iteration 660, loss = 2.64185
I0521 09:38:45.383854  3675 solver.cpp:259]     Train net output #0: ctcloss = 2.64185 (* 1 = 2.64185 loss)
I0521 09:38:45.383859  3675 sgd_solver.cpp:138] Iteration 660, lr = 0.0001
I0521 09:38:48.933007  3675 solver.cpp:243] Iteration 680, loss = 1.94424
I0521 09:38:48.933037  3675 solver.cpp:259]     Train net output #0: ctcloss = 1.94424 (* 1 = 1.94424 loss)
I0521 09:38:48.933043  3675 sgd_solver.cpp:138] Iteration 680, lr = 0.0001
I0521 09:38:52.466861  3675 solver.cpp:243] Iteration 700, loss = 2.06485
I0521 09:38:52.467006  3675 solver.cpp:259]     Train net output #0: ctcloss = 2.06485 (* 1 = 2.06485 loss)
I0521 09:38:52.467015  3675 sgd_solver.cpp:138] Iteration 700, lr = 0.0001
I0521 09:38:56.008334  3675 solver.cpp:243] Iteration 720, loss = 1.88047
I0521 09:38:56.008365  3675 solver.cpp:259]     Train net output #0: ctcloss = 1.88047 (* 1 = 1.88047 loss)
I0521 09:38:56.008370  3675 sgd_solver.cpp:138] Iteration 720, lr = 0.0001
I0521 09:38:59.555779  3675 solver.cpp:243] Iteration 740, loss = 2.28469
I0521 09:38:59.555809  3675 solver.cpp:259]     Train net output #0: ctcloss = 2.28469 (* 1 = 2.28469 loss)
I0521 09:38:59.555815  3675 sgd_solver.cpp:138] Iteration 740, lr = 0.0001
I0521 09:39:03.103296  3675 solver.cpp:243] Iteration 760, loss = 2.07214
I0521 09:39:03.103334  3675 solver.cpp:259]     Train net output #0: ctcloss = 2.07214 (* 1 = 2.07214 loss)
I0521 09:39:03.103343  3675 sgd_solver.cpp:138] Iteration 760, lr = 0.0001
I0521 09:39:06.637979  3675 solver.cpp:243] Iteration 780, loss = 1.62563
I0521 09:39:06.638010  3675 solver.cpp:259]     Train net output #0: ctcloss = 1.62563 (* 1 = 1.62563 loss)
I0521 09:39:06.638017  3675 sgd_solver.cpp:138] Iteration 780, lr = 0.0001
I0521 09:39:10.181247  3675 solver.cpp:243] Iteration 800, loss = 1.79017
I0521 09:39:10.181278  3675 solver.cpp:259]     Train net output #0: ctcloss = 1.79017 (* 1 = 1.79017 loss)
I0521 09:39:10.181284  3675 sgd_solver.cpp:138] Iteration 800, lr = 0.0001
I0521 09:39:13.728581  3675 solver.cpp:243] Iteration 820, loss = 1.9139
I0521 09:39:13.728613  3675 solver.cpp:259]     Train net output #0: ctcloss = 1.9139 (* 1 = 1.9139 loss)
I0521 09:39:13.728636  3675 sgd_solver.cpp:138] Iteration 820, lr = 0.0001
I0521 09:39:17.274514  3675 solver.cpp:243] Iteration 840, loss = 1.9644
I0521 09:39:17.274545  3675 solver.cpp:259]     Train net output #0: ctcloss = 1.9644 (* 1 = 1.9644 loss)
I0521 09:39:17.274566  3675 sgd_solver.cpp:138] Iteration 840, lr = 0.0001
I0521 09:39:20.807437  3675 solver.cpp:243] Iteration 860, loss = 1.47422
I0521 09:39:20.807468  3675 solver.cpp:259]     Train net output #0: ctcloss = 1.47422 (* 1 = 1.47422 loss)
I0521 09:39:20.807489  3675 sgd_solver.cpp:138] Iteration 860, lr = 0.0001
I0521 09:39:24.338266  3675 solver.cpp:243] Iteration 880, loss = 1.51801
I0521 09:39:24.339474  3675 solver.cpp:259]     Train net output #0: ctcloss = 1.51801 (* 1 = 1.51801 loss)
I0521 09:39:24.339483  3675 sgd_solver.cpp:138] Iteration 880, lr = 0.0001
I0521 09:39:27.881127  3675 solver.cpp:243] Iteration 900, loss = 1.66195
I0521 09:39:27.881181  3675 solver.cpp:259]     Train net output #0: ctcloss = 1.66195 (* 1 = 1.66195 loss)
I0521 09:39:27.881193  3675 sgd_solver.cpp:138] Iteration 900, lr = 0.0001
I0521 09:39:31.436203  3675 solver.cpp:243] Iteration 920, loss = 1.68808
I0521 09:39:31.436235  3675 solver.cpp:259]     Train net output #0: ctcloss = 1.68808 (* 1 = 1.68808 loss)
I0521 09:39:31.436241  3675 sgd_solver.cpp:138] Iteration 920, lr = 0.0001
I0521 09:39:34.977861  3675 solver.cpp:243] Iteration 940, loss = 1.48385
I0521 09:39:34.977890  3675 solver.cpp:259]     Train net output #0: ctcloss = 1.48385 (* 1 = 1.48385 loss)
I0521 09:39:34.977912  3675 sgd_solver.cpp:138] Iteration 940, lr = 0.0001
I0521 09:39:38.508565  3675 solver.cpp:243] Iteration 960, loss = 1.63853
I0521 09:39:38.508599  3675 solver.cpp:259]     Train net output #0: ctcloss = 1.63853 (* 1 = 1.63853 loss)
I0521 09:39:38.508605  3675 sgd_solver.cpp:138] Iteration 960, lr = 0.0001
I0521 09:39:42.048343  3675 solver.cpp:243] Iteration 980, loss = 1.25638
I0521 09:39:42.048373  3675 solver.cpp:259]     Train net output #0: ctcloss = 1.25638 (* 1 = 1.25638 loss)
I0521 09:39:42.048378  3675 sgd_solver.cpp:138] Iteration 980, lr = 0.0001
I0521 09:39:45.464447  3675 solver.cpp:358] Iteration 1000, Testing net (#0)
I0521 09:39:50.231526  3675 solver.cpp:425]     Test net output #0: acc = 0.92162
I0521 09:39:50.231555  3675 solver.cpp:425]     Test net output #1: acc = 0.603516
I0521 09:39:50.231561  3675 solver.cpp:425]     Test net output #2: ctcloss = 1.81091 (* 1 = 1.81091 loss)
I0521 09:39:50.370626  3675 solver.cpp:243] Iteration 1000, loss = 1.28399
I0521 09:39:50.370657  3675 solver.cpp:259]     Train net output #0: ctcloss = 1.28399 (* 1 = 1.28399 loss)
I0521 09:39:50.370678  3675 sgd_solver.cpp:138] Iteration 1000, lr = 0.0001
I0521 09:39:53.910132  3675 solver.cpp:243] Iteration 1020, loss = 1.41546
I0521 09:39:53.910164  3675 solver.cpp:259]     Train net output #0: ctcloss = 1.41546 (* 1 = 1.41546 loss)
I0521 09:39:53.910171  3675 sgd_solver.cpp:138] Iteration 1020, lr = 0.0001
I0521 09:39:57.464818  3675 solver.cpp:243] Iteration 1040, loss = 1.49225
I0521 09:39:57.464926  3675 solver.cpp:259]     Train net output #0: ctcloss = 1.49225 (* 1 = 1.49225 loss)
I0521 09:39:57.464933  3675 sgd_solver.cpp:138] Iteration 1040, lr = 0.0001
I0521 09:40:01.006211  3675 solver.cpp:243] Iteration 1060, loss = 1.61536
I0521 09:40:01.006242  3675 solver.cpp:259]     Train net output #0: ctcloss = 1.61536 (* 1 = 1.61536 loss)
I0521 09:40:01.006263  3675 sgd_solver.cpp:138] Iteration 1060, lr = 0.0001
I0521 09:40:04.547092  3675 solver.cpp:243] Iteration 1080, loss = 1.04234
I0521 09:40:04.547127  3675 solver.cpp:259]     Train net output #0: ctcloss = 1.04234 (* 1 = 1.04234 loss)
I0521 09:40:04.547148  3675 sgd_solver.cpp:138] Iteration 1080, lr = 0.0001
I0521 09:40:08.096082  3675 solver.cpp:243] Iteration 1100, loss = 1.12712
I0521 09:40:08.096112  3675 solver.cpp:259]     Train net output #0: ctcloss = 1.12712 (* 1 = 1.12712 loss)
I0521 09:40:08.096119  3675 sgd_solver.cpp:138] Iteration 1100, lr = 0.0001
I0521 09:40:11.644560  3675 solver.cpp:243] Iteration 1120, loss = 1.11137
I0521 09:40:11.644590  3675 solver.cpp:259]     Train net output #0: ctcloss = 1.11137 (* 1 = 1.11137 loss)
I0521 09:40:11.644596  3675 sgd_solver.cpp:138] Iteration 1120, lr = 0.0001
I0521 09:40:15.189023  3675 solver.cpp:243] Iteration 1140, loss = 0.950603
I0521 09:40:15.189054  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.950603 (* 1 = 0.950603 loss)
I0521 09:40:15.189060  3675 sgd_solver.cpp:138] Iteration 1140, lr = 0.0001
I0521 09:40:18.733731  3675 solver.cpp:243] Iteration 1160, loss = 1.06779
I0521 09:40:18.733760  3675 solver.cpp:259]     Train net output #0: ctcloss = 1.06779 (* 1 = 1.06779 loss)
I0521 09:40:18.733767  3675 sgd_solver.cpp:138] Iteration 1160, lr = 0.0001
I0521 09:40:22.281872  3675 solver.cpp:243] Iteration 1180, loss = 1.31821
I0521 09:40:22.281901  3675 solver.cpp:259]     Train net output #0: ctcloss = 1.31821 (* 1 = 1.31821 loss)
I0521 09:40:22.281908  3675 sgd_solver.cpp:138] Iteration 1180, lr = 0.0001
I0521 09:40:25.828817  3675 solver.cpp:243] Iteration 1200, loss = 0.965069
I0521 09:40:25.828850  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.965069 (* 1 = 0.965069 loss)
I0521 09:40:25.828855  3675 sgd_solver.cpp:138] Iteration 1200, lr = 0.0001
I0521 09:40:29.365433  3675 solver.cpp:243] Iteration 1220, loss = 1.27183
I0521 09:40:29.365586  3675 solver.cpp:259]     Train net output #0: ctcloss = 1.27183 (* 1 = 1.27183 loss)
I0521 09:40:29.365592  3675 sgd_solver.cpp:138] Iteration 1220, lr = 0.0001
I0521 09:40:32.898200  3675 solver.cpp:243] Iteration 1240, loss = 1.01326
I0521 09:40:32.898233  3675 solver.cpp:259]     Train net output #0: ctcloss = 1.01326 (* 1 = 1.01326 loss)
I0521 09:40:32.898241  3675 sgd_solver.cpp:138] Iteration 1240, lr = 0.0001
I0521 09:40:36.442704  3675 solver.cpp:243] Iteration 1260, loss = 0.956229
I0521 09:40:36.442734  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.956229 (* 1 = 0.956229 loss)
I0521 09:40:36.442740  3675 sgd_solver.cpp:138] Iteration 1260, lr = 0.0001
I0521 09:40:39.993436  3675 solver.cpp:243] Iteration 1280, loss = 0.905692
I0521 09:40:39.993469  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.905692 (* 1 = 0.905692 loss)
I0521 09:40:39.993475  3675 sgd_solver.cpp:138] Iteration 1280, lr = 0.0001
I0521 09:40:43.540910  3675 solver.cpp:243] Iteration 1300, loss = 0.866682
I0521 09:40:43.540940  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.866682 (* 1 = 0.866682 loss)
I0521 09:40:43.540946  3675 sgd_solver.cpp:138] Iteration 1300, lr = 0.0001
I0521 09:40:47.079972  3675 solver.cpp:243] Iteration 1320, loss = 1.18162
I0521 09:40:47.080001  3675 solver.cpp:259]     Train net output #0: ctcloss = 1.18162 (* 1 = 1.18162 loss)
I0521 09:40:47.080008  3675 sgd_solver.cpp:138] Iteration 1320, lr = 0.0001
I0521 09:40:50.623248  3675 solver.cpp:243] Iteration 1340, loss = 0.743973
I0521 09:40:50.623278  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.743973 (* 1 = 0.743973 loss)
I0521 09:40:50.623284  3675 sgd_solver.cpp:138] Iteration 1340, lr = 0.0001
I0521 09:40:54.173120  3675 solver.cpp:243] Iteration 1360, loss = 0.862917
I0521 09:40:54.173152  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.862917 (* 1 = 0.862917 loss)
I0521 09:40:54.173174  3675 sgd_solver.cpp:138] Iteration 1360, lr = 0.0001
I0521 09:40:57.651135  3675 solver.cpp:243] Iteration 1380, loss = 0.861835
I0521 09:40:57.651167  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.861835 (* 1 = 0.861835 loss)
I0521 09:40:57.651173  3675 sgd_solver.cpp:138] Iteration 1380, lr = 0.0001
I0521 09:41:01.189236  3675 solver.cpp:243] Iteration 1400, loss = 0.944153
I0521 09:41:01.189405  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.944153 (* 1 = 0.944153 loss)
I0521 09:41:01.189414  3675 sgd_solver.cpp:138] Iteration 1400, lr = 0.0001
I0521 09:41:04.731015  3675 solver.cpp:243] Iteration 1420, loss = 0.690201
I0521 09:41:04.731045  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.690201 (* 1 = 0.690201 loss)
I0521 09:41:04.731050  3675 sgd_solver.cpp:138] Iteration 1420, lr = 0.0001
I0521 09:41:08.278614  3675 solver.cpp:243] Iteration 1440, loss = 0.710182
I0521 09:41:08.278643  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.710182 (* 1 = 0.710182 loss)
I0521 09:41:08.278650  3675 sgd_solver.cpp:138] Iteration 1440, lr = 0.0001
I0521 09:41:11.813766  3675 solver.cpp:243] Iteration 1460, loss = 1.00626
I0521 09:41:11.813796  3675 solver.cpp:259]     Train net output #0: ctcloss = 1.00626 (* 1 = 1.00626 loss)
I0521 09:41:11.813802  3675 sgd_solver.cpp:138] Iteration 1460, lr = 0.0001
I0521 09:41:15.363997  3675 solver.cpp:243] Iteration 1480, loss = 0.957748
I0521 09:41:15.364027  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.957748 (* 1 = 0.957748 loss)
I0521 09:41:15.364032  3675 sgd_solver.cpp:138] Iteration 1480, lr = 0.0001
I0521 09:41:18.910576  3675 solver.cpp:243] Iteration 1500, loss = 0.771626
I0521 09:41:18.910607  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.771626 (* 1 = 0.771626 loss)
I0521 09:41:18.910614  3675 sgd_solver.cpp:138] Iteration 1500, lr = 0.0001
I0521 09:41:22.451480  3675 solver.cpp:243] Iteration 1520, loss = 0.765569
I0521 09:41:22.451511  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.765569 (* 1 = 0.765569 loss)
I0521 09:41:22.451516  3675 sgd_solver.cpp:138] Iteration 1520, lr = 0.0001
I0521 09:41:25.997321  3675 solver.cpp:243] Iteration 1540, loss = 0.895571
I0521 09:41:25.997351  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.895571 (* 1 = 0.895571 loss)
I0521 09:41:25.997359  3675 sgd_solver.cpp:138] Iteration 1540, lr = 0.0001
I0521 09:41:29.547969  3675 solver.cpp:243] Iteration 1560, loss = 0.782309
I0521 09:41:29.547999  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.782309 (* 1 = 0.782309 loss)
I0521 09:41:29.548004  3675 sgd_solver.cpp:138] Iteration 1560, lr = 0.0001
I0521 09:41:33.099846  3675 solver.cpp:243] Iteration 1580, loss = 0.856559
I0521 09:41:33.100034  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.856559 (* 1 = 0.856559 loss)
I0521 09:41:33.100042  3675 sgd_solver.cpp:138] Iteration 1580, lr = 0.0001
I0521 09:41:36.649255  3675 solver.cpp:243] Iteration 1600, loss = 0.661568
I0521 09:41:36.649286  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.661568 (* 1 = 0.661568 loss)
I0521 09:41:36.649291  3675 sgd_solver.cpp:138] Iteration 1600, lr = 0.0001
I0521 09:41:40.183761  3675 solver.cpp:243] Iteration 1620, loss = 0.60544
I0521 09:41:40.183792  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.60544 (* 1 = 0.60544 loss)
I0521 09:41:40.183799  3675 sgd_solver.cpp:138] Iteration 1620, lr = 0.0001
I0521 09:41:43.732209  3675 solver.cpp:243] Iteration 1640, loss = 0.808795
I0521 09:41:43.732239  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.808795 (* 1 = 0.808795 loss)
I0521 09:41:43.732245  3675 sgd_solver.cpp:138] Iteration 1640, lr = 0.0001
I0521 09:41:47.285601  3675 solver.cpp:243] Iteration 1660, loss = 0.67748
I0521 09:41:47.285629  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.67748 (* 1 = 0.67748 loss)
I0521 09:41:47.285635  3675 sgd_solver.cpp:138] Iteration 1660, lr = 0.0001
I0521 09:41:50.821852  3675 solver.cpp:243] Iteration 1680, loss = 0.585831
I0521 09:41:50.821882  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.585831 (* 1 = 0.585831 loss)
I0521 09:41:50.821888  3675 sgd_solver.cpp:138] Iteration 1680, lr = 0.0001
I0521 09:41:54.400768  3675 solver.cpp:243] Iteration 1700, loss = 0.755249
I0521 09:41:54.400801  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.755249 (* 1 = 0.755249 loss)
I0521 09:41:54.400807  3675 sgd_solver.cpp:138] Iteration 1700, lr = 0.0001
I0521 09:41:58.020488  3675 solver.cpp:243] Iteration 1720, loss = 0.641336
I0521 09:41:58.020521  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.641336 (* 1 = 0.641336 loss)
I0521 09:41:58.020529  3675 sgd_solver.cpp:138] Iteration 1720, lr = 0.0001
I0521 09:42:01.587565  3675 solver.cpp:243] Iteration 1740, loss = 0.472526
I0521 09:42:01.587596  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.472526 (* 1 = 0.472526 loss)
I0521 09:42:01.587601  3675 sgd_solver.cpp:138] Iteration 1740, lr = 0.0001
I0521 09:42:05.090500  3675 solver.cpp:243] Iteration 1760, loss = 0.526088
I0521 09:42:05.090589  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.526088 (* 1 = 0.526088 loss)
I0521 09:42:05.090595  3675 sgd_solver.cpp:138] Iteration 1760, lr = 0.0001
I0521 09:42:08.598124  3675 solver.cpp:243] Iteration 1780, loss = 0.899745
I0521 09:42:08.598155  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.899745 (* 1 = 0.899745 loss)
I0521 09:42:08.598177  3675 sgd_solver.cpp:138] Iteration 1780, lr = 0.0001
I0521 09:42:12.101799  3675 solver.cpp:243] Iteration 1800, loss = 0.716552
I0521 09:42:12.101831  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.716552 (* 1 = 0.716552 loss)
I0521 09:42:12.101837  3675 sgd_solver.cpp:138] Iteration 1800, lr = 0.0001
I0521 09:42:15.604825  3675 solver.cpp:243] Iteration 1820, loss = 0.664818
I0521 09:42:15.604856  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.664818 (* 1 = 0.664818 loss)
I0521 09:42:15.604877  3675 sgd_solver.cpp:138] Iteration 1820, lr = 0.0001
I0521 09:42:19.112555  3675 solver.cpp:243] Iteration 1840, loss = 0.596328
I0521 09:42:19.112583  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.596328 (* 1 = 0.596328 loss)
I0521 09:42:19.112588  3675 sgd_solver.cpp:138] Iteration 1840, lr = 0.0001
I0521 09:42:22.616765  3675 solver.cpp:243] Iteration 1860, loss = 0.651451
I0521 09:42:22.616799  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.651451 (* 1 = 0.651451 loss)
I0521 09:42:22.616806  3675 sgd_solver.cpp:138] Iteration 1860, lr = 0.0001
I0521 09:42:26.121022  3675 solver.cpp:243] Iteration 1880, loss = 0.506215
I0521 09:42:26.121052  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.506215 (* 1 = 0.506215 loss)
I0521 09:42:26.121073  3675 sgd_solver.cpp:138] Iteration 1880, lr = 0.0001
I0521 09:42:29.627399  3675 solver.cpp:243] Iteration 1900, loss = 0.506759
I0521 09:42:29.627429  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.506759 (* 1 = 0.506759 loss)
I0521 09:42:29.627434  3675 sgd_solver.cpp:138] Iteration 1900, lr = 0.0001
I0521 09:42:33.132004  3675 solver.cpp:243] Iteration 1920, loss = 0.64124
I0521 09:42:33.132035  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.64124 (* 1 = 0.64124 loss)
I0521 09:42:33.132040  3675 sgd_solver.cpp:138] Iteration 1920, lr = 0.0001
I0521 09:42:36.634016  3675 solver.cpp:243] Iteration 1940, loss = 0.593142
I0521 09:42:36.634182  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.593142 (* 1 = 0.593142 loss)
I0521 09:42:36.634189  3675 sgd_solver.cpp:138] Iteration 1940, lr = 0.0001
I0521 09:42:40.138564  3675 solver.cpp:243] Iteration 1960, loss = 0.36794
I0521 09:42:40.138595  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.36794 (* 1 = 0.36794 loss)
I0521 09:42:40.138600  3675 sgd_solver.cpp:138] Iteration 1960, lr = 0.0001
I0521 09:42:43.642385  3675 solver.cpp:243] Iteration 1980, loss = 0.689229
I0521 09:42:43.642416  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.689229 (* 1 = 0.689229 loss)
I0521 09:42:43.642422  3675 sgd_solver.cpp:138] Iteration 1980, lr = 0.0001
I0521 09:42:47.012722  3675 solver.cpp:596] Snapshotting to binary proto file models/LPR/lpr_resnet_lstm_iter_2000.caffemodel
I0521 09:42:47.053803  3675 sgd_solver.cpp:307] Snapshotting solver state to binary proto file models/LPR/lpr_resnet_lstm_iter_2000.solverstate
I0521 09:42:47.071082  3675 solver.cpp:358] Iteration 2000, Testing net (#0)
I0521 09:42:51.794723  3675 solver.cpp:425]     Test net output #0: acc = 0.981976
I0521 09:42:51.794751  3675 solver.cpp:425]     Test net output #1: acc = 0.885234
I0521 09:42:51.794757  3675 solver.cpp:425]     Test net output #2: ctcloss = 0.50805 (* 1 = 0.50805 loss)
I0521 09:42:51.932042  3675 solver.cpp:243] Iteration 2000, loss = 0.457576
I0521 09:42:51.932075  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.457576 (* 1 = 0.457576 loss)
I0521 09:42:51.932097  3675 sgd_solver.cpp:138] Iteration 2000, lr = 0.0001
I0521 09:42:55.449625  3675 solver.cpp:243] Iteration 2020, loss = 0.398668
I0521 09:42:55.449657  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.398668 (* 1 = 0.398668 loss)
I0521 09:42:55.449666  3675 sgd_solver.cpp:138] Iteration 2020, lr = 0.0001
I0521 09:42:58.959527  3675 solver.cpp:243] Iteration 2040, loss = 0.469808
I0521 09:42:58.959559  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.469808 (* 1 = 0.469808 loss)
I0521 09:42:58.959565  3675 sgd_solver.cpp:138] Iteration 2040, lr = 0.0001
I0521 09:43:02.476114  3675 solver.cpp:243] Iteration 2060, loss = 0.642888
I0521 09:43:02.476143  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.642888 (* 1 = 0.642888 loss)
I0521 09:43:02.476150  3675 sgd_solver.cpp:138] Iteration 2060, lr = 0.0001
I0521 09:43:05.985460  3675 solver.cpp:243] Iteration 2080, loss = 0.506641
I0521 09:43:05.985489  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.506641 (* 1 = 0.506641 loss)
I0521 09:43:05.985496  3675 sgd_solver.cpp:138] Iteration 2080, lr = 0.0001
I0521 09:43:09.494586  3675 solver.cpp:243] Iteration 2100, loss = 0.453742
I0521 09:43:09.494738  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.453742 (* 1 = 0.453742 loss)
I0521 09:43:09.494745  3675 sgd_solver.cpp:138] Iteration 2100, lr = 0.0001
I0521 09:43:13.006865  3675 solver.cpp:243] Iteration 2120, loss = 0.263767
I0521 09:43:13.006896  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.263767 (* 1 = 0.263767 loss)
I0521 09:43:13.006901  3675 sgd_solver.cpp:138] Iteration 2120, lr = 0.0001
I0521 09:43:16.517051  3675 solver.cpp:243] Iteration 2140, loss = 0.527373
I0521 09:43:16.517091  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.527373 (* 1 = 0.527373 loss)
I0521 09:43:16.517099  3675 sgd_solver.cpp:138] Iteration 2140, lr = 0.0001
I0521 09:43:20.022395  3675 solver.cpp:243] Iteration 2160, loss = 0.645441
I0521 09:43:20.022424  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.645441 (* 1 = 0.645441 loss)
I0521 09:43:20.022430  3675 sgd_solver.cpp:138] Iteration 2160, lr = 0.0001
I0521 09:43:23.530701  3675 solver.cpp:243] Iteration 2180, loss = 0.339503
I0521 09:43:23.530732  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.339503 (* 1 = 0.339503 loss)
I0521 09:43:23.530738  3675 sgd_solver.cpp:138] Iteration 2180, lr = 0.0001
I0521 09:43:27.040357  3675 solver.cpp:243] Iteration 2200, loss = 0.514129
I0521 09:43:27.040388  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.514129 (* 1 = 0.514129 loss)
I0521 09:43:27.040393  3675 sgd_solver.cpp:138] Iteration 2200, lr = 0.0001
I0521 09:43:30.545508  3675 solver.cpp:243] Iteration 2220, loss = 0.392103
I0521 09:43:30.545541  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.392103 (* 1 = 0.392103 loss)
I0521 09:43:30.545547  3675 sgd_solver.cpp:138] Iteration 2220, lr = 0.0001
I0521 09:43:34.055263  3675 solver.cpp:243] Iteration 2240, loss = 0.374878
I0521 09:43:34.055294  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.374878 (* 1 = 0.374878 loss)
I0521 09:43:34.055300  3675 sgd_solver.cpp:138] Iteration 2240, lr = 0.0001
I0521 09:43:37.562911  3675 solver.cpp:243] Iteration 2260, loss = 0.381249
I0521 09:43:37.562942  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.381249 (* 1 = 0.381249 loss)
I0521 09:43:37.562948  3675 sgd_solver.cpp:138] Iteration 2260, lr = 0.0001
I0521 09:43:41.067297  3675 solver.cpp:243] Iteration 2280, loss = 0.473264
I0521 09:43:41.067459  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.473264 (* 1 = 0.473264 loss)
I0521 09:43:41.067467  3675 sgd_solver.cpp:138] Iteration 2280, lr = 0.0001
I0521 09:43:44.575280  3675 solver.cpp:243] Iteration 2300, loss = 0.379298
I0521 09:43:44.575311  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.379298 (* 1 = 0.379298 loss)
I0521 09:43:44.575317  3675 sgd_solver.cpp:138] Iteration 2300, lr = 0.0001
I0521 09:43:48.086730  3675 solver.cpp:243] Iteration 2320, loss = 0.399016
I0521 09:43:48.086761  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.399016 (* 1 = 0.399016 loss)
I0521 09:43:48.086767  3675 sgd_solver.cpp:138] Iteration 2320, lr = 0.0001
I0521 09:43:51.592689  3675 solver.cpp:243] Iteration 2340, loss = 0.583158
I0521 09:43:51.592720  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.583158 (* 1 = 0.583158 loss)
I0521 09:43:51.592726  3675 sgd_solver.cpp:138] Iteration 2340, lr = 0.0001
I0521 09:43:55.098863  3675 solver.cpp:243] Iteration 2360, loss = 0.297921
I0521 09:43:55.098896  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.297921 (* 1 = 0.297921 loss)
I0521 09:43:55.098901  3675 sgd_solver.cpp:138] Iteration 2360, lr = 0.0001
I0521 09:43:58.604210  3675 solver.cpp:243] Iteration 2380, loss = 0.349604
I0521 09:43:58.604243  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.349604 (* 1 = 0.349604 loss)
I0521 09:43:58.604248  3675 sgd_solver.cpp:138] Iteration 2380, lr = 0.0001
I0521 09:44:02.116350  3675 solver.cpp:243] Iteration 2400, loss = 0.406494
I0521 09:44:02.116382  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.406494 (* 1 = 0.406494 loss)
I0521 09:44:02.116389  3675 sgd_solver.cpp:138] Iteration 2400, lr = 0.0001
I0521 09:44:05.626271  3675 solver.cpp:243] Iteration 2420, loss = 0.435767
I0521 09:44:05.626303  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.435767 (* 1 = 0.435767 loss)
I0521 09:44:05.626309  3675 sgd_solver.cpp:138] Iteration 2420, lr = 0.0001
I0521 09:44:09.140728  3675 solver.cpp:243] Iteration 2440, loss = 0.302858
I0521 09:44:09.140761  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.302858 (* 1 = 0.302858 loss)
I0521 09:44:09.140767  3675 sgd_solver.cpp:138] Iteration 2440, lr = 0.0001
I0521 09:44:12.643988  3675 solver.cpp:243] Iteration 2460, loss = 0.417538
I0521 09:44:12.644150  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.417538 (* 1 = 0.417538 loss)
I0521 09:44:12.644158  3675 sgd_solver.cpp:138] Iteration 2460, lr = 0.0001
I0521 09:44:16.148703  3675 solver.cpp:243] Iteration 2480, loss = 0.343748
I0521 09:44:16.148735  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.343748 (* 1 = 0.343748 loss)
I0521 09:44:16.148741  3675 sgd_solver.cpp:138] Iteration 2480, lr = 0.0001
I0521 09:44:19.656033  3675 solver.cpp:243] Iteration 2500, loss = 0.411648
I0521 09:44:19.656064  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.411648 (* 1 = 0.411648 loss)
I0521 09:44:19.656069  3675 sgd_solver.cpp:138] Iteration 2500, lr = 0.0001
I0521 09:44:23.165482  3675 solver.cpp:243] Iteration 2520, loss = 0.36034
I0521 09:44:23.165513  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.36034 (* 1 = 0.36034 loss)
I0521 09:44:23.165519  3675 sgd_solver.cpp:138] Iteration 2520, lr = 0.0001
I0521 09:44:26.677177  3675 solver.cpp:243] Iteration 2540, loss = 0.282131
I0521 09:44:26.677208  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.282131 (* 1 = 0.282131 loss)
I0521 09:44:26.677214  3675 sgd_solver.cpp:138] Iteration 2540, lr = 0.0001
I0521 09:44:30.193470  3675 solver.cpp:243] Iteration 2560, loss = 0.254407
I0521 09:44:30.193501  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.254407 (* 1 = 0.254407 loss)
I0521 09:44:30.193508  3675 sgd_solver.cpp:138] Iteration 2560, lr = 0.0001
I0521 09:44:33.706241  3675 solver.cpp:243] Iteration 2580, loss = 0.337986
I0521 09:44:33.706274  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.337986 (* 1 = 0.337986 loss)
I0521 09:44:33.706295  3675 sgd_solver.cpp:138] Iteration 2580, lr = 0.0001
I0521 09:44:37.225044  3675 solver.cpp:243] Iteration 2600, loss = 0.368068
I0521 09:44:37.225075  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.368068 (* 1 = 0.368068 loss)
I0521 09:44:37.225081  3675 sgd_solver.cpp:138] Iteration 2600, lr = 0.0001
I0521 09:44:40.739138  3675 solver.cpp:243] Iteration 2620, loss = 0.362188
I0521 09:44:40.739186  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.362188 (* 1 = 0.362188 loss)
I0521 09:44:40.739192  3675 sgd_solver.cpp:138] Iteration 2620, lr = 0.0001
I0521 09:44:44.248942  3675 solver.cpp:243] Iteration 2640, loss = 0.504418
I0521 09:44:44.249109  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.504418 (* 1 = 0.504418 loss)
I0521 09:44:44.249116  3675 sgd_solver.cpp:138] Iteration 2640, lr = 0.0001
I0521 09:44:47.762565  3675 solver.cpp:243] Iteration 2660, loss = 0.348004
I0521 09:44:47.762598  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.348004 (* 1 = 0.348004 loss)
I0521 09:44:47.762620  3675 sgd_solver.cpp:138] Iteration 2660, lr = 0.0001
I0521 09:44:51.209657  3675 solver.cpp:243] Iteration 2680, loss = 0.52645
I0521 09:44:51.209688  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.52645 (* 1 = 0.52645 loss)
I0521 09:44:51.209694  3675 sgd_solver.cpp:138] Iteration 2680, lr = 0.0001
I0521 09:44:54.721957  3675 solver.cpp:243] Iteration 2700, loss = 0.413666
I0521 09:44:54.721988  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.413666 (* 1 = 0.413666 loss)
I0521 09:44:54.721993  3675 sgd_solver.cpp:138] Iteration 2700, lr = 0.0001
I0521 09:44:58.233626  3675 solver.cpp:243] Iteration 2720, loss = 0.349565
I0521 09:44:58.233659  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.349565 (* 1 = 0.349565 loss)
I0521 09:44:58.233665  3675 sgd_solver.cpp:138] Iteration 2720, lr = 0.0001
I0521 09:45:01.748855  3675 solver.cpp:243] Iteration 2740, loss = 0.303027
I0521 09:45:01.748888  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.303027 (* 1 = 0.303027 loss)
I0521 09:45:01.748894  3675 sgd_solver.cpp:138] Iteration 2740, lr = 0.0001
I0521 09:45:05.262075  3675 solver.cpp:243] Iteration 2760, loss = 0.218108
I0521 09:45:05.262106  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.218108 (* 1 = 0.218108 loss)
I0521 09:45:05.262127  3675 sgd_solver.cpp:138] Iteration 2760, lr = 0.0001
I0521 09:45:08.774996  3675 solver.cpp:243] Iteration 2780, loss = 0.368222
I0521 09:45:08.775028  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.368222 (* 1 = 0.368222 loss)
I0521 09:45:08.775035  3675 sgd_solver.cpp:138] Iteration 2780, lr = 0.0001
I0521 09:45:12.289849  3675 solver.cpp:243] Iteration 2800, loss = 0.218974
I0521 09:45:12.289881  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.218974 (* 1 = 0.218974 loss)
I0521 09:45:12.289887  3675 sgd_solver.cpp:138] Iteration 2800, lr = 0.0001
I0521 09:45:15.809783  3675 solver.cpp:243] Iteration 2820, loss = 0.429161
I0521 09:45:15.809900  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.429161 (* 1 = 0.429161 loss)
I0521 09:45:15.809909  3675 sgd_solver.cpp:138] Iteration 2820, lr = 0.0001
I0521 09:45:19.322942  3675 solver.cpp:243] Iteration 2840, loss = 0.550312
I0521 09:45:19.322973  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.550312 (* 1 = 0.550312 loss)
I0521 09:45:19.322979  3675 sgd_solver.cpp:138] Iteration 2840, lr = 0.0001
I0521 09:45:22.831415  3675 solver.cpp:243] Iteration 2860, loss = 0.300341
I0521 09:45:22.831447  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.300341 (* 1 = 0.300341 loss)
I0521 09:45:22.831454  3675 sgd_solver.cpp:138] Iteration 2860, lr = 0.0001
I0521 09:45:26.345957  3675 solver.cpp:243] Iteration 2880, loss = 0.332357
I0521 09:45:26.345988  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.332357 (* 1 = 0.332357 loss)
I0521 09:45:26.345993  3675 sgd_solver.cpp:138] Iteration 2880, lr = 0.0001
I0521 09:45:29.863528  3675 solver.cpp:243] Iteration 2900, loss = 0.325715
I0521 09:45:29.863559  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.325715 (* 1 = 0.325715 loss)
I0521 09:45:29.863564  3675 sgd_solver.cpp:138] Iteration 2900, lr = 0.0001
I0521 09:45:33.376915  3675 solver.cpp:243] Iteration 2920, loss = 0.282949
I0521 09:45:33.376947  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.282949 (* 1 = 0.282949 loss)
I0521 09:45:33.376953  3675 sgd_solver.cpp:138] Iteration 2920, lr = 0.0001
I0521 09:45:36.890902  3675 solver.cpp:243] Iteration 2940, loss = 0.32759
I0521 09:45:36.890933  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.32759 (* 1 = 0.32759 loss)
I0521 09:45:36.890938  3675 sgd_solver.cpp:138] Iteration 2940, lr = 0.0001
I0521 09:45:40.406236  3675 solver.cpp:243] Iteration 2960, loss = 0.238287
I0521 09:45:40.406267  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.238287 (* 1 = 0.238287 loss)
I0521 09:45:40.406273  3675 sgd_solver.cpp:138] Iteration 2960, lr = 0.0001
I0521 09:45:43.922600  3675 solver.cpp:243] Iteration 2980, loss = 0.304569
I0521 09:45:43.922631  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.304569 (* 1 = 0.304569 loss)
I0521 09:45:43.922637  3675 sgd_solver.cpp:138] Iteration 2980, lr = 0.0001
I0521 09:45:47.310331  3675 solver.cpp:358] Iteration 3000, Testing net (#0)
I0521 09:45:52.030638  3675 solver.cpp:425]     Test net output #0: acc = 0.995893
I0521 09:45:52.030666  3675 solver.cpp:425]     Test net output #1: acc = 0.97125
I0521 09:45:52.030673  3675 solver.cpp:425]     Test net output #2: ctcloss = 0.0945509 (* 1 = 0.0945509 loss)
I0521 09:45:52.164631  3675 solver.cpp:243] Iteration 3000, loss = 0.322274
I0521 09:45:52.164659  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.322274 (* 1 = 0.322274 loss)
I0521 09:45:52.164665  3675 sgd_solver.cpp:138] Iteration 3000, lr = 0.0001
I0521 09:45:55.687391  3675 solver.cpp:243] Iteration 3020, loss = 0.300566
I0521 09:45:55.687438  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.300566 (* 1 = 0.300566 loss)
I0521 09:45:55.687444  3675 sgd_solver.cpp:138] Iteration 3020, lr = 0.0001
I0521 09:45:59.200364  3675 solver.cpp:243] Iteration 3040, loss = 0.329172
I0521 09:45:59.200395  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.329172 (* 1 = 0.329172 loss)
I0521 09:45:59.200400  3675 sgd_solver.cpp:138] Iteration 3040, lr = 0.0001
I0521 09:46:02.713430  3675 solver.cpp:243] Iteration 3060, loss = 0.253075
I0521 09:46:02.713462  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.253075 (* 1 = 0.253075 loss)
I0521 09:46:02.713485  3675 sgd_solver.cpp:138] Iteration 3060, lr = 0.0001
I0521 09:46:06.229369  3675 solver.cpp:243] Iteration 3080, loss = 0.268598
I0521 09:46:06.229398  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.268598 (* 1 = 0.268598 loss)
I0521 09:46:06.229419  3675 sgd_solver.cpp:138] Iteration 3080, lr = 0.0001
I0521 09:46:09.746249  3675 solver.cpp:243] Iteration 3100, loss = 0.190446
I0521 09:46:09.746280  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.190446 (* 1 = 0.190446 loss)
I0521 09:46:09.746286  3675 sgd_solver.cpp:138] Iteration 3100, lr = 0.0001
I0521 09:46:13.257019  3675 solver.cpp:243] Iteration 3120, loss = 0.233536
I0521 09:46:13.257050  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.233536 (* 1 = 0.233536 loss)
I0521 09:46:13.257055  3675 sgd_solver.cpp:138] Iteration 3120, lr = 0.0001
I0521 09:46:16.772119  3675 solver.cpp:243] Iteration 3140, loss = 0.296569
I0521 09:46:16.772148  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.296569 (* 1 = 0.296569 loss)
I0521 09:46:16.772155  3675 sgd_solver.cpp:138] Iteration 3140, lr = 0.0001
I0521 09:46:20.290508  3675 solver.cpp:243] Iteration 3160, loss = 0.216472
I0521 09:46:20.290679  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.216472 (* 1 = 0.216472 loss)
I0521 09:46:20.290688  3675 sgd_solver.cpp:138] Iteration 3160, lr = 0.0001
I0521 09:46:23.813118  3675 solver.cpp:243] Iteration 3180, loss = 0.180976
I0521 09:46:23.813149  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.180976 (* 1 = 0.180976 loss)
I0521 09:46:23.813155  3675 sgd_solver.cpp:138] Iteration 3180, lr = 0.0001
I0521 09:46:27.538067  3675 solver.cpp:243] Iteration 3200, loss = 0.163638
I0521 09:46:27.538098  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.163638 (* 1 = 0.163638 loss)
I0521 09:46:27.538120  3675 sgd_solver.cpp:138] Iteration 3200, lr = 0.0001
I0521 09:46:31.107532  3675 solver.cpp:243] Iteration 3220, loss = 0.223393
I0521 09:46:31.107563  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.223393 (* 1 = 0.223393 loss)
I0521 09:46:31.107584  3675 sgd_solver.cpp:138] Iteration 3220, lr = 0.0001
I0521 09:46:34.693632  3675 solver.cpp:243] Iteration 3240, loss = 0.242231
I0521 09:46:34.693663  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.242231 (* 1 = 0.242231 loss)
I0521 09:46:34.693684  3675 sgd_solver.cpp:138] Iteration 3240, lr = 0.0001
I0521 09:46:38.325211  3675 solver.cpp:243] Iteration 3260, loss = 0.156554
I0521 09:46:38.325243  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.156554 (* 1 = 0.156554 loss)
I0521 09:46:38.325250  3675 sgd_solver.cpp:138] Iteration 3260, lr = 0.0001
I0521 09:46:41.904754  3675 solver.cpp:243] Iteration 3280, loss = 0.199981
I0521 09:46:41.904789  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.199981 (* 1 = 0.199981 loss)
I0521 09:46:41.904795  3675 sgd_solver.cpp:138] Iteration 3280, lr = 0.0001
I0521 09:46:45.500205  3675 solver.cpp:243] Iteration 3300, loss = 0.185967
I0521 09:46:45.500237  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.185967 (* 1 = 0.185967 loss)
I0521 09:46:45.500243  3675 sgd_solver.cpp:138] Iteration 3300, lr = 0.0001
I0521 09:46:49.070637  3675 solver.cpp:243] Iteration 3320, loss = 0.164947
I0521 09:46:49.070667  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.164947 (* 1 = 0.164947 loss)
I0521 09:46:49.070672  3675 sgd_solver.cpp:138] Iteration 3320, lr = 0.0001
I0521 09:46:52.659656  3675 solver.cpp:243] Iteration 3340, loss = 0.126298
I0521 09:46:52.659822  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.126298 (* 1 = 0.126298 loss)
I0521 09:46:52.659829  3675 sgd_solver.cpp:138] Iteration 3340, lr = 0.0001
I0521 09:46:56.235432  3675 solver.cpp:243] Iteration 3360, loss = 0.1103
I0521 09:46:56.235463  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.1103 (* 1 = 0.1103 loss)
I0521 09:46:56.235486  3675 sgd_solver.cpp:138] Iteration 3360, lr = 0.0001
I0521 09:46:59.828361  3675 solver.cpp:243] Iteration 3380, loss = 0.25908
I0521 09:46:59.828392  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.25908 (* 1 = 0.25908 loss)
I0521 09:46:59.828415  3675 sgd_solver.cpp:138] Iteration 3380, lr = 0.0001
I0521 09:47:03.412830  3675 solver.cpp:243] Iteration 3400, loss = 0.150322
I0521 09:47:03.412863  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.150322 (* 1 = 0.150322 loss)
I0521 09:47:03.412870  3675 sgd_solver.cpp:138] Iteration 3400, lr = 0.0001
I0521 09:47:07.004982  3675 solver.cpp:243] Iteration 3420, loss = 0.230647
I0521 09:47:07.005012  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.230647 (* 1 = 0.230647 loss)
I0521 09:47:07.005018  3675 sgd_solver.cpp:138] Iteration 3420, lr = 0.0001
I0521 09:47:10.585659  3675 solver.cpp:243] Iteration 3440, loss = 0.281236
I0521 09:47:10.585690  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.281236 (* 1 = 0.281236 loss)
I0521 09:47:10.585711  3675 sgd_solver.cpp:138] Iteration 3440, lr = 0.0001
I0521 09:47:14.164645  3675 solver.cpp:243] Iteration 3460, loss = 0.268842
I0521 09:47:14.164677  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.268842 (* 1 = 0.268842 loss)
I0521 09:47:14.164685  3675 sgd_solver.cpp:138] Iteration 3460, lr = 0.0001
I0521 09:47:17.745162  3675 solver.cpp:243] Iteration 3480, loss = 0.325407
I0521 09:47:17.745191  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.325407 (* 1 = 0.325407 loss)
I0521 09:47:17.745198  3675 sgd_solver.cpp:138] Iteration 3480, lr = 0.0001
I0521 09:47:21.309986  3675 solver.cpp:243] Iteration 3500, loss = 0.180437
I0521 09:47:21.310019  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.180437 (* 1 = 0.180437 loss)
I0521 09:47:21.310024  3675 sgd_solver.cpp:138] Iteration 3500, lr = 0.0001
I0521 09:47:24.897827  3675 solver.cpp:243] Iteration 3520, loss = 0.224377
I0521 09:47:24.897995  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.224377 (* 1 = 0.224377 loss)
I0521 09:47:24.898003  3675 sgd_solver.cpp:138] Iteration 3520, lr = 0.0001
I0521 09:47:28.477387  3675 solver.cpp:243] Iteration 3540, loss = 0.257536
I0521 09:47:28.477418  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.257536 (* 1 = 0.257536 loss)
I0521 09:47:28.477442  3675 sgd_solver.cpp:138] Iteration 3540, lr = 0.0001
I0521 09:47:32.053690  3675 solver.cpp:243] Iteration 3560, loss = 0.171308
I0521 09:47:32.053721  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.171308 (* 1 = 0.171308 loss)
I0521 09:47:32.053745  3675 sgd_solver.cpp:138] Iteration 3560, lr = 0.0001
I0521 09:47:35.636996  3675 solver.cpp:243] Iteration 3580, loss = 0.121292
I0521 09:47:35.637027  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.121292 (* 1 = 0.121292 loss)
I0521 09:47:35.637033  3675 sgd_solver.cpp:138] Iteration 3580, lr = 0.0001
I0521 09:47:39.224591  3675 solver.cpp:243] Iteration 3600, loss = 0.150482
I0521 09:47:39.224624  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.150482 (* 1 = 0.150482 loss)
I0521 09:47:39.224630  3675 sgd_solver.cpp:138] Iteration 3600, lr = 0.0001
I0521 09:47:42.807082  3675 solver.cpp:243] Iteration 3620, loss = 0.125981
I0521 09:47:42.807121  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.125981 (* 1 = 0.125981 loss)
I0521 09:47:42.807128  3675 sgd_solver.cpp:138] Iteration 3620, lr = 0.0001
I0521 09:47:46.365933  3675 solver.cpp:243] Iteration 3640, loss = 0.122564
I0521 09:47:46.365967  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.122564 (* 1 = 0.122564 loss)
I0521 09:47:46.365972  3675 sgd_solver.cpp:138] Iteration 3640, lr = 0.0001
I0521 09:47:49.960043  3675 solver.cpp:243] Iteration 3660, loss = 0.33047
I0521 09:47:49.960074  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.33047 (* 1 = 0.33047 loss)
I0521 09:47:49.960095  3675 sgd_solver.cpp:138] Iteration 3660, lr = 0.0001
I0521 09:47:53.550732  3675 solver.cpp:243] Iteration 3680, loss = 0.159404
I0521 09:47:53.550762  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.159404 (* 1 = 0.159404 loss)
I0521 09:47:53.550768  3675 sgd_solver.cpp:138] Iteration 3680, lr = 0.0001
I0521 09:47:57.130746  3675 solver.cpp:243] Iteration 3700, loss = 0.136655
I0521 09:47:57.130923  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.136655 (* 1 = 0.136655 loss)
I0521 09:47:57.130931  3675 sgd_solver.cpp:138] Iteration 3700, lr = 0.0001
I0521 09:48:00.722609  3675 solver.cpp:243] Iteration 3720, loss = 0.0875991
I0521 09:48:00.722640  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0875991 (* 1 = 0.0875991 loss)
I0521 09:48:00.722645  3675 sgd_solver.cpp:138] Iteration 3720, lr = 0.0001
I0521 09:48:04.299278  3675 solver.cpp:243] Iteration 3740, loss = 0.153756
I0521 09:48:04.299311  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.153756 (* 1 = 0.153756 loss)
I0521 09:48:04.299317  3675 sgd_solver.cpp:138] Iteration 3740, lr = 0.0001
I0521 09:48:07.879297  3675 solver.cpp:243] Iteration 3760, loss = 0.0809255
I0521 09:48:07.879328  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0809254 (* 1 = 0.0809254 loss)
I0521 09:48:07.879334  3675 sgd_solver.cpp:138] Iteration 3760, lr = 0.0001
I0521 09:48:11.467325  3675 solver.cpp:243] Iteration 3780, loss = 0.15223
I0521 09:48:11.467356  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.15223 (* 1 = 0.15223 loss)
I0521 09:48:11.467362  3675 sgd_solver.cpp:138] Iteration 3780, lr = 0.0001
I0521 09:48:15.046499  3675 solver.cpp:243] Iteration 3800, loss = 0.107137
I0521 09:48:15.046530  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.107137 (* 1 = 0.107137 loss)
I0521 09:48:15.046536  3675 sgd_solver.cpp:138] Iteration 3800, lr = 0.0001
I0521 09:48:18.638942  3675 solver.cpp:243] Iteration 3820, loss = 0.126513
I0521 09:48:18.638972  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.126513 (* 1 = 0.126513 loss)
I0521 09:48:18.638978  3675 sgd_solver.cpp:138] Iteration 3820, lr = 0.0001
I0521 09:48:22.214498  3675 solver.cpp:243] Iteration 3840, loss = 0.140783
I0521 09:48:22.214529  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.140783 (* 1 = 0.140783 loss)
I0521 09:48:22.214550  3675 sgd_solver.cpp:138] Iteration 3840, lr = 0.0001
I0521 09:48:25.807796  3675 solver.cpp:243] Iteration 3860, loss = 0.131815
I0521 09:48:25.807826  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.131815 (* 1 = 0.131815 loss)
I0521 09:48:25.807832  3675 sgd_solver.cpp:138] Iteration 3860, lr = 0.0001
I0521 09:48:29.383344  3675 solver.cpp:243] Iteration 3880, loss = 0.130186
I0521 09:48:29.383477  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.130186 (* 1 = 0.130186 loss)
I0521 09:48:29.383484  3675 sgd_solver.cpp:138] Iteration 3880, lr = 0.0001
I0521 09:48:32.971673  3675 solver.cpp:243] Iteration 3900, loss = 0.162086
I0521 09:48:32.971705  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.162086 (* 1 = 0.162086 loss)
I0521 09:48:32.971711  3675 sgd_solver.cpp:138] Iteration 3900, lr = 0.0001
I0521 09:48:36.551990  3675 solver.cpp:243] Iteration 3920, loss = 0.208437
I0521 09:48:36.552022  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.208437 (* 1 = 0.208437 loss)
I0521 09:48:36.552028  3675 sgd_solver.cpp:138] Iteration 3920, lr = 0.0001
I0521 09:48:40.139995  3675 solver.cpp:243] Iteration 3940, loss = 0.156949
I0521 09:48:40.140027  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.156949 (* 1 = 0.156949 loss)
I0521 09:48:40.140033  3675 sgd_solver.cpp:138] Iteration 3940, lr = 0.0001
I0521 09:48:43.719877  3675 solver.cpp:243] Iteration 3960, loss = 0.204361
I0521 09:48:43.719908  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.204361 (* 1 = 0.204361 loss)
I0521 09:48:43.719930  3675 sgd_solver.cpp:138] Iteration 3960, lr = 0.0001
I0521 09:48:47.238572  3675 solver.cpp:243] Iteration 3980, loss = 0.101828
I0521 09:48:47.238605  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.101828 (* 1 = 0.101828 loss)
I0521 09:48:47.238610  3675 sgd_solver.cpp:138] Iteration 3980, lr = 0.0001
I0521 09:48:50.683841  3675 solver.cpp:596] Snapshotting to binary proto file models/LPR/lpr_resnet_lstm_iter_4000.caffemodel
I0521 09:48:50.714738  3675 sgd_solver.cpp:307] Snapshotting solver state to binary proto file models/LPR/lpr_resnet_lstm_iter_4000.solverstate
I0521 09:48:50.749356  3675 solver.cpp:358] Iteration 4000, Testing net (#0)
I0521 09:48:55.550627  3675 solver.cpp:425]     Test net output #0: acc = 0.997555
I0521 09:48:55.550657  3675 solver.cpp:425]     Test net output #1: acc = 0.982891
I0521 09:48:55.550665  3675 solver.cpp:425]     Test net output #2: ctcloss = 0.0673129 (* 1 = 0.0673129 loss)
I0521 09:48:55.691292  3675 solver.cpp:243] Iteration 4000, loss = 0.141033
I0521 09:48:55.691323  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.141033 (* 1 = 0.141033 loss)
I0521 09:48:55.691330  3675 sgd_solver.cpp:138] Iteration 4000, lr = 0.0001
I0521 09:48:59.272907  3675 solver.cpp:243] Iteration 4020, loss = 0.142694
I0521 09:48:59.272938  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.142694 (* 1 = 0.142694 loss)
I0521 09:48:59.272943  3675 sgd_solver.cpp:138] Iteration 4020, lr = 0.0001
I0521 09:49:02.856035  3675 solver.cpp:243] Iteration 4040, loss = 0.0924264
I0521 09:49:02.856149  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0924263 (* 1 = 0.0924263 loss)
I0521 09:49:02.856158  3675 sgd_solver.cpp:138] Iteration 4040, lr = 0.0001
I0521 09:49:06.435493  3675 solver.cpp:243] Iteration 4060, loss = 0.126026
I0521 09:49:06.435525  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.126026 (* 1 = 0.126026 loss)
I0521 09:49:06.435531  3675 sgd_solver.cpp:138] Iteration 4060, lr = 0.0001
I0521 09:49:10.018807  3675 solver.cpp:243] Iteration 4080, loss = 0.117804
I0521 09:49:10.018839  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.117804 (* 1 = 0.117804 loss)
I0521 09:49:10.018844  3675 sgd_solver.cpp:138] Iteration 4080, lr = 0.0001
I0521 09:49:13.595893  3675 solver.cpp:243] Iteration 4100, loss = 0.194961
I0521 09:49:13.595924  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.194961 (* 1 = 0.194961 loss)
I0521 09:49:13.595930  3675 sgd_solver.cpp:138] Iteration 4100, lr = 0.0001
I0521 09:49:17.179942  3675 solver.cpp:243] Iteration 4120, loss = 0.0913333
I0521 09:49:17.179975  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0913332 (* 1 = 0.0913332 loss)
I0521 09:49:17.179981  3675 sgd_solver.cpp:138] Iteration 4120, lr = 0.0001
I0521 09:49:20.750329  3675 solver.cpp:243] Iteration 4140, loss = 0.176811
I0521 09:49:20.750360  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.176811 (* 1 = 0.176811 loss)
I0521 09:49:20.750366  3675 sgd_solver.cpp:138] Iteration 4140, lr = 0.0001
I0521 09:49:24.330885  3675 solver.cpp:243] Iteration 4160, loss = 0.143651
I0521 09:49:24.330916  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.143651 (* 1 = 0.143651 loss)
I0521 09:49:24.330922  3675 sgd_solver.cpp:138] Iteration 4160, lr = 0.0001
I0521 09:49:27.911706  3675 solver.cpp:243] Iteration 4180, loss = 0.155135
I0521 09:49:27.911738  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.155135 (* 1 = 0.155135 loss)
I0521 09:49:27.911743  3675 sgd_solver.cpp:138] Iteration 4180, lr = 0.0001
I0521 09:49:31.500960  3675 solver.cpp:243] Iteration 4200, loss = 0.165479
I0521 09:49:31.500993  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.165478 (* 1 = 0.165478 loss)
I0521 09:49:31.500999  3675 sgd_solver.cpp:138] Iteration 4200, lr = 0.0001
I0521 09:49:35.076777  3675 solver.cpp:243] Iteration 4220, loss = 0.101653
I0521 09:49:35.076907  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.101653 (* 1 = 0.101653 loss)
I0521 09:49:35.076915  3675 sgd_solver.cpp:138] Iteration 4220, lr = 0.0001
I0521 09:49:38.660953  3675 solver.cpp:243] Iteration 4240, loss = 0.120117
I0521 09:49:38.660987  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.120117 (* 1 = 0.120117 loss)
I0521 09:49:38.660992  3675 sgd_solver.cpp:138] Iteration 4240, lr = 0.0001
I0521 09:49:42.222029  3675 solver.cpp:243] Iteration 4260, loss = 0.0587224
I0521 09:49:42.222060  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0587223 (* 1 = 0.0587223 loss)
I0521 09:49:42.222081  3675 sgd_solver.cpp:138] Iteration 4260, lr = 0.0001
I0521 09:49:45.805354  3675 solver.cpp:243] Iteration 4280, loss = 0.0901484
I0521 09:49:45.805387  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0901483 (* 1 = 0.0901483 loss)
I0521 09:49:45.805408  3675 sgd_solver.cpp:138] Iteration 4280, lr = 0.0001
I0521 09:49:49.392112  3675 solver.cpp:243] Iteration 4300, loss = 0.164709
I0521 09:49:49.392143  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.164709 (* 1 = 0.164709 loss)
I0521 09:49:49.392148  3675 sgd_solver.cpp:138] Iteration 4300, lr = 0.0001
I0521 09:49:52.974930  3675 solver.cpp:243] Iteration 4320, loss = 0.118883
I0521 09:49:52.974962  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.118883 (* 1 = 0.118883 loss)
I0521 09:49:52.974968  3675 sgd_solver.cpp:138] Iteration 4320, lr = 0.0001
I0521 09:49:56.561843  3675 solver.cpp:243] Iteration 4340, loss = 0.107906
I0521 09:49:56.561877  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.107906 (* 1 = 0.107906 loss)
I0521 09:49:56.561883  3675 sgd_solver.cpp:138] Iteration 4340, lr = 0.0001
I0521 09:50:00.144767  3675 solver.cpp:243] Iteration 4360, loss = 0.0716843
I0521 09:50:00.144805  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0716842 (* 1 = 0.0716842 loss)
I0521 09:50:00.144811  3675 sgd_solver.cpp:138] Iteration 4360, lr = 0.0001
I0521 09:50:03.723456  3675 solver.cpp:243] Iteration 4380, loss = 0.091384
I0521 09:50:03.723490  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0913839 (* 1 = 0.0913839 loss)
I0521 09:50:03.723496  3675 sgd_solver.cpp:138] Iteration 4380, lr = 0.0001
I0521 09:50:07.313311  3675 solver.cpp:243] Iteration 4400, loss = 0.0496509
I0521 09:50:07.313467  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0496508 (* 1 = 0.0496508 loss)
I0521 09:50:07.313474  3675 sgd_solver.cpp:138] Iteration 4400, lr = 0.0001
I0521 09:50:10.895995  3675 solver.cpp:243] Iteration 4420, loss = 0.192116
I0521 09:50:10.896028  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.192116 (* 1 = 0.192116 loss)
I0521 09:50:10.896033  3675 sgd_solver.cpp:138] Iteration 4420, lr = 0.0001
I0521 09:50:14.477691  3675 solver.cpp:243] Iteration 4440, loss = 0.0549908
I0521 09:50:14.477722  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0549908 (* 1 = 0.0549908 loss)
I0521 09:50:14.477728  3675 sgd_solver.cpp:138] Iteration 4440, lr = 0.0001
I0521 09:50:18.057389  3675 solver.cpp:243] Iteration 4460, loss = 0.130993
I0521 09:50:18.057420  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.130993 (* 1 = 0.130993 loss)
I0521 09:50:18.057427  3675 sgd_solver.cpp:138] Iteration 4460, lr = 0.0001
I0521 09:50:21.642688  3675 solver.cpp:243] Iteration 4480, loss = 0.0545727
I0521 09:50:21.642719  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0545726 (* 1 = 0.0545726 loss)
I0521 09:50:21.642724  3675 sgd_solver.cpp:138] Iteration 4480, lr = 0.0001
I0521 09:50:25.223168  3675 solver.cpp:243] Iteration 4500, loss = 0.123259
I0521 09:50:25.223201  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.123259 (* 1 = 0.123259 loss)
I0521 09:50:25.223207  3675 sgd_solver.cpp:138] Iteration 4500, lr = 0.0001
I0521 09:50:28.786365  3675 solver.cpp:243] Iteration 4520, loss = 0.0692632
I0521 09:50:28.786396  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0692631 (* 1 = 0.0692631 loss)
I0521 09:50:28.786418  3675 sgd_solver.cpp:138] Iteration 4520, lr = 0.0001
I0521 09:50:32.372822  3675 solver.cpp:243] Iteration 4540, loss = 0.0698429
I0521 09:50:32.372855  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0698428 (* 1 = 0.0698428 loss)
I0521 09:50:32.372861  3675 sgd_solver.cpp:138] Iteration 4540, lr = 0.0001
I0521 09:50:35.951090  3675 solver.cpp:243] Iteration 4560, loss = 0.14233
I0521 09:50:35.951120  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.14233 (* 1 = 0.14233 loss)
I0521 09:50:35.951126  3675 sgd_solver.cpp:138] Iteration 4560, lr = 0.0001
I0521 09:50:39.542584  3675 solver.cpp:243] Iteration 4580, loss = 0.115761
I0521 09:50:39.542753  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.115761 (* 1 = 0.115761 loss)
I0521 09:50:39.542762  3675 sgd_solver.cpp:138] Iteration 4580, lr = 0.0001
I0521 09:50:43.111563  3675 solver.cpp:243] Iteration 4600, loss = 0.12653
I0521 09:50:43.111595  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.126529 (* 1 = 0.126529 loss)
I0521 09:50:43.111600  3675 sgd_solver.cpp:138] Iteration 4600, lr = 0.0001
I0521 09:50:46.694991  3675 solver.cpp:243] Iteration 4620, loss = 0.141819
I0521 09:50:46.695022  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.141819 (* 1 = 0.141819 loss)
I0521 09:50:46.695029  3675 sgd_solver.cpp:138] Iteration 4620, lr = 0.0001
I0521 09:50:50.274428  3675 solver.cpp:243] Iteration 4640, loss = 0.0680889
I0521 09:50:50.274461  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0680888 (* 1 = 0.0680888 loss)
I0521 09:50:50.274466  3675 sgd_solver.cpp:138] Iteration 4640, lr = 0.0001
I0521 09:50:53.858287  3675 solver.cpp:243] Iteration 4660, loss = 0.0995499
I0521 09:50:53.858320  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0995498 (* 1 = 0.0995498 loss)
I0521 09:50:53.858342  3675 sgd_solver.cpp:138] Iteration 4660, lr = 0.0001
I0521 09:50:57.446187  3675 solver.cpp:243] Iteration 4680, loss = 0.198377
I0521 09:50:57.446218  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.198377 (* 1 = 0.198377 loss)
I0521 09:50:57.446224  3675 sgd_solver.cpp:138] Iteration 4680, lr = 0.0001
I0521 09:51:01.030429  3675 solver.cpp:243] Iteration 4700, loss = 0.15246
I0521 09:51:01.030460  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.15246 (* 1 = 0.15246 loss)
I0521 09:51:01.030467  3675 sgd_solver.cpp:138] Iteration 4700, lr = 0.0001
I0521 09:51:04.612464  3675 solver.cpp:243] Iteration 4720, loss = 0.0852422
I0521 09:51:04.612496  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0852421 (* 1 = 0.0852421 loss)
I0521 09:51:04.612502  3675 sgd_solver.cpp:138] Iteration 4720, lr = 0.0001
I0521 09:51:08.188225  3675 solver.cpp:243] Iteration 4740, loss = 0.108355
I0521 09:51:08.188256  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.108355 (* 1 = 0.108355 loss)
I0521 09:51:08.188261  3675 sgd_solver.cpp:138] Iteration 4740, lr = 0.0001
I0521 09:51:11.770123  3675 solver.cpp:243] Iteration 4760, loss = 0.0852698
I0521 09:51:11.770207  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0852697 (* 1 = 0.0852697 loss)
I0521 09:51:11.770215  3675 sgd_solver.cpp:138] Iteration 4760, lr = 0.0001
I0521 09:51:15.336974  3675 solver.cpp:243] Iteration 4780, loss = 0.126947
I0521 09:51:15.337007  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.126947 (* 1 = 0.126947 loss)
I0521 09:51:15.337013  3675 sgd_solver.cpp:138] Iteration 4780, lr = 0.0001
I0521 09:51:18.927631  3675 solver.cpp:243] Iteration 4800, loss = 0.143317
I0521 09:51:18.927661  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.143317 (* 1 = 0.143317 loss)
I0521 09:51:18.927667  3675 sgd_solver.cpp:138] Iteration 4800, lr = 0.0001
I0521 09:51:22.501706  3675 solver.cpp:243] Iteration 4820, loss = 0.0638204
I0521 09:51:22.501739  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0638203 (* 1 = 0.0638203 loss)
I0521 09:51:22.501746  3675 sgd_solver.cpp:138] Iteration 4820, lr = 0.0001
I0521 09:51:26.089709  3675 solver.cpp:243] Iteration 4840, loss = 0.10799
I0521 09:51:26.089742  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.10799 (* 1 = 0.10799 loss)
I0521 09:51:26.089747  3675 sgd_solver.cpp:138] Iteration 4840, lr = 0.0001
I0521 09:51:29.672344  3675 solver.cpp:243] Iteration 4860, loss = 0.053037
I0521 09:51:29.672376  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0530369 (* 1 = 0.0530369 loss)
I0521 09:51:29.672397  3675 sgd_solver.cpp:138] Iteration 4860, lr = 0.0001
I0521 09:51:33.257942  3675 solver.cpp:243] Iteration 4880, loss = 0.111097
I0521 09:51:33.257974  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.111097 (* 1 = 0.111097 loss)
I0521 09:51:33.257980  3675 sgd_solver.cpp:138] Iteration 4880, lr = 0.0001
I0521 09:51:36.816447  3675 solver.cpp:243] Iteration 4900, loss = 0.0969102
I0521 09:51:36.816479  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0969101 (* 1 = 0.0969101 loss)
I0521 09:51:36.816500  3675 sgd_solver.cpp:138] Iteration 4900, lr = 0.0001
I0521 09:51:40.471566  3675 solver.cpp:243] Iteration 4920, loss = 0.0698446
I0521 09:51:40.471597  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0698445 (* 1 = 0.0698445 loss)
I0521 09:51:40.471604  3675 sgd_solver.cpp:138] Iteration 4920, lr = 0.0001
I0521 09:51:44.119211  3675 solver.cpp:243] Iteration 4940, loss = 0.086072
I0521 09:51:44.119379  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.086072 (* 1 = 0.086072 loss)
I0521 09:51:44.119388  3675 sgd_solver.cpp:138] Iteration 4940, lr = 0.0001
I0521 09:51:47.706467  3675 solver.cpp:243] Iteration 4960, loss = 0.076732
I0521 09:51:47.706499  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0767319 (* 1 = 0.0767319 loss)
I0521 09:51:47.706504  3675 sgd_solver.cpp:138] Iteration 4960, lr = 0.0001
I0521 09:51:51.283210  3675 solver.cpp:243] Iteration 4980, loss = 0.048435
I0521 09:51:51.283243  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.048435 (* 1 = 0.048435 loss)
I0521 09:51:51.283249  3675 sgd_solver.cpp:138] Iteration 4980, lr = 0.0001
I0521 09:51:54.720827  3675 solver.cpp:358] Iteration 5000, Testing net (#0)
I0521 09:51:59.506420  3675 solver.cpp:425]     Test net output #0: acc = 0.999174
I0521 09:51:59.506449  3675 solver.cpp:425]     Test net output #1: acc = 0.994219
I0521 09:51:59.506456  3675 solver.cpp:425]     Test net output #2: ctcloss = 0.0287877 (* 1 = 0.0287877 loss)
I0521 09:51:59.646495  3675 solver.cpp:243] Iteration 5000, loss = 0.0714186
I0521 09:51:59.646526  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0714186 (* 1 = 0.0714186 loss)
I0521 09:51:59.646548  3675 sgd_solver.cpp:138] Iteration 5000, lr = 0.0001
I0521 09:52:03.237557  3675 solver.cpp:243] Iteration 5020, loss = 0.155843
I0521 09:52:03.237591  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.155843 (* 1 = 0.155843 loss)
I0521 09:52:03.237596  3675 sgd_solver.cpp:138] Iteration 5020, lr = 0.0001
I0521 09:52:06.811245  3675 solver.cpp:243] Iteration 5040, loss = 0.148683
I0521 09:52:06.811278  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.148683 (* 1 = 0.148683 loss)
I0521 09:52:06.811285  3675 sgd_solver.cpp:138] Iteration 5040, lr = 0.0001
I0521 09:52:10.399039  3675 solver.cpp:243] Iteration 5060, loss = 0.107619
I0521 09:52:10.399073  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.107619 (* 1 = 0.107619 loss)
I0521 09:52:10.399080  3675 sgd_solver.cpp:138] Iteration 5060, lr = 0.0001
I0521 09:52:13.976785  3675 solver.cpp:243] Iteration 5080, loss = 0.0694309
I0521 09:52:13.976819  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0694308 (* 1 = 0.0694308 loss)
I0521 09:52:13.976824  3675 sgd_solver.cpp:138] Iteration 5080, lr = 0.0001
I0521 09:52:17.562288  3675 solver.cpp:243] Iteration 5100, loss = 0.061569
I0521 09:52:17.562453  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0615689 (* 1 = 0.0615689 loss)
I0521 09:52:17.562460  3675 sgd_solver.cpp:138] Iteration 5100, lr = 0.0001
I0521 09:52:21.139761  3675 solver.cpp:243] Iteration 5120, loss = 0.098073
I0521 09:52:21.139794  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0980729 (* 1 = 0.0980729 loss)
I0521 09:52:21.139801  3675 sgd_solver.cpp:138] Iteration 5120, lr = 0.0001
I0521 09:52:24.713877  3675 solver.cpp:243] Iteration 5140, loss = 0.0469496
I0521 09:52:24.713907  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0469495 (* 1 = 0.0469495 loss)
I0521 09:52:24.713930  3675 sgd_solver.cpp:138] Iteration 5140, lr = 0.0001
I0521 09:52:28.297116  3675 solver.cpp:243] Iteration 5160, loss = 0.0761022
I0521 09:52:28.297147  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0761021 (* 1 = 0.0761021 loss)
I0521 09:52:28.297153  3675 sgd_solver.cpp:138] Iteration 5160, lr = 0.0001
I0521 09:52:31.873603  3675 solver.cpp:243] Iteration 5180, loss = 0.0944112
I0521 09:52:31.873637  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0944112 (* 1 = 0.0944112 loss)
I0521 09:52:31.873643  3675 sgd_solver.cpp:138] Iteration 5180, lr = 0.0001
I0521 09:52:35.460618  3675 solver.cpp:243] Iteration 5200, loss = 0.0850557
I0521 09:52:35.460649  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0850557 (* 1 = 0.0850557 loss)
I0521 09:52:35.460654  3675 sgd_solver.cpp:138] Iteration 5200, lr = 0.0001
I0521 09:52:39.042445  3675 solver.cpp:243] Iteration 5220, loss = 0.0383198
I0521 09:52:39.042477  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0383198 (* 1 = 0.0383198 loss)
I0521 09:52:39.042484  3675 sgd_solver.cpp:138] Iteration 5220, lr = 0.0001
I0521 09:52:42.622839  3675 solver.cpp:243] Iteration 5240, loss = 0.0762183
I0521 09:52:42.622869  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0762182 (* 1 = 0.0762182 loss)
I0521 09:52:42.622875  3675 sgd_solver.cpp:138] Iteration 5240, lr = 0.0001
I0521 09:52:46.197679  3675 solver.cpp:243] Iteration 5260, loss = 0.0627506
I0521 09:52:46.197711  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0627505 (* 1 = 0.0627505 loss)
I0521 09:52:46.197717  3675 sgd_solver.cpp:138] Iteration 5260, lr = 0.0001
I0521 09:52:49.712541  3675 solver.cpp:243] Iteration 5280, loss = 0.0709903
I0521 09:52:49.712705  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0709902 (* 1 = 0.0709902 loss)
I0521 09:52:49.712713  3675 sgd_solver.cpp:138] Iteration 5280, lr = 0.0001
I0521 09:52:53.283388  3675 solver.cpp:243] Iteration 5300, loss = 0.0961956
I0521 09:52:53.283421  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0961955 (* 1 = 0.0961955 loss)
I0521 09:52:53.283427  3675 sgd_solver.cpp:138] Iteration 5300, lr = 0.0001
I0521 09:52:56.856513  3675 solver.cpp:243] Iteration 5320, loss = 0.0810254
I0521 09:52:56.856546  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0810253 (* 1 = 0.0810253 loss)
I0521 09:52:56.856552  3675 sgd_solver.cpp:138] Iteration 5320, lr = 0.0001
I0521 09:53:00.435178  3675 solver.cpp:243] Iteration 5340, loss = 0.064409
I0521 09:53:00.435210  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.064409 (* 1 = 0.064409 loss)
I0521 09:53:00.435216  3675 sgd_solver.cpp:138] Iteration 5340, lr = 0.0001
I0521 09:53:04.010987  3675 solver.cpp:243] Iteration 5360, loss = 0.0391358
I0521 09:53:04.011020  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0391357 (* 1 = 0.0391357 loss)
I0521 09:53:04.011025  3675 sgd_solver.cpp:138] Iteration 5360, lr = 0.0001
I0521 09:53:07.593279  3675 solver.cpp:243] Iteration 5380, loss = 0.0859493
I0521 09:53:07.593312  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0859493 (* 1 = 0.0859493 loss)
I0521 09:53:07.593317  3675 sgd_solver.cpp:138] Iteration 5380, lr = 0.0001
I0521 09:53:11.174180  3675 solver.cpp:243] Iteration 5400, loss = 0.0379679
I0521 09:53:11.174212  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0379678 (* 1 = 0.0379678 loss)
I0521 09:53:11.174217  3675 sgd_solver.cpp:138] Iteration 5400, lr = 0.0001
I0521 09:53:14.762163  3675 solver.cpp:243] Iteration 5420, loss = 0.0661779
I0521 09:53:14.762194  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0661778 (* 1 = 0.0661778 loss)
I0521 09:53:14.762200  3675 sgd_solver.cpp:138] Iteration 5420, lr = 0.0001
I0521 09:53:18.347375  3675 solver.cpp:243] Iteration 5440, loss = 0.0380689
I0521 09:53:18.347407  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0380688 (* 1 = 0.0380688 loss)
I0521 09:53:18.347414  3675 sgd_solver.cpp:138] Iteration 5440, lr = 0.0001
I0521 09:53:21.929128  3675 solver.cpp:243] Iteration 5460, loss = 0.0578349
I0521 09:53:21.929258  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0578348 (* 1 = 0.0578348 loss)
I0521 09:53:21.929265  3675 sgd_solver.cpp:138] Iteration 5460, lr = 0.0001
I0521 09:53:25.510871  3675 solver.cpp:243] Iteration 5480, loss = 0.0285689
I0521 09:53:25.510901  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0285688 (* 1 = 0.0285688 loss)
I0521 09:53:25.510907  3675 sgd_solver.cpp:138] Iteration 5480, lr = 0.0001
I0521 09:53:29.093777  3675 solver.cpp:243] Iteration 5500, loss = 0.0418273
I0521 09:53:29.093807  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0418272 (* 1 = 0.0418272 loss)
I0521 09:53:29.093813  3675 sgd_solver.cpp:138] Iteration 5500, lr = 0.0001
I0521 09:53:32.671083  3675 solver.cpp:243] Iteration 5520, loss = 0.0485754
I0521 09:53:32.671118  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0485753 (* 1 = 0.0485753 loss)
I0521 09:53:32.671124  3675 sgd_solver.cpp:138] Iteration 5520, lr = 0.0001
I0521 09:53:36.233988  3675 solver.cpp:243] Iteration 5540, loss = 0.0388426
I0521 09:53:36.234021  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0388425 (* 1 = 0.0388425 loss)
I0521 09:53:36.234026  3675 sgd_solver.cpp:138] Iteration 5540, lr = 0.0001
I0521 09:53:39.830071  3675 solver.cpp:243] Iteration 5560, loss = 0.0499777
I0521 09:53:39.830102  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0499776 (* 1 = 0.0499776 loss)
I0521 09:53:39.830108  3675 sgd_solver.cpp:138] Iteration 5560, lr = 0.0001
I0521 09:53:43.409623  3675 solver.cpp:243] Iteration 5580, loss = 0.028468
I0521 09:53:43.409653  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0284679 (* 1 = 0.0284679 loss)
I0521 09:53:43.409675  3675 sgd_solver.cpp:138] Iteration 5580, lr = 0.0001
I0521 09:53:46.987820  3675 solver.cpp:243] Iteration 5600, loss = 0.0315667
I0521 09:53:46.987851  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0315666 (* 1 = 0.0315666 loss)
I0521 09:53:46.987857  3675 sgd_solver.cpp:138] Iteration 5600, lr = 0.0001
I0521 09:53:50.574144  3675 solver.cpp:243] Iteration 5620, loss = 0.0365314
I0521 09:53:50.574175  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0365313 (* 1 = 0.0365313 loss)
I0521 09:53:50.574182  3675 sgd_solver.cpp:138] Iteration 5620, lr = 0.0001
I0521 09:53:54.165769  3675 solver.cpp:243] Iteration 5640, loss = 0.0457489
I0521 09:53:54.165925  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0457488 (* 1 = 0.0457488 loss)
I0521 09:53:54.165933  3675 sgd_solver.cpp:138] Iteration 5640, lr = 0.0001
I0521 09:53:57.734357  3675 solver.cpp:243] Iteration 5660, loss = 0.0547834
I0521 09:53:57.734388  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0547833 (* 1 = 0.0547833 loss)
I0521 09:53:57.734410  3675 sgd_solver.cpp:138] Iteration 5660, lr = 0.0001
I0521 09:54:01.316287  3675 solver.cpp:243] Iteration 5680, loss = 0.0579728
I0521 09:54:01.316318  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0579727 (* 1 = 0.0579727 loss)
I0521 09:54:01.316340  3675 sgd_solver.cpp:138] Iteration 5680, lr = 0.0001
I0521 09:54:04.914458  3675 solver.cpp:243] Iteration 5700, loss = 0.0342698
I0521 09:54:04.914490  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0342697 (* 1 = 0.0342697 loss)
I0521 09:54:04.914496  3675 sgd_solver.cpp:138] Iteration 5700, lr = 0.0001
I0521 09:54:08.496201  3675 solver.cpp:243] Iteration 5720, loss = 0.0290891
I0521 09:54:08.496232  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.029089 (* 1 = 0.029089 loss)
I0521 09:54:08.496237  3675 sgd_solver.cpp:138] Iteration 5720, lr = 0.0001
I0521 09:54:12.077390  3675 solver.cpp:243] Iteration 5740, loss = 0.0507449
I0521 09:54:12.077421  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0507447 (* 1 = 0.0507447 loss)
I0521 09:54:12.077427  3675 sgd_solver.cpp:138] Iteration 5740, lr = 0.0001
I0521 09:54:15.652927  3675 solver.cpp:243] Iteration 5760, loss = 0.0249583
I0521 09:54:15.652958  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0249582 (* 1 = 0.0249582 loss)
I0521 09:54:15.652979  3675 sgd_solver.cpp:138] Iteration 5760, lr = 0.0001
I0521 09:54:19.221309  3675 solver.cpp:243] Iteration 5780, loss = 0.0286573
I0521 09:54:19.221340  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0286572 (* 1 = 0.0286572 loss)
I0521 09:54:19.221361  3675 sgd_solver.cpp:138] Iteration 5780, lr = 0.0001
I0521 09:54:22.807804  3675 solver.cpp:243] Iteration 5800, loss = 0.0377331
I0521 09:54:22.807834  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.037733 (* 1 = 0.037733 loss)
I0521 09:54:22.807839  3675 sgd_solver.cpp:138] Iteration 5800, lr = 0.0001
I0521 09:54:26.379400  3675 solver.cpp:243] Iteration 5820, loss = 0.0164253
I0521 09:54:26.379534  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0164252 (* 1 = 0.0164252 loss)
I0521 09:54:26.379544  3675 sgd_solver.cpp:138] Iteration 5820, lr = 0.0001
I0521 09:54:29.963395  3675 solver.cpp:243] Iteration 5840, loss = 0.0268494
I0521 09:54:29.963428  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0268493 (* 1 = 0.0268493 loss)
I0521 09:54:29.963433  3675 sgd_solver.cpp:138] Iteration 5840, lr = 0.0001
I0521 09:54:33.535100  3675 solver.cpp:243] Iteration 5860, loss = 0.0194502
I0521 09:54:33.535131  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0194501 (* 1 = 0.0194501 loss)
I0521 09:54:33.535153  3675 sgd_solver.cpp:138] Iteration 5860, lr = 0.0001
I0521 09:54:37.120823  3675 solver.cpp:243] Iteration 5880, loss = 0.0429627
I0521 09:54:37.120857  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0429627 (* 1 = 0.0429627 loss)
I0521 09:54:37.120864  3675 sgd_solver.cpp:138] Iteration 5880, lr = 0.0001
I0521 09:54:40.710453  3675 solver.cpp:243] Iteration 5900, loss = 0.0210087
I0521 09:54:40.710484  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0210086 (* 1 = 0.0210086 loss)
I0521 09:54:40.710489  3675 sgd_solver.cpp:138] Iteration 5900, lr = 0.0001
I0521 09:54:44.293398  3675 solver.cpp:243] Iteration 5920, loss = 0.0199699
I0521 09:54:44.293429  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0199698 (* 1 = 0.0199698 loss)
I0521 09:54:44.293435  3675 sgd_solver.cpp:138] Iteration 5920, lr = 0.0001
I0521 09:54:47.874243  3675 solver.cpp:243] Iteration 5940, loss = 0.0224303
I0521 09:54:47.874275  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0224302 (* 1 = 0.0224302 loss)
I0521 09:54:47.874280  3675 sgd_solver.cpp:138] Iteration 5940, lr = 0.0001
I0521 09:54:51.456881  3675 solver.cpp:243] Iteration 5960, loss = 0.0299067
I0521 09:54:51.456913  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0299066 (* 1 = 0.0299066 loss)
I0521 09:54:51.456918  3675 sgd_solver.cpp:138] Iteration 5960, lr = 0.0001
I0521 09:54:55.045464  3675 solver.cpp:243] Iteration 5980, loss = 0.0147899
I0521 09:54:55.045496  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0147898 (* 1 = 0.0147898 loss)
I0521 09:54:55.045518  3675 sgd_solver.cpp:138] Iteration 5980, lr = 0.0001
I0521 09:54:58.471140  3675 solver.cpp:596] Snapshotting to binary proto file models/LPR/lpr_resnet_lstm_iter_6000.caffemodel
I0521 09:54:58.502415  3675 sgd_solver.cpp:307] Snapshotting solver state to binary proto file models/LPR/lpr_resnet_lstm_iter_6000.solverstate
I0521 09:54:58.520537  3675 solver.cpp:358] Iteration 6000, Testing net (#0)
I0521 09:55:03.298115  3675 solver.cpp:425]     Test net output #0: acc = 1
I0521 09:55:03.298143  3675 solver.cpp:425]     Test net output #1: acc = 1
I0521 09:55:03.298151  3675 solver.cpp:425]     Test net output #2: ctcloss = 0.00785011 (* 1 = 0.00785011 loss)
I0521 09:55:03.440678  3675 solver.cpp:243] Iteration 6000, loss = 0.0314301
I0521 09:55:03.440712  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.03143 (* 1 = 0.03143 loss)
I0521 09:55:03.440721  3675 sgd_solver.cpp:138] Iteration 6000, lr = 0.0001
I0521 09:55:07.008800  3675 solver.cpp:243] Iteration 6020, loss = 0.0254707
I0521 09:55:07.008833  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0254706 (* 1 = 0.0254706 loss)
I0521 09:55:07.008839  3675 sgd_solver.cpp:138] Iteration 6020, lr = 0.0001
I0521 09:55:10.597901  3675 solver.cpp:243] Iteration 6040, loss = 0.0211511
I0521 09:55:10.597932  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.021151 (* 1 = 0.021151 loss)
I0521 09:55:10.597939  3675 sgd_solver.cpp:138] Iteration 6040, lr = 0.0001
I0521 09:55:14.176026  3675 solver.cpp:243] Iteration 6060, loss = 0.0194206
I0521 09:55:14.176057  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0194205 (* 1 = 0.0194205 loss)
I0521 09:55:14.176064  3675 sgd_solver.cpp:138] Iteration 6060, lr = 0.0001
I0521 09:55:17.772987  3675 solver.cpp:243] Iteration 6080, loss = 0.0278155
I0521 09:55:17.773020  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0278154 (* 1 = 0.0278154 loss)
I0521 09:55:17.773025  3675 sgd_solver.cpp:138] Iteration 6080, lr = 0.0001
I0521 09:55:21.350947  3675 solver.cpp:243] Iteration 6100, loss = 0.0226607
I0521 09:55:21.350977  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0226606 (* 1 = 0.0226606 loss)
I0521 09:55:21.350983  3675 sgd_solver.cpp:138] Iteration 6100, lr = 0.0001
I0521 09:55:24.936553  3675 solver.cpp:243] Iteration 6120, loss = 0.0371943
I0521 09:55:24.936583  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0371942 (* 1 = 0.0371942 loss)
I0521 09:55:24.936589  3675 sgd_solver.cpp:138] Iteration 6120, lr = 0.0001
I0521 09:55:28.525084  3675 solver.cpp:243] Iteration 6140, loss = 0.0515276
I0521 09:55:28.525264  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0515275 (* 1 = 0.0515275 loss)
I0521 09:55:28.525271  3675 sgd_solver.cpp:138] Iteration 6140, lr = 0.0001
I0521 09:55:32.115864  3675 solver.cpp:243] Iteration 6160, loss = 0.0429668
I0521 09:55:32.115896  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0429667 (* 1 = 0.0429667 loss)
I0521 09:55:32.115902  3675 sgd_solver.cpp:138] Iteration 6160, lr = 0.0001
I0521 09:55:35.707232  3675 solver.cpp:243] Iteration 6180, loss = 0.101003
I0521 09:55:35.707263  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.101003 (* 1 = 0.101003 loss)
I0521 09:55:35.707285  3675 sgd_solver.cpp:138] Iteration 6180, lr = 0.0001
I0521 09:55:39.276697  3675 solver.cpp:243] Iteration 6200, loss = 0.0278795
I0521 09:55:39.276731  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0278794 (* 1 = 0.0278794 loss)
I0521 09:55:39.276752  3675 sgd_solver.cpp:138] Iteration 6200, lr = 0.0001
I0521 09:55:42.845120  3675 solver.cpp:243] Iteration 6220, loss = 0.0949619
I0521 09:55:42.845155  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0949618 (* 1 = 0.0949618 loss)
I0521 09:55:42.845160  3675 sgd_solver.cpp:138] Iteration 6220, lr = 0.0001
I0521 09:55:46.433843  3675 solver.cpp:243] Iteration 6240, loss = 0.0273431
I0521 09:55:46.433876  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.027343 (* 1 = 0.027343 loss)
I0521 09:55:46.433882  3675 sgd_solver.cpp:138] Iteration 6240, lr = 0.0001
I0521 09:55:50.015523  3675 solver.cpp:243] Iteration 6260, loss = 0.0345005
I0521 09:55:50.015555  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0345004 (* 1 = 0.0345004 loss)
I0521 09:55:50.015560  3675 sgd_solver.cpp:138] Iteration 6260, lr = 0.0001
I0521 09:55:53.597405  3675 solver.cpp:243] Iteration 6280, loss = 0.0354703
I0521 09:55:53.597436  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0354702 (* 1 = 0.0354702 loss)
I0521 09:55:53.597458  3675 sgd_solver.cpp:138] Iteration 6280, lr = 0.0001
I0521 09:55:57.188302  3675 solver.cpp:243] Iteration 6300, loss = 0.0337144
I0521 09:55:57.188333  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0337143 (* 1 = 0.0337143 loss)
I0521 09:55:57.188354  3675 sgd_solver.cpp:138] Iteration 6300, lr = 0.0001
I0521 09:56:00.763012  3675 solver.cpp:243] Iteration 6320, loss = 0.0224299
I0521 09:56:00.763185  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0224298 (* 1 = 0.0224298 loss)
I0521 09:56:00.763192  3675 sgd_solver.cpp:138] Iteration 6320, lr = 0.0001
I0521 09:56:04.340878  3675 solver.cpp:243] Iteration 6340, loss = 0.0168698
I0521 09:56:04.340909  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0168697 (* 1 = 0.0168697 loss)
I0521 09:56:04.340914  3675 sgd_solver.cpp:138] Iteration 6340, lr = 0.0001
I0521 09:56:07.931959  3675 solver.cpp:243] Iteration 6360, loss = 0.0341839
I0521 09:56:07.931990  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0341838 (* 1 = 0.0341838 loss)
I0521 09:56:07.931996  3675 sgd_solver.cpp:138] Iteration 6360, lr = 0.0001
I0521 09:56:11.517729  3675 solver.cpp:243] Iteration 6380, loss = 0.0165071
I0521 09:56:11.517761  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.016507 (* 1 = 0.016507 loss)
I0521 09:56:11.517768  3675 sgd_solver.cpp:138] Iteration 6380, lr = 0.0001
I0521 09:56:15.105480  3675 solver.cpp:243] Iteration 6400, loss = 0.0115746
I0521 09:56:15.105512  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0115745 (* 1 = 0.0115745 loss)
I0521 09:56:15.105518  3675 sgd_solver.cpp:138] Iteration 6400, lr = 0.0001
I0521 09:56:18.686621  3675 solver.cpp:243] Iteration 6420, loss = 0.00955474
I0521 09:56:18.686655  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00955463 (* 1 = 0.00955463 loss)
I0521 09:56:18.686659  3675 sgd_solver.cpp:138] Iteration 6420, lr = 0.0001
I0521 09:56:22.266003  3675 solver.cpp:243] Iteration 6440, loss = 0.0242327
I0521 09:56:22.266036  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0242326 (* 1 = 0.0242326 loss)
I0521 09:56:22.266041  3675 sgd_solver.cpp:138] Iteration 6440, lr = 0.0001
I0521 09:56:25.861730  3675 solver.cpp:243] Iteration 6460, loss = 0.0416079
I0521 09:56:25.861763  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0416078 (* 1 = 0.0416078 loss)
I0521 09:56:25.861768  3675 sgd_solver.cpp:138] Iteration 6460, lr = 0.0001
I0521 09:56:29.435726  3675 solver.cpp:243] Iteration 6480, loss = 0.0157725
I0521 09:56:29.435758  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0157724 (* 1 = 0.0157724 loss)
I0521 09:56:29.435765  3675 sgd_solver.cpp:138] Iteration 6480, lr = 0.0001
I0521 09:56:33.018028  3675 solver.cpp:243] Iteration 6500, loss = 0.0290716
I0521 09:56:33.018208  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0290715 (* 1 = 0.0290715 loss)
I0521 09:56:33.018216  3675 sgd_solver.cpp:138] Iteration 6500, lr = 0.0001
I0521 09:56:36.599160  3675 solver.cpp:243] Iteration 6520, loss = 0.0163743
I0521 09:56:36.599196  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0163742 (* 1 = 0.0163742 loss)
I0521 09:56:36.599203  3675 sgd_solver.cpp:138] Iteration 6520, lr = 0.0001
I0521 09:56:40.167780  3675 solver.cpp:243] Iteration 6540, loss = 0.0163194
I0521 09:56:40.167814  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0163193 (* 1 = 0.0163193 loss)
I0521 09:56:40.167835  3675 sgd_solver.cpp:138] Iteration 6540, lr = 0.0001
I0521 09:56:43.754225  3675 solver.cpp:243] Iteration 6560, loss = 0.022668
I0521 09:56:43.754257  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0226679 (* 1 = 0.0226679 loss)
I0521 09:56:43.754264  3675 sgd_solver.cpp:138] Iteration 6560, lr = 0.0001
I0521 09:56:47.255647  3675 solver.cpp:243] Iteration 6580, loss = 0.0171365
I0521 09:56:47.255678  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0171364 (* 1 = 0.0171364 loss)
I0521 09:56:47.255699  3675 sgd_solver.cpp:138] Iteration 6580, lr = 0.0001
I0521 09:56:50.776809  3675 solver.cpp:243] Iteration 6600, loss = 0.0231494
I0521 09:56:50.776842  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0231493 (* 1 = 0.0231493 loss)
I0521 09:56:50.776849  3675 sgd_solver.cpp:138] Iteration 6600, lr = 0.0001
I0521 09:56:54.300190  3675 solver.cpp:243] Iteration 6620, loss = 0.0217593
I0521 09:56:54.300220  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0217592 (* 1 = 0.0217592 loss)
I0521 09:56:54.300226  3675 sgd_solver.cpp:138] Iteration 6620, lr = 0.0001
I0521 09:56:57.824250  3675 solver.cpp:243] Iteration 6640, loss = 0.0152631
I0521 09:56:57.824283  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.015263 (* 1 = 0.015263 loss)
I0521 09:56:57.824290  3675 sgd_solver.cpp:138] Iteration 6640, lr = 0.0001
I0521 09:57:01.345273  3675 solver.cpp:243] Iteration 6660, loss = 0.012749
I0521 09:57:01.345305  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0127489 (* 1 = 0.0127489 loss)
I0521 09:57:01.345311  3675 sgd_solver.cpp:138] Iteration 6660, lr = 0.0001
I0521 09:57:04.864311  3675 solver.cpp:243] Iteration 6680, loss = 0.0207442
I0521 09:57:04.864476  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0207441 (* 1 = 0.0207441 loss)
I0521 09:57:04.864503  3675 sgd_solver.cpp:138] Iteration 6680, lr = 0.0001
I0521 09:57:08.391530  3675 solver.cpp:243] Iteration 6700, loss = 0.0258048
I0521 09:57:08.391563  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0258047 (* 1 = 0.0258047 loss)
I0521 09:57:08.391568  3675 sgd_solver.cpp:138] Iteration 6700, lr = 0.0001
I0521 09:57:11.917037  3675 solver.cpp:243] Iteration 6720, loss = 0.0219849
I0521 09:57:11.917068  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0219848 (* 1 = 0.0219848 loss)
I0521 09:57:11.917073  3675 sgd_solver.cpp:138] Iteration 6720, lr = 0.0001
I0521 09:57:15.444453  3675 solver.cpp:243] Iteration 6740, loss = 0.0078533
I0521 09:57:15.444485  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00785318 (* 1 = 0.00785318 loss)
I0521 09:57:15.444490  3675 sgd_solver.cpp:138] Iteration 6740, lr = 0.0001
I0521 09:57:18.966558  3675 solver.cpp:243] Iteration 6760, loss = 0.0150544
I0521 09:57:18.966593  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0150543 (* 1 = 0.0150543 loss)
I0521 09:57:18.966614  3675 sgd_solver.cpp:138] Iteration 6760, lr = 0.0001
I0521 09:57:22.491075  3675 solver.cpp:243] Iteration 6780, loss = 0.0168189
I0521 09:57:22.491109  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0168187 (* 1 = 0.0168187 loss)
I0521 09:57:22.491114  3675 sgd_solver.cpp:138] Iteration 6780, lr = 0.0001
I0521 09:57:26.009439  3675 solver.cpp:243] Iteration 6800, loss = 0.0131706
I0521 09:57:26.009472  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0131705 (* 1 = 0.0131705 loss)
I0521 09:57:26.009477  3675 sgd_solver.cpp:138] Iteration 6800, lr = 0.0001
I0521 09:57:29.531415  3675 solver.cpp:243] Iteration 6820, loss = 0.0123694
I0521 09:57:29.531447  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0123693 (* 1 = 0.0123693 loss)
I0521 09:57:29.531452  3675 sgd_solver.cpp:138] Iteration 6820, lr = 0.0001
I0521 09:57:33.054478  3675 solver.cpp:243] Iteration 6840, loss = 0.0310015
I0521 09:57:33.054510  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0310014 (* 1 = 0.0310014 loss)
I0521 09:57:33.054517  3675 sgd_solver.cpp:138] Iteration 6840, lr = 0.0001
I0521 09:57:36.578874  3675 solver.cpp:243] Iteration 6860, loss = 0.0130287
I0521 09:57:36.579042  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0130286 (* 1 = 0.0130286 loss)
I0521 09:57:36.579049  3675 sgd_solver.cpp:138] Iteration 6860, lr = 0.0001
I0521 09:57:40.105633  3675 solver.cpp:243] Iteration 6880, loss = 0.0135102
I0521 09:57:40.105665  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0135101 (* 1 = 0.0135101 loss)
I0521 09:57:40.105670  3675 sgd_solver.cpp:138] Iteration 6880, lr = 0.0001
I0521 09:57:43.630194  3675 solver.cpp:243] Iteration 6900, loss = 0.00695875
I0521 09:57:43.630228  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00695863 (* 1 = 0.00695863 loss)
I0521 09:57:43.630232  3675 sgd_solver.cpp:138] Iteration 6900, lr = 0.0001
I0521 09:57:47.155475  3675 solver.cpp:243] Iteration 6920, loss = 0.0121942
I0521 09:57:47.155508  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.012194 (* 1 = 0.012194 loss)
I0521 09:57:47.155514  3675 sgd_solver.cpp:138] Iteration 6920, lr = 0.0001
I0521 09:57:50.677979  3675 solver.cpp:243] Iteration 6940, loss = 0.0179112
I0521 09:57:50.678012  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0179111 (* 1 = 0.0179111 loss)
I0521 09:57:50.678019  3675 sgd_solver.cpp:138] Iteration 6940, lr = 0.0001
I0521 09:57:54.206895  3675 solver.cpp:243] Iteration 6960, loss = 0.0146739
I0521 09:57:54.206976  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0146738 (* 1 = 0.0146738 loss)
I0521 09:57:54.206993  3675 sgd_solver.cpp:138] Iteration 6960, lr = 0.0001
I0521 09:57:57.725952  3675 solver.cpp:243] Iteration 6980, loss = 0.0391032
I0521 09:57:57.725983  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0391031 (* 1 = 0.0391031 loss)
I0521 09:57:57.725989  3675 sgd_solver.cpp:138] Iteration 6980, lr = 0.0001
I0521 09:58:01.122763  3675 solver.cpp:358] Iteration 7000, Testing net (#0)
I0521 09:58:05.863214  3675 solver.cpp:425]     Test net output #0: acc = 1
I0521 09:58:05.863240  3675 solver.cpp:425]     Test net output #1: acc = 1
I0521 09:58:05.863247  3675 solver.cpp:425]     Test net output #2: ctcloss = 0.00565392 (* 1 = 0.00565392 loss)
I0521 09:58:05.997592  3675 solver.cpp:243] Iteration 7000, loss = 0.00991241
I0521 09:58:05.997622  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0099123 (* 1 = 0.0099123 loss)
I0521 09:58:05.997629  3675 sgd_solver.cpp:138] Iteration 7000, lr = 0.0001
I0521 09:58:09.518777  3675 solver.cpp:243] Iteration 7020, loss = 0.0214137
I0521 09:58:09.518950  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0214136 (* 1 = 0.0214136 loss)
I0521 09:58:09.518959  3675 sgd_solver.cpp:138] Iteration 7020, lr = 0.0001
I0521 09:58:13.043051  3675 solver.cpp:243] Iteration 7040, loss = 0.0117217
I0521 09:58:13.043082  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0117216 (* 1 = 0.0117216 loss)
I0521 09:58:13.043103  3675 sgd_solver.cpp:138] Iteration 7040, lr = 0.0001
I0521 09:58:16.563618  3675 solver.cpp:243] Iteration 7060, loss = 0.0169572
I0521 09:58:16.563649  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0169571 (* 1 = 0.0169571 loss)
I0521 09:58:16.563654  3675 sgd_solver.cpp:138] Iteration 7060, lr = 0.0001
I0521 09:58:20.083269  3675 solver.cpp:243] Iteration 7080, loss = 0.0163369
I0521 09:58:20.083300  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0163368 (* 1 = 0.0163368 loss)
I0521 09:58:20.083322  3675 sgd_solver.cpp:138] Iteration 7080, lr = 0.0001
I0521 09:58:23.604651  3675 solver.cpp:243] Iteration 7100, loss = 0.0190702
I0521 09:58:23.604684  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0190701 (* 1 = 0.0190701 loss)
I0521 09:58:23.604689  3675 sgd_solver.cpp:138] Iteration 7100, lr = 0.0001
I0521 09:58:27.127974  3675 solver.cpp:243] Iteration 7120, loss = 0.0115008
I0521 09:58:27.128006  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0115007 (* 1 = 0.0115007 loss)
I0521 09:58:27.128012  3675 sgd_solver.cpp:138] Iteration 7120, lr = 0.0001
I0521 09:58:30.647429  3675 solver.cpp:243] Iteration 7140, loss = 0.0115339
I0521 09:58:30.647461  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0115338 (* 1 = 0.0115338 loss)
I0521 09:58:30.647466  3675 sgd_solver.cpp:138] Iteration 7140, lr = 0.0001
I0521 09:58:34.172479  3675 solver.cpp:243] Iteration 7160, loss = 0.0215269
I0521 09:58:34.172510  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0215268 (* 1 = 0.0215268 loss)
I0521 09:58:34.172516  3675 sgd_solver.cpp:138] Iteration 7160, lr = 0.0001
I0521 09:58:37.695293  3675 solver.cpp:243] Iteration 7180, loss = 0.00829258
I0521 09:58:37.695341  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00829246 (* 1 = 0.00829246 loss)
I0521 09:58:37.695348  3675 sgd_solver.cpp:138] Iteration 7180, lr = 0.0001
I0521 09:58:41.213946  3675 solver.cpp:243] Iteration 7200, loss = 0.00991814
I0521 09:58:41.214063  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00991802 (* 1 = 0.00991802 loss)
I0521 09:58:41.214071  3675 sgd_solver.cpp:138] Iteration 7200, lr = 0.0001
I0521 09:58:44.737246  3675 solver.cpp:243] Iteration 7220, loss = 0.0113846
I0521 09:58:44.737278  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0113845 (* 1 = 0.0113845 loss)
I0521 09:58:44.737284  3675 sgd_solver.cpp:138] Iteration 7220, lr = 0.0001
I0521 09:58:48.255839  3675 solver.cpp:243] Iteration 7240, loss = 0.0108495
I0521 09:58:48.255870  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0108494 (* 1 = 0.0108494 loss)
I0521 09:58:48.255875  3675 sgd_solver.cpp:138] Iteration 7240, lr = 0.0001
I0521 09:58:51.778733  3675 solver.cpp:243] Iteration 7260, loss = 0.0130862
I0521 09:58:51.778765  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0130861 (* 1 = 0.0130861 loss)
I0521 09:58:51.778770  3675 sgd_solver.cpp:138] Iteration 7260, lr = 0.0001
I0521 09:58:55.301061  3675 solver.cpp:243] Iteration 7280, loss = 0.0160345
I0521 09:58:55.301093  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0160344 (* 1 = 0.0160344 loss)
I0521 09:58:55.301098  3675 sgd_solver.cpp:138] Iteration 7280, lr = 0.0001
I0521 09:58:58.823662  3675 solver.cpp:243] Iteration 7300, loss = 0.0148789
I0521 09:58:58.823701  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0148788 (* 1 = 0.0148788 loss)
I0521 09:58:58.823710  3675 sgd_solver.cpp:138] Iteration 7300, lr = 0.0001
I0521 09:59:02.347501  3675 solver.cpp:243] Iteration 7320, loss = 0.0158576
I0521 09:59:02.347532  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0158574 (* 1 = 0.0158574 loss)
I0521 09:59:02.347537  3675 sgd_solver.cpp:138] Iteration 7320, lr = 0.0001
I0521 09:59:05.872630  3675 solver.cpp:243] Iteration 7340, loss = 0.0159284
I0521 09:59:05.872669  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0159283 (* 1 = 0.0159283 loss)
I0521 09:59:05.872678  3675 sgd_solver.cpp:138] Iteration 7340, lr = 0.0001
I0521 09:59:09.395287  3675 solver.cpp:243] Iteration 7360, loss = 0.00831155
I0521 09:59:09.395319  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00831143 (* 1 = 0.00831143 loss)
I0521 09:59:09.395324  3675 sgd_solver.cpp:138] Iteration 7360, lr = 0.0001
I0521 09:59:12.987591  3675 solver.cpp:243] Iteration 7380, loss = 0.0336906
I0521 09:59:12.987748  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0336904 (* 1 = 0.0336904 loss)
I0521 09:59:12.987759  3675 sgd_solver.cpp:138] Iteration 7380, lr = 0.0001
I0521 09:59:16.654429  3675 solver.cpp:243] Iteration 7400, loss = 0.00962783
I0521 09:59:16.654460  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00962771 (* 1 = 0.00962771 loss)
I0521 09:59:16.654466  3675 sgd_solver.cpp:138] Iteration 7400, lr = 0.0001
I0521 09:59:20.230545  3675 solver.cpp:243] Iteration 7420, loss = 0.014354
I0521 09:59:20.230576  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0143539 (* 1 = 0.0143539 loss)
I0521 09:59:20.230598  3675 sgd_solver.cpp:138] Iteration 7420, lr = 0.0001
I0521 09:59:23.819326  3675 solver.cpp:243] Iteration 7440, loss = 0.0115947
I0521 09:59:23.819358  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0115945 (* 1 = 0.0115945 loss)
I0521 09:59:23.819365  3675 sgd_solver.cpp:138] Iteration 7440, lr = 0.0001
I0521 09:59:27.408290  3675 solver.cpp:243] Iteration 7460, loss = 0.0114589
I0521 09:59:27.408322  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0114588 (* 1 = 0.0114588 loss)
I0521 09:59:27.408327  3675 sgd_solver.cpp:138] Iteration 7460, lr = 0.0001
I0521 09:59:30.975203  3675 solver.cpp:243] Iteration 7480, loss = 0.0268174
I0521 09:59:30.975236  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0268172 (* 1 = 0.0268172 loss)
I0521 09:59:30.975258  3675 sgd_solver.cpp:138] Iteration 7480, lr = 0.0001
I0521 09:59:34.544844  3675 solver.cpp:243] Iteration 7500, loss = 0.00807556
I0521 09:59:34.544880  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00807544 (* 1 = 0.00807544 loss)
I0521 09:59:34.544888  3675 sgd_solver.cpp:138] Iteration 7500, lr = 0.0001
I0521 09:59:38.125814  3675 solver.cpp:243] Iteration 7520, loss = 0.0107273
I0521 09:59:38.125844  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0107272 (* 1 = 0.0107272 loss)
I0521 09:59:38.125849  3675 sgd_solver.cpp:138] Iteration 7520, lr = 0.0001
I0521 09:59:41.713579  3675 solver.cpp:243] Iteration 7540, loss = 0.00843639
I0521 09:59:41.713610  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00843627 (* 1 = 0.00843627 loss)
I0521 09:59:41.713631  3675 sgd_solver.cpp:138] Iteration 7540, lr = 0.0001
I0521 09:59:45.288753  3675 solver.cpp:243] Iteration 7560, loss = 0.00981769
I0521 09:59:45.288892  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00981756 (* 1 = 0.00981756 loss)
I0521 09:59:45.288898  3675 sgd_solver.cpp:138] Iteration 7560, lr = 0.0001
I0521 09:59:48.874523  3675 solver.cpp:243] Iteration 7580, loss = 0.0093399
I0521 09:59:48.874555  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00933978 (* 1 = 0.00933978 loss)
I0521 09:59:48.874562  3675 sgd_solver.cpp:138] Iteration 7580, lr = 0.0001
I0521 09:59:52.442054  3675 solver.cpp:243] Iteration 7600, loss = 0.0108571
I0521 09:59:52.442085  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.010857 (* 1 = 0.010857 loss)
I0521 09:59:52.442091  3675 sgd_solver.cpp:138] Iteration 7600, lr = 0.0001
I0521 09:59:56.040107  3675 solver.cpp:243] Iteration 7620, loss = 0.00969826
I0521 09:59:56.040139  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00969814 (* 1 = 0.00969814 loss)
I0521 09:59:56.040161  3675 sgd_solver.cpp:138] Iteration 7620, lr = 0.0001
I0521 09:59:59.611006  3675 solver.cpp:243] Iteration 7640, loss = 0.0115763
I0521 09:59:59.611039  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0115761 (* 1 = 0.0115761 loss)
I0521 09:59:59.611045  3675 sgd_solver.cpp:138] Iteration 7640, lr = 0.0001
I0521 10:00:03.198334  3675 solver.cpp:243] Iteration 7660, loss = 0.0147345
I0521 10:00:03.198365  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0147344 (* 1 = 0.0147344 loss)
I0521 10:00:03.198374  3675 sgd_solver.cpp:138] Iteration 7660, lr = 0.0001
I0521 10:00:06.776546  3675 solver.cpp:243] Iteration 7680, loss = 0.00953795
I0521 10:00:06.776577  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00953783 (* 1 = 0.00953783 loss)
I0521 10:00:06.776583  3675 sgd_solver.cpp:138] Iteration 7680, lr = 0.0001
I0521 10:00:10.358127  3675 solver.cpp:243] Iteration 7700, loss = 0.00843477
I0521 10:00:10.358160  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00843465 (* 1 = 0.00843465 loss)
I0521 10:00:10.358165  3675 sgd_solver.cpp:138] Iteration 7700, lr = 0.0001
I0521 10:00:14.006271  3675 solver.cpp:243] Iteration 7720, loss = 0.00875301
I0521 10:00:14.006304  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00875289 (* 1 = 0.00875289 loss)
I0521 10:00:14.006325  3675 sgd_solver.cpp:138] Iteration 7720, lr = 0.0001
I0521 10:00:17.561329  3675 solver.cpp:243] Iteration 7740, loss = 0.00847965
I0521 10:00:17.561501  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00847953 (* 1 = 0.00847953 loss)
I0521 10:00:17.561509  3675 sgd_solver.cpp:138] Iteration 7740, lr = 0.0001
I0521 10:00:21.110477  3675 solver.cpp:243] Iteration 7760, loss = 0.0084847
I0521 10:00:21.110507  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00848459 (* 1 = 0.00848459 loss)
I0521 10:00:21.110512  3675 sgd_solver.cpp:138] Iteration 7760, lr = 0.0001
I0521 10:00:24.658918  3675 solver.cpp:243] Iteration 7780, loss = 0.0096132
I0521 10:00:24.658949  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00961309 (* 1 = 0.00961309 loss)
I0521 10:00:24.658955  3675 sgd_solver.cpp:138] Iteration 7780, lr = 0.0001
I0521 10:00:28.201237  3675 solver.cpp:243] Iteration 7800, loss = 0.00956212
I0521 10:00:28.201270  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00956201 (* 1 = 0.00956201 loss)
I0521 10:00:28.201277  3675 sgd_solver.cpp:138] Iteration 7800, lr = 0.0001
I0521 10:00:31.747220  3675 solver.cpp:243] Iteration 7820, loss = 0.0182979
I0521 10:00:31.747251  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0182978 (* 1 = 0.0182978 loss)
I0521 10:00:31.747256  3675 sgd_solver.cpp:138] Iteration 7820, lr = 0.0001
I0521 10:00:35.291934  3675 solver.cpp:243] Iteration 7840, loss = 0.00870707
I0521 10:00:35.291966  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00870696 (* 1 = 0.00870696 loss)
I0521 10:00:35.291972  3675 sgd_solver.cpp:138] Iteration 7840, lr = 0.0001
I0521 10:00:38.837581  3675 solver.cpp:243] Iteration 7860, loss = 0.0115939
I0521 10:00:38.837615  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0115938 (* 1 = 0.0115938 loss)
I0521 10:00:38.837620  3675 sgd_solver.cpp:138] Iteration 7860, lr = 0.0001
I0521 10:00:42.310755  3675 solver.cpp:243] Iteration 7880, loss = 0.00933821
I0521 10:00:42.310787  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0093381 (* 1 = 0.0093381 loss)
I0521 10:00:42.310808  3675 sgd_solver.cpp:138] Iteration 7880, lr = 0.0001
I0521 10:00:45.858209  3675 solver.cpp:243] Iteration 7900, loss = 0.00861824
I0521 10:00:45.858242  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00861813 (* 1 = 0.00861813 loss)
I0521 10:00:45.858248  3675 sgd_solver.cpp:138] Iteration 7900, lr = 0.0001
I0521 10:00:49.403411  3675 solver.cpp:243] Iteration 7920, loss = 0.00554729
I0521 10:00:49.403596  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00554718 (* 1 = 0.00554718 loss)
I0521 10:00:49.403605  3675 sgd_solver.cpp:138] Iteration 7920, lr = 0.0001
I0521 10:00:52.946940  3675 solver.cpp:243] Iteration 7940, loss = 0.00940287
I0521 10:00:52.946971  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00940276 (* 1 = 0.00940276 loss)
I0521 10:00:52.946976  3675 sgd_solver.cpp:138] Iteration 7940, lr = 0.0001
I0521 10:00:56.493108  3675 solver.cpp:243] Iteration 7960, loss = 0.00737103
I0521 10:00:56.493139  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00737092 (* 1 = 0.00737092 loss)
I0521 10:00:56.493145  3675 sgd_solver.cpp:138] Iteration 7960, lr = 0.0001
I0521 10:01:00.037046  3675 solver.cpp:243] Iteration 7980, loss = 0.0153476
I0521 10:01:00.037077  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0153475 (* 1 = 0.0153475 loss)
I0521 10:01:00.037084  3675 sgd_solver.cpp:138] Iteration 7980, lr = 0.0001
I0521 10:01:03.449128  3675 solver.cpp:596] Snapshotting to binary proto file models/LPR/lpr_resnet_lstm_iter_8000.caffemodel
I0521 10:01:03.477893  3675 sgd_solver.cpp:307] Snapshotting solver state to binary proto file models/LPR/lpr_resnet_lstm_iter_8000.solverstate
I0521 10:01:03.528493  3675 solver.cpp:358] Iteration 8000, Testing net (#0)
I0521 10:01:08.277083  3675 solver.cpp:425]     Test net output #0: acc = 1
I0521 10:01:08.277112  3675 solver.cpp:425]     Test net output #1: acc = 1
I0521 10:01:08.277119  3675 solver.cpp:425]     Test net output #2: ctcloss = 0.00276907 (* 1 = 0.00276907 loss)
I0521 10:01:08.416393  3675 solver.cpp:243] Iteration 8000, loss = 0.00803127
I0521 10:01:08.416424  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00803115 (* 1 = 0.00803115 loss)
I0521 10:01:08.416446  3675 sgd_solver.cpp:138] Iteration 8000, lr = 0.0001
I0521 10:01:11.953055  3675 solver.cpp:243] Iteration 8020, loss = 0.00910789
I0521 10:01:11.953088  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00910777 (* 1 = 0.00910777 loss)
I0521 10:01:11.953094  3675 sgd_solver.cpp:138] Iteration 8020, lr = 0.0001
I0521 10:01:15.494887  3675 solver.cpp:243] Iteration 8040, loss = 0.0102777
I0521 10:01:15.494920  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0102776 (* 1 = 0.0102776 loss)
I0521 10:01:15.494925  3675 sgd_solver.cpp:138] Iteration 8040, lr = 0.0001
I0521 10:01:19.040400  3675 solver.cpp:243] Iteration 8060, loss = 0.0127478
I0521 10:01:19.040432  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0127477 (* 1 = 0.0127477 loss)
I0521 10:01:19.040438  3675 sgd_solver.cpp:138] Iteration 8060, lr = 0.0001
I0521 10:01:22.584456  3675 solver.cpp:243] Iteration 8080, loss = 0.0104921
I0521 10:01:22.584542  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.010492 (* 1 = 0.010492 loss)
I0521 10:01:22.584549  3675 sgd_solver.cpp:138] Iteration 8080, lr = 0.0001
I0521 10:01:26.120298  3675 solver.cpp:243] Iteration 8100, loss = 0.00742204
I0521 10:01:26.120330  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00742192 (* 1 = 0.00742192 loss)
I0521 10:01:26.120337  3675 sgd_solver.cpp:138] Iteration 8100, lr = 0.0001
I0521 10:01:29.664208  3675 solver.cpp:243] Iteration 8120, loss = 0.00793555
I0521 10:01:29.664239  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00793542 (* 1 = 0.00793542 loss)
I0521 10:01:29.664244  3675 sgd_solver.cpp:138] Iteration 8120, lr = 0.0001
I0521 10:01:33.207008  3675 solver.cpp:243] Iteration 8140, loss = 0.00767223
I0521 10:01:33.207039  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00767211 (* 1 = 0.00767211 loss)
I0521 10:01:33.207062  3675 sgd_solver.cpp:138] Iteration 8140, lr = 0.0001
I0521 10:01:36.752657  3675 solver.cpp:243] Iteration 8160, loss = 0.00829857
I0521 10:01:36.752687  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00829846 (* 1 = 0.00829846 loss)
I0521 10:01:36.752709  3675 sgd_solver.cpp:138] Iteration 8160, lr = 0.0001
I0521 10:01:40.293148  3675 solver.cpp:243] Iteration 8180, loss = 0.00677684
I0521 10:01:40.293179  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00677672 (* 1 = 0.00677672 loss)
I0521 10:01:40.293200  3675 sgd_solver.cpp:138] Iteration 8180, lr = 0.0001
I0521 10:01:43.838940  3675 solver.cpp:243] Iteration 8200, loss = 0.00955913
I0521 10:01:43.838970  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00955901 (* 1 = 0.00955901 loss)
I0521 10:01:43.838976  3675 sgd_solver.cpp:138] Iteration 8200, lr = 0.0001
I0521 10:01:47.388568  3675 solver.cpp:243] Iteration 8220, loss = 0.00799351
I0521 10:01:47.388599  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0079934 (* 1 = 0.0079934 loss)
I0521 10:01:47.388605  3675 sgd_solver.cpp:138] Iteration 8220, lr = 0.0001
I0521 10:01:50.924772  3675 solver.cpp:243] Iteration 8240, loss = 0.0086651
I0521 10:01:50.924811  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00866498 (* 1 = 0.00866498 loss)
I0521 10:01:50.924818  3675 sgd_solver.cpp:138] Iteration 8240, lr = 0.0001
I0521 10:01:54.459460  3675 solver.cpp:243] Iteration 8260, loss = 0.0167366
I0521 10:01:54.459611  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0167365 (* 1 = 0.0167365 loss)
I0521 10:01:54.459619  3675 sgd_solver.cpp:138] Iteration 8260, lr = 0.0001
I0521 10:01:58.006814  3675 solver.cpp:243] Iteration 8280, loss = 0.0124323
I0521 10:01:58.006847  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0124322 (* 1 = 0.0124322 loss)
I0521 10:01:58.006870  3675 sgd_solver.cpp:138] Iteration 8280, lr = 0.0001
I0521 10:02:01.560214  3675 solver.cpp:243] Iteration 8300, loss = 0.01087
I0521 10:02:01.560245  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0108699 (* 1 = 0.0108699 loss)
I0521 10:02:01.560251  3675 sgd_solver.cpp:138] Iteration 8300, lr = 0.0001
I0521 10:02:05.101339  3675 solver.cpp:243] Iteration 8320, loss = 0.0111593
I0521 10:02:05.101370  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0111592 (* 1 = 0.0111592 loss)
I0521 10:02:05.101377  3675 sgd_solver.cpp:138] Iteration 8320, lr = 0.0001
I0521 10:02:08.642592  3675 solver.cpp:243] Iteration 8340, loss = 0.00729847
I0521 10:02:08.642624  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00729836 (* 1 = 0.00729836 loss)
I0521 10:02:08.642630  3675 sgd_solver.cpp:138] Iteration 8340, lr = 0.0001
I0521 10:02:12.179587  3675 solver.cpp:243] Iteration 8360, loss = 0.0115541
I0521 10:02:12.179620  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.011554 (* 1 = 0.011554 loss)
I0521 10:02:12.179626  3675 sgd_solver.cpp:138] Iteration 8360, lr = 0.0001
I0521 10:02:15.726398  3675 solver.cpp:243] Iteration 8380, loss = 0.00898797
I0521 10:02:15.726431  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00898785 (* 1 = 0.00898785 loss)
I0521 10:02:15.726438  3675 sgd_solver.cpp:138] Iteration 8380, lr = 0.0001
I0521 10:02:19.268548  3675 solver.cpp:243] Iteration 8400, loss = 0.00886009
I0521 10:02:19.268579  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00885997 (* 1 = 0.00885997 loss)
I0521 10:02:19.268599  3675 sgd_solver.cpp:138] Iteration 8400, lr = 0.0001
I0521 10:02:22.815106  3675 solver.cpp:243] Iteration 8420, loss = 0.00662787
I0521 10:02:22.815140  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00662775 (* 1 = 0.00662775 loss)
I0521 10:02:22.815145  3675 sgd_solver.cpp:138] Iteration 8420, lr = 0.0001
I0521 10:02:26.366518  3675 solver.cpp:243] Iteration 8440, loss = 0.00911987
I0521 10:02:26.366619  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00911976 (* 1 = 0.00911976 loss)
I0521 10:02:26.366626  3675 sgd_solver.cpp:138] Iteration 8440, lr = 0.0001
I0521 10:02:29.913625  3675 solver.cpp:243] Iteration 8460, loss = 0.00486794
I0521 10:02:29.913658  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00486783 (* 1 = 0.00486783 loss)
I0521 10:02:29.913679  3675 sgd_solver.cpp:138] Iteration 8460, lr = 0.0001
I0521 10:02:33.456812  3675 solver.cpp:243] Iteration 8480, loss = 0.00871585
I0521 10:02:33.456894  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00871573 (* 1 = 0.00871573 loss)
I0521 10:02:33.456913  3675 sgd_solver.cpp:138] Iteration 8480, lr = 0.0001
I0521 10:02:36.996562  3675 solver.cpp:243] Iteration 8500, loss = 0.00825695
I0521 10:02:36.996595  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00825684 (* 1 = 0.00825684 loss)
I0521 10:02:36.996601  3675 sgd_solver.cpp:138] Iteration 8500, lr = 0.0001
I0521 10:02:40.538877  3675 solver.cpp:243] Iteration 8520, loss = 0.00743617
I0521 10:02:40.538908  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00743606 (* 1 = 0.00743606 loss)
I0521 10:02:40.538913  3675 sgd_solver.cpp:138] Iteration 8520, lr = 0.0001
I0521 10:02:44.081493  3675 solver.cpp:243] Iteration 8540, loss = 0.0489605
I0521 10:02:44.081527  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0489604 (* 1 = 0.0489604 loss)
I0521 10:02:44.081533  3675 sgd_solver.cpp:138] Iteration 8540, lr = 0.0001
I0521 10:02:47.629068  3675 solver.cpp:243] Iteration 8560, loss = 0.00864829
I0521 10:02:47.629112  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00864818 (* 1 = 0.00864818 loss)
I0521 10:02:47.629119  3675 sgd_solver.cpp:138] Iteration 8560, lr = 0.0001
I0521 10:02:51.171051  3675 solver.cpp:243] Iteration 8580, loss = 0.00949468
I0521 10:02:51.171082  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00949456 (* 1 = 0.00949456 loss)
I0521 10:02:51.171104  3675 sgd_solver.cpp:138] Iteration 8580, lr = 0.0001
I0521 10:02:54.709094  3675 solver.cpp:243] Iteration 8600, loss = 0.00706111
I0521 10:02:54.709127  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.007061 (* 1 = 0.007061 loss)
I0521 10:02:54.709133  3675 sgd_solver.cpp:138] Iteration 8600, lr = 0.0001
I0521 10:02:58.252897  3675 solver.cpp:243] Iteration 8620, loss = 0.00643343
I0521 10:02:58.253077  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00643332 (* 1 = 0.00643332 loss)
I0521 10:02:58.253087  3675 sgd_solver.cpp:138] Iteration 8620, lr = 0.0001
I0521 10:03:01.796663  3675 solver.cpp:243] Iteration 8640, loss = 0.0125683
I0521 10:03:01.796694  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0125682 (* 1 = 0.0125682 loss)
I0521 10:03:01.796700  3675 sgd_solver.cpp:138] Iteration 8640, lr = 0.0001
I0521 10:03:05.338657  3675 solver.cpp:243] Iteration 8660, loss = 0.0094087
I0521 10:03:05.338688  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00940859 (* 1 = 0.00940859 loss)
I0521 10:03:05.338693  3675 sgd_solver.cpp:138] Iteration 8660, lr = 0.0001
I0521 10:03:08.881484  3675 solver.cpp:243] Iteration 8680, loss = 0.00532257
I0521 10:03:08.881516  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00532246 (* 1 = 0.00532246 loss)
I0521 10:03:08.881523  3675 sgd_solver.cpp:138] Iteration 8680, lr = 0.0001
I0521 10:03:12.415380  3675 solver.cpp:243] Iteration 8700, loss = 0.00865871
I0521 10:03:12.415411  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0086586 (* 1 = 0.0086586 loss)
I0521 10:03:12.415432  3675 sgd_solver.cpp:138] Iteration 8700, lr = 0.0001
I0521 10:03:15.963546  3675 solver.cpp:243] Iteration 8720, loss = 0.00912872
I0521 10:03:15.963578  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00912861 (* 1 = 0.00912861 loss)
I0521 10:03:15.963584  3675 sgd_solver.cpp:138] Iteration 8720, lr = 0.0001
I0521 10:03:19.515008  3675 solver.cpp:243] Iteration 8740, loss = 0.00738233
I0521 10:03:19.515040  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00738223 (* 1 = 0.00738223 loss)
I0521 10:03:19.515046  3675 sgd_solver.cpp:138] Iteration 8740, lr = 0.0001
I0521 10:03:23.056707  3675 solver.cpp:243] Iteration 8760, loss = 0.0070213
I0521 10:03:23.056740  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00702119 (* 1 = 0.00702119 loss)
I0521 10:03:23.056746  3675 sgd_solver.cpp:138] Iteration 8760, lr = 0.0001
I0521 10:03:26.597108  3675 solver.cpp:243] Iteration 8780, loss = 0.00671315
I0521 10:03:26.597141  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00671304 (* 1 = 0.00671304 loss)
I0521 10:03:26.597146  3675 sgd_solver.cpp:138] Iteration 8780, lr = 0.0001
I0521 10:03:30.146087  3675 solver.cpp:243] Iteration 8800, loss = 0.0100675
I0521 10:03:30.146247  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0100674 (* 1 = 0.0100674 loss)
I0521 10:03:30.146255  3675 sgd_solver.cpp:138] Iteration 8800, lr = 0.0001
I0521 10:03:33.689481  3675 solver.cpp:243] Iteration 8820, loss = 0.00668304
I0521 10:03:33.689512  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00668293 (* 1 = 0.00668293 loss)
I0521 10:03:33.689517  3675 sgd_solver.cpp:138] Iteration 8820, lr = 0.0001
I0521 10:03:37.232004  3675 solver.cpp:243] Iteration 8840, loss = 0.00840573
I0521 10:03:37.232035  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00840562 (* 1 = 0.00840562 loss)
I0521 10:03:37.232041  3675 sgd_solver.cpp:138] Iteration 8840, lr = 0.0001
I0521 10:03:40.768965  3675 solver.cpp:243] Iteration 8860, loss = 0.00636906
I0521 10:03:40.768996  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00636895 (* 1 = 0.00636895 loss)
I0521 10:03:40.769002  3675 sgd_solver.cpp:138] Iteration 8860, lr = 0.0001
I0521 10:03:44.312001  3675 solver.cpp:243] Iteration 8880, loss = 0.0071182
I0521 10:03:44.312036  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00711808 (* 1 = 0.00711808 loss)
I0521 10:03:44.312041  3675 sgd_solver.cpp:138] Iteration 8880, lr = 0.0001
I0521 10:03:47.861243  3675 solver.cpp:243] Iteration 8900, loss = 0.00915397
I0521 10:03:47.861274  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00915385 (* 1 = 0.00915385 loss)
I0521 10:03:47.861280  3675 sgd_solver.cpp:138] Iteration 8900, lr = 0.0001
I0521 10:03:51.401780  3675 solver.cpp:243] Iteration 8920, loss = 0.00759181
I0521 10:03:51.401810  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0075917 (* 1 = 0.0075917 loss)
I0521 10:03:51.401816  3675 sgd_solver.cpp:138] Iteration 8920, lr = 0.0001
I0521 10:03:54.940201  3675 solver.cpp:243] Iteration 8940, loss = 0.00757209
I0521 10:03:54.940235  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00757198 (* 1 = 0.00757198 loss)
I0521 10:03:54.940241  3675 sgd_solver.cpp:138] Iteration 8940, lr = 0.0001
I0521 10:03:58.479692  3675 solver.cpp:243] Iteration 8960, loss = 0.00752255
I0521 10:03:58.479775  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00752243 (* 1 = 0.00752243 loss)
I0521 10:03:58.479800  3675 sgd_solver.cpp:138] Iteration 8960, lr = 0.0001
I0521 10:04:02.026152  3675 solver.cpp:243] Iteration 8980, loss = 0.00504001
I0521 10:04:02.026260  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0050399 (* 1 = 0.0050399 loss)
I0521 10:04:02.026268  3675 sgd_solver.cpp:138] Iteration 8980, lr = 0.0001
I0521 10:04:05.431043  3675 solver.cpp:358] Iteration 9000, Testing net (#0)
I0521 10:04:10.180485  3675 solver.cpp:425]     Test net output #0: acc = 1
I0521 10:04:10.180512  3675 solver.cpp:425]     Test net output #1: acc = 1
I0521 10:04:10.180519  3675 solver.cpp:425]     Test net output #2: ctcloss = 0.00189046 (* 1 = 0.00189046 loss)
I0521 10:04:10.320793  3675 solver.cpp:243] Iteration 9000, loss = 0.00647945
I0521 10:04:10.320824  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00647934 (* 1 = 0.00647934 loss)
I0521 10:04:10.320847  3675 sgd_solver.cpp:138] Iteration 9000, lr = 0.0001
I0521 10:04:13.864166  3675 solver.cpp:243] Iteration 9020, loss = 0.00718686
I0521 10:04:13.864197  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00718675 (* 1 = 0.00718675 loss)
I0521 10:04:13.864203  3675 sgd_solver.cpp:138] Iteration 9020, lr = 0.0001
I0521 10:04:17.412858  3675 solver.cpp:243] Iteration 9040, loss = 0.00840836
I0521 10:04:17.412890  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00840824 (* 1 = 0.00840824 loss)
I0521 10:04:17.412896  3675 sgd_solver.cpp:138] Iteration 9040, lr = 0.0001
I0521 10:04:20.989703  3675 solver.cpp:243] Iteration 9060, loss = 0.00428025
I0521 10:04:20.989738  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00428014 (* 1 = 0.00428014 loss)
I0521 10:04:20.989745  3675 sgd_solver.cpp:138] Iteration 9060, lr = 0.0001
I0521 10:04:24.529971  3675 solver.cpp:243] Iteration 9080, loss = 0.00580508
I0521 10:04:24.530004  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00580497 (* 1 = 0.00580497 loss)
I0521 10:04:24.530009  3675 sgd_solver.cpp:138] Iteration 9080, lr = 0.0001
I0521 10:04:28.046824  3675 solver.cpp:243] Iteration 9100, loss = 0.00599275
I0521 10:04:28.046856  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00599264 (* 1 = 0.00599264 loss)
I0521 10:04:28.046861  3675 sgd_solver.cpp:138] Iteration 9100, lr = 0.0001
I0521 10:04:31.563853  3675 solver.cpp:243] Iteration 9120, loss = 0.00505353
I0521 10:04:31.563885  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00505342 (* 1 = 0.00505342 loss)
I0521 10:04:31.563891  3675 sgd_solver.cpp:138] Iteration 9120, lr = 0.0001
I0521 10:04:35.081255  3675 solver.cpp:243] Iteration 9140, loss = 0.00780351
I0521 10:04:35.081413  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0078034 (* 1 = 0.0078034 loss)
I0521 10:04:35.081421  3675 sgd_solver.cpp:138] Iteration 9140, lr = 0.0001
I0521 10:04:38.596396  3675 solver.cpp:243] Iteration 9160, loss = 0.00601568
I0521 10:04:38.596428  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00601556 (* 1 = 0.00601556 loss)
I0521 10:04:38.596434  3675 sgd_solver.cpp:138] Iteration 9160, lr = 0.0001
I0521 10:04:42.045936  3675 solver.cpp:243] Iteration 9180, loss = 0.00729664
I0521 10:04:42.045969  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00729653 (* 1 = 0.00729653 loss)
I0521 10:04:42.045974  3675 sgd_solver.cpp:138] Iteration 9180, lr = 0.0001
I0521 10:04:45.560210  3675 solver.cpp:243] Iteration 9200, loss = 0.0126426
I0521 10:04:45.560241  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0126425 (* 1 = 0.0126425 loss)
I0521 10:04:45.560247  3675 sgd_solver.cpp:138] Iteration 9200, lr = 0.0001
I0521 10:04:49.076335  3675 solver.cpp:243] Iteration 9220, loss = 0.00737403
I0521 10:04:49.076366  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00737391 (* 1 = 0.00737391 loss)
I0521 10:04:49.076371  3675 sgd_solver.cpp:138] Iteration 9220, lr = 0.0001
I0521 10:04:52.593647  3675 solver.cpp:243] Iteration 9240, loss = 0.00550979
I0521 10:04:52.593677  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00550968 (* 1 = 0.00550968 loss)
I0521 10:04:52.593683  3675 sgd_solver.cpp:138] Iteration 9240, lr = 0.0001
I0521 10:04:56.106204  3675 solver.cpp:243] Iteration 9260, loss = 0.00520044
I0521 10:04:56.106233  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00520033 (* 1 = 0.00520033 loss)
I0521 10:04:56.106238  3675 sgd_solver.cpp:138] Iteration 9260, lr = 0.0001
I0521 10:04:59.619468  3675 solver.cpp:243] Iteration 9280, loss = 0.00650796
I0521 10:04:59.619503  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00650784 (* 1 = 0.00650784 loss)
I0521 10:04:59.619509  3675 sgd_solver.cpp:138] Iteration 9280, lr = 0.0001
I0521 10:05:03.133939  3675 solver.cpp:243] Iteration 9300, loss = 0.00461431
I0521 10:05:03.133970  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0046142 (* 1 = 0.0046142 loss)
I0521 10:05:03.133975  3675 sgd_solver.cpp:138] Iteration 9300, lr = 0.0001
I0521 10:05:06.649309  3675 solver.cpp:243] Iteration 9320, loss = 0.00646643
I0521 10:05:06.649468  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00646632 (* 1 = 0.00646632 loss)
I0521 10:05:06.649475  3675 sgd_solver.cpp:138] Iteration 9320, lr = 0.0001
I0521 10:05:10.164675  3675 solver.cpp:243] Iteration 9340, loss = 0.00817827
I0521 10:05:10.164706  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00817816 (* 1 = 0.00817816 loss)
I0521 10:05:10.164711  3675 sgd_solver.cpp:138] Iteration 9340, lr = 0.0001
I0521 10:05:13.676645  3675 solver.cpp:243] Iteration 9360, loss = 0.00639209
I0521 10:05:13.676676  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00639198 (* 1 = 0.00639198 loss)
I0521 10:05:13.676681  3675 sgd_solver.cpp:138] Iteration 9360, lr = 0.0001
I0521 10:05:17.191073  3675 solver.cpp:243] Iteration 9380, loss = 0.00388068
I0521 10:05:17.191103  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00388057 (* 1 = 0.00388057 loss)
I0521 10:05:17.191108  3675 sgd_solver.cpp:138] Iteration 9380, lr = 0.0001
I0521 10:05:20.701133  3675 solver.cpp:243] Iteration 9400, loss = 0.0074383
I0521 10:05:20.701162  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00743819 (* 1 = 0.00743819 loss)
I0521 10:05:20.701184  3675 sgd_solver.cpp:138] Iteration 9400, lr = 0.0001
I0521 10:05:24.214483  3675 solver.cpp:243] Iteration 9420, loss = 0.00916818
I0521 10:05:24.214514  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00916807 (* 1 = 0.00916807 loss)
I0521 10:05:24.214520  3675 sgd_solver.cpp:138] Iteration 9420, lr = 0.0001
I0521 10:05:27.729624  3675 solver.cpp:243] Iteration 9440, loss = 0.00903871
I0521 10:05:27.729656  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0090386 (* 1 = 0.0090386 loss)
I0521 10:05:27.729662  3675 sgd_solver.cpp:138] Iteration 9440, lr = 0.0001
I0521 10:05:31.244098  3675 solver.cpp:243] Iteration 9460, loss = 0.00370883
I0521 10:05:31.244129  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00370872 (* 1 = 0.00370872 loss)
I0521 10:05:31.244134  3675 sgd_solver.cpp:138] Iteration 9460, lr = 0.0001
I0521 10:05:34.760176  3675 solver.cpp:243] Iteration 9480, loss = 0.0165021
I0521 10:05:34.760207  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.016502 (* 1 = 0.016502 loss)
I0521 10:05:34.760228  3675 sgd_solver.cpp:138] Iteration 9480, lr = 0.0001
I0521 10:05:38.273025  3675 solver.cpp:243] Iteration 9500, loss = 0.00908041
I0521 10:05:38.273178  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0090803 (* 1 = 0.0090803 loss)
I0521 10:05:38.273186  3675 sgd_solver.cpp:138] Iteration 9500, lr = 0.0001
I0521 10:05:41.792064  3675 solver.cpp:243] Iteration 9520, loss = 0.00666012
I0521 10:05:41.792095  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00666001 (* 1 = 0.00666001 loss)
I0521 10:05:41.792101  3675 sgd_solver.cpp:138] Iteration 9520, lr = 0.0001
I0521 10:05:45.303594  3675 solver.cpp:243] Iteration 9540, loss = 0.00610272
I0521 10:05:45.303627  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00610262 (* 1 = 0.00610262 loss)
I0521 10:05:45.303633  3675 sgd_solver.cpp:138] Iteration 9540, lr = 0.0001
I0521 10:05:48.819499  3675 solver.cpp:243] Iteration 9560, loss = 0.00641058
I0521 10:05:48.819530  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00641047 (* 1 = 0.00641047 loss)
I0521 10:05:48.819535  3675 sgd_solver.cpp:138] Iteration 9560, lr = 0.0001
I0521 10:05:52.333585  3675 solver.cpp:243] Iteration 9580, loss = 0.00605913
I0521 10:05:52.333618  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00605902 (* 1 = 0.00605902 loss)
I0521 10:05:52.333623  3675 sgd_solver.cpp:138] Iteration 9580, lr = 0.0001
I0521 10:05:55.847870  3675 solver.cpp:243] Iteration 9600, loss = 0.0103176
I0521 10:05:55.847901  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0103175 (* 1 = 0.0103175 loss)
I0521 10:05:55.847918  3675 sgd_solver.cpp:138] Iteration 9600, lr = 0.0001
I0521 10:05:59.361510  3675 solver.cpp:243] Iteration 9620, loss = 0.00397088
I0521 10:05:59.361541  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00397077 (* 1 = 0.00397077 loss)
I0521 10:05:59.361546  3675 sgd_solver.cpp:138] Iteration 9620, lr = 0.0001
I0521 10:06:02.875066  3675 solver.cpp:243] Iteration 9640, loss = 0.00482914
I0521 10:06:02.875097  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00482903 (* 1 = 0.00482903 loss)
I0521 10:06:02.875102  3675 sgd_solver.cpp:138] Iteration 9640, lr = 0.0001
I0521 10:06:06.389475  3675 solver.cpp:243] Iteration 9660, loss = 0.00385952
I0521 10:06:06.389508  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00385941 (* 1 = 0.00385941 loss)
I0521 10:06:06.389513  3675 sgd_solver.cpp:138] Iteration 9660, lr = 0.0001
I0521 10:06:09.902151  3675 solver.cpp:243] Iteration 9680, loss = 0.00537801
I0521 10:06:09.902312  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0053779 (* 1 = 0.0053779 loss)
I0521 10:06:09.902320  3675 sgd_solver.cpp:138] Iteration 9680, lr = 0.0001
I0521 10:06:13.416939  3675 solver.cpp:243] Iteration 9700, loss = 0.0050331
I0521 10:06:13.416970  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00503299 (* 1 = 0.00503299 loss)
I0521 10:06:13.416975  3675 sgd_solver.cpp:138] Iteration 9700, lr = 0.0001
I0521 10:06:16.929847  3675 solver.cpp:243] Iteration 9720, loss = 0.00651638
I0521 10:06:16.929877  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00651627 (* 1 = 0.00651627 loss)
I0521 10:06:16.929883  3675 sgd_solver.cpp:138] Iteration 9720, lr = 0.0001
I0521 10:06:20.442086  3675 solver.cpp:243] Iteration 9740, loss = 0.00859901
I0521 10:06:20.442117  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0085989 (* 1 = 0.0085989 loss)
I0521 10:06:20.442122  3675 sgd_solver.cpp:138] Iteration 9740, lr = 0.0001
I0521 10:06:23.957001  3675 solver.cpp:243] Iteration 9760, loss = 0.00437717
I0521 10:06:23.957032  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00437706 (* 1 = 0.00437706 loss)
I0521 10:06:23.957037  3675 sgd_solver.cpp:138] Iteration 9760, lr = 0.0001
I0521 10:06:27.472554  3675 solver.cpp:243] Iteration 9780, loss = 0.00428459
I0521 10:06:27.472586  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00428448 (* 1 = 0.00428448 loss)
I0521 10:06:27.472592  3675 sgd_solver.cpp:138] Iteration 9780, lr = 0.0001
I0521 10:06:30.985730  3675 solver.cpp:243] Iteration 9800, loss = 0.00513814
I0521 10:06:30.985762  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00513803 (* 1 = 0.00513803 loss)
I0521 10:06:30.985767  3675 sgd_solver.cpp:138] Iteration 9800, lr = 0.0001
I0521 10:06:34.499876  3675 solver.cpp:243] Iteration 9820, loss = 0.00772202
I0521 10:06:34.499907  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00772191 (* 1 = 0.00772191 loss)
I0521 10:06:34.499912  3675 sgd_solver.cpp:138] Iteration 9820, lr = 0.0001
I0521 10:06:38.014539  3675 solver.cpp:243] Iteration 9840, loss = 0.00430774
I0521 10:06:38.014573  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00430763 (* 1 = 0.00430763 loss)
I0521 10:06:38.014580  3675 sgd_solver.cpp:138] Iteration 9840, lr = 0.0001
I0521 10:06:41.524649  3675 solver.cpp:243] Iteration 9860, loss = 0.00576513
I0521 10:06:41.524786  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00576502 (* 1 = 0.00576502 loss)
I0521 10:06:41.524793  3675 sgd_solver.cpp:138] Iteration 9860, lr = 0.0001
I0521 10:06:45.038436  3675 solver.cpp:243] Iteration 9880, loss = 0.00638107
I0521 10:06:45.038468  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00638096 (* 1 = 0.00638096 loss)
I0521 10:06:45.038473  3675 sgd_solver.cpp:138] Iteration 9880, lr = 0.0001
I0521 10:06:48.559564  3675 solver.cpp:243] Iteration 9900, loss = 0.00570579
I0521 10:06:48.559597  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00570568 (* 1 = 0.00570568 loss)
I0521 10:06:48.559602  3675 sgd_solver.cpp:138] Iteration 9900, lr = 0.0001
I0521 10:06:52.074365  3675 solver.cpp:243] Iteration 9920, loss = 0.00535318
I0521 10:06:52.074396  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00535307 (* 1 = 0.00535307 loss)
I0521 10:06:52.074403  3675 sgd_solver.cpp:138] Iteration 9920, lr = 0.0001
I0521 10:06:55.592321  3675 solver.cpp:243] Iteration 9940, loss = 0.00763025
I0521 10:06:55.592352  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00763014 (* 1 = 0.00763014 loss)
I0521 10:06:55.592358  3675 sgd_solver.cpp:138] Iteration 9940, lr = 0.0001
I0521 10:06:59.107275  3675 solver.cpp:243] Iteration 9960, loss = 0.00867914
I0521 10:06:59.107306  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00867903 (* 1 = 0.00867903 loss)
I0521 10:06:59.107311  3675 sgd_solver.cpp:138] Iteration 9960, lr = 0.0001
I0521 10:07:02.626068  3675 solver.cpp:243] Iteration 9980, loss = 0.0110577
I0521 10:07:02.626099  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0110576 (* 1 = 0.0110576 loss)
I0521 10:07:02.626104  3675 sgd_solver.cpp:138] Iteration 9980, lr = 0.0001
I0521 10:07:06.008682  3675 solver.cpp:596] Snapshotting to binary proto file models/LPR/lpr_resnet_lstm_iter_10000.caffemodel
I0521 10:07:06.039386  3675 sgd_solver.cpp:307] Snapshotting solver state to binary proto file models/LPR/lpr_resnet_lstm_iter_10000.solverstate
I0521 10:07:06.056919  3675 solver.cpp:358] Iteration 10000, Testing net (#0)
I0521 10:07:10.790911  3675 solver.cpp:425]     Test net output #0: acc = 1
I0521 10:07:10.790938  3675 solver.cpp:425]     Test net output #1: acc = 1
I0521 10:07:10.790946  3675 solver.cpp:425]     Test net output #2: ctcloss = 0.0018875 (* 1 = 0.0018875 loss)
I0521 10:07:10.925913  3675 solver.cpp:243] Iteration 10000, loss = 0.00891729
I0521 10:07:10.925952  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00891718 (* 1 = 0.00891718 loss)
I0521 10:07:10.925974  3675 sgd_solver.cpp:138] Iteration 10000, lr = 5e-05
I0521 10:07:14.442317  3675 solver.cpp:243] Iteration 10020, loss = 0.00729541
I0521 10:07:14.442478  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0072953 (* 1 = 0.0072953 loss)
I0521 10:07:14.442487  3675 sgd_solver.cpp:138] Iteration 10020, lr = 5e-05
I0521 10:07:17.952458  3675 solver.cpp:243] Iteration 10040, loss = 0.0303211
I0521 10:07:17.952488  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.030321 (* 1 = 0.030321 loss)
I0521 10:07:17.952493  3675 sgd_solver.cpp:138] Iteration 10040, lr = 5e-05
I0521 10:07:21.467849  3675 solver.cpp:243] Iteration 10060, loss = 0.0115406
I0521 10:07:21.467880  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0115405 (* 1 = 0.0115405 loss)
I0521 10:07:21.467885  3675 sgd_solver.cpp:138] Iteration 10060, lr = 5e-05
I0521 10:07:24.973702  3675 solver.cpp:243] Iteration 10080, loss = 0.00543091
I0521 10:07:24.973733  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00543079 (* 1 = 0.00543079 loss)
I0521 10:07:24.973738  3675 sgd_solver.cpp:138] Iteration 10080, lr = 5e-05
I0521 10:07:28.483557  3675 solver.cpp:243] Iteration 10100, loss = 0.0103796
I0521 10:07:28.483588  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0103795 (* 1 = 0.0103795 loss)
I0521 10:07:28.483593  3675 sgd_solver.cpp:138] Iteration 10100, lr = 5e-05
I0521 10:07:31.992050  3675 solver.cpp:243] Iteration 10120, loss = 0.00449483
I0521 10:07:31.992081  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00449472 (* 1 = 0.00449472 loss)
I0521 10:07:31.992086  3675 sgd_solver.cpp:138] Iteration 10120, lr = 5e-05
I0521 10:07:35.500968  3675 solver.cpp:243] Iteration 10140, loss = 0.00512333
I0521 10:07:35.501001  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00512321 (* 1 = 0.00512321 loss)
I0521 10:07:35.501006  3675 sgd_solver.cpp:138] Iteration 10140, lr = 5e-05
I0521 10:07:39.010032  3675 solver.cpp:243] Iteration 10160, loss = 0.00811039
I0521 10:07:39.010064  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00811027 (* 1 = 0.00811027 loss)
I0521 10:07:39.010069  3675 sgd_solver.cpp:138] Iteration 10160, lr = 5e-05
I0521 10:07:42.515759  3675 solver.cpp:243] Iteration 10180, loss = 0.00347709
I0521 10:07:42.515790  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00347698 (* 1 = 0.00347698 loss)
I0521 10:07:42.515795  3675 sgd_solver.cpp:138] Iteration 10180, lr = 5e-05
I0521 10:07:46.025933  3675 solver.cpp:243] Iteration 10200, loss = 0.00799647
I0521 10:07:46.026098  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00799636 (* 1 = 0.00799636 loss)
I0521 10:07:46.026104  3675 sgd_solver.cpp:138] Iteration 10200, lr = 5e-05
I0521 10:07:49.534552  3675 solver.cpp:243] Iteration 10220, loss = 0.00450266
I0521 10:07:49.534584  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00450255 (* 1 = 0.00450255 loss)
I0521 10:07:49.534590  3675 sgd_solver.cpp:138] Iteration 10220, lr = 5e-05
I0521 10:07:53.044526  3675 solver.cpp:243] Iteration 10240, loss = 0.0099371
I0521 10:07:53.044559  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00993699 (* 1 = 0.00993699 loss)
I0521 10:07:53.044564  3675 sgd_solver.cpp:138] Iteration 10240, lr = 5e-05
I0521 10:07:56.555884  3675 solver.cpp:243] Iteration 10260, loss = 0.00368135
I0521 10:07:56.555917  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00368124 (* 1 = 0.00368124 loss)
I0521 10:07:56.555938  3675 sgd_solver.cpp:138] Iteration 10260, lr = 5e-05
I0521 10:08:00.064128  3675 solver.cpp:243] Iteration 10280, loss = 0.0059193
I0521 10:08:00.064162  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00591919 (* 1 = 0.00591919 loss)
I0521 10:08:00.064167  3675 sgd_solver.cpp:138] Iteration 10280, lr = 5e-05
I0521 10:08:03.576504  3675 solver.cpp:243] Iteration 10300, loss = 0.0048506
I0521 10:08:03.576535  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00485049 (* 1 = 0.00485049 loss)
I0521 10:08:03.576541  3675 sgd_solver.cpp:138] Iteration 10300, lr = 5e-05
I0521 10:08:07.087533  3675 solver.cpp:243] Iteration 10320, loss = 0.00474944
I0521 10:08:07.087563  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00474933 (* 1 = 0.00474933 loss)
I0521 10:08:07.087569  3675 sgd_solver.cpp:138] Iteration 10320, lr = 5e-05
I0521 10:08:10.600611  3675 solver.cpp:243] Iteration 10340, loss = 0.00550935
I0521 10:08:10.600641  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00550923 (* 1 = 0.00550923 loss)
I0521 10:08:10.600662  3675 sgd_solver.cpp:138] Iteration 10340, lr = 5e-05
I0521 10:08:14.113656  3675 solver.cpp:243] Iteration 10360, loss = 0.0057065
I0521 10:08:14.113688  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00570639 (* 1 = 0.00570639 loss)
I0521 10:08:14.113695  3675 sgd_solver.cpp:138] Iteration 10360, lr = 5e-05
I0521 10:08:17.621876  3675 solver.cpp:243] Iteration 10380, loss = 0.00736555
I0521 10:08:17.622007  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00736544 (* 1 = 0.00736544 loss)
I0521 10:08:17.622015  3675 sgd_solver.cpp:138] Iteration 10380, lr = 5e-05
I0521 10:08:21.131933  3675 solver.cpp:243] Iteration 10400, loss = 0.00434309
I0521 10:08:21.131964  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00434298 (* 1 = 0.00434298 loss)
I0521 10:08:21.131986  3675 sgd_solver.cpp:138] Iteration 10400, lr = 5e-05
I0521 10:08:24.644928  3675 solver.cpp:243] Iteration 10420, loss = 0.00561996
I0521 10:08:24.644960  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00561985 (* 1 = 0.00561985 loss)
I0521 10:08:24.644966  3675 sgd_solver.cpp:138] Iteration 10420, lr = 5e-05
I0521 10:08:28.153375  3675 solver.cpp:243] Iteration 10440, loss = 0.00458702
I0521 10:08:28.153407  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00458691 (* 1 = 0.00458691 loss)
I0521 10:08:28.153429  3675 sgd_solver.cpp:138] Iteration 10440, lr = 5e-05
I0521 10:08:31.665217  3675 solver.cpp:243] Iteration 10460, loss = 0.00461226
I0521 10:08:31.665248  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00461215 (* 1 = 0.00461215 loss)
I0521 10:08:31.665256  3675 sgd_solver.cpp:138] Iteration 10460, lr = 5e-05
I0521 10:08:35.116547  3675 solver.cpp:243] Iteration 10480, loss = 0.00631825
I0521 10:08:35.116578  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00631814 (* 1 = 0.00631814 loss)
I0521 10:08:35.116600  3675 sgd_solver.cpp:138] Iteration 10480, lr = 5e-05
I0521 10:08:38.624076  3675 solver.cpp:243] Iteration 10500, loss = 0.00565392
I0521 10:08:38.624109  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00565381 (* 1 = 0.00565381 loss)
I0521 10:08:38.624114  3675 sgd_solver.cpp:138] Iteration 10500, lr = 5e-05
I0521 10:08:42.131321  3675 solver.cpp:243] Iteration 10520, loss = 0.00429378
I0521 10:08:42.131351  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00429367 (* 1 = 0.00429367 loss)
I0521 10:08:42.131357  3675 sgd_solver.cpp:138] Iteration 10520, lr = 5e-05
I0521 10:08:45.644954  3675 solver.cpp:243] Iteration 10540, loss = 0.00405193
I0521 10:08:45.644985  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00405182 (* 1 = 0.00405182 loss)
I0521 10:08:45.644991  3675 sgd_solver.cpp:138] Iteration 10540, lr = 5e-05
I0521 10:08:49.157773  3675 solver.cpp:243] Iteration 10560, loss = 0.00734082
I0521 10:08:49.157938  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00734071 (* 1 = 0.00734071 loss)
I0521 10:08:49.157945  3675 sgd_solver.cpp:138] Iteration 10560, lr = 5e-05
I0521 10:08:52.665699  3675 solver.cpp:243] Iteration 10580, loss = 0.00406654
I0521 10:08:52.665730  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00406643 (* 1 = 0.00406643 loss)
I0521 10:08:52.665735  3675 sgd_solver.cpp:138] Iteration 10580, lr = 5e-05
I0521 10:08:56.175431  3675 solver.cpp:243] Iteration 10600, loss = 0.00485671
I0521 10:08:56.175463  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00485661 (* 1 = 0.00485661 loss)
I0521 10:08:56.175468  3675 sgd_solver.cpp:138] Iteration 10600, lr = 5e-05
I0521 10:08:59.690208  3675 solver.cpp:243] Iteration 10620, loss = 0.00312793
I0521 10:08:59.690240  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00312782 (* 1 = 0.00312782 loss)
I0521 10:08:59.690245  3675 sgd_solver.cpp:138] Iteration 10620, lr = 5e-05
I0521 10:09:03.200707  3675 solver.cpp:243] Iteration 10640, loss = 0.00780358
I0521 10:09:03.200738  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00780348 (* 1 = 0.00780348 loss)
I0521 10:09:03.200744  3675 sgd_solver.cpp:138] Iteration 10640, lr = 5e-05
I0521 10:09:06.710654  3675 solver.cpp:243] Iteration 10660, loss = 0.00344443
I0521 10:09:06.710686  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00344433 (* 1 = 0.00344433 loss)
I0521 10:09:06.710691  3675 sgd_solver.cpp:138] Iteration 10660, lr = 5e-05
I0521 10:09:10.221421  3675 solver.cpp:243] Iteration 10680, loss = 0.00443808
I0521 10:09:10.221453  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00443797 (* 1 = 0.00443797 loss)
I0521 10:09:10.221458  3675 sgd_solver.cpp:138] Iteration 10680, lr = 5e-05
I0521 10:09:13.730813  3675 solver.cpp:243] Iteration 10700, loss = 0.00375644
I0521 10:09:13.730870  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00375633 (* 1 = 0.00375633 loss)
I0521 10:09:13.730878  3675 sgd_solver.cpp:138] Iteration 10700, lr = 5e-05
I0521 10:09:17.240712  3675 solver.cpp:243] Iteration 10720, loss = 0.0064374
I0521 10:09:17.240744  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0064373 (* 1 = 0.0064373 loss)
I0521 10:09:17.240751  3675 sgd_solver.cpp:138] Iteration 10720, lr = 5e-05
I0521 10:09:20.744725  3675 solver.cpp:243] Iteration 10740, loss = 0.00331967
I0521 10:09:20.744892  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00331956 (* 1 = 0.00331956 loss)
I0521 10:09:20.744900  3675 sgd_solver.cpp:138] Iteration 10740, lr = 5e-05
I0521 10:09:24.258045  3675 solver.cpp:243] Iteration 10760, loss = 0.00371705
I0521 10:09:24.258077  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00371694 (* 1 = 0.00371694 loss)
I0521 10:09:24.258082  3675 sgd_solver.cpp:138] Iteration 10760, lr = 5e-05
I0521 10:09:27.768720  3675 solver.cpp:243] Iteration 10780, loss = 0.00520116
I0521 10:09:27.768754  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00520106 (* 1 = 0.00520106 loss)
I0521 10:09:27.768760  3675 sgd_solver.cpp:138] Iteration 10780, lr = 5e-05
I0521 10:09:31.280704  3675 solver.cpp:243] Iteration 10800, loss = 0.00627614
I0521 10:09:31.280735  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00627604 (* 1 = 0.00627604 loss)
I0521 10:09:31.280740  3675 sgd_solver.cpp:138] Iteration 10800, lr = 5e-05
I0521 10:09:34.791723  3675 solver.cpp:243] Iteration 10820, loss = 0.00358422
I0521 10:09:34.791755  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00358412 (* 1 = 0.00358412 loss)
I0521 10:09:34.791777  3675 sgd_solver.cpp:138] Iteration 10820, lr = 5e-05
I0521 10:09:38.302151  3675 solver.cpp:243] Iteration 10840, loss = 0.00431052
I0521 10:09:38.302182  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00431042 (* 1 = 0.00431042 loss)
I0521 10:09:38.302188  3675 sgd_solver.cpp:138] Iteration 10840, lr = 5e-05
I0521 10:09:41.817644  3675 solver.cpp:243] Iteration 10860, loss = 0.00307137
I0521 10:09:41.817677  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00307126 (* 1 = 0.00307126 loss)
I0521 10:09:41.817682  3675 sgd_solver.cpp:138] Iteration 10860, lr = 5e-05
I0521 10:09:45.327713  3675 solver.cpp:243] Iteration 10880, loss = 0.00378328
I0521 10:09:45.327744  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00378318 (* 1 = 0.00378318 loss)
I0521 10:09:45.327749  3675 sgd_solver.cpp:138] Iteration 10880, lr = 5e-05
I0521 10:09:48.835500  3675 solver.cpp:243] Iteration 10900, loss = 0.00359259
I0521 10:09:48.835531  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00359249 (* 1 = 0.00359249 loss)
I0521 10:09:48.835553  3675 sgd_solver.cpp:138] Iteration 10900, lr = 5e-05
I0521 10:09:52.344000  3675 solver.cpp:243] Iteration 10920, loss = 0.00792707
I0521 10:09:52.344669  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00792696 (* 1 = 0.00792696 loss)
I0521 10:09:52.344677  3675 sgd_solver.cpp:138] Iteration 10920, lr = 5e-05
I0521 10:09:55.855012  3675 solver.cpp:243] Iteration 10940, loss = 0.00400129
I0521 10:09:55.855044  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00400119 (* 1 = 0.00400119 loss)
I0521 10:09:55.855049  3675 sgd_solver.cpp:138] Iteration 10940, lr = 5e-05
I0521 10:09:59.367975  3675 solver.cpp:243] Iteration 10960, loss = 0.00523223
I0521 10:09:59.368006  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00523213 (* 1 = 0.00523213 loss)
I0521 10:09:59.368011  3675 sgd_solver.cpp:138] Iteration 10960, lr = 5e-05
I0521 10:10:02.874824  3675 solver.cpp:243] Iteration 10980, loss = 0.00390709
I0521 10:10:02.874871  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00390698 (* 1 = 0.00390698 loss)
I0521 10:10:02.874877  3675 sgd_solver.cpp:138] Iteration 10980, lr = 5e-05
I0521 10:10:06.259943  3675 solver.cpp:358] Iteration 11000, Testing net (#0)
I0521 10:10:10.992331  3675 solver.cpp:425]     Test net output #0: acc = 1
I0521 10:10:10.992359  3675 solver.cpp:425]     Test net output #1: acc = 1
I0521 10:10:10.992367  3675 solver.cpp:425]     Test net output #2: ctcloss = 0.00142459 (* 1 = 0.00142459 loss)
I0521 10:10:11.127765  3675 solver.cpp:243] Iteration 11000, loss = 0.00420319
I0521 10:10:11.127795  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00420309 (* 1 = 0.00420309 loss)
I0521 10:10:11.127801  3675 sgd_solver.cpp:138] Iteration 11000, lr = 5e-05
I0521 10:10:14.643182  3675 solver.cpp:243] Iteration 11020, loss = 0.00406942
I0521 10:10:14.643214  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00406931 (* 1 = 0.00406931 loss)
I0521 10:10:14.643220  3675 sgd_solver.cpp:138] Iteration 11020, lr = 5e-05
I0521 10:10:18.152292  3675 solver.cpp:243] Iteration 11040, loss = 0.00503647
I0521 10:10:18.152323  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00503636 (* 1 = 0.00503636 loss)
I0521 10:10:18.152328  3675 sgd_solver.cpp:138] Iteration 11040, lr = 5e-05
I0521 10:10:21.663805  3675 solver.cpp:243] Iteration 11060, loss = 0.00378896
I0521 10:10:21.663836  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00378885 (* 1 = 0.00378885 loss)
I0521 10:10:21.663841  3675 sgd_solver.cpp:138] Iteration 11060, lr = 5e-05
I0521 10:10:25.184656  3675 solver.cpp:243] Iteration 11080, loss = 0.00541931
I0521 10:10:25.184834  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0054192 (* 1 = 0.0054192 loss)
I0521 10:10:25.184841  3675 sgd_solver.cpp:138] Iteration 11080, lr = 5e-05
I0521 10:10:28.698598  3675 solver.cpp:243] Iteration 11100, loss = 0.00275274
I0521 10:10:28.698628  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00275263 (* 1 = 0.00275263 loss)
I0521 10:10:28.698634  3675 sgd_solver.cpp:138] Iteration 11100, lr = 5e-05
I0521 10:10:32.210815  3675 solver.cpp:243] Iteration 11120, loss = 0.00387342
I0521 10:10:32.210846  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00387331 (* 1 = 0.00387331 loss)
I0521 10:10:32.210867  3675 sgd_solver.cpp:138] Iteration 11120, lr = 5e-05
I0521 10:10:35.726096  3675 solver.cpp:243] Iteration 11140, loss = 0.0040724
I0521 10:10:35.726127  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00407229 (* 1 = 0.00407229 loss)
I0521 10:10:35.726132  3675 sgd_solver.cpp:138] Iteration 11140, lr = 5e-05
I0521 10:10:39.236212  3675 solver.cpp:243] Iteration 11160, loss = 0.00469795
I0521 10:10:39.236243  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00469784 (* 1 = 0.00469784 loss)
I0521 10:10:39.236248  3675 sgd_solver.cpp:138] Iteration 11160, lr = 5e-05
I0521 10:10:42.746353  3675 solver.cpp:243] Iteration 11180, loss = 0.0307183
I0521 10:10:42.746383  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0307182 (* 1 = 0.0307182 loss)
I0521 10:10:42.746389  3675 sgd_solver.cpp:138] Iteration 11180, lr = 5e-05
I0521 10:10:46.262806  3675 solver.cpp:243] Iteration 11200, loss = 0.00458151
I0521 10:10:46.262838  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0045814 (* 1 = 0.0045814 loss)
I0521 10:10:46.262845  3675 sgd_solver.cpp:138] Iteration 11200, lr = 5e-05
I0521 10:10:49.773613  3675 solver.cpp:243] Iteration 11220, loss = 0.00573882
I0521 10:10:49.773645  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00573871 (* 1 = 0.00573871 loss)
I0521 10:10:49.773650  3675 sgd_solver.cpp:138] Iteration 11220, lr = 5e-05
I0521 10:10:53.284727  3675 solver.cpp:243] Iteration 11240, loss = 0.0061977
I0521 10:10:53.284757  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00619759 (* 1 = 0.00619759 loss)
I0521 10:10:53.284762  3675 sgd_solver.cpp:138] Iteration 11240, lr = 5e-05
I0521 10:10:56.803397  3675 solver.cpp:243] Iteration 11260, loss = 0.0062414
I0521 10:10:56.803550  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00624129 (* 1 = 0.00624129 loss)
I0521 10:10:56.803557  3675 sgd_solver.cpp:138] Iteration 11260, lr = 5e-05
I0521 10:11:00.319494  3675 solver.cpp:243] Iteration 11280, loss = 0.00391978
I0521 10:11:00.319525  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00391967 (* 1 = 0.00391967 loss)
I0521 10:11:00.319530  3675 sgd_solver.cpp:138] Iteration 11280, lr = 5e-05
I0521 10:11:03.831521  3675 solver.cpp:243] Iteration 11300, loss = 0.00501855
I0521 10:11:03.831550  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00501844 (* 1 = 0.00501844 loss)
I0521 10:11:03.831573  3675 sgd_solver.cpp:138] Iteration 11300, lr = 5e-05
I0521 10:11:07.350759  3675 solver.cpp:243] Iteration 11320, loss = 0.00445598
I0521 10:11:07.350790  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00445587 (* 1 = 0.00445587 loss)
I0521 10:11:07.350795  3675 sgd_solver.cpp:138] Iteration 11320, lr = 5e-05
I0521 10:11:10.863274  3675 solver.cpp:243] Iteration 11340, loss = 0.00434685
I0521 10:11:10.863306  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00434674 (* 1 = 0.00434674 loss)
I0521 10:11:10.863312  3675 sgd_solver.cpp:138] Iteration 11340, lr = 5e-05
I0521 10:11:14.379169  3675 solver.cpp:243] Iteration 11360, loss = 0.00567855
I0521 10:11:14.379202  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00567844 (* 1 = 0.00567844 loss)
I0521 10:11:14.379207  3675 sgd_solver.cpp:138] Iteration 11360, lr = 5e-05
I0521 10:11:17.887727  3675 solver.cpp:243] Iteration 11380, loss = 0.00443753
I0521 10:11:17.887760  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00443742 (* 1 = 0.00443742 loss)
I0521 10:11:17.887766  3675 sgd_solver.cpp:138] Iteration 11380, lr = 5e-05
I0521 10:11:21.399302  3675 solver.cpp:243] Iteration 11400, loss = 0.00536997
I0521 10:11:21.399333  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00536986 (* 1 = 0.00536986 loss)
I0521 10:11:21.399338  3675 sgd_solver.cpp:138] Iteration 11400, lr = 5e-05
I0521 10:11:24.915745  3675 solver.cpp:243] Iteration 11420, loss = 0.00387547
I0521 10:11:24.915776  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00387536 (* 1 = 0.00387536 loss)
I0521 10:11:24.915781  3675 sgd_solver.cpp:138] Iteration 11420, lr = 5e-05
I0521 10:11:28.426632  3675 solver.cpp:243] Iteration 11440, loss = 0.00458899
I0521 10:11:28.426798  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00458887 (* 1 = 0.00458887 loss)
I0521 10:11:28.426806  3675 sgd_solver.cpp:138] Iteration 11440, lr = 5e-05
I0521 10:11:31.942670  3675 solver.cpp:243] Iteration 11460, loss = 0.00372931
I0521 10:11:31.942701  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0037292 (* 1 = 0.0037292 loss)
I0521 10:11:31.942708  3675 sgd_solver.cpp:138] Iteration 11460, lr = 5e-05
I0521 10:11:35.460613  3675 solver.cpp:243] Iteration 11480, loss = 0.00408974
I0521 10:11:35.460642  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00408963 (* 1 = 0.00408963 loss)
I0521 10:11:35.460647  3675 sgd_solver.cpp:138] Iteration 11480, lr = 5e-05
I0521 10:11:38.972723  3675 solver.cpp:243] Iteration 11500, loss = 0.00508439
I0521 10:11:38.972755  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00508428 (* 1 = 0.00508428 loss)
I0521 10:11:38.972776  3675 sgd_solver.cpp:138] Iteration 11500, lr = 5e-05
I0521 10:11:42.489970  3675 solver.cpp:243] Iteration 11520, loss = 0.00501357
I0521 10:11:42.490013  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00501346 (* 1 = 0.00501346 loss)
I0521 10:11:42.490018  3675 sgd_solver.cpp:138] Iteration 11520, lr = 5e-05
I0521 10:11:46.004737  3675 solver.cpp:243] Iteration 11540, loss = 0.0341239
I0521 10:11:46.004768  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0341238 (* 1 = 0.0341238 loss)
I0521 10:11:46.004793  3675 sgd_solver.cpp:138] Iteration 11540, lr = 5e-05
I0521 10:11:49.518435  3675 solver.cpp:243] Iteration 11560, loss = 0.00444289
I0521 10:11:49.518466  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00444278 (* 1 = 0.00444278 loss)
I0521 10:11:49.518472  3675 sgd_solver.cpp:138] Iteration 11560, lr = 5e-05
I0521 10:11:53.027053  3675 solver.cpp:243] Iteration 11580, loss = 0.0048802
I0521 10:11:53.027084  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00488008 (* 1 = 0.00488008 loss)
I0521 10:11:53.027089  3675 sgd_solver.cpp:138] Iteration 11580, lr = 5e-05
I0521 10:11:56.538652  3675 solver.cpp:243] Iteration 11600, loss = 0.00439728
I0521 10:11:56.538687  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00439716 (* 1 = 0.00439716 loss)
I0521 10:11:56.538693  3675 sgd_solver.cpp:138] Iteration 11600, lr = 5e-05
I0521 10:12:00.052633  3675 solver.cpp:243] Iteration 11620, loss = 0.00386649
I0521 10:12:00.052762  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00386638 (* 1 = 0.00386638 loss)
I0521 10:12:00.052769  3675 sgd_solver.cpp:138] Iteration 11620, lr = 5e-05
I0521 10:12:03.570469  3675 solver.cpp:243] Iteration 11640, loss = 0.00560602
I0521 10:12:03.570499  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00560591 (* 1 = 0.00560591 loss)
I0521 10:12:03.570505  3675 sgd_solver.cpp:138] Iteration 11640, lr = 5e-05
I0521 10:12:07.082939  3675 solver.cpp:243] Iteration 11660, loss = 0.00518417
I0521 10:12:07.082970  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00518406 (* 1 = 0.00518406 loss)
I0521 10:12:07.082975  3675 sgd_solver.cpp:138] Iteration 11660, lr = 5e-05
I0521 10:12:10.597896  3675 solver.cpp:243] Iteration 11680, loss = 0.0097513
I0521 10:12:10.597929  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00975119 (* 1 = 0.00975119 loss)
I0521 10:12:10.597950  3675 sgd_solver.cpp:138] Iteration 11680, lr = 5e-05
I0521 10:12:14.106531  3675 solver.cpp:243] Iteration 11700, loss = 0.0031668
I0521 10:12:14.106562  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00316669 (* 1 = 0.00316669 loss)
I0521 10:12:14.106568  3675 sgd_solver.cpp:138] Iteration 11700, lr = 5e-05
I0521 10:12:17.615005  3675 solver.cpp:243] Iteration 11720, loss = 0.00429719
I0521 10:12:17.615036  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00429708 (* 1 = 0.00429708 loss)
I0521 10:12:17.615042  3675 sgd_solver.cpp:138] Iteration 11720, lr = 5e-05
I0521 10:12:21.122256  3675 solver.cpp:243] Iteration 11740, loss = 0.00395907
I0521 10:12:21.122287  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00395896 (* 1 = 0.00395896 loss)
I0521 10:12:21.122292  3675 sgd_solver.cpp:138] Iteration 11740, lr = 5e-05
I0521 10:12:24.636301  3675 solver.cpp:243] Iteration 11760, loss = 0.00417865
I0521 10:12:24.636333  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00417854 (* 1 = 0.00417854 loss)
I0521 10:12:24.636340  3675 sgd_solver.cpp:138] Iteration 11760, lr = 5e-05
I0521 10:12:28.084074  3675 solver.cpp:243] Iteration 11780, loss = 0.00479081
I0521 10:12:28.084105  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0047907 (* 1 = 0.0047907 loss)
I0521 10:12:28.084110  3675 sgd_solver.cpp:138] Iteration 11780, lr = 5e-05
I0521 10:12:31.595005  3675 solver.cpp:243] Iteration 11800, loss = 0.0033367
I0521 10:12:31.595160  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00333659 (* 1 = 0.00333659 loss)
I0521 10:12:31.595168  3675 sgd_solver.cpp:138] Iteration 11800, lr = 5e-05
I0521 10:12:35.107198  3675 solver.cpp:243] Iteration 11820, loss = 0.00537114
I0521 10:12:35.107230  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00537103 (* 1 = 0.00537103 loss)
I0521 10:12:35.107236  3675 sgd_solver.cpp:138] Iteration 11820, lr = 5e-05
I0521 10:12:38.616189  3675 solver.cpp:243] Iteration 11840, loss = 0.00427489
I0521 10:12:38.616219  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00427478 (* 1 = 0.00427478 loss)
I0521 10:12:38.616225  3675 sgd_solver.cpp:138] Iteration 11840, lr = 5e-05
I0521 10:12:42.127735  3675 solver.cpp:243] Iteration 11860, loss = 0.00389441
I0521 10:12:42.127768  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0038943 (* 1 = 0.0038943 loss)
I0521 10:12:42.127774  3675 sgd_solver.cpp:138] Iteration 11860, lr = 5e-05
I0521 10:12:45.641574  3675 solver.cpp:243] Iteration 11880, loss = 0.00385749
I0521 10:12:45.641605  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00385738 (* 1 = 0.00385738 loss)
I0521 10:12:45.641628  3675 sgd_solver.cpp:138] Iteration 11880, lr = 5e-05
I0521 10:12:49.147672  3675 solver.cpp:243] Iteration 11900, loss = 0.00292942
I0521 10:12:49.147702  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00292931 (* 1 = 0.00292931 loss)
I0521 10:12:49.147723  3675 sgd_solver.cpp:138] Iteration 11900, lr = 5e-05
I0521 10:12:52.661638  3675 solver.cpp:243] Iteration 11920, loss = 0.00412162
I0521 10:12:52.661669  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00412151 (* 1 = 0.00412151 loss)
I0521 10:12:52.661675  3675 sgd_solver.cpp:138] Iteration 11920, lr = 5e-05
I0521 10:12:56.174450  3675 solver.cpp:243] Iteration 11940, loss = 0.00338887
I0521 10:12:56.174481  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00338876 (* 1 = 0.00338876 loss)
I0521 10:12:56.174486  3675 sgd_solver.cpp:138] Iteration 11940, lr = 5e-05
I0521 10:12:59.685937  3675 solver.cpp:243] Iteration 11960, loss = 0.00317261
I0521 10:12:59.685968  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0031725 (* 1 = 0.0031725 loss)
I0521 10:12:59.685974  3675 sgd_solver.cpp:138] Iteration 11960, lr = 5e-05
I0521 10:13:03.202508  3675 solver.cpp:243] Iteration 11980, loss = 0.00414539
I0521 10:13:03.202672  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00414528 (* 1 = 0.00414528 loss)
I0521 10:13:03.202679  3675 sgd_solver.cpp:138] Iteration 11980, lr = 5e-05
I0521 10:13:06.587221  3675 solver.cpp:596] Snapshotting to binary proto file models/LPR/lpr_resnet_lstm_iter_12000.caffemodel
I0521 10:13:06.617271  3675 sgd_solver.cpp:307] Snapshotting solver state to binary proto file models/LPR/lpr_resnet_lstm_iter_12000.solverstate
I0521 10:13:06.650884  3675 solver.cpp:358] Iteration 12000, Testing net (#0)
I0521 10:13:11.385610  3675 solver.cpp:425]     Test net output #0: acc = 1
I0521 10:13:11.385637  3675 solver.cpp:425]     Test net output #1: acc = 1
I0521 10:13:11.385644  3675 solver.cpp:425]     Test net output #2: ctcloss = 0.0013057 (* 1 = 0.0013057 loss)
I0521 10:13:11.521594  3675 solver.cpp:243] Iteration 12000, loss = 0.00406374
I0521 10:13:11.521622  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00406363 (* 1 = 0.00406363 loss)
I0521 10:13:11.521628  3675 sgd_solver.cpp:138] Iteration 12000, lr = 5e-05
I0521 10:13:15.035390  3675 solver.cpp:243] Iteration 12020, loss = 0.00472132
I0521 10:13:15.035421  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0047212 (* 1 = 0.0047212 loss)
I0521 10:13:15.035428  3675 sgd_solver.cpp:138] Iteration 12020, lr = 5e-05
I0521 10:13:18.552178  3675 solver.cpp:243] Iteration 12040, loss = 0.00906733
I0521 10:13:18.552209  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00906722 (* 1 = 0.00906722 loss)
I0521 10:13:18.552230  3675 sgd_solver.cpp:138] Iteration 12040, lr = 5e-05
I0521 10:13:22.069555  3675 solver.cpp:243] Iteration 12060, loss = 0.00456217
I0521 10:13:22.069587  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00456206 (* 1 = 0.00456206 loss)
I0521 10:13:22.069593  3675 sgd_solver.cpp:138] Iteration 12060, lr = 5e-05
I0521 10:13:25.586436  3675 solver.cpp:243] Iteration 12080, loss = 0.00302326
I0521 10:13:25.586467  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00302315 (* 1 = 0.00302315 loss)
I0521 10:13:25.586472  3675 sgd_solver.cpp:138] Iteration 12080, lr = 5e-05
I0521 10:13:29.102916  3675 solver.cpp:243] Iteration 12100, loss = 0.00335924
I0521 10:13:29.102946  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00335912 (* 1 = 0.00335912 loss)
I0521 10:13:29.102967  3675 sgd_solver.cpp:138] Iteration 12100, lr = 5e-05
I0521 10:13:32.619397  3675 solver.cpp:243] Iteration 12120, loss = 0.00267876
I0521 10:13:32.619428  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00267864 (* 1 = 0.00267864 loss)
I0521 10:13:32.619434  3675 sgd_solver.cpp:138] Iteration 12120, lr = 5e-05
I0521 10:13:36.136659  3675 solver.cpp:243] Iteration 12140, loss = 0.00305837
I0521 10:13:36.136844  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00305826 (* 1 = 0.00305826 loss)
I0521 10:13:36.136854  3675 sgd_solver.cpp:138] Iteration 12140, lr = 5e-05
I0521 10:13:39.650526  3675 solver.cpp:243] Iteration 12160, loss = 0.00725987
I0521 10:13:39.650557  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00725976 (* 1 = 0.00725976 loss)
I0521 10:13:39.650563  3675 sgd_solver.cpp:138] Iteration 12160, lr = 5e-05
I0521 10:13:43.169028  3675 solver.cpp:243] Iteration 12180, loss = 0.00667815
I0521 10:13:43.169059  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00667803 (* 1 = 0.00667803 loss)
I0521 10:13:43.169064  3675 sgd_solver.cpp:138] Iteration 12180, lr = 5e-05
I0521 10:13:46.689357  3675 solver.cpp:243] Iteration 12200, loss = 0.0049639
I0521 10:13:46.689389  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00496379 (* 1 = 0.00496379 loss)
I0521 10:13:46.689394  3675 sgd_solver.cpp:138] Iteration 12200, lr = 5e-05
I0521 10:13:50.205468  3675 solver.cpp:243] Iteration 12220, loss = 0.00331811
I0521 10:13:50.205499  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.003318 (* 1 = 0.003318 loss)
I0521 10:13:50.205504  3675 sgd_solver.cpp:138] Iteration 12220, lr = 5e-05
I0521 10:13:53.722380  3675 solver.cpp:243] Iteration 12240, loss = 0.00511532
I0521 10:13:53.722410  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0051152 (* 1 = 0.0051152 loss)
I0521 10:13:53.722416  3675 sgd_solver.cpp:138] Iteration 12240, lr = 5e-05
I0521 10:13:57.240763  3675 solver.cpp:243] Iteration 12260, loss = 0.00320007
I0521 10:13:57.240799  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00319996 (* 1 = 0.00319996 loss)
I0521 10:13:57.240821  3675 sgd_solver.cpp:138] Iteration 12260, lr = 5e-05
I0521 10:14:00.752528  3675 solver.cpp:243] Iteration 12280, loss = 0.00364255
I0521 10:14:00.752558  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00364243 (* 1 = 0.00364243 loss)
I0521 10:14:00.752564  3675 sgd_solver.cpp:138] Iteration 12280, lr = 5e-05
I0521 10:14:04.269908  3675 solver.cpp:243] Iteration 12300, loss = 0.00380721
I0521 10:14:04.269940  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00380709 (* 1 = 0.00380709 loss)
I0521 10:14:04.269945  3675 sgd_solver.cpp:138] Iteration 12300, lr = 5e-05
I0521 10:14:07.781575  3675 solver.cpp:243] Iteration 12320, loss = 0.00302782
I0521 10:14:07.781754  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00302771 (* 1 = 0.00302771 loss)
I0521 10:14:07.781762  3675 sgd_solver.cpp:138] Iteration 12320, lr = 5e-05
I0521 10:14:11.297507  3675 solver.cpp:243] Iteration 12340, loss = 0.00446341
I0521 10:14:11.297536  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0044633 (* 1 = 0.0044633 loss)
I0521 10:14:11.297542  3675 sgd_solver.cpp:138] Iteration 12340, lr = 5e-05
I0521 10:14:14.809813  3675 solver.cpp:243] Iteration 12360, loss = 0.0028916
I0521 10:14:14.809844  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00289149 (* 1 = 0.00289149 loss)
I0521 10:14:14.809850  3675 sgd_solver.cpp:138] Iteration 12360, lr = 5e-05
I0521 10:14:18.326254  3675 solver.cpp:243] Iteration 12380, loss = 0.00636463
I0521 10:14:18.326285  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00636452 (* 1 = 0.00636452 loss)
I0521 10:14:18.326290  3675 sgd_solver.cpp:138] Iteration 12380, lr = 5e-05
I0521 10:14:21.845618  3675 solver.cpp:243] Iteration 12400, loss = 0.00239186
I0521 10:14:21.845649  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00239175 (* 1 = 0.00239175 loss)
I0521 10:14:21.845654  3675 sgd_solver.cpp:138] Iteration 12400, lr = 5e-05
I0521 10:14:25.362310  3675 solver.cpp:243] Iteration 12420, loss = 0.00446118
I0521 10:14:25.362342  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00446107 (* 1 = 0.00446107 loss)
I0521 10:14:25.362347  3675 sgd_solver.cpp:138] Iteration 12420, lr = 5e-05
I0521 10:14:28.881664  3675 solver.cpp:243] Iteration 12440, loss = 0.00441535
I0521 10:14:28.881696  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00441524 (* 1 = 0.00441524 loss)
I0521 10:14:28.881702  3675 sgd_solver.cpp:138] Iteration 12440, lr = 5e-05
I0521 10:14:32.399619  3675 solver.cpp:243] Iteration 12460, loss = 0.0046824
I0521 10:14:32.399652  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00468229 (* 1 = 0.00468229 loss)
I0521 10:14:32.399657  3675 sgd_solver.cpp:138] Iteration 12460, lr = 5e-05
I0521 10:14:35.916141  3675 solver.cpp:243] Iteration 12480, loss = 0.00328185
I0521 10:14:35.916173  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00328174 (* 1 = 0.00328174 loss)
I0521 10:14:35.916178  3675 sgd_solver.cpp:138] Iteration 12480, lr = 5e-05
I0521 10:14:39.424635  3675 solver.cpp:243] Iteration 12500, loss = 0.00352114
I0521 10:14:39.424813  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00352103 (* 1 = 0.00352103 loss)
I0521 10:14:39.424819  3675 sgd_solver.cpp:138] Iteration 12500, lr = 5e-05
I0521 10:14:42.947901  3675 solver.cpp:243] Iteration 12520, loss = 0.00523263
I0521 10:14:42.947932  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00523252 (* 1 = 0.00523252 loss)
I0521 10:14:42.947937  3675 sgd_solver.cpp:138] Iteration 12520, lr = 5e-05
I0521 10:14:46.461102  3675 solver.cpp:243] Iteration 12540, loss = 0.00275901
I0521 10:14:46.461133  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0027589 (* 1 = 0.0027589 loss)
I0521 10:14:46.461138  3675 sgd_solver.cpp:138] Iteration 12540, lr = 5e-05
I0521 10:14:49.972882  3675 solver.cpp:243] Iteration 12560, loss = 0.00356713
I0521 10:14:49.972913  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00356702 (* 1 = 0.00356702 loss)
I0521 10:14:49.972918  3675 sgd_solver.cpp:138] Iteration 12560, lr = 5e-05
I0521 10:14:53.488477  3675 solver.cpp:243] Iteration 12580, loss = 0.00435122
I0521 10:14:53.488507  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00435111 (* 1 = 0.00435111 loss)
I0521 10:14:53.488513  3675 sgd_solver.cpp:138] Iteration 12580, lr = 5e-05
I0521 10:14:57.005108  3675 solver.cpp:243] Iteration 12600, loss = 0.00558524
I0521 10:14:57.005141  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00558512 (* 1 = 0.00558512 loss)
I0521 10:14:57.005147  3675 sgd_solver.cpp:138] Iteration 12600, lr = 5e-05
I0521 10:15:00.518451  3675 solver.cpp:243] Iteration 12620, loss = 0.0053864
I0521 10:15:00.518481  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00538629 (* 1 = 0.00538629 loss)
I0521 10:15:00.518486  3675 sgd_solver.cpp:138] Iteration 12620, lr = 5e-05
I0521 10:15:04.032012  3675 solver.cpp:243] Iteration 12640, loss = 0.0042987
I0521 10:15:04.032043  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00429859 (* 1 = 0.00429859 loss)
I0521 10:15:04.032049  3675 sgd_solver.cpp:138] Iteration 12640, lr = 5e-05
I0521 10:15:07.551398  3675 solver.cpp:243] Iteration 12660, loss = 0.0035208
I0521 10:15:07.551429  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00352069 (* 1 = 0.00352069 loss)
I0521 10:15:07.551434  3675 sgd_solver.cpp:138] Iteration 12660, lr = 5e-05
I0521 10:15:11.068177  3675 solver.cpp:243] Iteration 12680, loss = 0.019407
I0521 10:15:11.068357  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0194069 (* 1 = 0.0194069 loss)
I0521 10:15:11.068365  3675 sgd_solver.cpp:138] Iteration 12680, lr = 5e-05
I0521 10:15:14.586006  3675 solver.cpp:243] Iteration 12700, loss = 0.00509633
I0521 10:15:14.586036  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00509622 (* 1 = 0.00509622 loss)
I0521 10:15:14.586057  3675 sgd_solver.cpp:138] Iteration 12700, lr = 5e-05
I0521 10:15:18.102275  3675 solver.cpp:243] Iteration 12720, loss = 0.0194213
I0521 10:15:18.102308  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0194211 (* 1 = 0.0194211 loss)
I0521 10:15:18.102329  3675 sgd_solver.cpp:138] Iteration 12720, lr = 5e-05
I0521 10:15:21.619448  3675 solver.cpp:243] Iteration 12740, loss = 0.00475696
I0521 10:15:21.619479  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00475685 (* 1 = 0.00475685 loss)
I0521 10:15:21.619484  3675 sgd_solver.cpp:138] Iteration 12740, lr = 5e-05
I0521 10:15:25.137501  3675 solver.cpp:243] Iteration 12760, loss = 0.00385758
I0521 10:15:25.137533  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00385747 (* 1 = 0.00385747 loss)
I0521 10:15:25.137538  3675 sgd_solver.cpp:138] Iteration 12760, lr = 5e-05
I0521 10:15:28.649210  3675 solver.cpp:243] Iteration 12780, loss = 0.00338522
I0521 10:15:28.649242  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00338511 (* 1 = 0.00338511 loss)
I0521 10:15:28.649248  3675 sgd_solver.cpp:138] Iteration 12780, lr = 5e-05
I0521 10:15:32.165380  3675 solver.cpp:243] Iteration 12800, loss = 0.00327541
I0521 10:15:32.165410  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0032753 (* 1 = 0.0032753 loss)
I0521 10:15:32.165431  3675 sgd_solver.cpp:138] Iteration 12800, lr = 5e-05
I0521 10:15:35.685298  3675 solver.cpp:243] Iteration 12820, loss = 0.0041207
I0521 10:15:35.685329  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00412059 (* 1 = 0.00412059 loss)
I0521 10:15:35.685336  3675 sgd_solver.cpp:138] Iteration 12820, lr = 5e-05
I0521 10:15:39.205242  3675 solver.cpp:243] Iteration 12840, loss = 0.0046976
I0521 10:15:39.205276  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00469749 (* 1 = 0.00469749 loss)
I0521 10:15:39.205281  3675 sgd_solver.cpp:138] Iteration 12840, lr = 5e-05
I0521 10:15:42.723556  3675 solver.cpp:243] Iteration 12860, loss = 0.00414675
I0521 10:15:42.723711  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00414664 (* 1 = 0.00414664 loss)
I0521 10:15:42.723718  3675 sgd_solver.cpp:138] Iteration 12860, lr = 5e-05
I0521 10:15:46.241012  3675 solver.cpp:243] Iteration 12880, loss = 0.00401035
I0521 10:15:46.241044  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00401024 (* 1 = 0.00401024 loss)
I0521 10:15:46.241065  3675 sgd_solver.cpp:138] Iteration 12880, lr = 5e-05
I0521 10:15:49.755817  3675 solver.cpp:243] Iteration 12900, loss = 0.00289477
I0521 10:15:49.755847  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00289466 (* 1 = 0.00289466 loss)
I0521 10:15:49.755853  3675 sgd_solver.cpp:138] Iteration 12900, lr = 5e-05
I0521 10:15:53.267892  3675 solver.cpp:243] Iteration 12920, loss = 0.00317123
I0521 10:15:53.267923  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00317112 (* 1 = 0.00317112 loss)
I0521 10:15:53.267946  3675 sgd_solver.cpp:138] Iteration 12920, lr = 5e-05
I0521 10:15:56.782552  3675 solver.cpp:243] Iteration 12940, loss = 0.00386656
I0521 10:15:56.782582  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00386645 (* 1 = 0.00386645 loss)
I0521 10:15:56.782588  3675 sgd_solver.cpp:138] Iteration 12940, lr = 5e-05
I0521 10:16:00.297379  3675 solver.cpp:243] Iteration 12960, loss = 0.00349149
I0521 10:16:00.297410  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00349138 (* 1 = 0.00349138 loss)
I0521 10:16:00.297417  3675 sgd_solver.cpp:138] Iteration 12960, lr = 5e-05
I0521 10:16:03.813975  3675 solver.cpp:243] Iteration 12980, loss = 0.00284573
I0521 10:16:03.814007  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00284562 (* 1 = 0.00284562 loss)
I0521 10:16:03.814028  3675 sgd_solver.cpp:138] Iteration 12980, lr = 5e-05
I0521 10:16:07.134337  3675 solver.cpp:358] Iteration 13000, Testing net (#0)
I0521 10:16:11.866330  3675 solver.cpp:425]     Test net output #0: acc = 1
I0521 10:16:11.866358  3675 solver.cpp:425]     Test net output #1: acc = 1
I0521 10:16:11.866380  3675 solver.cpp:425]     Test net output #2: ctcloss = 0.00124578 (* 1 = 0.00124578 loss)
I0521 10:16:12.065812  3675 solver.cpp:243] Iteration 13000, loss = 0.00555039
I0521 10:16:12.065843  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00555028 (* 1 = 0.00555028 loss)
I0521 10:16:12.065850  3675 sgd_solver.cpp:138] Iteration 13000, lr = 5e-05
I0521 10:16:15.583398  3675 solver.cpp:243] Iteration 13020, loss = 0.00302251
I0521 10:16:15.583590  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0030224 (* 1 = 0.0030224 loss)
I0521 10:16:15.583598  3675 sgd_solver.cpp:138] Iteration 13020, lr = 5e-05
I0521 10:16:19.103401  3675 solver.cpp:243] Iteration 13040, loss = 0.00418606
I0521 10:16:19.103457  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00418595 (* 1 = 0.00418595 loss)
I0521 10:16:19.103466  3675 sgd_solver.cpp:138] Iteration 13040, lr = 5e-05
I0521 10:16:22.620506  3675 solver.cpp:243] Iteration 13060, loss = 0.0126494
I0521 10:16:22.620537  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0126493 (* 1 = 0.0126493 loss)
I0521 10:16:22.620544  3675 sgd_solver.cpp:138] Iteration 13060, lr = 5e-05
I0521 10:16:26.075912  3675 solver.cpp:243] Iteration 13080, loss = 0.00382032
I0521 10:16:26.075944  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00382021 (* 1 = 0.00382021 loss)
I0521 10:16:26.075949  3675 sgd_solver.cpp:138] Iteration 13080, lr = 5e-05
I0521 10:16:29.598142  3675 solver.cpp:243] Iteration 13100, loss = 0.00470227
I0521 10:16:29.598174  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00470216 (* 1 = 0.00470216 loss)
I0521 10:16:29.598196  3675 sgd_solver.cpp:138] Iteration 13100, lr = 5e-05
I0521 10:16:33.117656  3675 solver.cpp:243] Iteration 13120, loss = 0.00535038
I0521 10:16:33.117687  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00535027 (* 1 = 0.00535027 loss)
I0521 10:16:33.117693  3675 sgd_solver.cpp:138] Iteration 13120, lr = 5e-05
I0521 10:16:36.638634  3675 solver.cpp:243] Iteration 13140, loss = 0.00353104
I0521 10:16:36.638665  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00353093 (* 1 = 0.00353093 loss)
I0521 10:16:36.638670  3675 sgd_solver.cpp:138] Iteration 13140, lr = 5e-05
I0521 10:16:40.159466  3675 solver.cpp:243] Iteration 13160, loss = 0.00385349
I0521 10:16:40.159498  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00385338 (* 1 = 0.00385338 loss)
I0521 10:16:40.159504  3675 sgd_solver.cpp:138] Iteration 13160, lr = 5e-05
I0521 10:16:43.676267  3675 solver.cpp:243] Iteration 13180, loss = 0.00351166
I0521 10:16:43.676297  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00351155 (* 1 = 0.00351155 loss)
I0521 10:16:43.676302  3675 sgd_solver.cpp:138] Iteration 13180, lr = 5e-05
I0521 10:16:47.192334  3675 solver.cpp:243] Iteration 13200, loss = 0.00529738
I0521 10:16:47.192515  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00529727 (* 1 = 0.00529727 loss)
I0521 10:16:47.192524  3675 sgd_solver.cpp:138] Iteration 13200, lr = 5e-05
I0521 10:16:50.707777  3675 solver.cpp:243] Iteration 13220, loss = 0.00686169
I0521 10:16:50.707808  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00686158 (* 1 = 0.00686158 loss)
I0521 10:16:50.707813  3675 sgd_solver.cpp:138] Iteration 13220, lr = 5e-05
I0521 10:16:54.228147  3675 solver.cpp:243] Iteration 13240, loss = 0.00276189
I0521 10:16:54.228178  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00276178 (* 1 = 0.00276178 loss)
I0521 10:16:54.228183  3675 sgd_solver.cpp:138] Iteration 13240, lr = 5e-05
I0521 10:16:57.753772  3675 solver.cpp:243] Iteration 13260, loss = 0.00270302
I0521 10:16:57.753805  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00270291 (* 1 = 0.00270291 loss)
I0521 10:16:57.753813  3675 sgd_solver.cpp:138] Iteration 13260, lr = 5e-05
I0521 10:17:01.277104  3675 solver.cpp:243] Iteration 13280, loss = 0.0047099
I0521 10:17:01.277135  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00470979 (* 1 = 0.00470979 loss)
I0521 10:17:01.277142  3675 sgd_solver.cpp:138] Iteration 13280, lr = 5e-05
I0521 10:17:04.793980  3675 solver.cpp:243] Iteration 13300, loss = 0.00577406
I0521 10:17:04.794011  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00577395 (* 1 = 0.00577395 loss)
I0521 10:17:04.794016  3675 sgd_solver.cpp:138] Iteration 13300, lr = 5e-05
I0521 10:17:08.313412  3675 solver.cpp:243] Iteration 13320, loss = 0.00232315
I0521 10:17:08.313443  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00232304 (* 1 = 0.00232304 loss)
I0521 10:17:08.313448  3675 sgd_solver.cpp:138] Iteration 13320, lr = 5e-05
I0521 10:17:11.829632  3675 solver.cpp:243] Iteration 13340, loss = 0.00454159
I0521 10:17:11.829664  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00454148 (* 1 = 0.00454148 loss)
I0521 10:17:11.829671  3675 sgd_solver.cpp:138] Iteration 13340, lr = 5e-05
I0521 10:17:15.351667  3675 solver.cpp:243] Iteration 13360, loss = 0.00320749
I0521 10:17:15.351701  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00320738 (* 1 = 0.00320738 loss)
I0521 10:17:15.351722  3675 sgd_solver.cpp:138] Iteration 13360, lr = 5e-05
I0521 10:17:18.872071  3675 solver.cpp:243] Iteration 13380, loss = 0.00354437
I0521 10:17:18.872232  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00354426 (* 1 = 0.00354426 loss)
I0521 10:17:18.872239  3675 sgd_solver.cpp:138] Iteration 13380, lr = 5e-05
I0521 10:17:22.390977  3675 solver.cpp:243] Iteration 13400, loss = 0.00276622
I0521 10:17:22.391011  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0027661 (* 1 = 0.0027661 loss)
I0521 10:17:22.391016  3675 sgd_solver.cpp:138] Iteration 13400, lr = 5e-05
I0521 10:17:25.911486  3675 solver.cpp:243] Iteration 13420, loss = 0.0029287
I0521 10:17:25.911517  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00292859 (* 1 = 0.00292859 loss)
I0521 10:17:25.911523  3675 sgd_solver.cpp:138] Iteration 13420, lr = 5e-05
I0521 10:17:29.436305  3675 solver.cpp:243] Iteration 13440, loss = 0.00682663
I0521 10:17:29.436336  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00682652 (* 1 = 0.00682652 loss)
I0521 10:17:29.436342  3675 sgd_solver.cpp:138] Iteration 13440, lr = 5e-05
I0521 10:17:32.959450  3675 solver.cpp:243] Iteration 13460, loss = 0.00402703
I0521 10:17:32.959481  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00402692 (* 1 = 0.00402692 loss)
I0521 10:17:32.959486  3675 sgd_solver.cpp:138] Iteration 13460, lr = 5e-05
I0521 10:17:36.480024  3675 solver.cpp:243] Iteration 13480, loss = 0.00345939
I0521 10:17:36.480056  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00345928 (* 1 = 0.00345928 loss)
I0521 10:17:36.480062  3675 sgd_solver.cpp:138] Iteration 13480, lr = 5e-05
I0521 10:17:39.997229  3675 solver.cpp:243] Iteration 13500, loss = 0.0023422
I0521 10:17:39.997261  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00234209 (* 1 = 0.00234209 loss)
I0521 10:17:39.997267  3675 sgd_solver.cpp:138] Iteration 13500, lr = 5e-05
I0521 10:17:43.520409  3675 solver.cpp:243] Iteration 13520, loss = 0.00279175
I0521 10:17:43.520440  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00279164 (* 1 = 0.00279164 loss)
I0521 10:17:43.520445  3675 sgd_solver.cpp:138] Iteration 13520, lr = 5e-05
I0521 10:17:47.046480  3675 solver.cpp:243] Iteration 13540, loss = 0.00283659
I0521 10:17:47.046510  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00283647 (* 1 = 0.00283647 loss)
I0521 10:17:47.046515  3675 sgd_solver.cpp:138] Iteration 13540, lr = 5e-05
I0521 10:17:50.561825  3675 solver.cpp:243] Iteration 13560, loss = 0.00390165
I0521 10:17:50.561986  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00390154 (* 1 = 0.00390154 loss)
I0521 10:17:50.561993  3675 sgd_solver.cpp:138] Iteration 13560, lr = 5e-05
I0521 10:17:54.078160  3675 solver.cpp:243] Iteration 13580, loss = 0.00395841
I0521 10:17:54.078189  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0039583 (* 1 = 0.0039583 loss)
I0521 10:17:54.078194  3675 sgd_solver.cpp:138] Iteration 13580, lr = 5e-05
I0521 10:17:57.595885  3675 solver.cpp:243] Iteration 13600, loss = 0.00408493
I0521 10:17:57.595916  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00408482 (* 1 = 0.00408482 loss)
I0521 10:17:57.595937  3675 sgd_solver.cpp:138] Iteration 13600, lr = 5e-05
I0521 10:18:01.113500  3675 solver.cpp:243] Iteration 13620, loss = 0.00420122
I0521 10:18:01.113533  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00420111 (* 1 = 0.00420111 loss)
I0521 10:18:01.113538  3675 sgd_solver.cpp:138] Iteration 13620, lr = 5e-05
I0521 10:18:04.631829  3675 solver.cpp:243] Iteration 13640, loss = 0.0045967
I0521 10:18:04.631861  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00459659 (* 1 = 0.00459659 loss)
I0521 10:18:04.631866  3675 sgd_solver.cpp:138] Iteration 13640, lr = 5e-05
I0521 10:18:08.155618  3675 solver.cpp:243] Iteration 13660, loss = 0.00328603
I0521 10:18:08.155647  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00328592 (* 1 = 0.00328592 loss)
I0521 10:18:08.155652  3675 sgd_solver.cpp:138] Iteration 13660, lr = 5e-05
I0521 10:18:11.681903  3675 solver.cpp:243] Iteration 13680, loss = 0.00251612
I0521 10:18:11.681934  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00251601 (* 1 = 0.00251601 loss)
I0521 10:18:11.681941  3675 sgd_solver.cpp:138] Iteration 13680, lr = 5e-05
I0521 10:18:15.202316  3675 solver.cpp:243] Iteration 13700, loss = 0.0027622
I0521 10:18:15.202347  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00276208 (* 1 = 0.00276208 loss)
I0521 10:18:15.202352  3675 sgd_solver.cpp:138] Iteration 13700, lr = 5e-05
I0521 10:18:18.724445  3675 solver.cpp:243] Iteration 13720, loss = 0.00384215
I0521 10:18:18.724475  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00384204 (* 1 = 0.00384204 loss)
I0521 10:18:18.724481  3675 sgd_solver.cpp:138] Iteration 13720, lr = 5e-05
I0521 10:18:22.244117  3675 solver.cpp:243] Iteration 13740, loss = 0.00328524
I0521 10:18:22.244246  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00328513 (* 1 = 0.00328513 loss)
I0521 10:18:22.244251  3675 sgd_solver.cpp:138] Iteration 13740, lr = 5e-05
I0521 10:18:25.761858  3675 solver.cpp:243] Iteration 13760, loss = 0.00336723
I0521 10:18:25.761889  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00336712 (* 1 = 0.00336712 loss)
I0521 10:18:25.761896  3675 sgd_solver.cpp:138] Iteration 13760, lr = 5e-05
I0521 10:18:29.284708  3675 solver.cpp:243] Iteration 13780, loss = 0.00434499
I0521 10:18:29.284741  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00434488 (* 1 = 0.00434488 loss)
I0521 10:18:29.284762  3675 sgd_solver.cpp:138] Iteration 13780, lr = 5e-05
I0521 10:18:32.805294  3675 solver.cpp:243] Iteration 13800, loss = 0.00800827
I0521 10:18:32.805325  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00800816 (* 1 = 0.00800816 loss)
I0521 10:18:32.805330  3675 sgd_solver.cpp:138] Iteration 13800, lr = 5e-05
I0521 10:18:36.323241  3675 solver.cpp:243] Iteration 13820, loss = 0.00614295
I0521 10:18:36.323273  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00614284 (* 1 = 0.00614284 loss)
I0521 10:18:36.323294  3675 sgd_solver.cpp:138] Iteration 13820, lr = 5e-05
I0521 10:18:39.843998  3675 solver.cpp:243] Iteration 13840, loss = 0.00560022
I0521 10:18:39.844030  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00560011 (* 1 = 0.00560011 loss)
I0521 10:18:39.844035  3675 sgd_solver.cpp:138] Iteration 13840, lr = 5e-05
I0521 10:18:43.364367  3675 solver.cpp:243] Iteration 13860, loss = 0.00363466
I0521 10:18:43.364400  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00363455 (* 1 = 0.00363455 loss)
I0521 10:18:43.364408  3675 sgd_solver.cpp:138] Iteration 13860, lr = 5e-05
I0521 10:18:46.883237  3675 solver.cpp:243] Iteration 13880, loss = 0.00334412
I0521 10:18:46.883270  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00334401 (* 1 = 0.00334401 loss)
I0521 10:18:46.883275  3675 sgd_solver.cpp:138] Iteration 13880, lr = 5e-05
I0521 10:18:50.407001  3675 solver.cpp:243] Iteration 13900, loss = 0.00249244
I0521 10:18:50.407032  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00249233 (* 1 = 0.00249233 loss)
I0521 10:18:50.407037  3675 sgd_solver.cpp:138] Iteration 13900, lr = 5e-05
I0521 10:18:53.931116  3675 solver.cpp:243] Iteration 13920, loss = 0.0047875
I0521 10:18:53.931308  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00478739 (* 1 = 0.00478739 loss)
I0521 10:18:53.931315  3675 sgd_solver.cpp:138] Iteration 13920, lr = 5e-05
I0521 10:18:57.452262  3675 solver.cpp:243] Iteration 13940, loss = 0.00406844
I0521 10:18:57.452293  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00406833 (* 1 = 0.00406833 loss)
I0521 10:18:57.452298  3675 sgd_solver.cpp:138] Iteration 13940, lr = 5e-05
I0521 10:19:00.968071  3675 solver.cpp:243] Iteration 13960, loss = 0.00482157
I0521 10:19:00.968101  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00482145 (* 1 = 0.00482145 loss)
I0521 10:19:00.968107  3675 sgd_solver.cpp:138] Iteration 13960, lr = 5e-05
I0521 10:19:04.485086  3675 solver.cpp:243] Iteration 13980, loss = 0.00482411
I0521 10:19:04.485117  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.004824 (* 1 = 0.004824 loss)
I0521 10:19:04.485122  3675 sgd_solver.cpp:138] Iteration 13980, lr = 5e-05
I0521 10:19:07.873358  3675 solver.cpp:596] Snapshotting to binary proto file models/LPR/lpr_resnet_lstm_iter_14000.caffemodel
I0521 10:19:07.902334  3675 sgd_solver.cpp:307] Snapshotting solver state to binary proto file models/LPR/lpr_resnet_lstm_iter_14000.solverstate
I0521 10:19:07.918570  3675 solver.cpp:358] Iteration 14000, Testing net (#0)
I0521 10:19:12.654353  3675 solver.cpp:425]     Test net output #0: acc = 1
I0521 10:19:12.654382  3675 solver.cpp:425]     Test net output #1: acc = 1
I0521 10:19:12.654389  3675 solver.cpp:425]     Test net output #2: ctcloss = 0.00117987 (* 1 = 0.00117987 loss)
I0521 10:19:12.790021  3675 solver.cpp:243] Iteration 14000, loss = 0.00342178
I0521 10:19:12.790052  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00342167 (* 1 = 0.00342167 loss)
I0521 10:19:12.790058  3675 sgd_solver.cpp:138] Iteration 14000, lr = 5e-05
I0521 10:19:16.312885  3675 solver.cpp:243] Iteration 14020, loss = 0.00372468
I0521 10:19:16.312916  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00372456 (* 1 = 0.00372456 loss)
I0521 10:19:16.312921  3675 sgd_solver.cpp:138] Iteration 14020, lr = 5e-05
I0521 10:19:19.831532  3675 solver.cpp:243] Iteration 14040, loss = 0.00436932
I0521 10:19:19.831562  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00436921 (* 1 = 0.00436921 loss)
I0521 10:19:19.831566  3675 sgd_solver.cpp:138] Iteration 14040, lr = 5e-05
I0521 10:19:23.352000  3675 solver.cpp:243] Iteration 14060, loss = 0.00347886
I0521 10:19:23.352030  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00347875 (* 1 = 0.00347875 loss)
I0521 10:19:23.352051  3675 sgd_solver.cpp:138] Iteration 14060, lr = 5e-05
I0521 10:19:26.873759  3675 solver.cpp:243] Iteration 14080, loss = 0.00279385
I0521 10:19:26.873916  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00279373 (* 1 = 0.00279373 loss)
I0521 10:19:26.873924  3675 sgd_solver.cpp:138] Iteration 14080, lr = 5e-05
I0521 10:19:30.392694  3675 solver.cpp:243] Iteration 14100, loss = 0.00386932
I0521 10:19:30.392726  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00386921 (* 1 = 0.00386921 loss)
I0521 10:19:30.392732  3675 sgd_solver.cpp:138] Iteration 14100, lr = 5e-05
I0521 10:19:33.915694  3675 solver.cpp:243] Iteration 14120, loss = 0.00404025
I0521 10:19:33.915724  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00404014 (* 1 = 0.00404014 loss)
I0521 10:19:33.915730  3675 sgd_solver.cpp:138] Iteration 14120, lr = 5e-05
I0521 10:19:37.432929  3675 solver.cpp:243] Iteration 14140, loss = 0.00386625
I0521 10:19:37.432960  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00386614 (* 1 = 0.00386614 loss)
I0521 10:19:37.432966  3675 sgd_solver.cpp:138] Iteration 14140, lr = 5e-05
I0521 10:19:40.952931  3675 solver.cpp:243] Iteration 14160, loss = 0.00384675
I0521 10:19:40.952961  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00384664 (* 1 = 0.00384664 loss)
I0521 10:19:40.952966  3675 sgd_solver.cpp:138] Iteration 14160, lr = 5e-05
I0521 10:19:44.469925  3675 solver.cpp:243] Iteration 14180, loss = 0.0039202
I0521 10:19:44.469956  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00392009 (* 1 = 0.00392009 loss)
I0521 10:19:44.469962  3675 sgd_solver.cpp:138] Iteration 14180, lr = 5e-05
I0521 10:19:47.986085  3675 solver.cpp:243] Iteration 14200, loss = 0.00297158
I0521 10:19:47.986116  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00297147 (* 1 = 0.00297147 loss)
I0521 10:19:47.986122  3675 sgd_solver.cpp:138] Iteration 14200, lr = 5e-05
I0521 10:19:51.508023  3675 solver.cpp:243] Iteration 14220, loss = 0.0041587
I0521 10:19:51.508054  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00415859 (* 1 = 0.00415859 loss)
I0521 10:19:51.508059  3675 sgd_solver.cpp:138] Iteration 14220, lr = 5e-05
I0521 10:19:55.026546  3675 solver.cpp:243] Iteration 14240, loss = 0.00303423
I0521 10:19:55.026578  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00303412 (* 1 = 0.00303412 loss)
I0521 10:19:55.026584  3675 sgd_solver.cpp:138] Iteration 14240, lr = 5e-05
I0521 10:19:58.548074  3675 solver.cpp:243] Iteration 14260, loss = 0.00376579
I0521 10:19:58.548204  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00376568 (* 1 = 0.00376568 loss)
I0521 10:19:58.548211  3675 sgd_solver.cpp:138] Iteration 14260, lr = 5e-05
I0521 10:20:02.064786  3675 solver.cpp:243] Iteration 14280, loss = 0.00293019
I0521 10:20:02.064817  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00293008 (* 1 = 0.00293008 loss)
I0521 10:20:02.064823  3675 sgd_solver.cpp:138] Iteration 14280, lr = 5e-05
I0521 10:20:05.585387  3675 solver.cpp:243] Iteration 14300, loss = 0.00361037
I0521 10:20:05.585418  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00361026 (* 1 = 0.00361026 loss)
I0521 10:20:05.585439  3675 sgd_solver.cpp:138] Iteration 14300, lr = 5e-05
I0521 10:20:09.108000  3675 solver.cpp:243] Iteration 14320, loss = 0.00436651
I0521 10:20:09.108031  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00436639 (* 1 = 0.00436639 loss)
I0521 10:20:09.108037  3675 sgd_solver.cpp:138] Iteration 14320, lr = 5e-05
I0521 10:20:12.623761  3675 solver.cpp:243] Iteration 14340, loss = 0.00312749
I0521 10:20:12.623818  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00312738 (* 1 = 0.00312738 loss)
I0521 10:20:12.623827  3675 sgd_solver.cpp:138] Iteration 14340, lr = 5e-05
I0521 10:20:16.140481  3675 solver.cpp:243] Iteration 14360, loss = 0.00433244
I0521 10:20:16.140511  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00433233 (* 1 = 0.00433233 loss)
I0521 10:20:16.140517  3675 sgd_solver.cpp:138] Iteration 14360, lr = 5e-05
I0521 10:20:19.597627  3675 solver.cpp:243] Iteration 14380, loss = 0.00377106
I0521 10:20:19.597658  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00377095 (* 1 = 0.00377095 loss)
I0521 10:20:19.597664  3675 sgd_solver.cpp:138] Iteration 14380, lr = 5e-05
I0521 10:20:23.114609  3675 solver.cpp:243] Iteration 14400, loss = 0.00390018
I0521 10:20:23.114639  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00390006 (* 1 = 0.00390006 loss)
I0521 10:20:23.114660  3675 sgd_solver.cpp:138] Iteration 14400, lr = 5e-05
I0521 10:20:26.628881  3675 solver.cpp:243] Iteration 14420, loss = 0.0024299
I0521 10:20:26.628914  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00242978 (* 1 = 0.00242978 loss)
I0521 10:20:26.628935  3675 sgd_solver.cpp:138] Iteration 14420, lr = 5e-05
I0521 10:20:30.146632  3675 solver.cpp:243] Iteration 14440, loss = 0.00245112
I0521 10:20:30.146806  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00245101 (* 1 = 0.00245101 loss)
I0521 10:20:30.146814  3675 sgd_solver.cpp:138] Iteration 14440, lr = 5e-05
I0521 10:20:33.669483  3675 solver.cpp:243] Iteration 14460, loss = 0.00299609
I0521 10:20:33.669515  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00299598 (* 1 = 0.00299598 loss)
I0521 10:20:33.669523  3675 sgd_solver.cpp:138] Iteration 14460, lr = 5e-05
I0521 10:20:37.187561  3675 solver.cpp:243] Iteration 14480, loss = 0.00397321
I0521 10:20:37.187592  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00397309 (* 1 = 0.00397309 loss)
I0521 10:20:37.187597  3675 sgd_solver.cpp:138] Iteration 14480, lr = 5e-05
I0521 10:20:40.706775  3675 solver.cpp:243] Iteration 14500, loss = 0.00275993
I0521 10:20:40.706807  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00275982 (* 1 = 0.00275982 loss)
I0521 10:20:40.706812  3675 sgd_solver.cpp:138] Iteration 14500, lr = 5e-05
I0521 10:20:44.220150  3675 solver.cpp:243] Iteration 14520, loss = 0.00350131
I0521 10:20:44.220182  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0035012 (* 1 = 0.0035012 loss)
I0521 10:20:44.220187  3675 sgd_solver.cpp:138] Iteration 14520, lr = 5e-05
I0521 10:20:47.734495  3675 solver.cpp:243] Iteration 14540, loss = 0.00357683
I0521 10:20:47.734525  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00357671 (* 1 = 0.00357671 loss)
I0521 10:20:47.734547  3675 sgd_solver.cpp:138] Iteration 14540, lr = 5e-05
I0521 10:20:51.251121  3675 solver.cpp:243] Iteration 14560, loss = 0.00465116
I0521 10:20:51.251152  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00465105 (* 1 = 0.00465105 loss)
I0521 10:20:51.251173  3675 sgd_solver.cpp:138] Iteration 14560, lr = 5e-05
I0521 10:20:54.768988  3675 solver.cpp:243] Iteration 14580, loss = 0.00295832
I0521 10:20:54.769019  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0029582 (* 1 = 0.0029582 loss)
I0521 10:20:54.769040  3675 sgd_solver.cpp:138] Iteration 14580, lr = 5e-05
I0521 10:20:58.290751  3675 solver.cpp:243] Iteration 14600, loss = 0.00323785
I0521 10:20:58.290783  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00323774 (* 1 = 0.00323774 loss)
I0521 10:20:58.290789  3675 sgd_solver.cpp:138] Iteration 14600, lr = 5e-05
I0521 10:21:01.816992  3675 solver.cpp:243] Iteration 14620, loss = 0.00284528
I0521 10:21:01.817080  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00284517 (* 1 = 0.00284517 loss)
I0521 10:21:01.817087  3675 sgd_solver.cpp:138] Iteration 14620, lr = 5e-05
I0521 10:21:05.342912  3675 solver.cpp:243] Iteration 14640, loss = 0.00340502
I0521 10:21:05.342944  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00340491 (* 1 = 0.00340491 loss)
I0521 10:21:05.342949  3675 sgd_solver.cpp:138] Iteration 14640, lr = 5e-05
I0521 10:21:08.863694  3675 solver.cpp:243] Iteration 14660, loss = 0.00292406
I0521 10:21:08.863724  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00292395 (* 1 = 0.00292395 loss)
I0521 10:21:08.863729  3675 sgd_solver.cpp:138] Iteration 14660, lr = 5e-05
I0521 10:21:12.388381  3675 solver.cpp:243] Iteration 14680, loss = 0.00326584
I0521 10:21:12.388411  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00326573 (* 1 = 0.00326573 loss)
I0521 10:21:12.388415  3675 sgd_solver.cpp:138] Iteration 14680, lr = 5e-05
I0521 10:21:15.903410  3675 solver.cpp:243] Iteration 14700, loss = 0.00285881
I0521 10:21:15.903442  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0028587 (* 1 = 0.0028587 loss)
I0521 10:21:15.903447  3675 sgd_solver.cpp:138] Iteration 14700, lr = 5e-05
I0521 10:21:19.422099  3675 solver.cpp:243] Iteration 14720, loss = 0.00258759
I0521 10:21:19.422130  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00258747 (* 1 = 0.00258747 loss)
I0521 10:21:19.422135  3675 sgd_solver.cpp:138] Iteration 14720, lr = 5e-05
I0521 10:21:22.940037  3675 solver.cpp:243] Iteration 14740, loss = 0.00260154
I0521 10:21:22.940070  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00260142 (* 1 = 0.00260142 loss)
I0521 10:21:22.940075  3675 sgd_solver.cpp:138] Iteration 14740, lr = 5e-05
I0521 10:21:26.457036  3675 solver.cpp:243] Iteration 14760, loss = 0.00349935
I0521 10:21:26.457065  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00349923 (* 1 = 0.00349923 loss)
I0521 10:21:26.457087  3675 sgd_solver.cpp:138] Iteration 14760, lr = 5e-05
I0521 10:21:29.980352  3675 solver.cpp:243] Iteration 14780, loss = 0.00351989
I0521 10:21:29.980386  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00351978 (* 1 = 0.00351978 loss)
I0521 10:21:29.980406  3675 sgd_solver.cpp:138] Iteration 14780, lr = 5e-05
I0521 10:21:33.500470  3675 solver.cpp:243] Iteration 14800, loss = 0.00555301
I0521 10:21:33.500635  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0055529 (* 1 = 0.0055529 loss)
I0521 10:21:33.500643  3675 sgd_solver.cpp:138] Iteration 14800, lr = 5e-05
I0521 10:21:37.016088  3675 solver.cpp:243] Iteration 14820, loss = 0.00495283
I0521 10:21:37.016120  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00495271 (* 1 = 0.00495271 loss)
I0521 10:21:37.016125  3675 sgd_solver.cpp:138] Iteration 14820, lr = 5e-05
I0521 10:21:40.537180  3675 solver.cpp:243] Iteration 14840, loss = 0.00264861
I0521 10:21:40.537211  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0026485 (* 1 = 0.0026485 loss)
I0521 10:21:40.537216  3675 sgd_solver.cpp:138] Iteration 14840, lr = 5e-05
I0521 10:21:44.059273  3675 solver.cpp:243] Iteration 14860, loss = 0.00561542
I0521 10:21:44.059303  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00561531 (* 1 = 0.00561531 loss)
I0521 10:21:44.059322  3675 sgd_solver.cpp:138] Iteration 14860, lr = 5e-05
I0521 10:21:47.578958  3675 solver.cpp:243] Iteration 14880, loss = 0.00361537
I0521 10:21:47.578991  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00361526 (* 1 = 0.00361526 loss)
I0521 10:21:47.579012  3675 sgd_solver.cpp:138] Iteration 14880, lr = 5e-05
I0521 10:21:51.098242  3675 solver.cpp:243] Iteration 14900, loss = 0.00271295
I0521 10:21:51.098273  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00271284 (* 1 = 0.00271284 loss)
I0521 10:21:51.098278  3675 sgd_solver.cpp:138] Iteration 14900, lr = 5e-05
I0521 10:21:54.615774  3675 solver.cpp:243] Iteration 14920, loss = 0.0035425
I0521 10:21:54.615805  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00354239 (* 1 = 0.00354239 loss)
I0521 10:21:54.615811  3675 sgd_solver.cpp:138] Iteration 14920, lr = 5e-05
I0521 10:21:58.137080  3675 solver.cpp:243] Iteration 14940, loss = 0.00427191
I0521 10:21:58.137111  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0042718 (* 1 = 0.0042718 loss)
I0521 10:21:58.137117  3675 sgd_solver.cpp:138] Iteration 14940, lr = 5e-05
I0521 10:22:01.654844  3675 solver.cpp:243] Iteration 14960, loss = 0.0024284
I0521 10:22:01.654875  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00242828 (* 1 = 0.00242828 loss)
I0521 10:22:01.654881  3675 sgd_solver.cpp:138] Iteration 14960, lr = 5e-05
I0521 10:22:05.169286  3675 solver.cpp:243] Iteration 14980, loss = 0.00323193
I0521 10:22:05.169411  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00323181 (* 1 = 0.00323181 loss)
I0521 10:22:05.169420  3675 sgd_solver.cpp:138] Iteration 14980, lr = 5e-05
I0521 10:22:08.556987  3675 solver.cpp:358] Iteration 15000, Testing net (#0)
I0521 10:22:13.292363  3675 solver.cpp:425]     Test net output #0: acc = 1
I0521 10:22:13.292389  3675 solver.cpp:425]     Test net output #1: acc = 1
I0521 10:22:13.292397  3675 solver.cpp:425]     Test net output #2: ctcloss = 0.00114113 (* 1 = 0.00114113 loss)
I0521 10:22:13.427817  3675 solver.cpp:243] Iteration 15000, loss = 0.00299713
I0521 10:22:13.427846  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00299702 (* 1 = 0.00299702 loss)
I0521 10:22:13.427868  3675 sgd_solver.cpp:138] Iteration 15000, lr = 5e-05
I0521 10:22:16.949971  3675 solver.cpp:243] Iteration 15020, loss = 0.00521585
I0521 10:22:16.950001  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00521573 (* 1 = 0.00521573 loss)
I0521 10:22:16.950007  3675 sgd_solver.cpp:138] Iteration 15020, lr = 5e-05
I0521 10:22:20.478616  3675 solver.cpp:243] Iteration 15040, loss = 0.0145095
I0521 10:22:20.478646  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0145094 (* 1 = 0.0145094 loss)
I0521 10:22:20.478668  3675 sgd_solver.cpp:138] Iteration 15040, lr = 5e-05
I0521 10:22:23.999709  3675 solver.cpp:243] Iteration 15060, loss = 0.00493977
I0521 10:22:23.999742  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00493966 (* 1 = 0.00493966 loss)
I0521 10:22:23.999747  3675 sgd_solver.cpp:138] Iteration 15060, lr = 5e-05
I0521 10:22:27.516440  3675 solver.cpp:243] Iteration 15080, loss = 0.0127009
I0521 10:22:27.516470  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0127008 (* 1 = 0.0127008 loss)
I0521 10:22:27.516475  3675 sgd_solver.cpp:138] Iteration 15080, lr = 5e-05
I0521 10:22:31.040904  3675 solver.cpp:243] Iteration 15100, loss = 0.00323321
I0521 10:22:31.040938  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0032331 (* 1 = 0.0032331 loss)
I0521 10:22:31.040961  3675 sgd_solver.cpp:138] Iteration 15100, lr = 5e-05
I0521 10:22:34.572726  3675 solver.cpp:243] Iteration 15120, loss = 0.00249378
I0521 10:22:34.572757  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00249366 (* 1 = 0.00249366 loss)
I0521 10:22:34.572762  3675 sgd_solver.cpp:138] Iteration 15120, lr = 5e-05
I0521 10:22:38.094096  3675 solver.cpp:243] Iteration 15140, loss = 0.00384852
I0521 10:22:38.094259  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0038484 (* 1 = 0.0038484 loss)
I0521 10:22:38.094266  3675 sgd_solver.cpp:138] Iteration 15140, lr = 5e-05
I0521 10:22:41.618808  3675 solver.cpp:243] Iteration 15160, loss = 0.00435783
I0521 10:22:41.618839  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00435772 (* 1 = 0.00435772 loss)
I0521 10:22:41.618845  3675 sgd_solver.cpp:138] Iteration 15160, lr = 5e-05
I0521 10:22:45.139456  3675 solver.cpp:243] Iteration 15180, loss = 0.00299485
I0521 10:22:45.139487  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00299473 (* 1 = 0.00299473 loss)
I0521 10:22:45.139492  3675 sgd_solver.cpp:138] Iteration 15180, lr = 5e-05
I0521 10:22:48.662784  3675 solver.cpp:243] Iteration 15200, loss = 0.00441718
I0521 10:22:48.662816  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00441707 (* 1 = 0.00441707 loss)
I0521 10:22:48.662822  3675 sgd_solver.cpp:138] Iteration 15200, lr = 5e-05
I0521 10:22:52.186085  3675 solver.cpp:243] Iteration 15220, loss = 0.0037744
I0521 10:22:52.186117  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00377429 (* 1 = 0.00377429 loss)
I0521 10:22:52.186125  3675 sgd_solver.cpp:138] Iteration 15220, lr = 5e-05
I0521 10:22:55.706218  3675 solver.cpp:243] Iteration 15240, loss = 0.0034753
I0521 10:22:55.706250  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00347518 (* 1 = 0.00347518 loss)
I0521 10:22:55.706256  3675 sgd_solver.cpp:138] Iteration 15240, lr = 5e-05
I0521 10:22:59.230517  3675 solver.cpp:243] Iteration 15260, loss = 0.00370404
I0521 10:22:59.230549  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00370393 (* 1 = 0.00370393 loss)
I0521 10:22:59.230554  3675 sgd_solver.cpp:138] Iteration 15260, lr = 5e-05
I0521 10:23:02.752153  3675 solver.cpp:243] Iteration 15280, loss = 0.00364855
I0521 10:23:02.752185  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00364843 (* 1 = 0.00364843 loss)
I0521 10:23:02.752207  3675 sgd_solver.cpp:138] Iteration 15280, lr = 5e-05
I0521 10:23:06.273089  3675 solver.cpp:243] Iteration 15300, loss = 0.00301906
I0521 10:23:06.273121  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00301895 (* 1 = 0.00301895 loss)
I0521 10:23:06.273128  3675 sgd_solver.cpp:138] Iteration 15300, lr = 5e-05
I0521 10:23:09.793177  3675 solver.cpp:243] Iteration 15320, loss = 0.00306901
I0521 10:23:09.793341  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0030689 (* 1 = 0.0030689 loss)
I0521 10:23:09.793349  3675 sgd_solver.cpp:138] Iteration 15320, lr = 5e-05
I0521 10:23:13.313472  3675 solver.cpp:243] Iteration 15340, loss = 0.00384696
I0521 10:23:13.313503  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00384684 (* 1 = 0.00384684 loss)
I0521 10:23:13.313509  3675 sgd_solver.cpp:138] Iteration 15340, lr = 5e-05
I0521 10:23:16.831626  3675 solver.cpp:243] Iteration 15360, loss = 0.00288371
I0521 10:23:16.831657  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00288359 (* 1 = 0.00288359 loss)
I0521 10:23:16.831663  3675 sgd_solver.cpp:138] Iteration 15360, lr = 5e-05
I0521 10:23:20.351068  3675 solver.cpp:243] Iteration 15380, loss = 0.00313988
I0521 10:23:20.351101  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00313977 (* 1 = 0.00313977 loss)
I0521 10:23:20.351106  3675 sgd_solver.cpp:138] Iteration 15380, lr = 5e-05
I0521 10:23:23.874737  3675 solver.cpp:243] Iteration 15400, loss = 0.00407935
I0521 10:23:23.874769  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00407923 (* 1 = 0.00407923 loss)
I0521 10:23:23.874774  3675 sgd_solver.cpp:138] Iteration 15400, lr = 5e-05
I0521 10:23:27.400159  3675 solver.cpp:243] Iteration 15420, loss = 0.00334543
I0521 10:23:27.400190  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00334531 (* 1 = 0.00334531 loss)
I0521 10:23:27.400197  3675 sgd_solver.cpp:138] Iteration 15420, lr = 5e-05
I0521 10:23:30.920750  3675 solver.cpp:243] Iteration 15440, loss = 0.00254099
I0521 10:23:30.920784  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00254087 (* 1 = 0.00254087 loss)
I0521 10:23:30.920790  3675 sgd_solver.cpp:138] Iteration 15440, lr = 5e-05
I0521 10:23:34.452296  3675 solver.cpp:243] Iteration 15460, loss = 0.00340628
I0521 10:23:34.452328  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00340617 (* 1 = 0.00340617 loss)
I0521 10:23:34.452334  3675 sgd_solver.cpp:138] Iteration 15460, lr = 5e-05
I0521 10:23:37.979763  3675 solver.cpp:243] Iteration 15480, loss = 0.00299796
I0521 10:23:37.979794  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00299784 (* 1 = 0.00299784 loss)
I0521 10:23:37.979799  3675 sgd_solver.cpp:138] Iteration 15480, lr = 5e-05
I0521 10:23:41.503724  3675 solver.cpp:243] Iteration 15500, loss = 0.00327762
I0521 10:23:41.503881  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0032775 (* 1 = 0.0032775 loss)
I0521 10:23:41.503887  3675 sgd_solver.cpp:138] Iteration 15500, lr = 5e-05
I0521 10:23:45.026386  3675 solver.cpp:243] Iteration 15520, loss = 0.00354372
I0521 10:23:45.026417  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00354361 (* 1 = 0.00354361 loss)
I0521 10:23:45.026422  3675 sgd_solver.cpp:138] Iteration 15520, lr = 5e-05
I0521 10:23:48.548338  3675 solver.cpp:243] Iteration 15540, loss = 0.00295737
I0521 10:23:48.548369  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00295725 (* 1 = 0.00295725 loss)
I0521 10:23:48.548375  3675 sgd_solver.cpp:138] Iteration 15540, lr = 5e-05
I0521 10:23:52.069130  3675 solver.cpp:243] Iteration 15560, loss = 0.00254653
I0521 10:23:52.069161  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00254641 (* 1 = 0.00254641 loss)
I0521 10:23:52.069166  3675 sgd_solver.cpp:138] Iteration 15560, lr = 5e-05
I0521 10:23:55.595271  3675 solver.cpp:243] Iteration 15580, loss = 0.00362176
I0521 10:23:55.595304  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00362165 (* 1 = 0.00362165 loss)
I0521 10:23:55.595309  3675 sgd_solver.cpp:138] Iteration 15580, lr = 5e-05
I0521 10:23:59.118495  3675 solver.cpp:243] Iteration 15600, loss = 0.00455303
I0521 10:23:59.118526  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00455291 (* 1 = 0.00455291 loss)
I0521 10:23:59.118532  3675 sgd_solver.cpp:138] Iteration 15600, lr = 5e-05
I0521 10:24:02.645140  3675 solver.cpp:243] Iteration 15620, loss = 0.00265583
I0521 10:24:02.645174  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00265572 (* 1 = 0.00265572 loss)
I0521 10:24:02.645179  3675 sgd_solver.cpp:138] Iteration 15620, lr = 5e-05
I0521 10:24:06.170248  3675 solver.cpp:243] Iteration 15640, loss = 0.00449066
I0521 10:24:06.170279  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00449054 (* 1 = 0.00449054 loss)
I0521 10:24:06.170285  3675 sgd_solver.cpp:138] Iteration 15640, lr = 5e-05
I0521 10:24:09.692272  3675 solver.cpp:243] Iteration 15660, loss = 0.00266717
I0521 10:24:09.692306  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00266706 (* 1 = 0.00266706 loss)
I0521 10:24:09.692327  3675 sgd_solver.cpp:138] Iteration 15660, lr = 5e-05
I0521 10:24:13.142407  3675 solver.cpp:243] Iteration 15680, loss = 0.00399379
I0521 10:24:13.142524  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00399368 (* 1 = 0.00399368 loss)
I0521 10:24:13.142532  3675 sgd_solver.cpp:138] Iteration 15680, lr = 5e-05
I0521 10:24:16.664300  3675 solver.cpp:243] Iteration 15700, loss = 0.00535457
I0521 10:24:16.664331  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00535445 (* 1 = 0.00535445 loss)
I0521 10:24:16.664336  3675 sgd_solver.cpp:138] Iteration 15700, lr = 5e-05
I0521 10:24:20.181591  3675 solver.cpp:243] Iteration 15720, loss = 0.00421388
I0521 10:24:20.181622  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00421377 (* 1 = 0.00421377 loss)
I0521 10:24:20.181643  3675 sgd_solver.cpp:138] Iteration 15720, lr = 5e-05
I0521 10:24:23.705015  3675 solver.cpp:243] Iteration 15740, loss = 0.00357645
I0521 10:24:23.705049  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00357633 (* 1 = 0.00357633 loss)
I0521 10:24:23.705054  3675 sgd_solver.cpp:138] Iteration 15740, lr = 5e-05
I0521 10:24:27.220829  3675 solver.cpp:243] Iteration 15760, loss = 0.00216488
I0521 10:24:27.220861  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00216477 (* 1 = 0.00216477 loss)
I0521 10:24:27.220867  3675 sgd_solver.cpp:138] Iteration 15760, lr = 5e-05
I0521 10:24:30.743394  3675 solver.cpp:243] Iteration 15780, loss = 0.00291872
I0521 10:24:30.743424  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00291861 (* 1 = 0.00291861 loss)
I0521 10:24:30.743430  3675 sgd_solver.cpp:138] Iteration 15780, lr = 5e-05
I0521 10:24:34.270051  3675 solver.cpp:243] Iteration 15800, loss = 0.00270376
I0521 10:24:34.270082  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00270364 (* 1 = 0.00270364 loss)
I0521 10:24:34.270087  3675 sgd_solver.cpp:138] Iteration 15800, lr = 5e-05
I0521 10:24:37.797574  3675 solver.cpp:243] Iteration 15820, loss = 0.00352737
I0521 10:24:37.797606  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00352726 (* 1 = 0.00352726 loss)
I0521 10:24:37.797611  3675 sgd_solver.cpp:138] Iteration 15820, lr = 5e-05
I0521 10:24:41.318584  3675 solver.cpp:243] Iteration 15840, loss = 0.00435496
I0521 10:24:41.318615  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00435485 (* 1 = 0.00435485 loss)
I0521 10:24:41.318620  3675 sgd_solver.cpp:138] Iteration 15840, lr = 5e-05
I0521 10:24:44.840178  3675 solver.cpp:243] Iteration 15860, loss = 0.00383784
I0521 10:24:44.840338  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00383772 (* 1 = 0.00383772 loss)
I0521 10:24:44.840348  3675 sgd_solver.cpp:138] Iteration 15860, lr = 5e-05
I0521 10:24:48.361881  3675 solver.cpp:243] Iteration 15880, loss = 0.00243439
I0521 10:24:48.361912  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00243428 (* 1 = 0.00243428 loss)
I0521 10:24:48.361917  3675 sgd_solver.cpp:138] Iteration 15880, lr = 5e-05
I0521 10:24:51.881507  3675 solver.cpp:243] Iteration 15900, loss = 0.00249265
I0521 10:24:51.881539  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00249254 (* 1 = 0.00249254 loss)
I0521 10:24:51.881547  3675 sgd_solver.cpp:138] Iteration 15900, lr = 5e-05
I0521 10:24:55.401494  3675 solver.cpp:243] Iteration 15920, loss = 0.00428609
I0521 10:24:55.401525  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00428597 (* 1 = 0.00428597 loss)
I0521 10:24:55.401530  3675 sgd_solver.cpp:138] Iteration 15920, lr = 5e-05
I0521 10:24:58.922319  3675 solver.cpp:243] Iteration 15940, loss = 0.00575914
I0521 10:24:58.922350  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00575903 (* 1 = 0.00575903 loss)
I0521 10:24:58.922356  3675 sgd_solver.cpp:138] Iteration 15940, lr = 5e-05
I0521 10:25:02.443511  3675 solver.cpp:243] Iteration 15960, loss = 0.00223699
I0521 10:25:02.443542  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00223688 (* 1 = 0.00223688 loss)
I0521 10:25:02.443548  3675 sgd_solver.cpp:138] Iteration 15960, lr = 5e-05
I0521 10:25:05.964680  3675 solver.cpp:243] Iteration 15980, loss = 0.00293187
I0521 10:25:05.964712  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00293175 (* 1 = 0.00293175 loss)
I0521 10:25:05.964718  3675 sgd_solver.cpp:138] Iteration 15980, lr = 5e-05
I0521 10:25:09.349999  3675 solver.cpp:596] Snapshotting to binary proto file models/LPR/lpr_resnet_lstm_iter_16000.caffemodel
I0521 10:25:09.379261  3675 sgd_solver.cpp:307] Snapshotting solver state to binary proto file models/LPR/lpr_resnet_lstm_iter_16000.solverstate
I0521 10:25:09.395385  3675 solver.cpp:358] Iteration 16000, Testing net (#0)
I0521 10:25:14.129001  3675 solver.cpp:425]     Test net output #0: acc = 1
I0521 10:25:14.129029  3675 solver.cpp:425]     Test net output #1: acc = 1
I0521 10:25:14.129035  3675 solver.cpp:425]     Test net output #2: ctcloss = 0.00106286 (* 1 = 0.00106286 loss)
I0521 10:25:14.264022  3675 solver.cpp:243] Iteration 16000, loss = 0.00307254
I0521 10:25:14.264052  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00307243 (* 1 = 0.00307243 loss)
I0521 10:25:14.264060  3675 sgd_solver.cpp:138] Iteration 16000, lr = 5e-05
I0521 10:25:17.787315  3675 solver.cpp:243] Iteration 16020, loss = 0.00714884
I0521 10:25:17.787480  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00714873 (* 1 = 0.00714873 loss)
I0521 10:25:17.787487  3675 sgd_solver.cpp:138] Iteration 16020, lr = 5e-05
I0521 10:25:21.304759  3675 solver.cpp:243] Iteration 16040, loss = 0.00352178
I0521 10:25:21.304792  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00352167 (* 1 = 0.00352167 loss)
I0521 10:25:21.304798  3675 sgd_solver.cpp:138] Iteration 16040, lr = 5e-05
I0521 10:25:24.825265  3675 solver.cpp:243] Iteration 16060, loss = 0.00324401
I0521 10:25:24.825296  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00324389 (* 1 = 0.00324389 loss)
I0521 10:25:24.825304  3675 sgd_solver.cpp:138] Iteration 16060, lr = 5e-05
I0521 10:25:28.345329  3675 solver.cpp:243] Iteration 16080, loss = 0.00371595
I0521 10:25:28.345360  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00371583 (* 1 = 0.00371583 loss)
I0521 10:25:28.345381  3675 sgd_solver.cpp:138] Iteration 16080, lr = 5e-05
I0521 10:25:31.867301  3675 solver.cpp:243] Iteration 16100, loss = 0.0033665
I0521 10:25:31.867334  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00336639 (* 1 = 0.00336639 loss)
I0521 10:25:31.867341  3675 sgd_solver.cpp:138] Iteration 16100, lr = 5e-05
I0521 10:25:35.389112  3675 solver.cpp:243] Iteration 16120, loss = 0.00235725
I0521 10:25:35.389142  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00235714 (* 1 = 0.00235714 loss)
I0521 10:25:35.389148  3675 sgd_solver.cpp:138] Iteration 16120, lr = 5e-05
I0521 10:25:38.908298  3675 solver.cpp:243] Iteration 16140, loss = 0.00323897
I0521 10:25:38.908327  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00323886 (* 1 = 0.00323886 loss)
I0521 10:25:38.908334  3675 sgd_solver.cpp:138] Iteration 16140, lr = 5e-05
I0521 10:25:42.430014  3675 solver.cpp:243] Iteration 16160, loss = 0.00254164
I0521 10:25:42.430043  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00254153 (* 1 = 0.00254153 loss)
I0521 10:25:42.430048  3675 sgd_solver.cpp:138] Iteration 16160, lr = 5e-05
I0521 10:25:45.962116  3675 solver.cpp:243] Iteration 16180, loss = 0.00278403
I0521 10:25:45.962147  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00278392 (* 1 = 0.00278392 loss)
I0521 10:25:45.962168  3675 sgd_solver.cpp:138] Iteration 16180, lr = 5e-05
I0521 10:25:49.487056  3675 solver.cpp:243] Iteration 16200, loss = 0.00250652
I0521 10:25:49.487236  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00250641 (* 1 = 0.00250641 loss)
I0521 10:25:49.487243  3675 sgd_solver.cpp:138] Iteration 16200, lr = 5e-05
I0521 10:25:53.012184  3675 solver.cpp:243] Iteration 16220, loss = 0.00399505
I0521 10:25:53.012214  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00399493 (* 1 = 0.00399493 loss)
I0521 10:25:53.012219  3675 sgd_solver.cpp:138] Iteration 16220, lr = 5e-05
I0521 10:25:56.533054  3675 solver.cpp:243] Iteration 16240, loss = 0.00460169
I0521 10:25:56.533084  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00460158 (* 1 = 0.00460158 loss)
I0521 10:25:56.533090  3675 sgd_solver.cpp:138] Iteration 16240, lr = 5e-05
I0521 10:26:00.057317  3675 solver.cpp:243] Iteration 16260, loss = 0.00283025
I0521 10:26:00.057348  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00283014 (* 1 = 0.00283014 loss)
I0521 10:26:00.057355  3675 sgd_solver.cpp:138] Iteration 16260, lr = 5e-05
I0521 10:26:03.581588  3675 solver.cpp:243] Iteration 16280, loss = 0.00225949
I0521 10:26:03.581619  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00225938 (* 1 = 0.00225938 loss)
I0521 10:26:03.581624  3675 sgd_solver.cpp:138] Iteration 16280, lr = 5e-05
I0521 10:26:07.103925  3675 solver.cpp:243] Iteration 16300, loss = 0.00232819
I0521 10:26:07.103955  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00232808 (* 1 = 0.00232808 loss)
I0521 10:26:07.103961  3675 sgd_solver.cpp:138] Iteration 16300, lr = 5e-05
I0521 10:26:10.621711  3675 solver.cpp:243] Iteration 16320, loss = 0.00272381
I0521 10:26:10.621742  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0027237 (* 1 = 0.0027237 loss)
I0521 10:26:10.621747  3675 sgd_solver.cpp:138] Iteration 16320, lr = 5e-05
I0521 10:26:14.144893  3675 solver.cpp:243] Iteration 16340, loss = 0.00246135
I0521 10:26:14.144924  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00246124 (* 1 = 0.00246124 loss)
I0521 10:26:14.144930  3675 sgd_solver.cpp:138] Iteration 16340, lr = 5e-05
I0521 10:26:17.668205  3675 solver.cpp:243] Iteration 16360, loss = 0.00320686
I0521 10:26:17.668236  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00320674 (* 1 = 0.00320674 loss)
I0521 10:26:17.668241  3675 sgd_solver.cpp:138] Iteration 16360, lr = 5e-05
I0521 10:26:21.190970  3675 solver.cpp:243] Iteration 16380, loss = 0.00260463
I0521 10:26:21.191117  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00260452 (* 1 = 0.00260452 loss)
I0521 10:26:21.191123  3675 sgd_solver.cpp:138] Iteration 16380, lr = 5e-05
I0521 10:26:24.715435  3675 solver.cpp:243] Iteration 16400, loss = 0.00423659
I0521 10:26:24.715466  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00423648 (* 1 = 0.00423648 loss)
I0521 10:26:24.715471  3675 sgd_solver.cpp:138] Iteration 16400, lr = 5e-05
I0521 10:26:28.238379  3675 solver.cpp:243] Iteration 16420, loss = 0.0042785
I0521 10:26:28.238409  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00427839 (* 1 = 0.00427839 loss)
I0521 10:26:28.238413  3675 sgd_solver.cpp:138] Iteration 16420, lr = 5e-05
I0521 10:26:31.760664  3675 solver.cpp:243] Iteration 16440, loss = 0.00417103
I0521 10:26:31.760695  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00417092 (* 1 = 0.00417092 loss)
I0521 10:26:31.760717  3675 sgd_solver.cpp:138] Iteration 16440, lr = 5e-05
I0521 10:26:35.286587  3675 solver.cpp:243] Iteration 16460, loss = 0.00372025
I0521 10:26:35.286617  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00372014 (* 1 = 0.00372014 loss)
I0521 10:26:35.286623  3675 sgd_solver.cpp:138] Iteration 16460, lr = 5e-05
I0521 10:26:38.806409  3675 solver.cpp:243] Iteration 16480, loss = 0.00420658
I0521 10:26:38.806440  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00420647 (* 1 = 0.00420647 loss)
I0521 10:26:38.806445  3675 sgd_solver.cpp:138] Iteration 16480, lr = 5e-05
I0521 10:26:42.332430  3675 solver.cpp:243] Iteration 16500, loss = 0.00356477
I0521 10:26:42.332460  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00356466 (* 1 = 0.00356466 loss)
I0521 10:26:42.332466  3675 sgd_solver.cpp:138] Iteration 16500, lr = 5e-05
I0521 10:26:45.856391  3675 solver.cpp:243] Iteration 16520, loss = 0.00269143
I0521 10:26:45.856421  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00269132 (* 1 = 0.00269132 loss)
I0521 10:26:45.856427  3675 sgd_solver.cpp:138] Iteration 16520, lr = 5e-05
I0521 10:26:49.378705  3675 solver.cpp:243] Iteration 16540, loss = 0.00973697
I0521 10:26:49.378736  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00973686 (* 1 = 0.00973686 loss)
I0521 10:26:49.378741  3675 sgd_solver.cpp:138] Iteration 16540, lr = 5e-05
I0521 10:26:52.900930  3675 solver.cpp:243] Iteration 16560, loss = 0.00413267
I0521 10:26:52.901098  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00413256 (* 1 = 0.00413256 loss)
I0521 10:26:52.901105  3675 sgd_solver.cpp:138] Iteration 16560, lr = 5e-05
I0521 10:26:56.422948  3675 solver.cpp:243] Iteration 16580, loss = 0.00296752
I0521 10:26:56.422981  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00296741 (* 1 = 0.00296741 loss)
I0521 10:26:56.422986  3675 sgd_solver.cpp:138] Iteration 16580, lr = 5e-05
I0521 10:26:59.947341  3675 solver.cpp:243] Iteration 16600, loss = 0.00305108
I0521 10:26:59.947371  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00305097 (* 1 = 0.00305097 loss)
I0521 10:26:59.947393  3675 sgd_solver.cpp:138] Iteration 16600, lr = 5e-05
I0521 10:27:03.471725  3675 solver.cpp:243] Iteration 16620, loss = 0.00257595
I0521 10:27:03.471755  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00257584 (* 1 = 0.00257584 loss)
I0521 10:27:03.471760  3675 sgd_solver.cpp:138] Iteration 16620, lr = 5e-05
I0521 10:27:06.992276  3675 solver.cpp:243] Iteration 16640, loss = 0.0024328
I0521 10:27:06.992307  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00243269 (* 1 = 0.00243269 loss)
I0521 10:27:06.992312  3675 sgd_solver.cpp:138] Iteration 16640, lr = 5e-05
I0521 10:27:10.591514  3675 solver.cpp:243] Iteration 16660, loss = 0.00318024
I0521 10:27:10.591547  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00318013 (* 1 = 0.00318013 loss)
I0521 10:27:10.591552  3675 sgd_solver.cpp:138] Iteration 16660, lr = 5e-05
I0521 10:27:14.189091  3675 solver.cpp:243] Iteration 16680, loss = 0.00207275
I0521 10:27:14.189123  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00207264 (* 1 = 0.00207264 loss)
I0521 10:27:14.189128  3675 sgd_solver.cpp:138] Iteration 16680, lr = 5e-05
I0521 10:27:17.761788  3675 solver.cpp:243] Iteration 16700, loss = 0.00348538
I0521 10:27:17.761817  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00348527 (* 1 = 0.00348527 loss)
I0521 10:27:17.761822  3675 sgd_solver.cpp:138] Iteration 16700, lr = 5e-05
I0521 10:27:21.310612  3675 solver.cpp:243] Iteration 16720, loss = 0.0030132
I0521 10:27:21.310644  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00301309 (* 1 = 0.00301309 loss)
I0521 10:27:21.310649  3675 sgd_solver.cpp:138] Iteration 16720, lr = 5e-05
I0521 10:27:24.850802  3675 solver.cpp:243] Iteration 16740, loss = 0.00340707
I0521 10:27:24.850962  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00340696 (* 1 = 0.00340696 loss)
I0521 10:27:24.850970  3675 sgd_solver.cpp:138] Iteration 16740, lr = 5e-05
I0521 10:27:28.386996  3675 solver.cpp:243] Iteration 16760, loss = 0.00292871
I0521 10:27:28.387027  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0029286 (* 1 = 0.0029286 loss)
I0521 10:27:28.387033  3675 sgd_solver.cpp:138] Iteration 16760, lr = 5e-05
I0521 10:27:31.922535  3675 solver.cpp:243] Iteration 16780, loss = 0.00279086
I0521 10:27:31.922567  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00279075 (* 1 = 0.00279075 loss)
I0521 10:27:31.922590  3675 sgd_solver.cpp:138] Iteration 16780, lr = 5e-05
I0521 10:27:35.451220  3675 solver.cpp:243] Iteration 16800, loss = 0.00423197
I0521 10:27:35.451251  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00423186 (* 1 = 0.00423186 loss)
I0521 10:27:35.451257  3675 sgd_solver.cpp:138] Iteration 16800, lr = 5e-05
I0521 10:27:38.978480  3675 solver.cpp:243] Iteration 16820, loss = 0.00306046
I0521 10:27:38.978511  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00306035 (* 1 = 0.00306035 loss)
I0521 10:27:38.978516  3675 sgd_solver.cpp:138] Iteration 16820, lr = 5e-05
I0521 10:27:42.503154  3675 solver.cpp:243] Iteration 16840, loss = 0.00251981
I0521 10:27:42.503183  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0025197 (* 1 = 0.0025197 loss)
I0521 10:27:42.503188  3675 sgd_solver.cpp:138] Iteration 16840, lr = 5e-05
I0521 10:27:46.028551  3675 solver.cpp:243] Iteration 16860, loss = 0.00330567
I0521 10:27:46.028581  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00330556 (* 1 = 0.00330556 loss)
I0521 10:27:46.028586  3675 sgd_solver.cpp:138] Iteration 16860, lr = 5e-05
I0521 10:27:49.556927  3675 solver.cpp:243] Iteration 16880, loss = 0.00334979
I0521 10:27:49.556958  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00334968 (* 1 = 0.00334968 loss)
I0521 10:27:49.556964  3675 sgd_solver.cpp:138] Iteration 16880, lr = 5e-05
I0521 10:27:53.082485  3675 solver.cpp:243] Iteration 16900, loss = 0.00262347
I0521 10:27:53.082516  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00262336 (* 1 = 0.00262336 loss)
I0521 10:27:53.082522  3675 sgd_solver.cpp:138] Iteration 16900, lr = 5e-05
I0521 10:27:56.605172  3675 solver.cpp:243] Iteration 16920, loss = 0.00360789
I0521 10:27:56.605290  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00360778 (* 1 = 0.00360778 loss)
I0521 10:27:56.605298  3675 sgd_solver.cpp:138] Iteration 16920, lr = 5e-05
I0521 10:28:00.125406  3675 solver.cpp:243] Iteration 16940, loss = 0.00272701
I0521 10:28:00.125438  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0027269 (* 1 = 0.0027269 loss)
I0521 10:28:00.125445  3675 sgd_solver.cpp:138] Iteration 16940, lr = 5e-05
I0521 10:28:03.655696  3675 solver.cpp:243] Iteration 16960, loss = 0.00356698
I0521 10:28:03.655742  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00356687 (* 1 = 0.00356687 loss)
I0521 10:28:03.655750  3675 sgd_solver.cpp:138] Iteration 16960, lr = 5e-05
I0521 10:28:07.114022  3675 solver.cpp:243] Iteration 16980, loss = 0.00334859
I0521 10:28:07.114054  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00334848 (* 1 = 0.00334848 loss)
I0521 10:28:07.114075  3675 sgd_solver.cpp:138] Iteration 16980, lr = 5e-05
I0521 10:28:10.511328  3675 solver.cpp:358] Iteration 17000, Testing net (#0)
I0521 10:28:15.246490  3675 solver.cpp:425]     Test net output #0: acc = 1
I0521 10:28:15.246518  3675 solver.cpp:425]     Test net output #1: acc = 1
I0521 10:28:15.246526  3675 solver.cpp:425]     Test net output #2: ctcloss = 0.00102041 (* 1 = 0.00102041 loss)
I0521 10:28:15.382201  3675 solver.cpp:243] Iteration 17000, loss = 0.00310792
I0521 10:28:15.382232  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00310782 (* 1 = 0.00310782 loss)
I0521 10:28:15.382238  3675 sgd_solver.cpp:138] Iteration 17000, lr = 5e-05
I0521 10:28:18.902798  3675 solver.cpp:243] Iteration 17020, loss = 0.00282234
I0521 10:28:18.902829  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00282223 (* 1 = 0.00282223 loss)
I0521 10:28:18.902850  3675 sgd_solver.cpp:138] Iteration 17020, lr = 5e-05
I0521 10:28:22.424412  3675 solver.cpp:243] Iteration 17040, loss = 0.00197105
I0521 10:28:22.424443  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00197094 (* 1 = 0.00197094 loss)
I0521 10:28:22.424448  3675 sgd_solver.cpp:138] Iteration 17040, lr = 5e-05
I0521 10:28:25.939560  3675 solver.cpp:243] Iteration 17060, loss = 0.00304975
I0521 10:28:25.939591  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00304964 (* 1 = 0.00304964 loss)
I0521 10:28:25.939596  3675 sgd_solver.cpp:138] Iteration 17060, lr = 5e-05
I0521 10:28:29.462889  3675 solver.cpp:243] Iteration 17080, loss = 0.00286771
I0521 10:28:29.463035  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0028676 (* 1 = 0.0028676 loss)
I0521 10:28:29.463042  3675 sgd_solver.cpp:138] Iteration 17080, lr = 5e-05
I0521 10:28:32.985853  3675 solver.cpp:243] Iteration 17100, loss = 0.00283166
I0521 10:28:32.985886  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00283155 (* 1 = 0.00283155 loss)
I0521 10:28:32.985893  3675 sgd_solver.cpp:138] Iteration 17100, lr = 5e-05
I0521 10:28:36.503295  3675 solver.cpp:243] Iteration 17120, loss = 0.00228305
I0521 10:28:36.503325  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00228294 (* 1 = 0.00228294 loss)
I0521 10:28:36.503330  3675 sgd_solver.cpp:138] Iteration 17120, lr = 5e-05
I0521 10:28:40.020428  3675 solver.cpp:243] Iteration 17140, loss = 0.00328318
I0521 10:28:40.020460  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00328307 (* 1 = 0.00328307 loss)
I0521 10:28:40.020483  3675 sgd_solver.cpp:138] Iteration 17140, lr = 5e-05
I0521 10:28:43.535956  3675 solver.cpp:243] Iteration 17160, loss = 0.00360954
I0521 10:28:43.535986  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00360943 (* 1 = 0.00360943 loss)
I0521 10:28:43.535991  3675 sgd_solver.cpp:138] Iteration 17160, lr = 5e-05
I0521 10:28:47.053463  3675 solver.cpp:243] Iteration 17180, loss = 0.0030854
I0521 10:28:47.053494  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00308529 (* 1 = 0.00308529 loss)
I0521 10:28:47.053499  3675 sgd_solver.cpp:138] Iteration 17180, lr = 5e-05
I0521 10:28:50.573544  3675 solver.cpp:243] Iteration 17200, loss = 0.00277973
I0521 10:28:50.573576  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00277962 (* 1 = 0.00277962 loss)
I0521 10:28:50.573582  3675 sgd_solver.cpp:138] Iteration 17200, lr = 5e-05
I0521 10:28:54.095906  3675 solver.cpp:243] Iteration 17220, loss = 0.0026071
I0521 10:28:54.095935  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00260699 (* 1 = 0.00260699 loss)
I0521 10:28:54.095942  3675 sgd_solver.cpp:138] Iteration 17220, lr = 5e-05
I0521 10:28:57.615254  3675 solver.cpp:243] Iteration 17240, loss = 0.00271231
I0521 10:28:57.615286  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0027122 (* 1 = 0.0027122 loss)
I0521 10:28:57.615309  3675 sgd_solver.cpp:138] Iteration 17240, lr = 5e-05
I0521 10:29:01.137231  3675 solver.cpp:243] Iteration 17260, loss = 0.00231704
I0521 10:29:01.137394  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00231693 (* 1 = 0.00231693 loss)
I0521 10:29:01.137401  3675 sgd_solver.cpp:138] Iteration 17260, lr = 5e-05
I0521 10:29:04.655340  3675 solver.cpp:243] Iteration 17280, loss = 0.00447307
I0521 10:29:04.655371  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00447296 (* 1 = 0.00447296 loss)
I0521 10:29:04.655377  3675 sgd_solver.cpp:138] Iteration 17280, lr = 5e-05
I0521 10:29:08.175173  3675 solver.cpp:243] Iteration 17300, loss = 0.00460466
I0521 10:29:08.175220  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00460455 (* 1 = 0.00460455 loss)
I0521 10:29:08.175225  3675 sgd_solver.cpp:138] Iteration 17300, lr = 5e-05
I0521 10:29:11.697160  3675 solver.cpp:243] Iteration 17320, loss = 0.00548494
I0521 10:29:11.697190  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00548483 (* 1 = 0.00548483 loss)
I0521 10:29:11.697196  3675 sgd_solver.cpp:138] Iteration 17320, lr = 5e-05
I0521 10:29:15.212191  3675 solver.cpp:243] Iteration 17340, loss = 0.00329041
I0521 10:29:15.212232  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0032903 (* 1 = 0.0032903 loss)
I0521 10:29:15.212239  3675 sgd_solver.cpp:138] Iteration 17340, lr = 5e-05
I0521 10:29:18.731904  3675 solver.cpp:243] Iteration 17360, loss = 0.00214245
I0521 10:29:18.731935  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00214234 (* 1 = 0.00214234 loss)
I0521 10:29:18.731956  3675 sgd_solver.cpp:138] Iteration 17360, lr = 5e-05
I0521 10:29:22.254544  3675 solver.cpp:243] Iteration 17380, loss = 0.00300816
I0521 10:29:22.254575  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00300805 (* 1 = 0.00300805 loss)
I0521 10:29:22.254581  3675 sgd_solver.cpp:138] Iteration 17380, lr = 5e-05
I0521 10:29:25.769394  3675 solver.cpp:243] Iteration 17400, loss = 0.00212633
I0521 10:29:25.769424  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00212622 (* 1 = 0.00212622 loss)
I0521 10:29:25.769430  3675 sgd_solver.cpp:138] Iteration 17400, lr = 5e-05
I0521 10:29:29.284905  3675 solver.cpp:243] Iteration 17420, loss = 0.00438281
I0521 10:29:29.284936  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0043827 (* 1 = 0.0043827 loss)
I0521 10:29:29.284941  3675 sgd_solver.cpp:138] Iteration 17420, lr = 5e-05
I0521 10:29:32.799731  3675 solver.cpp:243] Iteration 17440, loss = 0.00298952
I0521 10:29:32.799899  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00298941 (* 1 = 0.00298941 loss)
I0521 10:29:32.799907  3675 sgd_solver.cpp:138] Iteration 17440, lr = 5e-05
I0521 10:29:36.320144  3675 solver.cpp:243] Iteration 17460, loss = 0.00293508
I0521 10:29:36.320175  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00293497 (* 1 = 0.00293497 loss)
I0521 10:29:36.320180  3675 sgd_solver.cpp:138] Iteration 17460, lr = 5e-05
I0521 10:29:39.838157  3675 solver.cpp:243] Iteration 17480, loss = 0.0028196
I0521 10:29:39.838188  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00281949 (* 1 = 0.00281949 loss)
I0521 10:29:39.838193  3675 sgd_solver.cpp:138] Iteration 17480, lr = 5e-05
I0521 10:29:43.358373  3675 solver.cpp:243] Iteration 17500, loss = 0.00287817
I0521 10:29:43.358405  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00287806 (* 1 = 0.00287806 loss)
I0521 10:29:43.358410  3675 sgd_solver.cpp:138] Iteration 17500, lr = 5e-05
I0521 10:29:46.875603  3675 solver.cpp:243] Iteration 17520, loss = 0.00232063
I0521 10:29:46.875633  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00232052 (* 1 = 0.00232052 loss)
I0521 10:29:46.875655  3675 sgd_solver.cpp:138] Iteration 17520, lr = 5e-05
I0521 10:29:50.394791  3675 solver.cpp:243] Iteration 17540, loss = 0.00270987
I0521 10:29:50.394822  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00270976 (* 1 = 0.00270976 loss)
I0521 10:29:50.394829  3675 sgd_solver.cpp:138] Iteration 17540, lr = 5e-05
I0521 10:29:53.908319  3675 solver.cpp:243] Iteration 17560, loss = 0.00278325
I0521 10:29:53.908349  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00278314 (* 1 = 0.00278314 loss)
I0521 10:29:53.908370  3675 sgd_solver.cpp:138] Iteration 17560, lr = 5e-05
I0521 10:29:57.422919  3675 solver.cpp:243] Iteration 17580, loss = 0.00285476
I0521 10:29:57.422948  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00285465 (* 1 = 0.00285465 loss)
I0521 10:29:57.422955  3675 sgd_solver.cpp:138] Iteration 17580, lr = 5e-05
I0521 10:30:00.936194  3675 solver.cpp:243] Iteration 17600, loss = 0.00232189
I0521 10:30:00.936226  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00232178 (* 1 = 0.00232178 loss)
I0521 10:30:00.936231  3675 sgd_solver.cpp:138] Iteration 17600, lr = 5e-05
I0521 10:30:04.455772  3675 solver.cpp:243] Iteration 17620, loss = 0.00243
I0521 10:30:04.455942  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00242989 (* 1 = 0.00242989 loss)
I0521 10:30:04.455950  3675 sgd_solver.cpp:138] Iteration 17620, lr = 5e-05
I0521 10:30:07.975373  3675 solver.cpp:243] Iteration 17640, loss = 0.00251239
I0521 10:30:07.975404  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00251228 (* 1 = 0.00251228 loss)
I0521 10:30:07.975409  3675 sgd_solver.cpp:138] Iteration 17640, lr = 5e-05
I0521 10:30:11.494546  3675 solver.cpp:243] Iteration 17660, loss = 0.00288185
I0521 10:30:11.494596  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00288174 (* 1 = 0.00288174 loss)
I0521 10:30:11.494601  3675 sgd_solver.cpp:138] Iteration 17660, lr = 5e-05
I0521 10:30:15.015136  3675 solver.cpp:243] Iteration 17680, loss = 0.0100244
I0521 10:30:15.015167  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0100243 (* 1 = 0.0100243 loss)
I0521 10:30:15.015172  3675 sgd_solver.cpp:138] Iteration 17680, lr = 5e-05
I0521 10:30:18.533454  3675 solver.cpp:243] Iteration 17700, loss = 0.00328323
I0521 10:30:18.533484  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00328312 (* 1 = 0.00328312 loss)
I0521 10:30:18.533506  3675 sgd_solver.cpp:138] Iteration 17700, lr = 5e-05
I0521 10:30:22.053881  3675 solver.cpp:243] Iteration 17720, loss = 0.00375193
I0521 10:30:22.053915  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00375183 (* 1 = 0.00375183 loss)
I0521 10:30:22.053920  3675 sgd_solver.cpp:138] Iteration 17720, lr = 5e-05
I0521 10:30:25.569625  3675 solver.cpp:243] Iteration 17740, loss = 0.00323096
I0521 10:30:25.569658  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00323086 (* 1 = 0.00323086 loss)
I0521 10:30:25.569664  3675 sgd_solver.cpp:138] Iteration 17740, lr = 5e-05
I0521 10:30:29.090174  3675 solver.cpp:243] Iteration 17760, loss = 0.00256032
I0521 10:30:29.090205  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00256021 (* 1 = 0.00256021 loss)
I0521 10:30:29.090211  3675 sgd_solver.cpp:138] Iteration 17760, lr = 5e-05
I0521 10:30:32.609484  3675 solver.cpp:243] Iteration 17780, loss = 0.00271408
I0521 10:30:32.609515  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00271397 (* 1 = 0.00271397 loss)
I0521 10:30:32.609537  3675 sgd_solver.cpp:138] Iteration 17780, lr = 5e-05
I0521 10:30:36.131198  3675 solver.cpp:243] Iteration 17800, loss = 0.00403763
I0521 10:30:36.131361  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00403752 (* 1 = 0.00403752 loss)
I0521 10:30:36.131367  3675 sgd_solver.cpp:138] Iteration 17800, lr = 5e-05
I0521 10:30:39.650158  3675 solver.cpp:243] Iteration 17820, loss = 0.00528085
I0521 10:30:39.650190  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00528074 (* 1 = 0.00528074 loss)
I0521 10:30:39.650195  3675 sgd_solver.cpp:138] Iteration 17820, lr = 5e-05
I0521 10:30:43.166496  3675 solver.cpp:243] Iteration 17840, loss = 0.00301555
I0521 10:30:43.166527  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00301544 (* 1 = 0.00301544 loss)
I0521 10:30:43.166548  3675 sgd_solver.cpp:138] Iteration 17840, lr = 5e-05
I0521 10:30:46.681327  3675 solver.cpp:243] Iteration 17860, loss = 0.00348968
I0521 10:30:46.681357  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00348957 (* 1 = 0.00348957 loss)
I0521 10:30:46.681363  3675 sgd_solver.cpp:138] Iteration 17860, lr = 5e-05
I0521 10:30:50.198647  3675 solver.cpp:243] Iteration 17880, loss = 0.00295659
I0521 10:30:50.198678  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00295649 (* 1 = 0.00295649 loss)
I0521 10:30:50.198684  3675 sgd_solver.cpp:138] Iteration 17880, lr = 5e-05
I0521 10:30:53.714507  3675 solver.cpp:243] Iteration 17900, loss = 0.00291133
I0521 10:30:53.714537  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00291123 (* 1 = 0.00291123 loss)
I0521 10:30:53.714542  3675 sgd_solver.cpp:138] Iteration 17900, lr = 5e-05
I0521 10:30:57.230700  3675 solver.cpp:243] Iteration 17920, loss = 0.00286887
I0521 10:30:57.230729  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00286876 (* 1 = 0.00286876 loss)
I0521 10:30:57.230736  3675 sgd_solver.cpp:138] Iteration 17920, lr = 5e-05
I0521 10:31:00.748868  3675 solver.cpp:243] Iteration 17940, loss = 0.00262212
I0521 10:31:00.748899  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00262201 (* 1 = 0.00262201 loss)
I0521 10:31:00.748904  3675 sgd_solver.cpp:138] Iteration 17940, lr = 5e-05
I0521 10:31:04.262773  3675 solver.cpp:243] Iteration 17960, loss = 0.00306614
I0521 10:31:04.262804  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00306603 (* 1 = 0.00306603 loss)
I0521 10:31:04.262809  3675 sgd_solver.cpp:138] Iteration 17960, lr = 5e-05
I0521 10:31:07.776446  3675 solver.cpp:243] Iteration 17980, loss = 0.00300673
I0521 10:31:07.776620  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00300662 (* 1 = 0.00300662 loss)
I0521 10:31:07.776628  3675 sgd_solver.cpp:138] Iteration 17980, lr = 5e-05
I0521 10:31:11.162274  3675 solver.cpp:596] Snapshotting to binary proto file models/LPR/lpr_resnet_lstm_iter_18000.caffemodel
I0521 10:31:11.191630  3675 sgd_solver.cpp:307] Snapshotting solver state to binary proto file models/LPR/lpr_resnet_lstm_iter_18000.solverstate
I0521 10:31:11.207715  3675 solver.cpp:358] Iteration 18000, Testing net (#0)
I0521 10:31:15.941160  3675 solver.cpp:425]     Test net output #0: acc = 1
I0521 10:31:15.941187  3675 solver.cpp:425]     Test net output #1: acc = 1
I0521 10:31:15.941193  3675 solver.cpp:425]     Test net output #2: ctcloss = 0.000976573 (* 1 = 0.000976573 loss)
I0521 10:31:16.076719  3675 solver.cpp:243] Iteration 18000, loss = 0.00284272
I0521 10:31:16.076750  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00284261 (* 1 = 0.00284261 loss)
I0521 10:31:16.076756  3675 sgd_solver.cpp:138] Iteration 18000, lr = 5e-05
I0521 10:31:19.594545  3675 solver.cpp:243] Iteration 18020, loss = 0.00338528
I0521 10:31:19.594575  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00338517 (* 1 = 0.00338517 loss)
I0521 10:31:19.594581  3675 sgd_solver.cpp:138] Iteration 18020, lr = 5e-05
I0521 10:31:23.110002  3675 solver.cpp:243] Iteration 18040, loss = 0.0152627
I0521 10:31:23.110031  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0152626 (* 1 = 0.0152626 loss)
I0521 10:31:23.110054  3675 sgd_solver.cpp:138] Iteration 18040, lr = 5e-05
I0521 10:31:26.623076  3675 solver.cpp:243] Iteration 18060, loss = 0.0026361
I0521 10:31:26.623107  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00263599 (* 1 = 0.00263599 loss)
I0521 10:31:26.623113  3675 sgd_solver.cpp:138] Iteration 18060, lr = 5e-05
I0521 10:31:30.136297  3675 solver.cpp:243] Iteration 18080, loss = 0.00290626
I0521 10:31:30.136327  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00290615 (* 1 = 0.00290615 loss)
I0521 10:31:30.136332  3675 sgd_solver.cpp:138] Iteration 18080, lr = 5e-05
I0521 10:31:33.651048  3675 solver.cpp:243] Iteration 18100, loss = 0.00269692
I0521 10:31:33.651078  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00269681 (* 1 = 0.00269681 loss)
I0521 10:31:33.651084  3675 sgd_solver.cpp:138] Iteration 18100, lr = 5e-05
I0521 10:31:37.163529  3675 solver.cpp:243] Iteration 18120, loss = 0.00301133
I0521 10:31:37.163560  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00301122 (* 1 = 0.00301122 loss)
I0521 10:31:37.163565  3675 sgd_solver.cpp:138] Iteration 18120, lr = 5e-05
I0521 10:31:40.677412  3675 solver.cpp:243] Iteration 18140, loss = 0.00414754
I0521 10:31:40.677533  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00414743 (* 1 = 0.00414743 loss)
I0521 10:31:40.677541  3675 sgd_solver.cpp:138] Iteration 18140, lr = 5e-05
I0521 10:31:44.190279  3675 solver.cpp:243] Iteration 18160, loss = 0.00334303
I0521 10:31:44.190309  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00334292 (* 1 = 0.00334292 loss)
I0521 10:31:44.190315  3675 sgd_solver.cpp:138] Iteration 18160, lr = 5e-05
I0521 10:31:47.703498  3675 solver.cpp:243] Iteration 18180, loss = 0.00355478
I0521 10:31:47.703527  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00355468 (* 1 = 0.00355468 loss)
I0521 10:31:47.703533  3675 sgd_solver.cpp:138] Iteration 18180, lr = 5e-05
I0521 10:31:51.211604  3675 solver.cpp:243] Iteration 18200, loss = 0.00187457
I0521 10:31:51.211634  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00187447 (* 1 = 0.00187447 loss)
I0521 10:31:51.211640  3675 sgd_solver.cpp:138] Iteration 18200, lr = 5e-05
I0521 10:31:54.723767  3675 solver.cpp:243] Iteration 18220, loss = 0.00410222
I0521 10:31:54.723798  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00410211 (* 1 = 0.00410211 loss)
I0521 10:31:54.723803  3675 sgd_solver.cpp:138] Iteration 18220, lr = 5e-05
I0521 10:31:58.234607  3675 solver.cpp:243] Iteration 18240, loss = 0.00271185
I0521 10:31:58.234650  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00271174 (* 1 = 0.00271174 loss)
I0521 10:31:58.234656  3675 sgd_solver.cpp:138] Iteration 18240, lr = 5e-05
I0521 10:32:01.744817  3675 solver.cpp:243] Iteration 18260, loss = 0.00442402
I0521 10:32:01.744848  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00442391 (* 1 = 0.00442391 loss)
I0521 10:32:01.744854  3675 sgd_solver.cpp:138] Iteration 18260, lr = 5e-05
I0521 10:32:05.198186  3675 solver.cpp:243] Iteration 18280, loss = 0.00266633
I0521 10:32:05.198217  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00266622 (* 1 = 0.00266622 loss)
I0521 10:32:05.198223  3675 sgd_solver.cpp:138] Iteration 18280, lr = 5e-05
I0521 10:32:08.706840  3675 solver.cpp:243] Iteration 18300, loss = 0.00347423
I0521 10:32:08.706871  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00347413 (* 1 = 0.00347413 loss)
I0521 10:32:08.706876  3675 sgd_solver.cpp:138] Iteration 18300, lr = 5e-05
I0521 10:32:12.217831  3675 solver.cpp:243] Iteration 18320, loss = 0.00342118
I0521 10:32:12.217986  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00342108 (* 1 = 0.00342108 loss)
I0521 10:32:12.217993  3675 sgd_solver.cpp:138] Iteration 18320, lr = 5e-05
I0521 10:32:15.729930  3675 solver.cpp:243] Iteration 18340, loss = 0.00324649
I0521 10:32:15.729961  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00324639 (* 1 = 0.00324639 loss)
I0521 10:32:15.729969  3675 sgd_solver.cpp:138] Iteration 18340, lr = 5e-05
I0521 10:32:19.241101  3675 solver.cpp:243] Iteration 18360, loss = 0.00351415
I0521 10:32:19.241130  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00351405 (* 1 = 0.00351405 loss)
I0521 10:32:19.241135  3675 sgd_solver.cpp:138] Iteration 18360, lr = 5e-05
I0521 10:32:22.751843  3675 solver.cpp:243] Iteration 18380, loss = 0.00300506
I0521 10:32:22.751874  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00300495 (* 1 = 0.00300495 loss)
I0521 10:32:22.751880  3675 sgd_solver.cpp:138] Iteration 18380, lr = 5e-05
I0521 10:32:26.266989  3675 solver.cpp:243] Iteration 18400, loss = 0.00248851
I0521 10:32:26.267019  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00248841 (* 1 = 0.00248841 loss)
I0521 10:32:26.267024  3675 sgd_solver.cpp:138] Iteration 18400, lr = 5e-05
I0521 10:32:29.781554  3675 solver.cpp:243] Iteration 18420, loss = 0.00327842
I0521 10:32:29.781584  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00327831 (* 1 = 0.00327831 loss)
I0521 10:32:29.781590  3675 sgd_solver.cpp:138] Iteration 18420, lr = 5e-05
I0521 10:32:33.287832  3675 solver.cpp:243] Iteration 18440, loss = 0.00267351
I0521 10:32:33.287864  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00267341 (* 1 = 0.00267341 loss)
I0521 10:32:33.287869  3675 sgd_solver.cpp:138] Iteration 18440, lr = 5e-05
I0521 10:32:36.806941  3675 solver.cpp:243] Iteration 18460, loss = 0.00290814
I0521 10:32:36.806973  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00290804 (* 1 = 0.00290804 loss)
I0521 10:32:36.806978  3675 sgd_solver.cpp:138] Iteration 18460, lr = 5e-05
I0521 10:32:40.321290  3675 solver.cpp:243] Iteration 18480, loss = 0.00228925
I0521 10:32:40.321321  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00228914 (* 1 = 0.00228914 loss)
I0521 10:32:40.321327  3675 sgd_solver.cpp:138] Iteration 18480, lr = 5e-05
I0521 10:32:43.838042  3675 solver.cpp:243] Iteration 18500, loss = 0.00258567
I0521 10:32:43.838217  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00258556 (* 1 = 0.00258556 loss)
I0521 10:32:43.838224  3675 sgd_solver.cpp:138] Iteration 18500, lr = 5e-05
I0521 10:32:47.354197  3675 solver.cpp:243] Iteration 18520, loss = 0.00286395
I0521 10:32:47.354228  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00286384 (* 1 = 0.00286384 loss)
I0521 10:32:47.354234  3675 sgd_solver.cpp:138] Iteration 18520, lr = 5e-05
I0521 10:32:50.869675  3675 solver.cpp:243] Iteration 18540, loss = 0.00390128
I0521 10:32:50.869707  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00390117 (* 1 = 0.00390117 loss)
I0521 10:32:50.869712  3675 sgd_solver.cpp:138] Iteration 18540, lr = 5e-05
I0521 10:32:54.384414  3675 solver.cpp:243] Iteration 18560, loss = 0.00383868
I0521 10:32:54.384446  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00383858 (* 1 = 0.00383858 loss)
I0521 10:32:54.384451  3675 sgd_solver.cpp:138] Iteration 18560, lr = 5e-05
I0521 10:32:57.898478  3675 solver.cpp:243] Iteration 18580, loss = 0.00284072
I0521 10:32:57.898509  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00284061 (* 1 = 0.00284061 loss)
I0521 10:32:57.898515  3675 sgd_solver.cpp:138] Iteration 18580, lr = 5e-05
I0521 10:33:01.414678  3675 solver.cpp:243] Iteration 18600, loss = 0.0020708
I0521 10:33:01.414707  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0020707 (* 1 = 0.0020707 loss)
I0521 10:33:01.414713  3675 sgd_solver.cpp:138] Iteration 18600, lr = 5e-05
I0521 10:33:04.933377  3675 solver.cpp:243] Iteration 18620, loss = 0.00213785
I0521 10:33:04.933408  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00213775 (* 1 = 0.00213775 loss)
I0521 10:33:04.933414  3675 sgd_solver.cpp:138] Iteration 18620, lr = 5e-05
I0521 10:33:08.449421  3675 solver.cpp:243] Iteration 18640, loss = 0.00224434
I0521 10:33:08.449453  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00224424 (* 1 = 0.00224424 loss)
I0521 10:33:08.449460  3675 sgd_solver.cpp:138] Iteration 18640, lr = 5e-05
I0521 10:33:11.967409  3675 solver.cpp:243] Iteration 18660, loss = 0.00367135
I0521 10:33:11.967442  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00367125 (* 1 = 0.00367125 loss)
I0521 10:33:11.967447  3675 sgd_solver.cpp:138] Iteration 18660, lr = 5e-05
I0521 10:33:15.485090  3675 solver.cpp:243] Iteration 18680, loss = 0.00454973
I0521 10:33:15.485209  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00454963 (* 1 = 0.00454963 loss)
I0521 10:33:15.485216  3675 sgd_solver.cpp:138] Iteration 18680, lr = 5e-05
I0521 10:33:19.003401  3675 solver.cpp:243] Iteration 18700, loss = 0.00302435
I0521 10:33:19.003432  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00302424 (* 1 = 0.00302424 loss)
I0521 10:33:19.003438  3675 sgd_solver.cpp:138] Iteration 18700, lr = 5e-05
I0521 10:33:22.516067  3675 solver.cpp:243] Iteration 18720, loss = 0.00312465
I0521 10:33:22.516098  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00312454 (* 1 = 0.00312454 loss)
I0521 10:33:22.516103  3675 sgd_solver.cpp:138] Iteration 18720, lr = 5e-05
I0521 10:33:26.035028  3675 solver.cpp:243] Iteration 18740, loss = 0.00334166
I0521 10:33:26.035059  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00334156 (* 1 = 0.00334156 loss)
I0521 10:33:26.035065  3675 sgd_solver.cpp:138] Iteration 18740, lr = 5e-05
I0521 10:33:29.551038  3675 solver.cpp:243] Iteration 18760, loss = 0.00230886
I0521 10:33:29.551070  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00230876 (* 1 = 0.00230876 loss)
I0521 10:33:29.551076  3675 sgd_solver.cpp:138] Iteration 18760, lr = 5e-05
I0521 10:33:33.063861  3675 solver.cpp:243] Iteration 18780, loss = 0.00285002
I0521 10:33:33.063892  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00284991 (* 1 = 0.00284991 loss)
I0521 10:33:33.063897  3675 sgd_solver.cpp:138] Iteration 18780, lr = 5e-05
I0521 10:33:36.575670  3675 solver.cpp:243] Iteration 18800, loss = 0.00239024
I0521 10:33:36.575702  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00239013 (* 1 = 0.00239013 loss)
I0521 10:33:36.575707  3675 sgd_solver.cpp:138] Iteration 18800, lr = 5e-05
I0521 10:33:40.087592  3675 solver.cpp:243] Iteration 18820, loss = 0.00336725
I0521 10:33:40.087623  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00336714 (* 1 = 0.00336714 loss)
I0521 10:33:40.087628  3675 sgd_solver.cpp:138] Iteration 18820, lr = 5e-05
I0521 10:33:43.601076  3675 solver.cpp:243] Iteration 18840, loss = 0.00270831
I0521 10:33:43.601109  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0027082 (* 1 = 0.0027082 loss)
I0521 10:33:43.601114  3675 sgd_solver.cpp:138] Iteration 18840, lr = 5e-05
I0521 10:33:47.112495  3675 solver.cpp:243] Iteration 18860, loss = 0.00286124
I0521 10:33:47.112673  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00286113 (* 1 = 0.00286113 loss)
I0521 10:33:47.112679  3675 sgd_solver.cpp:138] Iteration 18860, lr = 5e-05
I0521 10:33:50.624155  3675 solver.cpp:243] Iteration 18880, loss = 0.00316689
I0521 10:33:50.624186  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00316678 (* 1 = 0.00316678 loss)
I0521 10:33:50.624191  3675 sgd_solver.cpp:138] Iteration 18880, lr = 5e-05
I0521 10:33:54.135296  3675 solver.cpp:243] Iteration 18900, loss = 0.00240268
I0521 10:33:54.135327  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00240257 (* 1 = 0.00240257 loss)
I0521 10:33:54.135332  3675 sgd_solver.cpp:138] Iteration 18900, lr = 5e-05
I0521 10:33:57.650651  3675 solver.cpp:243] Iteration 18920, loss = 0.00309999
I0521 10:33:57.650682  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00309988 (* 1 = 0.00309988 loss)
I0521 10:33:57.650687  3675 sgd_solver.cpp:138] Iteration 18920, lr = 5e-05
I0521 10:34:01.171161  3675 solver.cpp:243] Iteration 18940, loss = 0.00398595
I0521 10:34:01.171192  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00398585 (* 1 = 0.00398585 loss)
I0521 10:34:01.171197  3675 sgd_solver.cpp:138] Iteration 18940, lr = 5e-05
I0521 10:34:04.684262  3675 solver.cpp:243] Iteration 18960, loss = 0.00211468
I0521 10:34:04.684293  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00211458 (* 1 = 0.00211458 loss)
I0521 10:34:04.684298  3675 sgd_solver.cpp:138] Iteration 18960, lr = 5e-05
I0521 10:34:08.193265  3675 solver.cpp:243] Iteration 18980, loss = 0.00215269
I0521 10:34:08.193296  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00215259 (* 1 = 0.00215259 loss)
I0521 10:34:08.193302  3675 sgd_solver.cpp:138] Iteration 18980, lr = 5e-05
I0521 10:34:11.579789  3675 solver.cpp:358] Iteration 19000, Testing net (#0)
I0521 10:34:16.312923  3675 solver.cpp:425]     Test net output #0: acc = 1
I0521 10:34:16.312949  3675 solver.cpp:425]     Test net output #1: acc = 1
I0521 10:34:16.312955  3675 solver.cpp:425]     Test net output #2: ctcloss = 0.00094983 (* 1 = 0.00094983 loss)
I0521 10:34:16.448052  3675 solver.cpp:243] Iteration 19000, loss = 0.00258866
I0521 10:34:16.448082  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00258856 (* 1 = 0.00258856 loss)
I0521 10:34:16.448087  3675 sgd_solver.cpp:138] Iteration 19000, lr = 5e-05
I0521 10:34:19.962687  3675 solver.cpp:243] Iteration 19020, loss = 0.00286222
I0521 10:34:19.962813  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00286212 (* 1 = 0.00286212 loss)
I0521 10:34:19.962821  3675 sgd_solver.cpp:138] Iteration 19020, lr = 5e-05
I0521 10:34:23.483860  3675 solver.cpp:243] Iteration 19040, loss = 0.00212145
I0521 10:34:23.483891  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00212134 (* 1 = 0.00212134 loss)
I0521 10:34:23.483896  3675 sgd_solver.cpp:138] Iteration 19040, lr = 5e-05
I0521 10:34:27.006115  3675 solver.cpp:243] Iteration 19060, loss = 0.00283401
I0521 10:34:27.006146  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00283391 (* 1 = 0.00283391 loss)
I0521 10:34:27.006151  3675 sgd_solver.cpp:138] Iteration 19060, lr = 5e-05
I0521 10:34:30.526711  3675 solver.cpp:243] Iteration 19080, loss = 0.00249776
I0521 10:34:30.526742  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00249765 (* 1 = 0.00249765 loss)
I0521 10:34:30.526747  3675 sgd_solver.cpp:138] Iteration 19080, lr = 5e-05
I0521 10:34:34.051908  3675 solver.cpp:243] Iteration 19100, loss = 0.00330267
I0521 10:34:34.051937  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00330256 (* 1 = 0.00330256 loss)
I0521 10:34:34.051944  3675 sgd_solver.cpp:138] Iteration 19100, lr = 5e-05
I0521 10:34:37.575130  3675 solver.cpp:243] Iteration 19120, loss = 0.0045278
I0521 10:34:37.575162  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0045277 (* 1 = 0.0045277 loss)
I0521 10:34:37.575168  3675 sgd_solver.cpp:138] Iteration 19120, lr = 5e-05
I0521 10:34:41.098232  3675 solver.cpp:243] Iteration 19140, loss = 0.0027369
I0521 10:34:41.098263  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0027368 (* 1 = 0.0027368 loss)
I0521 10:34:41.098269  3675 sgd_solver.cpp:138] Iteration 19140, lr = 5e-05
I0521 10:34:44.621510  3675 solver.cpp:243] Iteration 19160, loss = 0.0032223
I0521 10:34:44.621541  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0032222 (* 1 = 0.0032222 loss)
I0521 10:34:44.621546  3675 sgd_solver.cpp:138] Iteration 19160, lr = 5e-05
I0521 10:34:48.140686  3675 solver.cpp:243] Iteration 19180, loss = 0.0150269
I0521 10:34:48.140717  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0150268 (* 1 = 0.0150268 loss)
I0521 10:34:48.140722  3675 sgd_solver.cpp:138] Iteration 19180, lr = 5e-05
I0521 10:34:51.660588  3675 solver.cpp:243] Iteration 19200, loss = 0.00281662
I0521 10:34:51.660786  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00281652 (* 1 = 0.00281652 loss)
I0521 10:34:51.660795  3675 sgd_solver.cpp:138] Iteration 19200, lr = 5e-05
I0521 10:34:55.179698  3675 solver.cpp:243] Iteration 19220, loss = 0.00710849
I0521 10:34:55.179729  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00710838 (* 1 = 0.00710838 loss)
I0521 10:34:55.179734  3675 sgd_solver.cpp:138] Iteration 19220, lr = 5e-05
I0521 10:34:58.704234  3675 solver.cpp:243] Iteration 19240, loss = 0.00339274
I0521 10:34:58.704264  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00339264 (* 1 = 0.00339264 loss)
I0521 10:34:58.704272  3675 sgd_solver.cpp:138] Iteration 19240, lr = 5e-05
I0521 10:35:02.226672  3675 solver.cpp:243] Iteration 19260, loss = 0.00244606
I0521 10:35:02.226704  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00244596 (* 1 = 0.00244596 loss)
I0521 10:35:02.226709  3675 sgd_solver.cpp:138] Iteration 19260, lr = 5e-05
I0521 10:35:05.747023  3675 solver.cpp:243] Iteration 19280, loss = 0.00236237
I0521 10:35:05.747054  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00236227 (* 1 = 0.00236227 loss)
I0521 10:35:05.747061  3675 sgd_solver.cpp:138] Iteration 19280, lr = 5e-05
I0521 10:35:09.272246  3675 solver.cpp:243] Iteration 19300, loss = 0.00218087
I0521 10:35:09.272277  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00218077 (* 1 = 0.00218077 loss)
I0521 10:35:09.272284  3675 sgd_solver.cpp:138] Iteration 19300, lr = 5e-05
I0521 10:35:12.791096  3675 solver.cpp:243] Iteration 19320, loss = 0.00284875
I0521 10:35:12.791127  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00284865 (* 1 = 0.00284865 loss)
I0521 10:35:12.791132  3675 sgd_solver.cpp:138] Iteration 19320, lr = 5e-05
I0521 10:35:16.305572  3675 solver.cpp:243] Iteration 19340, loss = 0.0031989
I0521 10:35:16.305603  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0031988 (* 1 = 0.0031988 loss)
I0521 10:35:16.305625  3675 sgd_solver.cpp:138] Iteration 19340, lr = 5e-05
I0521 10:35:19.823644  3675 solver.cpp:243] Iteration 19360, loss = 0.0031144
I0521 10:35:19.823675  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0031143 (* 1 = 0.0031143 loss)
I0521 10:35:19.823680  3675 sgd_solver.cpp:138] Iteration 19360, lr = 5e-05
I0521 10:35:23.335002  3675 solver.cpp:243] Iteration 19380, loss = 0.00257448
I0521 10:35:23.335211  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00257438 (* 1 = 0.00257438 loss)
I0521 10:35:23.335220  3675 sgd_solver.cpp:138] Iteration 19380, lr = 5e-05
I0521 10:35:26.845759  3675 solver.cpp:243] Iteration 19400, loss = 0.00297059
I0521 10:35:26.845790  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00297048 (* 1 = 0.00297048 loss)
I0521 10:35:26.845811  3675 sgd_solver.cpp:138] Iteration 19400, lr = 5e-05
I0521 10:35:30.363358  3675 solver.cpp:243] Iteration 19420, loss = 0.00220066
I0521 10:35:30.363389  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00220056 (* 1 = 0.00220056 loss)
I0521 10:35:30.363395  3675 sgd_solver.cpp:138] Iteration 19420, lr = 5e-05
I0521 10:35:33.879328  3675 solver.cpp:243] Iteration 19440, loss = 0.00313253
I0521 10:35:33.879360  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00313242 (* 1 = 0.00313242 loss)
I0521 10:35:33.879365  3675 sgd_solver.cpp:138] Iteration 19440, lr = 5e-05
I0521 10:35:37.394356  3675 solver.cpp:243] Iteration 19460, loss = 0.00273259
I0521 10:35:37.394387  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00273249 (* 1 = 0.00273249 loss)
I0521 10:35:37.394393  3675 sgd_solver.cpp:138] Iteration 19460, lr = 5e-05
I0521 10:35:40.912154  3675 solver.cpp:243] Iteration 19480, loss = 0.0020784
I0521 10:35:40.912185  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0020783 (* 1 = 0.0020783 loss)
I0521 10:35:40.912191  3675 sgd_solver.cpp:138] Iteration 19480, lr = 5e-05
I0521 10:35:44.427527  3675 solver.cpp:243] Iteration 19500, loss = 0.00323585
I0521 10:35:44.427561  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00323575 (* 1 = 0.00323575 loss)
I0521 10:35:44.427567  3675 sgd_solver.cpp:138] Iteration 19500, lr = 5e-05
I0521 10:35:47.947638  3675 solver.cpp:243] Iteration 19520, loss = 0.00227968
I0521 10:35:47.947669  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00227958 (* 1 = 0.00227958 loss)
I0521 10:35:47.947675  3675 sgd_solver.cpp:138] Iteration 19520, lr = 5e-05
I0521 10:35:51.465987  3675 solver.cpp:243] Iteration 19540, loss = 0.00459005
I0521 10:35:51.466029  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00458994 (* 1 = 0.00458994 loss)
I0521 10:35:51.466035  3675 sgd_solver.cpp:138] Iteration 19540, lr = 5e-05
I0521 10:35:54.978791  3675 solver.cpp:243] Iteration 19560, loss = 0.00307638
I0521 10:35:54.978951  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00307628 (* 1 = 0.00307628 loss)
I0521 10:35:54.978960  3675 sgd_solver.cpp:138] Iteration 19560, lr = 5e-05
I0521 10:35:58.430757  3675 solver.cpp:243] Iteration 19580, loss = 0.00328873
I0521 10:35:58.430788  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00328863 (* 1 = 0.00328863 loss)
I0521 10:35:58.430793  3675 sgd_solver.cpp:138] Iteration 19580, lr = 5e-05
I0521 10:36:01.941952  3675 solver.cpp:243] Iteration 19600, loss = 0.00342438
I0521 10:36:01.941983  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00342428 (* 1 = 0.00342428 loss)
I0521 10:36:01.941988  3675 sgd_solver.cpp:138] Iteration 19600, lr = 5e-05
I0521 10:36:05.460376  3675 solver.cpp:243] Iteration 19620, loss = 0.00248354
I0521 10:36:05.460405  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00248343 (* 1 = 0.00248343 loss)
I0521 10:36:05.460412  3675 sgd_solver.cpp:138] Iteration 19620, lr = 5e-05
I0521 10:36:08.976466  3675 solver.cpp:243] Iteration 19640, loss = 0.00281521
I0521 10:36:08.976496  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00281511 (* 1 = 0.00281511 loss)
I0521 10:36:08.976518  3675 sgd_solver.cpp:138] Iteration 19640, lr = 5e-05
I0521 10:36:12.496677  3675 solver.cpp:243] Iteration 19660, loss = 0.00215768
I0521 10:36:12.496708  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00215758 (* 1 = 0.00215758 loss)
I0521 10:36:12.496713  3675 sgd_solver.cpp:138] Iteration 19660, lr = 5e-05
I0521 10:36:16.016873  3675 solver.cpp:243] Iteration 19680, loss = 0.00268943
I0521 10:36:16.016923  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00268933 (* 1 = 0.00268933 loss)
I0521 10:36:16.016930  3675 sgd_solver.cpp:138] Iteration 19680, lr = 5e-05
I0521 10:36:19.542364  3675 solver.cpp:243] Iteration 19700, loss = 0.00486735
I0521 10:36:19.542394  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00486725 (* 1 = 0.00486725 loss)
I0521 10:36:19.542400  3675 sgd_solver.cpp:138] Iteration 19700, lr = 5e-05
I0521 10:36:23.060807  3675 solver.cpp:243] Iteration 19720, loss = 0.00358014
I0521 10:36:23.060838  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00358004 (* 1 = 0.00358004 loss)
I0521 10:36:23.060843  3675 sgd_solver.cpp:138] Iteration 19720, lr = 5e-05
I0521 10:36:26.580408  3675 solver.cpp:243] Iteration 19740, loss = 0.00277847
I0521 10:36:26.580559  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00277837 (* 1 = 0.00277837 loss)
I0521 10:36:26.580566  3675 sgd_solver.cpp:138] Iteration 19740, lr = 5e-05
I0521 10:36:30.101894  3675 solver.cpp:243] Iteration 19760, loss = 0.00194525
I0521 10:36:30.101927  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00194515 (* 1 = 0.00194515 loss)
I0521 10:36:30.101931  3675 sgd_solver.cpp:138] Iteration 19760, lr = 5e-05
I0521 10:36:33.625514  3675 solver.cpp:243] Iteration 19780, loss = 0.00320329
I0521 10:36:33.625545  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00320319 (* 1 = 0.00320319 loss)
I0521 10:36:33.625551  3675 sgd_solver.cpp:138] Iteration 19780, lr = 5e-05
I0521 10:36:37.146522  3675 solver.cpp:243] Iteration 19800, loss = 0.00446948
I0521 10:36:37.146555  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00446937 (* 1 = 0.00446937 loss)
I0521 10:36:37.146576  3675 sgd_solver.cpp:138] Iteration 19800, lr = 5e-05
I0521 10:36:40.668203  3675 solver.cpp:243] Iteration 19820, loss = 0.002291
I0521 10:36:40.668234  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00229089 (* 1 = 0.00229089 loss)
I0521 10:36:40.668256  3675 sgd_solver.cpp:138] Iteration 19820, lr = 5e-05
I0521 10:36:44.183300  3675 solver.cpp:243] Iteration 19840, loss = 0.00342318
I0521 10:36:44.183331  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00342308 (* 1 = 0.00342308 loss)
I0521 10:36:44.183352  3675 sgd_solver.cpp:138] Iteration 19840, lr = 5e-05
I0521 10:36:47.704907  3675 solver.cpp:243] Iteration 19860, loss = 0.00233251
I0521 10:36:47.704938  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0023324 (* 1 = 0.0023324 loss)
I0521 10:36:47.704944  3675 sgd_solver.cpp:138] Iteration 19860, lr = 5e-05
I0521 10:36:51.219982  3675 solver.cpp:243] Iteration 19880, loss = 0.00292891
I0521 10:36:51.220013  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00292881 (* 1 = 0.00292881 loss)
I0521 10:36:51.220018  3675 sgd_solver.cpp:138] Iteration 19880, lr = 5e-05
I0521 10:36:54.733335  3675 solver.cpp:243] Iteration 19900, loss = 0.00223822
I0521 10:36:54.733383  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00223812 (* 1 = 0.00223812 loss)
I0521 10:36:54.733389  3675 sgd_solver.cpp:138] Iteration 19900, lr = 5e-05
I0521 10:36:58.259088  3675 solver.cpp:243] Iteration 19920, loss = 0.00239264
I0521 10:36:58.259181  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00239254 (* 1 = 0.00239254 loss)
I0521 10:36:58.259187  3675 sgd_solver.cpp:138] Iteration 19920, lr = 5e-05
I0521 10:37:01.781466  3675 solver.cpp:243] Iteration 19940, loss = 0.00295066
I0521 10:37:01.781496  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00295055 (* 1 = 0.00295055 loss)
I0521 10:37:01.781502  3675 sgd_solver.cpp:138] Iteration 19940, lr = 5e-05
I0521 10:37:05.304368  3675 solver.cpp:243] Iteration 19960, loss = 0.0056651
I0521 10:37:05.304400  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.005665 (* 1 = 0.005665 loss)
I0521 10:37:05.304405  3675 sgd_solver.cpp:138] Iteration 19960, lr = 5e-05
I0521 10:37:08.819957  3675 solver.cpp:243] Iteration 19980, loss = 0.00264091
I0521 10:37:08.819988  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00264081 (* 1 = 0.00264081 loss)
I0521 10:37:08.819993  3675 sgd_solver.cpp:138] Iteration 19980, lr = 5e-05
I0521 10:37:12.207705  3675 solver.cpp:596] Snapshotting to binary proto file models/LPR/lpr_resnet_lstm_iter_20000.caffemodel
I0521 10:37:12.239123  3675 sgd_solver.cpp:307] Snapshotting solver state to binary proto file models/LPR/lpr_resnet_lstm_iter_20000.solverstate
I0521 10:37:12.255393  3675 solver.cpp:358] Iteration 20000, Testing net (#0)
I0521 10:37:16.994336  3675 solver.cpp:425]     Test net output #0: acc = 1
I0521 10:37:16.994365  3675 solver.cpp:425]     Test net output #1: acc = 1
I0521 10:37:16.994371  3675 solver.cpp:425]     Test net output #2: ctcloss = 0.000902163 (* 1 = 0.000902163 loss)
I0521 10:37:17.129422  3675 solver.cpp:243] Iteration 20000, loss = 0.00134699
I0521 10:37:17.129456  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00134689 (* 1 = 0.00134689 loss)
I0521 10:37:17.129462  3675 sgd_solver.cpp:138] Iteration 20000, lr = 2.5e-05
I0521 10:37:20.650002  3675 solver.cpp:243] Iteration 20020, loss = 0.00310482
I0521 10:37:20.650034  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00310472 (* 1 = 0.00310472 loss)
I0521 10:37:20.650040  3675 sgd_solver.cpp:138] Iteration 20020, lr = 2.5e-05
I0521 10:37:24.166646  3675 solver.cpp:243] Iteration 20040, loss = 0.00230225
I0521 10:37:24.166677  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00230214 (* 1 = 0.00230214 loss)
I0521 10:37:24.166682  3675 sgd_solver.cpp:138] Iteration 20040, lr = 2.5e-05
I0521 10:37:27.685925  3675 solver.cpp:243] Iteration 20060, loss = 0.00314393
I0521 10:37:27.685956  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00314383 (* 1 = 0.00314383 loss)
I0521 10:37:27.685962  3675 sgd_solver.cpp:138] Iteration 20060, lr = 2.5e-05
I0521 10:37:31.203912  3675 solver.cpp:243] Iteration 20080, loss = 0.00217075
I0521 10:37:31.204088  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00217065 (* 1 = 0.00217065 loss)
I0521 10:37:31.204097  3675 sgd_solver.cpp:138] Iteration 20080, lr = 2.5e-05
I0521 10:37:34.724025  3675 solver.cpp:243] Iteration 20100, loss = 0.00261208
I0521 10:37:34.724056  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00261198 (* 1 = 0.00261198 loss)
I0521 10:37:34.724061  3675 sgd_solver.cpp:138] Iteration 20100, lr = 2.5e-05
I0521 10:37:38.242117  3675 solver.cpp:243] Iteration 20120, loss = 0.00295079
I0521 10:37:38.242149  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00295069 (* 1 = 0.00295069 loss)
I0521 10:37:38.242154  3675 sgd_solver.cpp:138] Iteration 20120, lr = 2.5e-05
I0521 10:37:41.756248  3675 solver.cpp:243] Iteration 20140, loss = 0.00231659
I0521 10:37:41.756279  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00231649 (* 1 = 0.00231649 loss)
I0521 10:37:41.756284  3675 sgd_solver.cpp:138] Iteration 20140, lr = 2.5e-05
I0521 10:37:45.275032  3675 solver.cpp:243] Iteration 20160, loss = 0.00269102
I0521 10:37:45.275063  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00269092 (* 1 = 0.00269092 loss)
I0521 10:37:45.275084  3675 sgd_solver.cpp:138] Iteration 20160, lr = 2.5e-05
I0521 10:37:48.788457  3675 solver.cpp:243] Iteration 20180, loss = 0.00219099
I0521 10:37:48.788489  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00219089 (* 1 = 0.00219089 loss)
I0521 10:37:48.788494  3675 sgd_solver.cpp:138] Iteration 20180, lr = 2.5e-05
I0521 10:37:52.307461  3675 solver.cpp:243] Iteration 20200, loss = 0.00188875
I0521 10:37:52.307493  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00188865 (* 1 = 0.00188865 loss)
I0521 10:37:52.307498  3675 sgd_solver.cpp:138] Iteration 20200, lr = 2.5e-05
I0521 10:37:55.831799  3675 solver.cpp:243] Iteration 20220, loss = 0.00275908
I0521 10:37:55.831830  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00275898 (* 1 = 0.00275898 loss)
I0521 10:37:55.831836  3675 sgd_solver.cpp:138] Iteration 20220, lr = 2.5e-05
I0521 10:37:59.345576  3675 solver.cpp:243] Iteration 20240, loss = 0.00232057
I0521 10:37:59.345605  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00232047 (* 1 = 0.00232047 loss)
I0521 10:37:59.345611  3675 sgd_solver.cpp:138] Iteration 20240, lr = 2.5e-05
I0521 10:38:02.863682  3675 solver.cpp:243] Iteration 20260, loss = 0.0026868
I0521 10:38:02.863857  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00268669 (* 1 = 0.00268669 loss)
I0521 10:38:02.863864  3675 sgd_solver.cpp:138] Iteration 20260, lr = 2.5e-05
I0521 10:38:06.383903  3675 solver.cpp:243] Iteration 20280, loss = 0.00248165
I0521 10:38:06.383934  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00248155 (* 1 = 0.00248155 loss)
I0521 10:38:06.383939  3675 sgd_solver.cpp:138] Iteration 20280, lr = 2.5e-05
I0521 10:38:09.899638  3675 solver.cpp:243] Iteration 20300, loss = 0.00452236
I0521 10:38:09.899669  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00452226 (* 1 = 0.00452226 loss)
I0521 10:38:09.899690  3675 sgd_solver.cpp:138] Iteration 20300, lr = 2.5e-05
I0521 10:38:13.421452  3675 solver.cpp:243] Iteration 20320, loss = 0.00283337
I0521 10:38:13.421481  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00283327 (* 1 = 0.00283327 loss)
I0521 10:38:13.421486  3675 sgd_solver.cpp:138] Iteration 20320, lr = 2.5e-05
I0521 10:38:16.939770  3675 solver.cpp:243] Iteration 20340, loss = 0.0047975
I0521 10:38:16.939800  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0047974 (* 1 = 0.0047974 loss)
I0521 10:38:16.939806  3675 sgd_solver.cpp:138] Iteration 20340, lr = 2.5e-05
I0521 10:38:20.459756  3675 solver.cpp:243] Iteration 20360, loss = 0.00173253
I0521 10:38:20.459787  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00173243 (* 1 = 0.00173243 loss)
I0521 10:38:20.459794  3675 sgd_solver.cpp:138] Iteration 20360, lr = 2.5e-05
I0521 10:38:23.982415  3675 solver.cpp:243] Iteration 20380, loss = 0.00270301
I0521 10:38:23.982446  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00270291 (* 1 = 0.00270291 loss)
I0521 10:38:23.982452  3675 sgd_solver.cpp:138] Iteration 20380, lr = 2.5e-05
I0521 10:38:27.501718  3675 solver.cpp:243] Iteration 20400, loss = 0.00206814
I0521 10:38:27.501749  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00206804 (* 1 = 0.00206804 loss)
I0521 10:38:27.501754  3675 sgd_solver.cpp:138] Iteration 20400, lr = 2.5e-05
I0521 10:38:31.019451  3675 solver.cpp:243] Iteration 20420, loss = 0.00383012
I0521 10:38:31.019482  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00383002 (* 1 = 0.00383002 loss)
I0521 10:38:31.019488  3675 sgd_solver.cpp:138] Iteration 20420, lr = 2.5e-05
I0521 10:38:34.538556  3675 solver.cpp:243] Iteration 20440, loss = 0.003211
I0521 10:38:34.538686  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0032109 (* 1 = 0.0032109 loss)
I0521 10:38:34.538692  3675 sgd_solver.cpp:138] Iteration 20440, lr = 2.5e-05
I0521 10:38:38.055861  3675 solver.cpp:243] Iteration 20460, loss = 0.00437085
I0521 10:38:38.055892  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00437075 (* 1 = 0.00437075 loss)
I0521 10:38:38.055897  3675 sgd_solver.cpp:138] Iteration 20460, lr = 2.5e-05
I0521 10:38:41.573585  3675 solver.cpp:243] Iteration 20480, loss = 0.00267203
I0521 10:38:41.573616  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00267193 (* 1 = 0.00267193 loss)
I0521 10:38:41.573622  3675 sgd_solver.cpp:138] Iteration 20480, lr = 2.5e-05
I0521 10:38:45.089169  3675 solver.cpp:243] Iteration 20500, loss = 0.00209782
I0521 10:38:45.089198  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00209772 (* 1 = 0.00209772 loss)
I0521 10:38:45.089221  3675 sgd_solver.cpp:138] Iteration 20500, lr = 2.5e-05
I0521 10:38:48.606824  3675 solver.cpp:243] Iteration 20520, loss = 0.00319209
I0521 10:38:48.606854  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00319199 (* 1 = 0.00319199 loss)
I0521 10:38:48.606860  3675 sgd_solver.cpp:138] Iteration 20520, lr = 2.5e-05
I0521 10:38:52.123955  3675 solver.cpp:243] Iteration 20540, loss = 0.00254194
I0521 10:38:52.123986  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00254183 (* 1 = 0.00254183 loss)
I0521 10:38:52.123991  3675 sgd_solver.cpp:138] Iteration 20540, lr = 2.5e-05
I0521 10:38:55.639227  3675 solver.cpp:243] Iteration 20560, loss = 0.00247093
I0521 10:38:55.639257  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00247083 (* 1 = 0.00247083 loss)
I0521 10:38:55.639279  3675 sgd_solver.cpp:138] Iteration 20560, lr = 2.5e-05
I0521 10:38:59.156816  3675 solver.cpp:243] Iteration 20580, loss = 0.00283839
I0521 10:38:59.156862  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00283829 (* 1 = 0.00283829 loss)
I0521 10:38:59.156869  3675 sgd_solver.cpp:138] Iteration 20580, lr = 2.5e-05
I0521 10:39:02.677022  3675 solver.cpp:243] Iteration 20600, loss = 0.00229631
I0521 10:39:02.677053  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00229621 (* 1 = 0.00229621 loss)
I0521 10:39:02.677058  3675 sgd_solver.cpp:138] Iteration 20600, lr = 2.5e-05
I0521 10:39:06.201262  3675 solver.cpp:243] Iteration 20620, loss = 0.00197521
I0521 10:39:06.201380  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00197511 (* 1 = 0.00197511 loss)
I0521 10:39:06.201390  3675 sgd_solver.cpp:138] Iteration 20620, lr = 2.5e-05
I0521 10:39:09.716763  3675 solver.cpp:243] Iteration 20640, loss = 0.00253117
I0521 10:39:09.716797  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00253107 (* 1 = 0.00253107 loss)
I0521 10:39:09.716802  3675 sgd_solver.cpp:138] Iteration 20640, lr = 2.5e-05
I0521 10:39:13.233167  3675 solver.cpp:243] Iteration 20660, loss = 0.00358177
I0521 10:39:13.233199  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00358167 (* 1 = 0.00358167 loss)
I0521 10:39:13.233206  3675 sgd_solver.cpp:138] Iteration 20660, lr = 2.5e-05
I0521 10:39:16.748088  3675 solver.cpp:243] Iteration 20680, loss = 0.00234051
I0521 10:39:16.748118  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0023404 (* 1 = 0.0023404 loss)
I0521 10:39:16.748123  3675 sgd_solver.cpp:138] Iteration 20680, lr = 2.5e-05
I0521 10:39:20.263154  3675 solver.cpp:243] Iteration 20700, loss = 0.00228617
I0521 10:39:20.263185  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00228607 (* 1 = 0.00228607 loss)
I0521 10:39:20.263206  3675 sgd_solver.cpp:138] Iteration 20700, lr = 2.5e-05
I0521 10:39:23.778627  3675 solver.cpp:243] Iteration 20720, loss = 0.003337
I0521 10:39:23.778658  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0033369 (* 1 = 0.0033369 loss)
I0521 10:39:23.778663  3675 sgd_solver.cpp:138] Iteration 20720, lr = 2.5e-05
I0521 10:39:27.297505  3675 solver.cpp:243] Iteration 20740, loss = 0.00192529
I0521 10:39:27.297538  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00192519 (* 1 = 0.00192519 loss)
I0521 10:39:27.297544  3675 sgd_solver.cpp:138] Iteration 20740, lr = 2.5e-05
I0521 10:39:30.810029  3675 solver.cpp:243] Iteration 20760, loss = 0.00172075
I0521 10:39:30.810060  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00172065 (* 1 = 0.00172065 loss)
I0521 10:39:30.810065  3675 sgd_solver.cpp:138] Iteration 20760, lr = 2.5e-05
I0521 10:39:34.323218  3675 solver.cpp:243] Iteration 20780, loss = 0.00253651
I0521 10:39:34.323248  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00253641 (* 1 = 0.00253641 loss)
I0521 10:39:34.323254  3675 sgd_solver.cpp:138] Iteration 20780, lr = 2.5e-05
I0521 10:39:37.840631  3675 solver.cpp:243] Iteration 20800, loss = 0.00265866
I0521 10:39:37.840795  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00265856 (* 1 = 0.00265856 loss)
I0521 10:39:37.840803  3675 sgd_solver.cpp:138] Iteration 20800, lr = 2.5e-05
I0521 10:39:41.355201  3675 solver.cpp:243] Iteration 20820, loss = 0.00288948
I0521 10:39:41.355232  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00288938 (* 1 = 0.00288938 loss)
I0521 10:39:41.355238  3675 sgd_solver.cpp:138] Iteration 20820, lr = 2.5e-05
I0521 10:39:44.868942  3675 solver.cpp:243] Iteration 20840, loss = 0.00270448
I0521 10:39:44.868971  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00270438 (* 1 = 0.00270438 loss)
I0521 10:39:44.868978  3675 sgd_solver.cpp:138] Iteration 20840, lr = 2.5e-05
I0521 10:39:48.388891  3675 solver.cpp:243] Iteration 20860, loss = 0.00243263
I0521 10:39:48.388922  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00243253 (* 1 = 0.00243253 loss)
I0521 10:39:48.388928  3675 sgd_solver.cpp:138] Iteration 20860, lr = 2.5e-05
I0521 10:39:51.841665  3675 solver.cpp:243] Iteration 20880, loss = 0.00276861
I0521 10:39:51.841694  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00276851 (* 1 = 0.00276851 loss)
I0521 10:39:51.841717  3675 sgd_solver.cpp:138] Iteration 20880, lr = 2.5e-05
I0521 10:39:55.357537  3675 solver.cpp:243] Iteration 20900, loss = 0.00315577
I0521 10:39:55.357568  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00315567 (* 1 = 0.00315567 loss)
I0521 10:39:55.357574  3675 sgd_solver.cpp:138] Iteration 20900, lr = 2.5e-05
I0521 10:39:58.876029  3675 solver.cpp:243] Iteration 20920, loss = 0.00244006
I0521 10:39:58.876060  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00243996 (* 1 = 0.00243996 loss)
I0521 10:39:58.876081  3675 sgd_solver.cpp:138] Iteration 20920, lr = 2.5e-05
I0521 10:40:02.394435  3675 solver.cpp:243] Iteration 20940, loss = 0.00216454
I0521 10:40:02.394467  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00216444 (* 1 = 0.00216444 loss)
I0521 10:40:02.394474  3675 sgd_solver.cpp:138] Iteration 20940, lr = 2.5e-05
I0521 10:40:05.911675  3675 solver.cpp:243] Iteration 20960, loss = 0.00291524
I0521 10:40:05.911706  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00291514 (* 1 = 0.00291514 loss)
I0521 10:40:05.911712  3675 sgd_solver.cpp:138] Iteration 20960, lr = 2.5e-05
I0521 10:40:09.425246  3675 solver.cpp:243] Iteration 20980, loss = 0.00302312
I0521 10:40:09.425410  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00302301 (* 1 = 0.00302301 loss)
I0521 10:40:09.425418  3675 sgd_solver.cpp:138] Iteration 20980, lr = 2.5e-05
I0521 10:40:12.814496  3675 solver.cpp:358] Iteration 21000, Testing net (#0)
I0521 10:40:17.546612  3675 solver.cpp:425]     Test net output #0: acc = 1
I0521 10:40:17.546641  3675 solver.cpp:425]     Test net output #1: acc = 1
I0521 10:40:17.546648  3675 solver.cpp:425]     Test net output #2: ctcloss = 0.000879927 (* 1 = 0.000879927 loss)
I0521 10:40:17.682037  3675 solver.cpp:243] Iteration 21000, loss = 0.00196399
I0521 10:40:17.682066  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00196389 (* 1 = 0.00196389 loss)
I0521 10:40:17.682072  3675 sgd_solver.cpp:138] Iteration 21000, lr = 2.5e-05
I0521 10:40:21.197248  3675 solver.cpp:243] Iteration 21020, loss = 0.00201346
I0521 10:40:21.197281  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00201336 (* 1 = 0.00201336 loss)
I0521 10:40:21.197288  3675 sgd_solver.cpp:138] Iteration 21020, lr = 2.5e-05
I0521 10:40:24.710433  3675 solver.cpp:243] Iteration 21040, loss = 0.00265113
I0521 10:40:24.710464  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00265103 (* 1 = 0.00265103 loss)
I0521 10:40:24.710470  3675 sgd_solver.cpp:138] Iteration 21040, lr = 2.5e-05
I0521 10:40:28.225817  3675 solver.cpp:243] Iteration 21060, loss = 0.0031831
I0521 10:40:28.225847  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.003183 (* 1 = 0.003183 loss)
I0521 10:40:28.225852  3675 sgd_solver.cpp:138] Iteration 21060, lr = 2.5e-05
I0521 10:40:31.740779  3675 solver.cpp:243] Iteration 21080, loss = 0.00246576
I0521 10:40:31.740813  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00246565 (* 1 = 0.00246565 loss)
I0521 10:40:31.740818  3675 sgd_solver.cpp:138] Iteration 21080, lr = 2.5e-05
I0521 10:40:35.258472  3675 solver.cpp:243] Iteration 21100, loss = 0.00273411
I0521 10:40:35.258502  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00273401 (* 1 = 0.00273401 loss)
I0521 10:40:35.258508  3675 sgd_solver.cpp:138] Iteration 21100, lr = 2.5e-05
I0521 10:40:38.773831  3675 solver.cpp:243] Iteration 21120, loss = 0.00253339
I0521 10:40:38.773861  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00253329 (* 1 = 0.00253329 loss)
I0521 10:40:38.773867  3675 sgd_solver.cpp:138] Iteration 21120, lr = 2.5e-05
I0521 10:40:42.291575  3675 solver.cpp:243] Iteration 21140, loss = 0.0032999
I0521 10:40:42.291728  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0032998 (* 1 = 0.0032998 loss)
I0521 10:40:42.291735  3675 sgd_solver.cpp:138] Iteration 21140, lr = 2.5e-05
I0521 10:40:45.810066  3675 solver.cpp:243] Iteration 21160, loss = 0.00422981
I0521 10:40:45.810096  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00422971 (* 1 = 0.00422971 loss)
I0521 10:40:45.810102  3675 sgd_solver.cpp:138] Iteration 21160, lr = 2.5e-05
I0521 10:40:49.324137  3675 solver.cpp:243] Iteration 21180, loss = 0.00221718
I0521 10:40:49.324168  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00221708 (* 1 = 0.00221708 loss)
I0521 10:40:49.324173  3675 sgd_solver.cpp:138] Iteration 21180, lr = 2.5e-05
I0521 10:40:52.838843  3675 solver.cpp:243] Iteration 21200, loss = 0.00267199
I0521 10:40:52.838873  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00267189 (* 1 = 0.00267189 loss)
I0521 10:40:52.838878  3675 sgd_solver.cpp:138] Iteration 21200, lr = 2.5e-05
I0521 10:40:56.351593  3675 solver.cpp:243] Iteration 21220, loss = 0.00198189
I0521 10:40:56.351625  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00198179 (* 1 = 0.00198179 loss)
I0521 10:40:56.351630  3675 sgd_solver.cpp:138] Iteration 21220, lr = 2.5e-05
I0521 10:40:59.858386  3675 solver.cpp:243] Iteration 21240, loss = 0.0019689
I0521 10:40:59.858417  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0019688 (* 1 = 0.0019688 loss)
I0521 10:40:59.858422  3675 sgd_solver.cpp:138] Iteration 21240, lr = 2.5e-05
I0521 10:41:03.375115  3675 solver.cpp:243] Iteration 21260, loss = 0.00243205
I0521 10:41:03.375146  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00243195 (* 1 = 0.00243195 loss)
I0521 10:41:03.375151  3675 sgd_solver.cpp:138] Iteration 21260, lr = 2.5e-05
I0521 10:41:06.882879  3675 solver.cpp:243] Iteration 21280, loss = 0.00362474
I0521 10:41:06.882910  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00362464 (* 1 = 0.00362464 loss)
I0521 10:41:06.882915  3675 sgd_solver.cpp:138] Iteration 21280, lr = 2.5e-05
I0521 10:41:10.394815  3675 solver.cpp:243] Iteration 21300, loss = 0.00301331
I0521 10:41:10.394850  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00301321 (* 1 = 0.00301321 loss)
I0521 10:41:10.394855  3675 sgd_solver.cpp:138] Iteration 21300, lr = 2.5e-05
I0521 10:41:13.906162  3675 solver.cpp:243] Iteration 21320, loss = 0.00295021
I0521 10:41:13.906288  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00295011 (* 1 = 0.00295011 loss)
I0521 10:41:13.906294  3675 sgd_solver.cpp:138] Iteration 21320, lr = 2.5e-05
I0521 10:41:17.423560  3675 solver.cpp:243] Iteration 21340, loss = 0.00322853
I0521 10:41:17.423590  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00322843 (* 1 = 0.00322843 loss)
I0521 10:41:17.423611  3675 sgd_solver.cpp:138] Iteration 21340, lr = 2.5e-05
I0521 10:41:20.937996  3675 solver.cpp:243] Iteration 21360, loss = 0.00270025
I0521 10:41:20.938028  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00270014 (* 1 = 0.00270014 loss)
I0521 10:41:20.938033  3675 sgd_solver.cpp:138] Iteration 21360, lr = 2.5e-05
I0521 10:41:24.449579  3675 solver.cpp:243] Iteration 21380, loss = 0.00223849
I0521 10:41:24.449609  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00223839 (* 1 = 0.00223839 loss)
I0521 10:41:24.449615  3675 sgd_solver.cpp:138] Iteration 21380, lr = 2.5e-05
I0521 10:41:27.967622  3675 solver.cpp:243] Iteration 21400, loss = 0.0024627
I0521 10:41:27.967653  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0024626 (* 1 = 0.0024626 loss)
I0521 10:41:27.967658  3675 sgd_solver.cpp:138] Iteration 21400, lr = 2.5e-05
I0521 10:41:31.481496  3675 solver.cpp:243] Iteration 21420, loss = 0.00230242
I0521 10:41:31.481528  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00230232 (* 1 = 0.00230232 loss)
I0521 10:41:31.481534  3675 sgd_solver.cpp:138] Iteration 21420, lr = 2.5e-05
I0521 10:41:34.998435  3675 solver.cpp:243] Iteration 21440, loss = 0.00360954
I0521 10:41:34.998466  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00360944 (* 1 = 0.00360944 loss)
I0521 10:41:34.998472  3675 sgd_solver.cpp:138] Iteration 21440, lr = 2.5e-05
I0521 10:41:38.513295  3675 solver.cpp:243] Iteration 21460, loss = 0.00159278
I0521 10:41:38.513325  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00159267 (* 1 = 0.00159267 loss)
I0521 10:41:38.513330  3675 sgd_solver.cpp:138] Iteration 21460, lr = 2.5e-05
I0521 10:41:42.026971  3675 solver.cpp:243] Iteration 21480, loss = 0.00349375
I0521 10:41:42.027002  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00349365 (* 1 = 0.00349365 loss)
I0521 10:41:42.027009  3675 sgd_solver.cpp:138] Iteration 21480, lr = 2.5e-05
I0521 10:41:45.538939  3675 solver.cpp:243] Iteration 21500, loss = 0.00192288
I0521 10:41:45.539096  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00192278 (* 1 = 0.00192278 loss)
I0521 10:41:45.539104  3675 sgd_solver.cpp:138] Iteration 21500, lr = 2.5e-05
I0521 10:41:49.055203  3675 solver.cpp:243] Iteration 21520, loss = 0.0029191
I0521 10:41:49.055235  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00291899 (* 1 = 0.00291899 loss)
I0521 10:41:49.055240  3675 sgd_solver.cpp:138] Iteration 21520, lr = 2.5e-05
I0521 10:41:52.572391  3675 solver.cpp:243] Iteration 21540, loss = 0.00677139
I0521 10:41:52.572423  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00677129 (* 1 = 0.00677129 loss)
I0521 10:41:52.572428  3675 sgd_solver.cpp:138] Iteration 21540, lr = 2.5e-05
I0521 10:41:56.082157  3675 solver.cpp:243] Iteration 21560, loss = 0.00282246
I0521 10:41:56.082188  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00282236 (* 1 = 0.00282236 loss)
I0521 10:41:56.082211  3675 sgd_solver.cpp:138] Iteration 21560, lr = 2.5e-05
I0521 10:41:59.597225  3675 solver.cpp:243] Iteration 21580, loss = 0.00287988
I0521 10:41:59.597257  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00287978 (* 1 = 0.00287978 loss)
I0521 10:41:59.597262  3675 sgd_solver.cpp:138] Iteration 21580, lr = 2.5e-05
I0521 10:42:03.113349  3675 solver.cpp:243] Iteration 21600, loss = 0.00404336
I0521 10:42:03.113382  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00404326 (* 1 = 0.00404326 loss)
I0521 10:42:03.113389  3675 sgd_solver.cpp:138] Iteration 21600, lr = 2.5e-05
I0521 10:42:06.625093  3675 solver.cpp:243] Iteration 21620, loss = 0.00273197
I0521 10:42:06.625124  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00273187 (* 1 = 0.00273187 loss)
I0521 10:42:06.625146  3675 sgd_solver.cpp:138] Iteration 21620, lr = 2.5e-05
I0521 10:42:10.145557  3675 solver.cpp:243] Iteration 21640, loss = 0.0031
I0521 10:42:10.145588  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0030999 (* 1 = 0.0030999 loss)
I0521 10:42:10.145593  3675 sgd_solver.cpp:138] Iteration 21640, lr = 2.5e-05
I0521 10:42:13.659349  3675 solver.cpp:243] Iteration 21660, loss = 0.00286662
I0521 10:42:13.659380  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00286652 (* 1 = 0.00286652 loss)
I0521 10:42:13.659386  3675 sgd_solver.cpp:138] Iteration 21660, lr = 2.5e-05
I0521 10:42:17.180171  3675 solver.cpp:243] Iteration 21680, loss = 0.00187527
I0521 10:42:17.180330  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00187517 (* 1 = 0.00187517 loss)
I0521 10:42:17.180337  3675 sgd_solver.cpp:138] Iteration 21680, lr = 2.5e-05
I0521 10:42:20.697331  3675 solver.cpp:243] Iteration 21700, loss = 0.00285606
I0521 10:42:20.697362  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00285596 (* 1 = 0.00285596 loss)
I0521 10:42:20.697367  3675 sgd_solver.cpp:138] Iteration 21700, lr = 2.5e-05
I0521 10:42:24.209528  3675 solver.cpp:243] Iteration 21720, loss = 0.00215319
I0521 10:42:24.209561  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00215309 (* 1 = 0.00215309 loss)
I0521 10:42:24.209568  3675 sgd_solver.cpp:138] Iteration 21720, lr = 2.5e-05
I0521 10:42:27.723973  3675 solver.cpp:243] Iteration 21740, loss = 0.00227231
I0521 10:42:27.724005  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0022722 (* 1 = 0.0022722 loss)
I0521 10:42:27.724010  3675 sgd_solver.cpp:138] Iteration 21740, lr = 2.5e-05
I0521 10:42:31.235030  3675 solver.cpp:243] Iteration 21760, loss = 0.0026958
I0521 10:42:31.235060  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0026957 (* 1 = 0.0026957 loss)
I0521 10:42:31.235066  3675 sgd_solver.cpp:138] Iteration 21760, lr = 2.5e-05
I0521 10:42:34.750610  3675 solver.cpp:243] Iteration 21780, loss = 0.0027493
I0521 10:42:34.750641  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0027492 (* 1 = 0.0027492 loss)
I0521 10:42:34.750648  3675 sgd_solver.cpp:138] Iteration 21780, lr = 2.5e-05
I0521 10:42:38.263818  3675 solver.cpp:243] Iteration 21800, loss = 0.00291578
I0521 10:42:38.263849  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00291568 (* 1 = 0.00291568 loss)
I0521 10:42:38.263855  3675 sgd_solver.cpp:138] Iteration 21800, lr = 2.5e-05
I0521 10:42:41.777349  3675 solver.cpp:243] Iteration 21820, loss = 0.00213887
I0521 10:42:41.777380  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00213877 (* 1 = 0.00213877 loss)
I0521 10:42:41.777401  3675 sgd_solver.cpp:138] Iteration 21820, lr = 2.5e-05
I0521 10:42:45.294396  3675 solver.cpp:243] Iteration 21840, loss = 0.00317959
I0521 10:42:45.294428  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00317949 (* 1 = 0.00317949 loss)
I0521 10:42:45.294433  3675 sgd_solver.cpp:138] Iteration 21840, lr = 2.5e-05
I0521 10:42:48.812521  3675 solver.cpp:243] Iteration 21860, loss = 0.00206034
I0521 10:42:48.812696  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00206024 (* 1 = 0.00206024 loss)
I0521 10:42:48.812705  3675 sgd_solver.cpp:138] Iteration 21860, lr = 2.5e-05
I0521 10:42:52.329270  3675 solver.cpp:243] Iteration 21880, loss = 0.00379476
I0521 10:42:52.329303  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00379465 (* 1 = 0.00379465 loss)
I0521 10:42:52.329308  3675 sgd_solver.cpp:138] Iteration 21880, lr = 2.5e-05
I0521 10:42:55.846424  3675 solver.cpp:243] Iteration 21900, loss = 0.00282666
I0521 10:42:55.846453  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00282656 (* 1 = 0.00282656 loss)
I0521 10:42:55.846459  3675 sgd_solver.cpp:138] Iteration 21900, lr = 2.5e-05
I0521 10:42:59.359804  3675 solver.cpp:243] Iteration 21920, loss = 0.00269818
I0521 10:42:59.359835  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00269808 (* 1 = 0.00269808 loss)
I0521 10:42:59.359841  3675 sgd_solver.cpp:138] Iteration 21920, lr = 2.5e-05
I0521 10:43:02.875094  3675 solver.cpp:243] Iteration 21940, loss = 0.00180952
I0521 10:43:02.875124  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00180942 (* 1 = 0.00180942 loss)
I0521 10:43:02.875130  3675 sgd_solver.cpp:138] Iteration 21940, lr = 2.5e-05
I0521 10:43:06.391033  3675 solver.cpp:243] Iteration 21960, loss = 0.00257942
I0521 10:43:06.391063  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00257931 (* 1 = 0.00257931 loss)
I0521 10:43:06.391068  3675 sgd_solver.cpp:138] Iteration 21960, lr = 2.5e-05
I0521 10:43:09.905128  3675 solver.cpp:243] Iteration 21980, loss = 0.00191328
I0521 10:43:09.905158  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00191317 (* 1 = 0.00191317 loss)
I0521 10:43:09.905164  3675 sgd_solver.cpp:138] Iteration 21980, lr = 2.5e-05
I0521 10:43:13.293190  3675 solver.cpp:596] Snapshotting to binary proto file models/LPR/lpr_resnet_lstm_iter_22000.caffemodel
I0521 10:43:13.320158  3675 sgd_solver.cpp:307] Snapshotting solver state to binary proto file models/LPR/lpr_resnet_lstm_iter_22000.solverstate
I0521 10:43:13.334928  3675 solver.cpp:358] Iteration 22000, Testing net (#0)
I0521 10:43:18.066162  3675 solver.cpp:425]     Test net output #0: acc = 1
I0521 10:43:18.066190  3675 solver.cpp:425]     Test net output #1: acc = 1
I0521 10:43:18.066200  3675 solver.cpp:425]     Test net output #2: ctcloss = 0.000854691 (* 1 = 0.000854691 loss)
I0521 10:43:18.200974  3675 solver.cpp:243] Iteration 22000, loss = 0.00276786
I0521 10:43:18.201004  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00276775 (* 1 = 0.00276775 loss)
I0521 10:43:18.201010  3675 sgd_solver.cpp:138] Iteration 22000, lr = 2.5e-05
I0521 10:43:21.718588  3675 solver.cpp:243] Iteration 22020, loss = 0.00224212
I0521 10:43:21.718750  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00224202 (* 1 = 0.00224202 loss)
I0521 10:43:21.718757  3675 sgd_solver.cpp:138] Iteration 22020, lr = 2.5e-05
I0521 10:43:25.239744  3675 solver.cpp:243] Iteration 22040, loss = 0.00265515
I0521 10:43:25.239775  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00265504 (* 1 = 0.00265504 loss)
I0521 10:43:25.239797  3675 sgd_solver.cpp:138] Iteration 22040, lr = 2.5e-05
I0521 10:43:28.754639  3675 solver.cpp:243] Iteration 22060, loss = 0.00238733
I0521 10:43:28.754669  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00238723 (* 1 = 0.00238723 loss)
I0521 10:43:28.754674  3675 sgd_solver.cpp:138] Iteration 22060, lr = 2.5e-05
I0521 10:43:32.267292  3675 solver.cpp:243] Iteration 22080, loss = 0.00216928
I0521 10:43:32.267321  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00216918 (* 1 = 0.00216918 loss)
I0521 10:43:32.267328  3675 sgd_solver.cpp:138] Iteration 22080, lr = 2.5e-05
I0521 10:43:35.782493  3675 solver.cpp:243] Iteration 22100, loss = 0.00255747
I0521 10:43:35.782526  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00255736 (* 1 = 0.00255736 loss)
I0521 10:43:35.782531  3675 sgd_solver.cpp:138] Iteration 22100, lr = 2.5e-05
I0521 10:43:39.298015  3675 solver.cpp:243] Iteration 22120, loss = 0.00243437
I0521 10:43:39.298048  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00243427 (* 1 = 0.00243427 loss)
I0521 10:43:39.298054  3675 sgd_solver.cpp:138] Iteration 22120, lr = 2.5e-05
I0521 10:43:42.812315  3675 solver.cpp:243] Iteration 22140, loss = 0.00374701
I0521 10:43:42.812346  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00374691 (* 1 = 0.00374691 loss)
I0521 10:43:42.812352  3675 sgd_solver.cpp:138] Iteration 22140, lr = 2.5e-05
I0521 10:43:46.328922  3675 solver.cpp:243] Iteration 22160, loss = 0.00205856
I0521 10:43:46.328954  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00205846 (* 1 = 0.00205846 loss)
I0521 10:43:46.328961  3675 sgd_solver.cpp:138] Iteration 22160, lr = 2.5e-05
I0521 10:43:49.779011  3675 solver.cpp:243] Iteration 22180, loss = 0.00454534
I0521 10:43:49.779042  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00454524 (* 1 = 0.00454524 loss)
I0521 10:43:49.779047  3675 sgd_solver.cpp:138] Iteration 22180, lr = 2.5e-05
I0521 10:43:53.294497  3675 solver.cpp:243] Iteration 22200, loss = 0.00314336
I0521 10:43:53.294611  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00314326 (* 1 = 0.00314326 loss)
I0521 10:43:53.294620  3675 sgd_solver.cpp:138] Iteration 22200, lr = 2.5e-05
I0521 10:43:56.809590  3675 solver.cpp:243] Iteration 22220, loss = 0.00302526
I0521 10:43:56.809621  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00302516 (* 1 = 0.00302516 loss)
I0521 10:43:56.809628  3675 sgd_solver.cpp:138] Iteration 22220, lr = 2.5e-05
I0521 10:44:00.325748  3675 solver.cpp:243] Iteration 22240, loss = 0.00369211
I0521 10:44:00.325780  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.003692 (* 1 = 0.003692 loss)
I0521 10:44:00.325786  3675 sgd_solver.cpp:138] Iteration 22240, lr = 2.5e-05
I0521 10:44:03.842209  3675 solver.cpp:243] Iteration 22260, loss = 0.00234118
I0521 10:44:03.842242  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00234108 (* 1 = 0.00234108 loss)
I0521 10:44:03.842262  3675 sgd_solver.cpp:138] Iteration 22260, lr = 2.5e-05
I0521 10:44:07.358785  3675 solver.cpp:243] Iteration 22280, loss = 0.00280211
I0521 10:44:07.358816  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.002802 (* 1 = 0.002802 loss)
I0521 10:44:07.358822  3675 sgd_solver.cpp:138] Iteration 22280, lr = 2.5e-05
I0521 10:44:10.873240  3675 solver.cpp:243] Iteration 22300, loss = 0.00178568
I0521 10:44:10.873271  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00178558 (* 1 = 0.00178558 loss)
I0521 10:44:10.873277  3675 sgd_solver.cpp:138] Iteration 22300, lr = 2.5e-05
I0521 10:44:14.392163  3675 solver.cpp:243] Iteration 22320, loss = 0.00307976
I0521 10:44:14.392194  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00307965 (* 1 = 0.00307965 loss)
I0521 10:44:14.392199  3675 sgd_solver.cpp:138] Iteration 22320, lr = 2.5e-05
I0521 10:44:17.910145  3675 solver.cpp:243] Iteration 22340, loss = 0.00347161
I0521 10:44:17.910176  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0034715 (* 1 = 0.0034715 loss)
I0521 10:44:17.910181  3675 sgd_solver.cpp:138] Iteration 22340, lr = 2.5e-05
I0521 10:44:21.426734  3675 solver.cpp:243] Iteration 22360, loss = 0.00446776
I0521 10:44:21.426766  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00446765 (* 1 = 0.00446765 loss)
I0521 10:44:21.426772  3675 sgd_solver.cpp:138] Iteration 22360, lr = 2.5e-05
I0521 10:44:24.940757  3675 solver.cpp:243] Iteration 22380, loss = 0.00177013
I0521 10:44:24.940953  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00177003 (* 1 = 0.00177003 loss)
I0521 10:44:24.940960  3675 sgd_solver.cpp:138] Iteration 22380, lr = 2.5e-05
I0521 10:44:28.457648  3675 solver.cpp:243] Iteration 22400, loss = 0.00180233
I0521 10:44:28.457680  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00180222 (* 1 = 0.00180222 loss)
I0521 10:44:28.457686  3675 sgd_solver.cpp:138] Iteration 22400, lr = 2.5e-05
I0521 10:44:31.968652  3675 solver.cpp:243] Iteration 22420, loss = 0.00333391
I0521 10:44:31.968683  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00333381 (* 1 = 0.00333381 loss)
I0521 10:44:31.968688  3675 sgd_solver.cpp:138] Iteration 22420, lr = 2.5e-05
I0521 10:44:35.482244  3675 solver.cpp:243] Iteration 22440, loss = 0.00658355
I0521 10:44:35.482275  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00658345 (* 1 = 0.00658345 loss)
I0521 10:44:35.482281  3675 sgd_solver.cpp:138] Iteration 22440, lr = 2.5e-05
I0521 10:44:38.993882  3675 solver.cpp:243] Iteration 22460, loss = 0.00189836
I0521 10:44:38.993912  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00189826 (* 1 = 0.00189826 loss)
I0521 10:44:38.993917  3675 sgd_solver.cpp:138] Iteration 22460, lr = 2.5e-05
I0521 10:44:42.504499  3675 solver.cpp:243] Iteration 22480, loss = 0.00302024
I0521 10:44:42.504532  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00302013 (* 1 = 0.00302013 loss)
I0521 10:44:42.504539  3675 sgd_solver.cpp:138] Iteration 22480, lr = 2.5e-05
I0521 10:44:46.021618  3675 solver.cpp:243] Iteration 22500, loss = 0.0024865
I0521 10:44:46.021649  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00248639 (* 1 = 0.00248639 loss)
I0521 10:44:46.021670  3675 sgd_solver.cpp:138] Iteration 22500, lr = 2.5e-05
I0521 10:44:49.533255  3675 solver.cpp:243] Iteration 22520, loss = 0.0029925
I0521 10:44:49.533287  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0029924 (* 1 = 0.0029924 loss)
I0521 10:44:49.533293  3675 sgd_solver.cpp:138] Iteration 22520, lr = 2.5e-05
I0521 10:44:53.047108  3675 solver.cpp:243] Iteration 22540, loss = 0.00347835
I0521 10:44:53.047137  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00347825 (* 1 = 0.00347825 loss)
I0521 10:44:53.047142  3675 sgd_solver.cpp:138] Iteration 22540, lr = 2.5e-05
I0521 10:44:56.560232  3675 solver.cpp:243] Iteration 22560, loss = 0.00210162
I0521 10:44:56.560369  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00210152 (* 1 = 0.00210152 loss)
I0521 10:44:56.560375  3675 sgd_solver.cpp:138] Iteration 22560, lr = 2.5e-05
I0521 10:45:00.068043  3675 solver.cpp:243] Iteration 22580, loss = 0.00202836
I0521 10:45:00.068074  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00202826 (* 1 = 0.00202826 loss)
I0521 10:45:00.068080  3675 sgd_solver.cpp:138] Iteration 22580, lr = 2.5e-05
I0521 10:45:03.582190  3675 solver.cpp:243] Iteration 22600, loss = 0.00298003
I0521 10:45:03.582222  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00297993 (* 1 = 0.00297993 loss)
I0521 10:45:03.582227  3675 sgd_solver.cpp:138] Iteration 22600, lr = 2.5e-05
I0521 10:45:07.098958  3675 solver.cpp:243] Iteration 22620, loss = 0.00182049
I0521 10:45:07.098989  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00182038 (* 1 = 0.00182038 loss)
I0521 10:45:07.098994  3675 sgd_solver.cpp:138] Iteration 22620, lr = 2.5e-05
I0521 10:45:10.612499  3675 solver.cpp:243] Iteration 22640, loss = 0.00237722
I0521 10:45:10.612529  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00237712 (* 1 = 0.00237712 loss)
I0521 10:45:10.612535  3675 sgd_solver.cpp:138] Iteration 22640, lr = 2.5e-05
I0521 10:45:14.124183  3675 solver.cpp:243] Iteration 22660, loss = 0.00176155
I0521 10:45:14.124217  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00176144 (* 1 = 0.00176144 loss)
I0521 10:45:14.124222  3675 sgd_solver.cpp:138] Iteration 22660, lr = 2.5e-05
I0521 10:45:17.638455  3675 solver.cpp:243] Iteration 22680, loss = 0.00201992
I0521 10:45:17.638486  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00201982 (* 1 = 0.00201982 loss)
I0521 10:45:17.638492  3675 sgd_solver.cpp:138] Iteration 22680, lr = 2.5e-05
I0521 10:45:21.157949  3675 solver.cpp:243] Iteration 22700, loss = 0.00196713
I0521 10:45:21.157980  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00196702 (* 1 = 0.00196702 loss)
I0521 10:45:21.157986  3675 sgd_solver.cpp:138] Iteration 22700, lr = 2.5e-05
I0521 10:45:24.673357  3675 solver.cpp:243] Iteration 22720, loss = 0.00354743
I0521 10:45:24.673388  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00354732 (* 1 = 0.00354732 loss)
I0521 10:45:24.673393  3675 sgd_solver.cpp:138] Iteration 22720, lr = 2.5e-05
I0521 10:45:28.194809  3675 solver.cpp:243] Iteration 22740, loss = 0.00385951
I0521 10:45:28.194979  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0038594 (* 1 = 0.0038594 loss)
I0521 10:45:28.194988  3675 sgd_solver.cpp:138] Iteration 22740, lr = 2.5e-05
I0521 10:45:31.706027  3675 solver.cpp:243] Iteration 22760, loss = 0.00213016
I0521 10:45:31.706058  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00213005 (* 1 = 0.00213005 loss)
I0521 10:45:31.706063  3675 sgd_solver.cpp:138] Iteration 22760, lr = 2.5e-05
I0521 10:45:35.227666  3675 solver.cpp:243] Iteration 22780, loss = 0.00167161
I0521 10:45:35.227699  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0016715 (* 1 = 0.0016715 loss)
I0521 10:45:35.227705  3675 sgd_solver.cpp:138] Iteration 22780, lr = 2.5e-05
I0521 10:45:38.746974  3675 solver.cpp:243] Iteration 22800, loss = 0.00193942
I0521 10:45:38.747007  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00193931 (* 1 = 0.00193931 loss)
I0521 10:45:38.747012  3675 sgd_solver.cpp:138] Iteration 22800, lr = 2.5e-05
I0521 10:45:42.267144  3675 solver.cpp:243] Iteration 22820, loss = 0.00208052
I0521 10:45:42.267175  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00208042 (* 1 = 0.00208042 loss)
I0521 10:45:42.267197  3675 sgd_solver.cpp:138] Iteration 22820, lr = 2.5e-05
I0521 10:45:45.783462  3675 solver.cpp:243] Iteration 22840, loss = 0.00199163
I0521 10:45:45.783493  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00199152 (* 1 = 0.00199152 loss)
I0521 10:45:45.783497  3675 sgd_solver.cpp:138] Iteration 22840, lr = 2.5e-05
I0521 10:45:49.294317  3675 solver.cpp:243] Iteration 22860, loss = 0.00251414
I0521 10:45:49.294348  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00251403 (* 1 = 0.00251403 loss)
I0521 10:45:49.294353  3675 sgd_solver.cpp:138] Iteration 22860, lr = 2.5e-05
I0521 10:45:52.810286  3675 solver.cpp:243] Iteration 22880, loss = 0.00210018
I0521 10:45:52.810317  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00210008 (* 1 = 0.00210008 loss)
I0521 10:45:52.810323  3675 sgd_solver.cpp:138] Iteration 22880, lr = 2.5e-05
I0521 10:45:56.333536  3675 solver.cpp:243] Iteration 22900, loss = 0.00285223
I0521 10:45:56.333570  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00285213 (* 1 = 0.00285213 loss)
I0521 10:45:56.333575  3675 sgd_solver.cpp:138] Iteration 22900, lr = 2.5e-05
I0521 10:45:59.853826  3675 solver.cpp:243] Iteration 22920, loss = 0.00257411
I0521 10:45:59.854022  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00257401 (* 1 = 0.00257401 loss)
I0521 10:45:59.854029  3675 sgd_solver.cpp:138] Iteration 22920, lr = 2.5e-05
I0521 10:46:03.368669  3675 solver.cpp:243] Iteration 22940, loss = 0.00356743
I0521 10:46:03.368701  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00356733 (* 1 = 0.00356733 loss)
I0521 10:46:03.368707  3675 sgd_solver.cpp:138] Iteration 22940, lr = 2.5e-05
I0521 10:46:06.881943  3675 solver.cpp:243] Iteration 22960, loss = 0.00296164
I0521 10:46:06.881975  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00296154 (* 1 = 0.00296154 loss)
I0521 10:46:06.881980  3675 sgd_solver.cpp:138] Iteration 22960, lr = 2.5e-05
I0521 10:46:10.398391  3675 solver.cpp:243] Iteration 22980, loss = 0.00381517
I0521 10:46:10.398439  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00381507 (* 1 = 0.00381507 loss)
I0521 10:46:10.398447  3675 sgd_solver.cpp:138] Iteration 22980, lr = 2.5e-05
I0521 10:46:13.785838  3675 solver.cpp:358] Iteration 23000, Testing net (#0)
I0521 10:46:18.517693  3675 solver.cpp:425]     Test net output #0: acc = 1
I0521 10:46:18.517719  3675 solver.cpp:425]     Test net output #1: acc = 1
I0521 10:46:18.517725  3675 solver.cpp:425]     Test net output #2: ctcloss = 0.000841737 (* 1 = 0.000841737 loss)
I0521 10:46:18.652263  3675 solver.cpp:243] Iteration 23000, loss = 0.00325156
I0521 10:46:18.652293  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00325146 (* 1 = 0.00325146 loss)
I0521 10:46:18.652317  3675 sgd_solver.cpp:138] Iteration 23000, lr = 2.5e-05
I0521 10:46:22.171841  3675 solver.cpp:243] Iteration 23020, loss = 0.00205331
I0521 10:46:22.171874  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0020532 (* 1 = 0.0020532 loss)
I0521 10:46:22.171878  3675 sgd_solver.cpp:138] Iteration 23020, lr = 2.5e-05
I0521 10:46:25.688203  3675 solver.cpp:243] Iteration 23040, loss = 0.005215
I0521 10:46:25.688233  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0052149 (* 1 = 0.0052149 loss)
I0521 10:46:25.688238  3675 sgd_solver.cpp:138] Iteration 23040, lr = 2.5e-05
I0521 10:46:29.205898  3675 solver.cpp:243] Iteration 23060, loss = 0.00329051
I0521 10:46:29.205929  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00329041 (* 1 = 0.00329041 loss)
I0521 10:46:29.205935  3675 sgd_solver.cpp:138] Iteration 23060, lr = 2.5e-05
I0521 10:46:32.727664  3675 solver.cpp:243] Iteration 23080, loss = 0.00198282
I0521 10:46:32.727831  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00198271 (* 1 = 0.00198271 loss)
I0521 10:46:32.727839  3675 sgd_solver.cpp:138] Iteration 23080, lr = 2.5e-05
I0521 10:46:36.241158  3675 solver.cpp:243] Iteration 23100, loss = 0.00256414
I0521 10:46:36.241189  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00256403 (* 1 = 0.00256403 loss)
I0521 10:46:36.241194  3675 sgd_solver.cpp:138] Iteration 23100, lr = 2.5e-05
I0521 10:46:39.754792  3675 solver.cpp:243] Iteration 23120, loss = 0.00249372
I0521 10:46:39.754823  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00249362 (* 1 = 0.00249362 loss)
I0521 10:46:39.754829  3675 sgd_solver.cpp:138] Iteration 23120, lr = 2.5e-05
I0521 10:46:43.271242  3675 solver.cpp:243] Iteration 23140, loss = 0.00248581
I0521 10:46:43.271272  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00248571 (* 1 = 0.00248571 loss)
I0521 10:46:43.271277  3675 sgd_solver.cpp:138] Iteration 23140, lr = 2.5e-05
I0521 10:46:46.783952  3675 solver.cpp:243] Iteration 23160, loss = 0.00258994
I0521 10:46:46.783984  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00258983 (* 1 = 0.00258983 loss)
I0521 10:46:46.783989  3675 sgd_solver.cpp:138] Iteration 23160, lr = 2.5e-05
I0521 10:46:50.300885  3675 solver.cpp:243] Iteration 23180, loss = 0.001852
I0521 10:46:50.300916  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0018519 (* 1 = 0.0018519 loss)
I0521 10:46:50.300922  3675 sgd_solver.cpp:138] Iteration 23180, lr = 2.5e-05
I0521 10:46:53.814237  3675 solver.cpp:243] Iteration 23200, loss = 0.00212193
I0521 10:46:53.814267  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00212182 (* 1 = 0.00212182 loss)
I0521 10:46:53.814273  3675 sgd_solver.cpp:138] Iteration 23200, lr = 2.5e-05
I0521 10:46:57.328418  3675 solver.cpp:243] Iteration 23220, loss = 0.00181274
I0521 10:46:57.328447  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00181264 (* 1 = 0.00181264 loss)
I0521 10:46:57.328454  3675 sgd_solver.cpp:138] Iteration 23220, lr = 2.5e-05
I0521 10:47:00.839700  3675 solver.cpp:243] Iteration 23240, loss = 0.00336457
I0521 10:47:00.839730  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00336447 (* 1 = 0.00336447 loss)
I0521 10:47:00.839735  3675 sgd_solver.cpp:138] Iteration 23240, lr = 2.5e-05
I0521 10:47:04.360568  3675 solver.cpp:243] Iteration 23260, loss = 0.00325899
I0521 10:47:04.360735  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00325888 (* 1 = 0.00325888 loss)
I0521 10:47:04.360743  3675 sgd_solver.cpp:138] Iteration 23260, lr = 2.5e-05
I0521 10:47:07.872998  3675 solver.cpp:243] Iteration 23280, loss = 0.00174192
I0521 10:47:07.873029  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00174182 (* 1 = 0.00174182 loss)
I0521 10:47:07.873050  3675 sgd_solver.cpp:138] Iteration 23280, lr = 2.5e-05
I0521 10:47:11.385764  3675 solver.cpp:243] Iteration 23300, loss = 0.00249863
I0521 10:47:11.385795  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00249853 (* 1 = 0.00249853 loss)
I0521 10:47:11.385802  3675 sgd_solver.cpp:138] Iteration 23300, lr = 2.5e-05
I0521 10:47:14.903904  3675 solver.cpp:243] Iteration 23320, loss = 0.00214775
I0521 10:47:14.903935  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00214764 (* 1 = 0.00214764 loss)
I0521 10:47:14.903956  3675 sgd_solver.cpp:138] Iteration 23320, lr = 2.5e-05
I0521 10:47:18.424346  3675 solver.cpp:243] Iteration 23340, loss = 0.0021372
I0521 10:47:18.424376  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0021371 (* 1 = 0.0021371 loss)
I0521 10:47:18.424381  3675 sgd_solver.cpp:138] Iteration 23340, lr = 2.5e-05
I0521 10:47:21.936038  3675 solver.cpp:243] Iteration 23360, loss = 0.002559
I0521 10:47:21.936070  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00255889 (* 1 = 0.00255889 loss)
I0521 10:47:21.936075  3675 sgd_solver.cpp:138] Iteration 23360, lr = 2.5e-05
I0521 10:47:25.451632  3675 solver.cpp:243] Iteration 23380, loss = 0.00238901
I0521 10:47:25.451663  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0023889 (* 1 = 0.0023889 loss)
I0521 10:47:25.451669  3675 sgd_solver.cpp:138] Iteration 23380, lr = 2.5e-05
I0521 10:47:28.968168  3675 solver.cpp:243] Iteration 23400, loss = 0.00208104
I0521 10:47:28.968197  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00208094 (* 1 = 0.00208094 loss)
I0521 10:47:28.968204  3675 sgd_solver.cpp:138] Iteration 23400, lr = 2.5e-05
I0521 10:47:32.482264  3675 solver.cpp:243] Iteration 23420, loss = 0.00262907
I0521 10:47:32.482298  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00262897 (* 1 = 0.00262897 loss)
I0521 10:47:32.482304  3675 sgd_solver.cpp:138] Iteration 23420, lr = 2.5e-05
I0521 10:47:35.997486  3675 solver.cpp:243] Iteration 23440, loss = 0.00222318
I0521 10:47:35.997653  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00222307 (* 1 = 0.00222307 loss)
I0521 10:47:35.997660  3675 sgd_solver.cpp:138] Iteration 23440, lr = 2.5e-05
I0521 10:47:39.514387  3675 solver.cpp:243] Iteration 23460, loss = 0.00243098
I0521 10:47:39.514418  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00243087 (* 1 = 0.00243087 loss)
I0521 10:47:39.514425  3675 sgd_solver.cpp:138] Iteration 23460, lr = 2.5e-05
I0521 10:47:42.964475  3675 solver.cpp:243] Iteration 23480, loss = 0.00301715
I0521 10:47:42.964507  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00301705 (* 1 = 0.00301705 loss)
I0521 10:47:42.964514  3675 sgd_solver.cpp:138] Iteration 23480, lr = 2.5e-05
I0521 10:47:46.481102  3675 solver.cpp:243] Iteration 23500, loss = 0.00259285
I0521 10:47:46.481133  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00259274 (* 1 = 0.00259274 loss)
I0521 10:47:46.481138  3675 sgd_solver.cpp:138] Iteration 23500, lr = 2.5e-05
I0521 10:47:49.989917  3675 solver.cpp:243] Iteration 23520, loss = 0.00280277
I0521 10:47:49.989948  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00280266 (* 1 = 0.00280266 loss)
I0521 10:47:49.989954  3675 sgd_solver.cpp:138] Iteration 23520, lr = 2.5e-05
I0521 10:47:53.505435  3675 solver.cpp:243] Iteration 23540, loss = 0.0017312
I0521 10:47:53.505463  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00173109 (* 1 = 0.00173109 loss)
I0521 10:47:53.505470  3675 sgd_solver.cpp:138] Iteration 23540, lr = 2.5e-05
I0521 10:47:57.019989  3675 solver.cpp:243] Iteration 23560, loss = 0.00804074
I0521 10:47:57.020020  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00804064 (* 1 = 0.00804064 loss)
I0521 10:47:57.020025  3675 sgd_solver.cpp:138] Iteration 23560, lr = 2.5e-05
I0521 10:48:00.532418  3675 solver.cpp:243] Iteration 23580, loss = 0.00197806
I0521 10:48:00.532449  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00197795 (* 1 = 0.00197795 loss)
I0521 10:48:00.532454  3675 sgd_solver.cpp:138] Iteration 23580, lr = 2.5e-05
I0521 10:48:04.049512  3675 solver.cpp:243] Iteration 23600, loss = 0.00244589
I0521 10:48:04.049544  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00244579 (* 1 = 0.00244579 loss)
I0521 10:48:04.049566  3675 sgd_solver.cpp:138] Iteration 23600, lr = 2.5e-05
I0521 10:48:07.565371  3675 solver.cpp:243] Iteration 23620, loss = 0.00161661
I0521 10:48:07.565531  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0016165 (* 1 = 0.0016165 loss)
I0521 10:48:07.565539  3675 sgd_solver.cpp:138] Iteration 23620, lr = 2.5e-05
I0521 10:48:11.078958  3675 solver.cpp:243] Iteration 23640, loss = 0.00217652
I0521 10:48:11.078987  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00217641 (* 1 = 0.00217641 loss)
I0521 10:48:11.078992  3675 sgd_solver.cpp:138] Iteration 23640, lr = 2.5e-05
I0521 10:48:14.587842  3675 solver.cpp:243] Iteration 23660, loss = 0.00179715
I0521 10:48:14.587873  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00179705 (* 1 = 0.00179705 loss)
I0521 10:48:14.587879  3675 sgd_solver.cpp:138] Iteration 23660, lr = 2.5e-05
I0521 10:48:18.103263  3675 solver.cpp:243] Iteration 23680, loss = 0.00336019
I0521 10:48:18.103296  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00336009 (* 1 = 0.00336009 loss)
I0521 10:48:18.103302  3675 sgd_solver.cpp:138] Iteration 23680, lr = 2.5e-05
I0521 10:48:21.613998  3675 solver.cpp:243] Iteration 23700, loss = 0.00264253
I0521 10:48:21.614030  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00264242 (* 1 = 0.00264242 loss)
I0521 10:48:21.614035  3675 sgd_solver.cpp:138] Iteration 23700, lr = 2.5e-05
I0521 10:48:25.126541  3675 solver.cpp:243] Iteration 23720, loss = 0.00305539
I0521 10:48:25.126572  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00305528 (* 1 = 0.00305528 loss)
I0521 10:48:25.126577  3675 sgd_solver.cpp:138] Iteration 23720, lr = 2.5e-05
I0521 10:48:28.639154  3675 solver.cpp:243] Iteration 23740, loss = 0.00253338
I0521 10:48:28.639187  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00253327 (* 1 = 0.00253327 loss)
I0521 10:48:28.639194  3675 sgd_solver.cpp:138] Iteration 23740, lr = 2.5e-05
I0521 10:48:32.157090  3675 solver.cpp:243] Iteration 23760, loss = 0.00154367
I0521 10:48:32.157121  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00154357 (* 1 = 0.00154357 loss)
I0521 10:48:32.157126  3675 sgd_solver.cpp:138] Iteration 23760, lr = 2.5e-05
I0521 10:48:35.672335  3675 solver.cpp:243] Iteration 23780, loss = 0.00241444
I0521 10:48:35.672366  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00241433 (* 1 = 0.00241433 loss)
I0521 10:48:35.672372  3675 sgd_solver.cpp:138] Iteration 23780, lr = 2.5e-05
I0521 10:48:39.182013  3675 solver.cpp:243] Iteration 23800, loss = 0.00305133
I0521 10:48:39.182179  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00305122 (* 1 = 0.00305122 loss)
I0521 10:48:39.182188  3675 sgd_solver.cpp:138] Iteration 23800, lr = 2.5e-05
I0521 10:48:42.701669  3675 solver.cpp:243] Iteration 23820, loss = 0.0031098
I0521 10:48:42.701701  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0031097 (* 1 = 0.0031097 loss)
I0521 10:48:42.701707  3675 sgd_solver.cpp:138] Iteration 23820, lr = 2.5e-05
I0521 10:48:46.216534  3675 solver.cpp:243] Iteration 23840, loss = 0.00328815
I0521 10:48:46.216567  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00328805 (* 1 = 0.00328805 loss)
I0521 10:48:46.216572  3675 sgd_solver.cpp:138] Iteration 23840, lr = 2.5e-05
I0521 10:48:49.730125  3675 solver.cpp:243] Iteration 23860, loss = 0.00189412
I0521 10:48:49.730155  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00189401 (* 1 = 0.00189401 loss)
I0521 10:48:49.730160  3675 sgd_solver.cpp:138] Iteration 23860, lr = 2.5e-05
I0521 10:48:53.249191  3675 solver.cpp:243] Iteration 23880, loss = 0.00199243
I0521 10:48:53.249222  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00199232 (* 1 = 0.00199232 loss)
I0521 10:48:53.249243  3675 sgd_solver.cpp:138] Iteration 23880, lr = 2.5e-05
I0521 10:48:56.762765  3675 solver.cpp:243] Iteration 23900, loss = 0.00186949
I0521 10:48:56.762796  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00186939 (* 1 = 0.00186939 loss)
I0521 10:48:56.762802  3675 sgd_solver.cpp:138] Iteration 23900, lr = 2.5e-05
I0521 10:49:00.278985  3675 solver.cpp:243] Iteration 23920, loss = 0.00387633
I0521 10:49:00.279016  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00387623 (* 1 = 0.00387623 loss)
I0521 10:49:00.279022  3675 sgd_solver.cpp:138] Iteration 23920, lr = 2.5e-05
I0521 10:49:03.793192  3675 solver.cpp:243] Iteration 23940, loss = 0.00185033
I0521 10:49:03.793223  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00185022 (* 1 = 0.00185022 loss)
I0521 10:49:03.793228  3675 sgd_solver.cpp:138] Iteration 23940, lr = 2.5e-05
I0521 10:49:07.306411  3675 solver.cpp:243] Iteration 23960, loss = 0.00283825
I0521 10:49:07.306440  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00283814 (* 1 = 0.00283814 loss)
I0521 10:49:07.306447  3675 sgd_solver.cpp:138] Iteration 23960, lr = 2.5e-05
I0521 10:49:10.822749  3675 solver.cpp:243] Iteration 23980, loss = 0.0099222
I0521 10:49:10.822872  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0099221 (* 1 = 0.0099221 loss)
I0521 10:49:10.822880  3675 sgd_solver.cpp:138] Iteration 23980, lr = 2.5e-05
I0521 10:49:14.212262  3675 solver.cpp:596] Snapshotting to binary proto file models/LPR/lpr_resnet_lstm_iter_24000.caffemodel
I0521 10:49:14.242630  3675 sgd_solver.cpp:307] Snapshotting solver state to binary proto file models/LPR/lpr_resnet_lstm_iter_24000.solverstate
I0521 10:49:14.258713  3675 solver.cpp:358] Iteration 24000, Testing net (#0)
I0521 10:49:18.994263  3675 solver.cpp:425]     Test net output #0: acc = 1
I0521 10:49:18.994302  3675 solver.cpp:425]     Test net output #1: acc = 1
I0521 10:49:18.994325  3675 solver.cpp:425]     Test net output #2: ctcloss = 0.000821038 (* 1 = 0.000821038 loss)
I0521 10:49:19.130111  3675 solver.cpp:243] Iteration 24000, loss = 0.00258832
I0521 10:49:19.130142  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00258821 (* 1 = 0.00258821 loss)
I0521 10:49:19.130147  3675 sgd_solver.cpp:138] Iteration 24000, lr = 2.5e-05
I0521 10:49:22.643477  3675 solver.cpp:243] Iteration 24020, loss = 0.00195255
I0521 10:49:22.643510  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00195244 (* 1 = 0.00195244 loss)
I0521 10:49:22.643517  3675 sgd_solver.cpp:138] Iteration 24020, lr = 2.5e-05
I0521 10:49:26.160079  3675 solver.cpp:243] Iteration 24040, loss = 0.00242126
I0521 10:49:26.160110  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00242116 (* 1 = 0.00242116 loss)
I0521 10:49:26.160115  3675 sgd_solver.cpp:138] Iteration 24040, lr = 2.5e-05
I0521 10:49:29.676941  3675 solver.cpp:243] Iteration 24060, loss = 0.00658264
I0521 10:49:29.676975  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00658253 (* 1 = 0.00658253 loss)
I0521 10:49:29.676982  3675 sgd_solver.cpp:138] Iteration 24060, lr = 2.5e-05
I0521 10:49:33.189193  3675 solver.cpp:243] Iteration 24080, loss = 0.00256157
I0521 10:49:33.189224  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00256146 (* 1 = 0.00256146 loss)
I0521 10:49:33.189229  3675 sgd_solver.cpp:138] Iteration 24080, lr = 2.5e-05
I0521 10:49:36.706084  3675 solver.cpp:243] Iteration 24100, loss = 0.00174878
I0521 10:49:36.706116  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00174867 (* 1 = 0.00174867 loss)
I0521 10:49:36.706122  3675 sgd_solver.cpp:138] Iteration 24100, lr = 2.5e-05
I0521 10:49:40.223203  3675 solver.cpp:243] Iteration 24120, loss = 0.00228456
I0521 10:49:40.223234  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00228446 (* 1 = 0.00228446 loss)
I0521 10:49:40.223240  3675 sgd_solver.cpp:138] Iteration 24120, lr = 2.5e-05
I0521 10:49:43.732905  3675 solver.cpp:243] Iteration 24140, loss = 0.00195715
I0521 10:49:43.733044  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00195704 (* 1 = 0.00195704 loss)
I0521 10:49:43.733053  3675 sgd_solver.cpp:138] Iteration 24140, lr = 2.5e-05
I0521 10:49:47.254045  3675 solver.cpp:243] Iteration 24160, loss = 0.00239967
I0521 10:49:47.254076  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00239957 (* 1 = 0.00239957 loss)
I0521 10:49:47.254081  3675 sgd_solver.cpp:138] Iteration 24160, lr = 2.5e-05
I0521 10:49:50.771214  3675 solver.cpp:243] Iteration 24180, loss = 0.00656252
I0521 10:49:50.771245  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00656241 (* 1 = 0.00656241 loss)
I0521 10:49:50.771251  3675 sgd_solver.cpp:138] Iteration 24180, lr = 2.5e-05
I0521 10:49:54.293023  3675 solver.cpp:243] Iteration 24200, loss = 0.00281654
I0521 10:49:54.293056  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00281643 (* 1 = 0.00281643 loss)
I0521 10:49:54.293061  3675 sgd_solver.cpp:138] Iteration 24200, lr = 2.5e-05
I0521 10:49:57.813432  3675 solver.cpp:243] Iteration 24220, loss = 0.00358371
I0521 10:49:57.813463  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0035836 (* 1 = 0.0035836 loss)
I0521 10:49:57.813469  3675 sgd_solver.cpp:138] Iteration 24220, lr = 2.5e-05
I0521 10:50:01.331382  3675 solver.cpp:243] Iteration 24240, loss = 0.00343503
I0521 10:50:01.331413  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00343492 (* 1 = 0.00343492 loss)
I0521 10:50:01.331418  3675 sgd_solver.cpp:138] Iteration 24240, lr = 2.5e-05
I0521 10:50:04.850024  3675 solver.cpp:243] Iteration 24260, loss = 0.00204406
I0521 10:50:04.850056  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00204395 (* 1 = 0.00204395 loss)
I0521 10:50:04.850062  3675 sgd_solver.cpp:138] Iteration 24260, lr = 2.5e-05
I0521 10:50:08.364814  3675 solver.cpp:243] Iteration 24280, loss = 0.00217177
I0521 10:50:08.364845  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00217167 (* 1 = 0.00217167 loss)
I0521 10:50:08.364850  3675 sgd_solver.cpp:138] Iteration 24280, lr = 2.5e-05
I0521 10:50:11.880869  3675 solver.cpp:243] Iteration 24300, loss = 0.00316465
I0521 10:50:11.880910  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00316455 (* 1 = 0.00316455 loss)
I0521 10:50:11.880919  3675 sgd_solver.cpp:138] Iteration 24300, lr = 2.5e-05
I0521 10:50:15.396240  3675 solver.cpp:243] Iteration 24320, loss = 0.00240865
I0521 10:50:15.396400  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00240854 (* 1 = 0.00240854 loss)
I0521 10:50:15.396407  3675 sgd_solver.cpp:138] Iteration 24320, lr = 2.5e-05
I0521 10:50:18.915794  3675 solver.cpp:243] Iteration 24340, loss = 0.00292388
I0521 10:50:18.915827  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00292377 (* 1 = 0.00292377 loss)
I0521 10:50:18.915833  3675 sgd_solver.cpp:138] Iteration 24340, lr = 2.5e-05
I0521 10:50:22.431275  3675 solver.cpp:243] Iteration 24360, loss = 0.00227726
I0521 10:50:22.431308  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00227715 (* 1 = 0.00227715 loss)
I0521 10:50:22.431313  3675 sgd_solver.cpp:138] Iteration 24360, lr = 2.5e-05
I0521 10:50:25.952919  3675 solver.cpp:243] Iteration 24380, loss = 0.00203624
I0521 10:50:25.952951  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00203614 (* 1 = 0.00203614 loss)
I0521 10:50:25.952972  3675 sgd_solver.cpp:138] Iteration 24380, lr = 2.5e-05
I0521 10:50:29.467156  3675 solver.cpp:243] Iteration 24400, loss = 0.00215032
I0521 10:50:29.467187  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00215022 (* 1 = 0.00215022 loss)
I0521 10:50:29.467192  3675 sgd_solver.cpp:138] Iteration 24400, lr = 2.5e-05
I0521 10:50:32.983723  3675 solver.cpp:243] Iteration 24420, loss = 0.002265
I0521 10:50:32.983772  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0022649 (* 1 = 0.0022649 loss)
I0521 10:50:32.983777  3675 sgd_solver.cpp:138] Iteration 24420, lr = 2.5e-05
I0521 10:50:36.499646  3675 solver.cpp:243] Iteration 24440, loss = 0.00193594
I0521 10:50:36.499676  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00193584 (* 1 = 0.00193584 loss)
I0521 10:50:36.499682  3675 sgd_solver.cpp:138] Iteration 24440, lr = 2.5e-05
I0521 10:50:40.019901  3675 solver.cpp:243] Iteration 24460, loss = 0.00241405
I0521 10:50:40.019932  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00241394 (* 1 = 0.00241394 loss)
I0521 10:50:40.019939  3675 sgd_solver.cpp:138] Iteration 24460, lr = 2.5e-05
I0521 10:50:43.534181  3675 solver.cpp:243] Iteration 24480, loss = 0.00242306
I0521 10:50:43.534212  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00242295 (* 1 = 0.00242295 loss)
I0521 10:50:43.534219  3675 sgd_solver.cpp:138] Iteration 24480, lr = 2.5e-05
I0521 10:50:47.054919  3675 solver.cpp:243] Iteration 24500, loss = 0.00253355
I0521 10:50:47.055088  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00253345 (* 1 = 0.00253345 loss)
I0521 10:50:47.055094  3675 sgd_solver.cpp:138] Iteration 24500, lr = 2.5e-05
I0521 10:50:50.570447  3675 solver.cpp:243] Iteration 24520, loss = 0.0029521
I0521 10:50:50.570479  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00295199 (* 1 = 0.00295199 loss)
I0521 10:50:50.570485  3675 sgd_solver.cpp:138] Iteration 24520, lr = 2.5e-05
I0521 10:50:54.089187  3675 solver.cpp:243] Iteration 24540, loss = 0.00787946
I0521 10:50:54.089220  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00787935 (* 1 = 0.00787935 loss)
I0521 10:50:54.089226  3675 sgd_solver.cpp:138] Iteration 24540, lr = 2.5e-05
I0521 10:50:57.605214  3675 solver.cpp:243] Iteration 24560, loss = 0.00177927
I0521 10:50:57.605245  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00177916 (* 1 = 0.00177916 loss)
I0521 10:50:57.605250  3675 sgd_solver.cpp:138] Iteration 24560, lr = 2.5e-05
I0521 10:51:01.120087  3675 solver.cpp:243] Iteration 24580, loss = 0.00198099
I0521 10:51:01.120118  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00198089 (* 1 = 0.00198089 loss)
I0521 10:51:01.120123  3675 sgd_solver.cpp:138] Iteration 24580, lr = 2.5e-05
I0521 10:51:04.636613  3675 solver.cpp:243] Iteration 24600, loss = 0.00223471
I0521 10:51:04.636643  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0022346 (* 1 = 0.0022346 loss)
I0521 10:51:04.636649  3675 sgd_solver.cpp:138] Iteration 24600, lr = 2.5e-05
I0521 10:51:08.155355  3675 solver.cpp:243] Iteration 24620, loss = 0.00303241
I0521 10:51:08.155386  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0030323 (* 1 = 0.0030323 loss)
I0521 10:51:08.155393  3675 sgd_solver.cpp:138] Iteration 24620, lr = 2.5e-05
I0521 10:51:11.676174  3675 solver.cpp:243] Iteration 24640, loss = 0.00325799
I0521 10:51:11.676206  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00325788 (* 1 = 0.00325788 loss)
I0521 10:51:11.676213  3675 sgd_solver.cpp:138] Iteration 24640, lr = 2.5e-05
I0521 10:51:15.190990  3675 solver.cpp:243] Iteration 24660, loss = 0.0027992
I0521 10:51:15.191020  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00279909 (* 1 = 0.00279909 loss)
I0521 10:51:15.191026  3675 sgd_solver.cpp:138] Iteration 24660, lr = 2.5e-05
I0521 10:51:18.710081  3675 solver.cpp:243] Iteration 24680, loss = 0.00257368
I0521 10:51:18.710211  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00257357 (* 1 = 0.00257357 loss)
I0521 10:51:18.710219  3675 sgd_solver.cpp:138] Iteration 24680, lr = 2.5e-05
I0521 10:51:22.229547  3675 solver.cpp:243] Iteration 24700, loss = 0.00179224
I0521 10:51:22.229578  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00179214 (* 1 = 0.00179214 loss)
I0521 10:51:22.229584  3675 sgd_solver.cpp:138] Iteration 24700, lr = 2.5e-05
I0521 10:51:25.748075  3675 solver.cpp:243] Iteration 24720, loss = 0.00247516
I0521 10:51:25.748104  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00247505 (* 1 = 0.00247505 loss)
I0521 10:51:25.748111  3675 sgd_solver.cpp:138] Iteration 24720, lr = 2.5e-05
I0521 10:51:29.275252  3675 solver.cpp:243] Iteration 24740, loss = 0.00214511
I0521 10:51:29.275283  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.002145 (* 1 = 0.002145 loss)
I0521 10:51:29.275305  3675 sgd_solver.cpp:138] Iteration 24740, lr = 2.5e-05
I0521 10:51:32.795053  3675 solver.cpp:243] Iteration 24760, loss = 0.00187534
I0521 10:51:32.795084  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00187524 (* 1 = 0.00187524 loss)
I0521 10:51:32.795091  3675 sgd_solver.cpp:138] Iteration 24760, lr = 2.5e-05
I0521 10:51:36.250159  3675 solver.cpp:243] Iteration 24780, loss = 0.00218787
I0521 10:51:36.250188  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00218776 (* 1 = 0.00218776 loss)
I0521 10:51:36.250193  3675 sgd_solver.cpp:138] Iteration 24780, lr = 2.5e-05
I0521 10:51:39.767429  3675 solver.cpp:243] Iteration 24800, loss = 0.00247344
I0521 10:51:39.767460  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00247333 (* 1 = 0.00247333 loss)
I0521 10:51:39.767467  3675 sgd_solver.cpp:138] Iteration 24800, lr = 2.5e-05
I0521 10:51:43.287897  3675 solver.cpp:243] Iteration 24820, loss = 0.00230164
I0521 10:51:43.287930  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00230153 (* 1 = 0.00230153 loss)
I0521 10:51:43.287936  3675 sgd_solver.cpp:138] Iteration 24820, lr = 2.5e-05
I0521 10:51:46.806664  3675 solver.cpp:243] Iteration 24840, loss = 0.00304012
I0521 10:51:46.806694  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00304002 (* 1 = 0.00304002 loss)
I0521 10:51:46.806700  3675 sgd_solver.cpp:138] Iteration 24840, lr = 2.5e-05
I0521 10:51:50.319394  3675 solver.cpp:243] Iteration 24860, loss = 0.00214835
I0521 10:51:50.319557  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00214825 (* 1 = 0.00214825 loss)
I0521 10:51:50.319563  3675 sgd_solver.cpp:138] Iteration 24860, lr = 2.5e-05
I0521 10:51:53.835019  3675 solver.cpp:243] Iteration 24880, loss = 0.00194497
I0521 10:51:53.835052  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00194486 (* 1 = 0.00194486 loss)
I0521 10:51:53.835057  3675 sgd_solver.cpp:138] Iteration 24880, lr = 2.5e-05
I0521 10:51:57.348832  3675 solver.cpp:243] Iteration 24900, loss = 0.00255136
I0521 10:51:57.348863  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00255126 (* 1 = 0.00255126 loss)
I0521 10:51:57.348870  3675 sgd_solver.cpp:138] Iteration 24900, lr = 2.5e-05
I0521 10:52:00.861939  3675 solver.cpp:243] Iteration 24920, loss = 0.00285368
I0521 10:52:00.861971  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00285358 (* 1 = 0.00285358 loss)
I0521 10:52:00.861976  3675 sgd_solver.cpp:138] Iteration 24920, lr = 2.5e-05
I0521 10:52:04.378410  3675 solver.cpp:243] Iteration 24940, loss = 0.00190217
I0521 10:52:04.378443  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00190207 (* 1 = 0.00190207 loss)
I0521 10:52:04.378448  3675 sgd_solver.cpp:138] Iteration 24940, lr = 2.5e-05
I0521 10:52:07.898799  3675 solver.cpp:243] Iteration 24960, loss = 0.00197353
I0521 10:52:07.898831  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00197343 (* 1 = 0.00197343 loss)
I0521 10:52:07.898838  3675 sgd_solver.cpp:138] Iteration 24960, lr = 2.5e-05
I0521 10:52:11.415076  3675 solver.cpp:243] Iteration 24980, loss = 0.001968
I0521 10:52:11.415107  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0019679 (* 1 = 0.0019679 loss)
I0521 10:52:11.415112  3675 sgd_solver.cpp:138] Iteration 24980, lr = 2.5e-05
I0521 10:52:14.803520  3675 solver.cpp:358] Iteration 25000, Testing net (#0)
I0521 10:52:19.536648  3675 solver.cpp:425]     Test net output #0: acc = 1
I0521 10:52:19.536677  3675 solver.cpp:425]     Test net output #1: acc = 1
I0521 10:52:19.536684  3675 solver.cpp:425]     Test net output #2: ctcloss = 0.000811038 (* 1 = 0.000811038 loss)
I0521 10:52:19.671592  3675 solver.cpp:243] Iteration 25000, loss = 0.00227959
I0521 10:52:19.671623  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00227949 (* 1 = 0.00227949 loss)
I0521 10:52:19.671629  3675 sgd_solver.cpp:138] Iteration 25000, lr = 2.5e-05
I0521 10:52:23.194387  3675 solver.cpp:243] Iteration 25020, loss = 0.00410862
I0521 10:52:23.194547  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00410851 (* 1 = 0.00410851 loss)
I0521 10:52:23.194555  3675 sgd_solver.cpp:138] Iteration 25020, lr = 2.5e-05
I0521 10:52:26.712100  3675 solver.cpp:243] Iteration 25040, loss = 0.00318159
I0521 10:52:26.712131  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00318149 (* 1 = 0.00318149 loss)
I0521 10:52:26.712136  3675 sgd_solver.cpp:138] Iteration 25040, lr = 2.5e-05
I0521 10:52:30.230774  3675 solver.cpp:243] Iteration 25060, loss = 0.00300562
I0521 10:52:30.230805  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00300551 (* 1 = 0.00300551 loss)
I0521 10:52:30.230811  3675 sgd_solver.cpp:138] Iteration 25060, lr = 2.5e-05
I0521 10:52:33.749697  3675 solver.cpp:243] Iteration 25080, loss = 0.00217274
I0521 10:52:33.749729  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00217263 (* 1 = 0.00217263 loss)
I0521 10:52:33.749735  3675 sgd_solver.cpp:138] Iteration 25080, lr = 2.5e-05
I0521 10:52:37.269304  3675 solver.cpp:243] Iteration 25100, loss = 0.00191589
I0521 10:52:37.269335  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00191579 (* 1 = 0.00191579 loss)
I0521 10:52:37.269340  3675 sgd_solver.cpp:138] Iteration 25100, lr = 2.5e-05
I0521 10:52:40.784047  3675 solver.cpp:243] Iteration 25120, loss = 0.002547
I0521 10:52:40.784078  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0025469 (* 1 = 0.0025469 loss)
I0521 10:52:40.784099  3675 sgd_solver.cpp:138] Iteration 25120, lr = 2.5e-05
I0521 10:52:44.303963  3675 solver.cpp:243] Iteration 25140, loss = 0.00224707
I0521 10:52:44.303994  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00224696 (* 1 = 0.00224696 loss)
I0521 10:52:44.304015  3675 sgd_solver.cpp:138] Iteration 25140, lr = 2.5e-05
I0521 10:52:47.823024  3675 solver.cpp:243] Iteration 25160, loss = 0.00288286
I0521 10:52:47.823055  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00288276 (* 1 = 0.00288276 loss)
I0521 10:52:47.823060  3675 sgd_solver.cpp:138] Iteration 25160, lr = 2.5e-05
I0521 10:52:51.343591  3675 solver.cpp:243] Iteration 25180, loss = 0.00388112
I0521 10:52:51.343622  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00388102 (* 1 = 0.00388102 loss)
I0521 10:52:51.343628  3675 sgd_solver.cpp:138] Iteration 25180, lr = 2.5e-05
I0521 10:52:54.867027  3675 solver.cpp:243] Iteration 25200, loss = 0.00239997
I0521 10:52:54.867182  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00239986 (* 1 = 0.00239986 loss)
I0521 10:52:54.867189  3675 sgd_solver.cpp:138] Iteration 25200, lr = 2.5e-05
I0521 10:52:58.388875  3675 solver.cpp:243] Iteration 25220, loss = 0.00223673
I0521 10:52:58.388907  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00223663 (* 1 = 0.00223663 loss)
I0521 10:52:58.388913  3675 sgd_solver.cpp:138] Iteration 25220, lr = 2.5e-05
I0521 10:53:01.907788  3675 solver.cpp:243] Iteration 25240, loss = 0.002734
I0521 10:53:01.907819  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0027339 (* 1 = 0.0027339 loss)
I0521 10:53:01.907825  3675 sgd_solver.cpp:138] Iteration 25240, lr = 2.5e-05
I0521 10:53:05.429618  3675 solver.cpp:243] Iteration 25260, loss = 0.00217729
I0521 10:53:05.429651  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00217718 (* 1 = 0.00217718 loss)
I0521 10:53:05.429656  3675 sgd_solver.cpp:138] Iteration 25260, lr = 2.5e-05
I0521 10:53:08.941381  3675 solver.cpp:243] Iteration 25280, loss = 0.00431557
I0521 10:53:08.941414  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00431547 (* 1 = 0.00431547 loss)
I0521 10:53:08.941421  3675 sgd_solver.cpp:138] Iteration 25280, lr = 2.5e-05
I0521 10:53:12.465399  3675 solver.cpp:243] Iteration 25300, loss = 0.00186948
I0521 10:53:12.465432  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00186938 (* 1 = 0.00186938 loss)
I0521 10:53:12.465437  3675 sgd_solver.cpp:138] Iteration 25300, lr = 2.5e-05
I0521 10:53:15.990095  3675 solver.cpp:243] Iteration 25320, loss = 0.00183268
I0521 10:53:15.990128  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00183258 (* 1 = 0.00183258 loss)
I0521 10:53:15.990134  3675 sgd_solver.cpp:138] Iteration 25320, lr = 2.5e-05
I0521 10:53:19.507972  3675 solver.cpp:243] Iteration 25340, loss = 0.00218911
I0521 10:53:19.508000  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00218901 (* 1 = 0.00218901 loss)
I0521 10:53:19.508006  3675 sgd_solver.cpp:138] Iteration 25340, lr = 2.5e-05
I0521 10:53:23.032729  3675 solver.cpp:243] Iteration 25360, loss = 0.00197892
I0521 10:53:23.032761  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00197881 (* 1 = 0.00197881 loss)
I0521 10:53:23.032768  3675 sgd_solver.cpp:138] Iteration 25360, lr = 2.5e-05
I0521 10:53:26.548149  3675 solver.cpp:243] Iteration 25380, loss = 0.00273605
I0521 10:53:26.548311  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00273594 (* 1 = 0.00273594 loss)
I0521 10:53:26.548321  3675 sgd_solver.cpp:138] Iteration 25380, lr = 2.5e-05
I0521 10:53:30.061264  3675 solver.cpp:243] Iteration 25400, loss = 0.0022283
I0521 10:53:30.061296  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00222819 (* 1 = 0.00222819 loss)
I0521 10:53:30.061302  3675 sgd_solver.cpp:138] Iteration 25400, lr = 2.5e-05
I0521 10:53:33.584357  3675 solver.cpp:243] Iteration 25420, loss = 0.00228692
I0521 10:53:33.584388  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00228682 (* 1 = 0.00228682 loss)
I0521 10:53:33.584393  3675 sgd_solver.cpp:138] Iteration 25420, lr = 2.5e-05
I0521 10:53:37.101545  3675 solver.cpp:243] Iteration 25440, loss = 0.00198838
I0521 10:53:37.101577  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00198828 (* 1 = 0.00198828 loss)
I0521 10:53:37.101581  3675 sgd_solver.cpp:138] Iteration 25440, lr = 2.5e-05
I0521 10:53:40.622025  3675 solver.cpp:243] Iteration 25460, loss = 0.00255411
I0521 10:53:40.622054  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00255401 (* 1 = 0.00255401 loss)
I0521 10:53:40.622061  3675 sgd_solver.cpp:138] Iteration 25460, lr = 2.5e-05
I0521 10:53:44.139389  3675 solver.cpp:243] Iteration 25480, loss = 0.00203268
I0521 10:53:44.139420  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00203258 (* 1 = 0.00203258 loss)
I0521 10:53:44.139441  3675 sgd_solver.cpp:138] Iteration 25480, lr = 2.5e-05
I0521 10:53:47.657516  3675 solver.cpp:243] Iteration 25500, loss = 0.00209888
I0521 10:53:47.657562  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00209878 (* 1 = 0.00209878 loss)
I0521 10:53:47.657568  3675 sgd_solver.cpp:138] Iteration 25500, lr = 2.5e-05
I0521 10:53:51.172662  3675 solver.cpp:243] Iteration 25520, loss = 0.00233196
I0521 10:53:51.172691  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00233186 (* 1 = 0.00233186 loss)
I0521 10:53:51.172713  3675 sgd_solver.cpp:138] Iteration 25520, lr = 2.5e-05
I0521 10:53:54.689438  3675 solver.cpp:243] Iteration 25540, loss = 0.00167265
I0521 10:53:54.689468  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00167254 (* 1 = 0.00167254 loss)
I0521 10:53:54.689474  3675 sgd_solver.cpp:138] Iteration 25540, lr = 2.5e-05
I0521 10:53:58.206759  3675 solver.cpp:243] Iteration 25560, loss = 0.00172508
I0521 10:53:58.206935  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00172497 (* 1 = 0.00172497 loss)
I0521 10:53:58.206943  3675 sgd_solver.cpp:138] Iteration 25560, lr = 2.5e-05
I0521 10:54:01.726136  3675 solver.cpp:243] Iteration 25580, loss = 0.00261894
I0521 10:54:01.726168  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00261884 (* 1 = 0.00261884 loss)
I0521 10:54:01.726174  3675 sgd_solver.cpp:138] Iteration 25580, lr = 2.5e-05
I0521 10:54:05.246390  3675 solver.cpp:243] Iteration 25600, loss = 0.00314156
I0521 10:54:05.246421  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00314146 (* 1 = 0.00314146 loss)
I0521 10:54:05.246428  3675 sgd_solver.cpp:138] Iteration 25600, lr = 2.5e-05
I0521 10:54:08.767786  3675 solver.cpp:243] Iteration 25620, loss = 0.00267846
I0521 10:54:08.767817  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00267835 (* 1 = 0.00267835 loss)
I0521 10:54:08.767822  3675 sgd_solver.cpp:138] Iteration 25620, lr = 2.5e-05
I0521 10:54:12.286129  3675 solver.cpp:243] Iteration 25640, loss = 0.00305838
I0521 10:54:12.286160  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00305828 (* 1 = 0.00305828 loss)
I0521 10:54:12.286166  3675 sgd_solver.cpp:138] Iteration 25640, lr = 2.5e-05
I0521 10:54:15.809990  3675 solver.cpp:243] Iteration 25660, loss = 0.00305524
I0521 10:54:15.810022  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00305514 (* 1 = 0.00305514 loss)
I0521 10:54:15.810027  3675 sgd_solver.cpp:138] Iteration 25660, lr = 2.5e-05
I0521 10:54:19.329582  3675 solver.cpp:243] Iteration 25680, loss = 0.00638883
I0521 10:54:19.329615  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00638873 (* 1 = 0.00638873 loss)
I0521 10:54:19.329620  3675 sgd_solver.cpp:138] Iteration 25680, lr = 2.5e-05
I0521 10:54:22.852685  3675 solver.cpp:243] Iteration 25700, loss = 0.00200294
I0521 10:54:22.852717  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00200283 (* 1 = 0.00200283 loss)
I0521 10:54:22.852722  3675 sgd_solver.cpp:138] Iteration 25700, lr = 2.5e-05
I0521 10:54:26.374310  3675 solver.cpp:243] Iteration 25720, loss = 0.00517739
I0521 10:54:26.374341  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00517729 (* 1 = 0.00517729 loss)
I0521 10:54:26.374346  3675 sgd_solver.cpp:138] Iteration 25720, lr = 2.5e-05
I0521 10:54:29.892902  3675 solver.cpp:243] Iteration 25740, loss = 0.00231607
I0521 10:54:29.893069  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00231596 (* 1 = 0.00231596 loss)
I0521 10:54:29.893075  3675 sgd_solver.cpp:138] Iteration 25740, lr = 2.5e-05
I0521 10:54:33.410773  3675 solver.cpp:243] Iteration 25760, loss = 0.00250113
I0521 10:54:33.410804  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00250103 (* 1 = 0.00250103 loss)
I0521 10:54:33.410809  3675 sgd_solver.cpp:138] Iteration 25760, lr = 2.5e-05
I0521 10:54:36.932068  3675 solver.cpp:243] Iteration 25780, loss = 0.00174734
I0521 10:54:36.932098  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00174724 (* 1 = 0.00174724 loss)
I0521 10:54:36.932103  3675 sgd_solver.cpp:138] Iteration 25780, lr = 2.5e-05
I0521 10:54:40.448513  3675 solver.cpp:243] Iteration 25800, loss = 0.00217258
I0521 10:54:40.448542  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00217247 (* 1 = 0.00217247 loss)
I0521 10:54:40.448549  3675 sgd_solver.cpp:138] Iteration 25800, lr = 2.5e-05
I0521 10:54:43.964395  3675 solver.cpp:243] Iteration 25820, loss = 0.00287963
I0521 10:54:43.964426  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00287952 (* 1 = 0.00287952 loss)
I0521 10:54:43.964432  3675 sgd_solver.cpp:138] Iteration 25820, lr = 2.5e-05
I0521 10:54:47.480618  3675 solver.cpp:243] Iteration 25840, loss = 0.00197112
I0521 10:54:47.480648  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00197102 (* 1 = 0.00197102 loss)
I0521 10:54:47.480654  3675 sgd_solver.cpp:138] Iteration 25840, lr = 2.5e-05
I0521 10:54:50.999444  3675 solver.cpp:243] Iteration 25860, loss = 0.00242494
I0521 10:54:50.999475  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00242483 (* 1 = 0.00242483 loss)
I0521 10:54:50.999480  3675 sgd_solver.cpp:138] Iteration 25860, lr = 2.5e-05
I0521 10:54:54.515499  3675 solver.cpp:243] Iteration 25880, loss = 0.00291536
I0521 10:54:54.515530  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00291526 (* 1 = 0.00291526 loss)
I0521 10:54:54.515537  3675 sgd_solver.cpp:138] Iteration 25880, lr = 2.5e-05
I0521 10:54:58.031136  3675 solver.cpp:243] Iteration 25900, loss = 0.00202709
I0521 10:54:58.031168  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00202699 (* 1 = 0.00202699 loss)
I0521 10:54:58.031174  3675 sgd_solver.cpp:138] Iteration 25900, lr = 2.5e-05
I0521 10:55:01.549118  3675 solver.cpp:243] Iteration 25920, loss = 0.0016877
I0521 10:55:01.549229  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00168759 (* 1 = 0.00168759 loss)
I0521 10:55:01.549237  3675 sgd_solver.cpp:138] Iteration 25920, lr = 2.5e-05
I0521 10:55:05.065829  3675 solver.cpp:243] Iteration 25940, loss = 0.00246984
I0521 10:55:05.065861  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00246973 (* 1 = 0.00246973 loss)
I0521 10:55:05.065867  3675 sgd_solver.cpp:138] Iteration 25940, lr = 2.5e-05
I0521 10:55:08.582860  3675 solver.cpp:243] Iteration 25960, loss = 0.00194314
I0521 10:55:08.582890  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00194304 (* 1 = 0.00194304 loss)
I0521 10:55:08.582895  3675 sgd_solver.cpp:138] Iteration 25960, lr = 2.5e-05
I0521 10:55:12.104640  3675 solver.cpp:243] Iteration 25980, loss = 0.00226197
I0521 10:55:12.104671  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00226187 (* 1 = 0.00226187 loss)
I0521 10:55:12.104678  3675 sgd_solver.cpp:138] Iteration 25980, lr = 2.5e-05
I0521 10:55:15.432091  3675 solver.cpp:596] Snapshotting to binary proto file models/LPR/lpr_resnet_lstm_iter_26000.caffemodel
I0521 10:55:15.459400  3675 sgd_solver.cpp:307] Snapshotting solver state to binary proto file models/LPR/lpr_resnet_lstm_iter_26000.solverstate
I0521 10:55:15.474046  3675 solver.cpp:358] Iteration 26000, Testing net (#0)
I0521 10:55:20.206890  3675 solver.cpp:425]     Test net output #0: acc = 1
I0521 10:55:20.206918  3675 solver.cpp:425]     Test net output #1: acc = 1
I0521 10:55:20.206924  3675 solver.cpp:425]     Test net output #2: ctcloss = 0.000789476 (* 1 = 0.000789476 loss)
I0521 10:55:20.405354  3675 solver.cpp:243] Iteration 26000, loss = 0.0029304
I0521 10:55:20.405385  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0029303 (* 1 = 0.0029303 loss)
I0521 10:55:20.405391  3675 sgd_solver.cpp:138] Iteration 26000, lr = 2.5e-05
I0521 10:55:23.915926  3675 solver.cpp:243] Iteration 26020, loss = 0.0020065
I0521 10:55:23.915957  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0020064 (* 1 = 0.0020064 loss)
I0521 10:55:23.915963  3675 sgd_solver.cpp:138] Iteration 26020, lr = 2.5e-05
I0521 10:55:27.427290  3675 solver.cpp:243] Iteration 26040, loss = 0.00614265
I0521 10:55:27.427320  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00614254 (* 1 = 0.00614254 loss)
I0521 10:55:27.427328  3675 sgd_solver.cpp:138] Iteration 26040, lr = 2.5e-05
I0521 10:55:30.940862  3675 solver.cpp:243] Iteration 26060, loss = 0.00260505
I0521 10:55:30.940896  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00260494 (* 1 = 0.00260494 loss)
I0521 10:55:30.940901  3675 sgd_solver.cpp:138] Iteration 26060, lr = 2.5e-05
I0521 10:55:34.387224  3675 solver.cpp:243] Iteration 26080, loss = 0.00237385
I0521 10:55:34.387415  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00237375 (* 1 = 0.00237375 loss)
I0521 10:55:34.387423  3675 sgd_solver.cpp:138] Iteration 26080, lr = 2.5e-05
I0521 10:55:37.902617  3675 solver.cpp:243] Iteration 26100, loss = 0.00318357
I0521 10:55:37.902649  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00318347 (* 1 = 0.00318347 loss)
I0521 10:55:37.902655  3675 sgd_solver.cpp:138] Iteration 26100, lr = 2.5e-05
I0521 10:55:41.413735  3675 solver.cpp:243] Iteration 26120, loss = 0.00295926
I0521 10:55:41.413765  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00295916 (* 1 = 0.00295916 loss)
I0521 10:55:41.413770  3675 sgd_solver.cpp:138] Iteration 26120, lr = 2.5e-05
I0521 10:55:44.926781  3675 solver.cpp:243] Iteration 26140, loss = 0.00188093
I0521 10:55:44.926815  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00188083 (* 1 = 0.00188083 loss)
I0521 10:55:44.926837  3675 sgd_solver.cpp:138] Iteration 26140, lr = 2.5e-05
I0521 10:55:48.441406  3675 solver.cpp:243] Iteration 26160, loss = 0.00198081
I0521 10:55:48.441435  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0019807 (* 1 = 0.0019807 loss)
I0521 10:55:48.441440  3675 sgd_solver.cpp:138] Iteration 26160, lr = 2.5e-05
I0521 10:55:51.949012  3675 solver.cpp:243] Iteration 26180, loss = 0.00225408
I0521 10:55:51.949045  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00225398 (* 1 = 0.00225398 loss)
I0521 10:55:51.949050  3675 sgd_solver.cpp:138] Iteration 26180, lr = 2.5e-05
I0521 10:55:55.463335  3675 solver.cpp:243] Iteration 26200, loss = 0.00325589
I0521 10:55:55.463366  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00325579 (* 1 = 0.00325579 loss)
I0521 10:55:55.463371  3675 sgd_solver.cpp:138] Iteration 26200, lr = 2.5e-05
I0521 10:55:58.980821  3675 solver.cpp:243] Iteration 26220, loss = 0.00286665
I0521 10:55:58.980851  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00286655 (* 1 = 0.00286655 loss)
I0521 10:55:58.980857  3675 sgd_solver.cpp:138] Iteration 26220, lr = 2.5e-05
I0521 10:56:02.495148  3675 solver.cpp:243] Iteration 26240, loss = 0.00214814
I0521 10:56:02.495179  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00214803 (* 1 = 0.00214803 loss)
I0521 10:56:02.495184  3675 sgd_solver.cpp:138] Iteration 26240, lr = 2.5e-05
I0521 10:56:06.007056  3675 solver.cpp:243] Iteration 26260, loss = 0.00201718
I0521 10:56:06.007221  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00201707 (* 1 = 0.00201707 loss)
I0521 10:56:06.007230  3675 sgd_solver.cpp:138] Iteration 26260, lr = 2.5e-05
I0521 10:56:09.519275  3675 solver.cpp:243] Iteration 26280, loss = 0.00282203
I0521 10:56:09.519306  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00282193 (* 1 = 0.00282193 loss)
I0521 10:56:09.519311  3675 sgd_solver.cpp:138] Iteration 26280, lr = 2.5e-05
I0521 10:56:13.031862  3675 solver.cpp:243] Iteration 26300, loss = 0.00259841
I0521 10:56:13.031893  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0025983 (* 1 = 0.0025983 loss)
I0521 10:56:13.031899  3675 sgd_solver.cpp:138] Iteration 26300, lr = 2.5e-05
I0521 10:56:16.547652  3675 solver.cpp:243] Iteration 26320, loss = 0.0013973
I0521 10:56:16.547683  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00139719 (* 1 = 0.00139719 loss)
I0521 10:56:16.547688  3675 sgd_solver.cpp:138] Iteration 26320, lr = 2.5e-05
I0521 10:56:20.057220  3675 solver.cpp:243] Iteration 26340, loss = 0.00205698
I0521 10:56:20.057252  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00205687 (* 1 = 0.00205687 loss)
I0521 10:56:20.057257  3675 sgd_solver.cpp:138] Iteration 26340, lr = 2.5e-05
I0521 10:56:23.568336  3675 solver.cpp:243] Iteration 26360, loss = 0.00222361
I0521 10:56:23.568365  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0022235 (* 1 = 0.0022235 loss)
I0521 10:56:23.568372  3675 sgd_solver.cpp:138] Iteration 26360, lr = 2.5e-05
I0521 10:56:27.084551  3675 solver.cpp:243] Iteration 26380, loss = 0.00272567
I0521 10:56:27.084581  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00272557 (* 1 = 0.00272557 loss)
I0521 10:56:27.084586  3675 sgd_solver.cpp:138] Iteration 26380, lr = 2.5e-05
I0521 10:56:30.597016  3675 solver.cpp:243] Iteration 26400, loss = 0.00161335
I0521 10:56:30.597048  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00161325 (* 1 = 0.00161325 loss)
I0521 10:56:30.597054  3675 sgd_solver.cpp:138] Iteration 26400, lr = 2.5e-05
I0521 10:56:34.106151  3675 solver.cpp:243] Iteration 26420, loss = 0.00215123
I0521 10:56:34.106182  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00215113 (* 1 = 0.00215113 loss)
I0521 10:56:34.106187  3675 sgd_solver.cpp:138] Iteration 26420, lr = 2.5e-05
I0521 10:56:37.616439  3675 solver.cpp:243] Iteration 26440, loss = 0.00251851
I0521 10:56:37.616638  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0025184 (* 1 = 0.0025184 loss)
I0521 10:56:37.616647  3675 sgd_solver.cpp:138] Iteration 26440, lr = 2.5e-05
I0521 10:56:41.125880  3675 solver.cpp:243] Iteration 26460, loss = 0.00224135
I0521 10:56:41.125913  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00224124 (* 1 = 0.00224124 loss)
I0521 10:56:41.125918  3675 sgd_solver.cpp:138] Iteration 26460, lr = 2.5e-05
I0521 10:56:44.636144  3675 solver.cpp:243] Iteration 26480, loss = 0.00223598
I0521 10:56:44.636175  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00223587 (* 1 = 0.00223587 loss)
I0521 10:56:44.636181  3675 sgd_solver.cpp:138] Iteration 26480, lr = 2.5e-05
I0521 10:56:48.142571  3675 solver.cpp:243] Iteration 26500, loss = 0.00135175
I0521 10:56:48.142603  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00135165 (* 1 = 0.00135165 loss)
I0521 10:56:48.142624  3675 sgd_solver.cpp:138] Iteration 26500, lr = 2.5e-05
I0521 10:56:51.653625  3675 solver.cpp:243] Iteration 26520, loss = 0.00228758
I0521 10:56:51.653656  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00228748 (* 1 = 0.00228748 loss)
I0521 10:56:51.653677  3675 sgd_solver.cpp:138] Iteration 26520, lr = 2.5e-05
I0521 10:56:55.160620  3675 solver.cpp:243] Iteration 26540, loss = 0.00277369
I0521 10:56:55.160650  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00277358 (* 1 = 0.00277358 loss)
I0521 10:56:55.160656  3675 sgd_solver.cpp:138] Iteration 26540, lr = 2.5e-05
I0521 10:56:58.674831  3675 solver.cpp:243] Iteration 26560, loss = 0.00330999
I0521 10:56:58.674880  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00330988 (* 1 = 0.00330988 loss)
I0521 10:56:58.674885  3675 sgd_solver.cpp:138] Iteration 26560, lr = 2.5e-05
I0521 10:57:02.185734  3675 solver.cpp:243] Iteration 26580, loss = 0.00234631
I0521 10:57:02.185763  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00234621 (* 1 = 0.00234621 loss)
I0521 10:57:02.185768  3675 sgd_solver.cpp:138] Iteration 26580, lr = 2.5e-05
I0521 10:57:05.693699  3675 solver.cpp:243] Iteration 26600, loss = 0.00241532
I0521 10:57:05.693732  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00241521 (* 1 = 0.00241521 loss)
I0521 10:57:05.693737  3675 sgd_solver.cpp:138] Iteration 26600, lr = 2.5e-05
I0521 10:57:09.203368  3675 solver.cpp:243] Iteration 26620, loss = 0.00217304
I0521 10:57:09.203497  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00217294 (* 1 = 0.00217294 loss)
I0521 10:57:09.203505  3675 sgd_solver.cpp:138] Iteration 26620, lr = 2.5e-05
I0521 10:57:12.710911  3675 solver.cpp:243] Iteration 26640, loss = 0.00213332
I0521 10:57:12.710943  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00213322 (* 1 = 0.00213322 loss)
I0521 10:57:12.710949  3675 sgd_solver.cpp:138] Iteration 26640, lr = 2.5e-05
I0521 10:57:16.227116  3675 solver.cpp:243] Iteration 26660, loss = 0.00224018
I0521 10:57:16.227147  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00224008 (* 1 = 0.00224008 loss)
I0521 10:57:16.227152  3675 sgd_solver.cpp:138] Iteration 26660, lr = 2.5e-05
I0521 10:57:19.741997  3675 solver.cpp:243] Iteration 26680, loss = 0.00178994
I0521 10:57:19.742028  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00178983 (* 1 = 0.00178983 loss)
I0521 10:57:19.742033  3675 sgd_solver.cpp:138] Iteration 26680, lr = 2.5e-05
I0521 10:57:23.256623  3675 solver.cpp:243] Iteration 26700, loss = 0.00209106
I0521 10:57:23.256654  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00209096 (* 1 = 0.00209096 loss)
I0521 10:57:23.256659  3675 sgd_solver.cpp:138] Iteration 26700, lr = 2.5e-05
I0521 10:57:26.768863  3675 solver.cpp:243] Iteration 26720, loss = 0.00197888
I0521 10:57:26.768896  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00197878 (* 1 = 0.00197878 loss)
I0521 10:57:26.768901  3675 sgd_solver.cpp:138] Iteration 26720, lr = 2.5e-05
I0521 10:57:30.282477  3675 solver.cpp:243] Iteration 26740, loss = 0.00335623
I0521 10:57:30.282510  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00335613 (* 1 = 0.00335613 loss)
I0521 10:57:30.282516  3675 sgd_solver.cpp:138] Iteration 26740, lr = 2.5e-05
I0521 10:57:33.795287  3675 solver.cpp:243] Iteration 26760, loss = 0.00231656
I0521 10:57:33.795320  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00231645 (* 1 = 0.00231645 loss)
I0521 10:57:33.795325  3675 sgd_solver.cpp:138] Iteration 26760, lr = 2.5e-05
I0521 10:57:37.300439  3675 solver.cpp:243] Iteration 26780, loss = 0.0035901
I0521 10:57:37.300470  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00358999 (* 1 = 0.00358999 loss)
I0521 10:57:37.300477  3675 sgd_solver.cpp:138] Iteration 26780, lr = 2.5e-05
I0521 10:57:40.813747  3675 solver.cpp:243] Iteration 26800, loss = 0.00292131
I0521 10:57:40.813899  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00292121 (* 1 = 0.00292121 loss)
I0521 10:57:40.813905  3675 sgd_solver.cpp:138] Iteration 26800, lr = 2.5e-05
I0521 10:57:44.325462  3675 solver.cpp:243] Iteration 26820, loss = 0.00239496
I0521 10:57:44.325495  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00239485 (* 1 = 0.00239485 loss)
I0521 10:57:44.325502  3675 sgd_solver.cpp:138] Iteration 26820, lr = 2.5e-05
I0521 10:57:47.835927  3675 solver.cpp:243] Iteration 26840, loss = 0.00333893
I0521 10:57:47.835958  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00333883 (* 1 = 0.00333883 loss)
I0521 10:57:47.835963  3675 sgd_solver.cpp:138] Iteration 26840, lr = 2.5e-05
I0521 10:57:51.350379  3675 solver.cpp:243] Iteration 26860, loss = 0.00182786
I0521 10:57:51.350410  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00182776 (* 1 = 0.00182776 loss)
I0521 10:57:51.350416  3675 sgd_solver.cpp:138] Iteration 26860, lr = 2.5e-05
I0521 10:57:54.861052  3675 solver.cpp:243] Iteration 26880, loss = 0.00212323
I0521 10:57:54.861083  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00212313 (* 1 = 0.00212313 loss)
I0521 10:57:54.861089  3675 sgd_solver.cpp:138] Iteration 26880, lr = 2.5e-05
I0521 10:57:58.378126  3675 solver.cpp:243] Iteration 26900, loss = 0.00213909
I0521 10:57:58.378157  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00213899 (* 1 = 0.00213899 loss)
I0521 10:57:58.378163  3675 sgd_solver.cpp:138] Iteration 26900, lr = 2.5e-05
I0521 10:58:01.889729  3675 solver.cpp:243] Iteration 26920, loss = 0.00333824
I0521 10:58:01.889758  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00333813 (* 1 = 0.00333813 loss)
I0521 10:58:01.889765  3675 sgd_solver.cpp:138] Iteration 26920, lr = 2.5e-05
I0521 10:58:05.402343  3675 solver.cpp:243] Iteration 26940, loss = 0.00226973
I0521 10:58:05.402375  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00226963 (* 1 = 0.00226963 loss)
I0521 10:58:05.402396  3675 sgd_solver.cpp:138] Iteration 26940, lr = 2.5e-05
I0521 10:58:08.911693  3675 solver.cpp:243] Iteration 26960, loss = 0.00378664
I0521 10:58:08.911725  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00378654 (* 1 = 0.00378654 loss)
I0521 10:58:08.911731  3675 sgd_solver.cpp:138] Iteration 26960, lr = 2.5e-05
I0521 10:58:12.422077  3675 solver.cpp:243] Iteration 26980, loss = 0.00286354
I0521 10:58:12.422237  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00286344 (* 1 = 0.00286344 loss)
I0521 10:58:12.422245  3675 sgd_solver.cpp:138] Iteration 26980, lr = 2.5e-05
I0521 10:58:15.798060  3675 solver.cpp:358] Iteration 27000, Testing net (#0)
I0521 10:58:20.528419  3675 solver.cpp:425]     Test net output #0: acc = 1
I0521 10:58:20.528458  3675 solver.cpp:425]     Test net output #1: acc = 1
I0521 10:58:20.528481  3675 solver.cpp:425]     Test net output #2: ctcloss = 0.000768469 (* 1 = 0.000768469 loss)
I0521 10:58:20.664312  3675 solver.cpp:243] Iteration 27000, loss = 0.00186576
I0521 10:58:20.664342  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00186565 (* 1 = 0.00186565 loss)
I0521 10:58:20.664347  3675 sgd_solver.cpp:138] Iteration 27000, lr = 2.5e-05
I0521 10:58:24.175945  3675 solver.cpp:243] Iteration 27020, loss = 0.00271285
I0521 10:58:24.175976  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00271274 (* 1 = 0.00271274 loss)
I0521 10:58:24.175997  3675 sgd_solver.cpp:138] Iteration 27020, lr = 2.5e-05
I0521 10:58:27.690062  3675 solver.cpp:243] Iteration 27040, loss = 0.00232902
I0521 10:58:27.690093  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00232892 (* 1 = 0.00232892 loss)
I0521 10:58:27.690096  3675 sgd_solver.cpp:138] Iteration 27040, lr = 2.5e-05
I0521 10:58:31.206810  3675 solver.cpp:243] Iteration 27060, loss = 0.00189819
I0521 10:58:31.206841  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00189809 (* 1 = 0.00189809 loss)
I0521 10:58:31.206863  3675 sgd_solver.cpp:138] Iteration 27060, lr = 2.5e-05
I0521 10:58:34.728448  3675 solver.cpp:243] Iteration 27080, loss = 0.00187598
I0521 10:58:34.728478  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00187588 (* 1 = 0.00187588 loss)
I0521 10:58:34.728485  3675 sgd_solver.cpp:138] Iteration 27080, lr = 2.5e-05
I0521 10:58:38.246824  3675 solver.cpp:243] Iteration 27100, loss = 0.00234952
I0521 10:58:38.246855  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00234942 (* 1 = 0.00234942 loss)
I0521 10:58:38.246860  3675 sgd_solver.cpp:138] Iteration 27100, lr = 2.5e-05
I0521 10:58:41.766541  3675 solver.cpp:243] Iteration 27120, loss = 0.00189427
I0521 10:58:41.766571  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00189417 (* 1 = 0.00189417 loss)
I0521 10:58:41.766577  3675 sgd_solver.cpp:138] Iteration 27120, lr = 2.5e-05
I0521 10:58:45.284801  3675 solver.cpp:243] Iteration 27140, loss = 0.0020879
I0521 10:58:45.284926  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0020878 (* 1 = 0.0020878 loss)
I0521 10:58:45.284934  3675 sgd_solver.cpp:138] Iteration 27140, lr = 2.5e-05
I0521 10:58:48.803510  3675 solver.cpp:243] Iteration 27160, loss = 0.00336185
I0521 10:58:48.803541  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00336175 (* 1 = 0.00336175 loss)
I0521 10:58:48.803547  3675 sgd_solver.cpp:138] Iteration 27160, lr = 2.5e-05
I0521 10:58:52.318959  3675 solver.cpp:243] Iteration 27180, loss = 0.0030279
I0521 10:58:52.318990  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0030278 (* 1 = 0.0030278 loss)
I0521 10:58:52.318996  3675 sgd_solver.cpp:138] Iteration 27180, lr = 2.5e-05
I0521 10:58:55.834071  3675 solver.cpp:243] Iteration 27200, loss = 0.00175865
I0521 10:58:55.834102  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00175855 (* 1 = 0.00175855 loss)
I0521 10:58:55.834108  3675 sgd_solver.cpp:138] Iteration 27200, lr = 2.5e-05
I0521 10:58:59.349709  3675 solver.cpp:243] Iteration 27220, loss = 0.00300402
I0521 10:58:59.349740  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00300392 (* 1 = 0.00300392 loss)
I0521 10:58:59.349745  3675 sgd_solver.cpp:138] Iteration 27220, lr = 2.5e-05
I0521 10:59:02.868758  3675 solver.cpp:243] Iteration 27240, loss = 0.00197108
I0521 10:59:02.868791  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00197098 (* 1 = 0.00197098 loss)
I0521 10:59:02.868796  3675 sgd_solver.cpp:138] Iteration 27240, lr = 2.5e-05
I0521 10:59:06.387184  3675 solver.cpp:243] Iteration 27260, loss = 0.00173377
I0521 10:59:06.387217  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00173367 (* 1 = 0.00173367 loss)
I0521 10:59:06.387223  3675 sgd_solver.cpp:138] Iteration 27260, lr = 2.5e-05
I0521 10:59:09.903056  3675 solver.cpp:243] Iteration 27280, loss = 0.00189972
I0521 10:59:09.903087  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00189962 (* 1 = 0.00189962 loss)
I0521 10:59:09.903092  3675 sgd_solver.cpp:138] Iteration 27280, lr = 2.5e-05
I0521 10:59:13.420693  3675 solver.cpp:243] Iteration 27300, loss = 0.00225426
I0521 10:59:13.420725  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00225416 (* 1 = 0.00225416 loss)
I0521 10:59:13.420732  3675 sgd_solver.cpp:138] Iteration 27300, lr = 2.5e-05
I0521 10:59:16.934320  3675 solver.cpp:243] Iteration 27320, loss = 0.00238114
I0521 10:59:16.934494  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00238103 (* 1 = 0.00238103 loss)
I0521 10:59:16.934501  3675 sgd_solver.cpp:138] Iteration 27320, lr = 2.5e-05
I0521 10:59:20.452975  3675 solver.cpp:243] Iteration 27340, loss = 0.00208212
I0521 10:59:20.453006  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00208202 (* 1 = 0.00208202 loss)
I0521 10:59:20.453011  3675 sgd_solver.cpp:138] Iteration 27340, lr = 2.5e-05
I0521 10:59:23.973206  3675 solver.cpp:243] Iteration 27360, loss = 0.00315912
I0521 10:59:23.973235  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00315902 (* 1 = 0.00315902 loss)
I0521 10:59:23.973242  3675 sgd_solver.cpp:138] Iteration 27360, lr = 2.5e-05
I0521 10:59:27.421412  3675 solver.cpp:243] Iteration 27380, loss = 0.00237383
I0521 10:59:27.421442  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00237373 (* 1 = 0.00237373 loss)
I0521 10:59:27.421448  3675 sgd_solver.cpp:138] Iteration 27380, lr = 2.5e-05
I0521 10:59:30.934954  3675 solver.cpp:243] Iteration 27400, loss = 0.00213998
I0521 10:59:30.934986  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00213987 (* 1 = 0.00213987 loss)
I0521 10:59:30.934993  3675 sgd_solver.cpp:138] Iteration 27400, lr = 2.5e-05
I0521 10:59:34.451939  3675 solver.cpp:243] Iteration 27420, loss = 0.0019277
I0521 10:59:34.451972  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00192759 (* 1 = 0.00192759 loss)
I0521 10:59:34.451978  3675 sgd_solver.cpp:138] Iteration 27420, lr = 2.5e-05
I0521 10:59:37.970821  3675 solver.cpp:243] Iteration 27440, loss = 0.00213557
I0521 10:59:37.970854  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00213546 (* 1 = 0.00213546 loss)
I0521 10:59:37.970860  3675 sgd_solver.cpp:138] Iteration 27440, lr = 2.5e-05
I0521 10:59:41.486289  3675 solver.cpp:243] Iteration 27460, loss = 0.00259782
I0521 10:59:41.486321  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00259772 (* 1 = 0.00259772 loss)
I0521 10:59:41.486326  3675 sgd_solver.cpp:138] Iteration 27460, lr = 2.5e-05
I0521 10:59:45.001765  3675 solver.cpp:243] Iteration 27480, loss = 0.00238288
I0521 10:59:45.001796  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00238278 (* 1 = 0.00238278 loss)
I0521 10:59:45.001801  3675 sgd_solver.cpp:138] Iteration 27480, lr = 2.5e-05
I0521 10:59:48.523872  3675 solver.cpp:243] Iteration 27500, loss = 0.00166352
I0521 10:59:48.524008  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00166341 (* 1 = 0.00166341 loss)
I0521 10:59:48.524014  3675 sgd_solver.cpp:138] Iteration 27500, lr = 2.5e-05
I0521 10:59:52.041337  3675 solver.cpp:243] Iteration 27520, loss = 0.00200205
I0521 10:59:52.041368  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00200194 (* 1 = 0.00200194 loss)
I0521 10:59:52.041373  3675 sgd_solver.cpp:138] Iteration 27520, lr = 2.5e-05
I0521 10:59:55.556416  3675 solver.cpp:243] Iteration 27540, loss = 0.0023128
I0521 10:59:55.556447  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0023127 (* 1 = 0.0023127 loss)
I0521 10:59:55.556469  3675 sgd_solver.cpp:138] Iteration 27540, lr = 2.5e-05
I0521 10:59:59.070654  3675 solver.cpp:243] Iteration 27560, loss = 0.00292364
I0521 10:59:59.070703  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00292354 (* 1 = 0.00292354 loss)
I0521 10:59:59.070711  3675 sgd_solver.cpp:138] Iteration 27560, lr = 2.5e-05
I0521 11:00:02.585355  3675 solver.cpp:243] Iteration 27580, loss = 0.00239011
I0521 11:00:02.585387  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00239 (* 1 = 0.00239 loss)
I0521 11:00:02.585392  3675 sgd_solver.cpp:138] Iteration 27580, lr = 2.5e-05
I0521 11:00:06.104842  3675 solver.cpp:243] Iteration 27600, loss = 0.00233562
I0521 11:00:06.104874  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00233552 (* 1 = 0.00233552 loss)
I0521 11:00:06.104879  3675 sgd_solver.cpp:138] Iteration 27600, lr = 2.5e-05
I0521 11:00:09.622869  3675 solver.cpp:243] Iteration 27620, loss = 0.00221237
I0521 11:00:09.622900  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00221227 (* 1 = 0.00221227 loss)
I0521 11:00:09.622907  3675 sgd_solver.cpp:138] Iteration 27620, lr = 2.5e-05
I0521 11:00:13.138089  3675 solver.cpp:243] Iteration 27640, loss = 0.00219867
I0521 11:00:13.138121  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00219856 (* 1 = 0.00219856 loss)
I0521 11:00:13.138128  3675 sgd_solver.cpp:138] Iteration 27640, lr = 2.5e-05
I0521 11:00:16.655125  3675 solver.cpp:243] Iteration 27660, loss = 0.00212284
I0521 11:00:16.655156  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00212274 (* 1 = 0.00212274 loss)
I0521 11:00:16.655161  3675 sgd_solver.cpp:138] Iteration 27660, lr = 2.5e-05
I0521 11:00:20.173894  3675 solver.cpp:243] Iteration 27680, loss = 0.00191509
I0521 11:00:20.174057  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00191498 (* 1 = 0.00191498 loss)
I0521 11:00:20.174064  3675 sgd_solver.cpp:138] Iteration 27680, lr = 2.5e-05
I0521 11:00:23.690896  3675 solver.cpp:243] Iteration 27700, loss = 0.00184588
I0521 11:00:23.690963  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00184577 (* 1 = 0.00184577 loss)
I0521 11:00:23.690971  3675 sgd_solver.cpp:138] Iteration 27700, lr = 2.5e-05
I0521 11:00:27.214311  3675 solver.cpp:243] Iteration 27720, loss = 0.00171905
I0521 11:00:27.214344  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00171895 (* 1 = 0.00171895 loss)
I0521 11:00:27.214350  3675 sgd_solver.cpp:138] Iteration 27720, lr = 2.5e-05
I0521 11:00:30.733467  3675 solver.cpp:243] Iteration 27740, loss = 0.0019493
I0521 11:00:30.733498  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00194919 (* 1 = 0.00194919 loss)
I0521 11:00:30.733505  3675 sgd_solver.cpp:138] Iteration 27740, lr = 2.5e-05
I0521 11:00:34.251363  3675 solver.cpp:243] Iteration 27760, loss = 0.00210914
I0521 11:00:34.251394  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00210904 (* 1 = 0.00210904 loss)
I0521 11:00:34.251399  3675 sgd_solver.cpp:138] Iteration 27760, lr = 2.5e-05
I0521 11:00:37.771232  3675 solver.cpp:243] Iteration 27780, loss = 0.00316181
I0521 11:00:37.771265  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00316171 (* 1 = 0.00316171 loss)
I0521 11:00:37.771270  3675 sgd_solver.cpp:138] Iteration 27780, lr = 2.5e-05
I0521 11:00:41.288552  3675 solver.cpp:243] Iteration 27800, loss = 0.00247898
I0521 11:00:41.288583  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00247888 (* 1 = 0.00247888 loss)
I0521 11:00:41.288589  3675 sgd_solver.cpp:138] Iteration 27800, lr = 2.5e-05
I0521 11:00:44.803225  3675 solver.cpp:243] Iteration 27820, loss = 0.00293694
I0521 11:00:44.803256  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00293683 (* 1 = 0.00293683 loss)
I0521 11:00:44.803261  3675 sgd_solver.cpp:138] Iteration 27820, lr = 2.5e-05
I0521 11:00:48.316107  3675 solver.cpp:243] Iteration 27840, loss = 0.00201764
I0521 11:00:48.316140  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00201754 (* 1 = 0.00201754 loss)
I0521 11:00:48.316146  3675 sgd_solver.cpp:138] Iteration 27840, lr = 2.5e-05
I0521 11:00:51.827443  3675 solver.cpp:243] Iteration 27860, loss = 0.00192672
I0521 11:00:51.827610  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00192662 (* 1 = 0.00192662 loss)
I0521 11:00:51.827618  3675 sgd_solver.cpp:138] Iteration 27860, lr = 2.5e-05
I0521 11:00:55.339701  3675 solver.cpp:243] Iteration 27880, loss = 0.00228017
I0521 11:00:55.339733  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00228006 (* 1 = 0.00228006 loss)
I0521 11:00:55.339740  3675 sgd_solver.cpp:138] Iteration 27880, lr = 2.5e-05
I0521 11:00:58.856369  3675 solver.cpp:243] Iteration 27900, loss = 0.00330664
I0521 11:00:58.856400  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00330653 (* 1 = 0.00330653 loss)
I0521 11:00:58.856405  3675 sgd_solver.cpp:138] Iteration 27900, lr = 2.5e-05
I0521 11:01:02.378358  3675 solver.cpp:243] Iteration 27920, loss = 0.0020679
I0521 11:01:02.378387  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0020678 (* 1 = 0.0020678 loss)
I0521 11:01:02.378393  3675 sgd_solver.cpp:138] Iteration 27920, lr = 2.5e-05
I0521 11:01:05.896472  3675 solver.cpp:243] Iteration 27940, loss = 0.00257263
I0521 11:01:05.896503  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00257253 (* 1 = 0.00257253 loss)
I0521 11:01:05.896508  3675 sgd_solver.cpp:138] Iteration 27940, lr = 2.5e-05
I0521 11:01:09.420775  3675 solver.cpp:243] Iteration 27960, loss = 0.00180786
I0521 11:01:09.420809  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00180776 (* 1 = 0.00180776 loss)
I0521 11:01:09.420830  3675 sgd_solver.cpp:138] Iteration 27960, lr = 2.5e-05
I0521 11:01:12.943295  3675 solver.cpp:243] Iteration 27980, loss = 0.00279607
I0521 11:01:12.943351  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00279596 (* 1 = 0.00279596 loss)
I0521 11:01:12.943358  3675 sgd_solver.cpp:138] Iteration 27980, lr = 2.5e-05
I0521 11:01:16.326192  3675 solver.cpp:596] Snapshotting to binary proto file models/LPR/lpr_resnet_lstm_iter_28000.caffemodel
I0521 11:01:16.353564  3675 sgd_solver.cpp:307] Snapshotting solver state to binary proto file models/LPR/lpr_resnet_lstm_iter_28000.solverstate
I0521 11:01:16.368352  3675 solver.cpp:358] Iteration 28000, Testing net (#0)
I0521 11:01:21.099709  3675 solver.cpp:425]     Test net output #0: acc = 1
I0521 11:01:21.099736  3675 solver.cpp:425]     Test net output #1: acc = 1
I0521 11:01:21.099743  3675 solver.cpp:425]     Test net output #2: ctcloss = 0.00075569 (* 1 = 0.00075569 loss)
I0521 11:01:21.234694  3675 solver.cpp:243] Iteration 28000, loss = 0.00196287
I0521 11:01:21.234725  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00196276 (* 1 = 0.00196276 loss)
I0521 11:01:21.234731  3675 sgd_solver.cpp:138] Iteration 28000, lr = 2.5e-05
I0521 11:01:24.752403  3675 solver.cpp:243] Iteration 28020, loss = 0.00299927
I0521 11:01:24.752532  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00299916 (* 1 = 0.00299916 loss)
I0521 11:01:24.752538  3675 sgd_solver.cpp:138] Iteration 28020, lr = 2.5e-05
I0521 11:01:28.266419  3675 solver.cpp:243] Iteration 28040, loss = 0.006606
I0521 11:01:28.266451  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0066059 (* 1 = 0.0066059 loss)
I0521 11:01:28.266456  3675 sgd_solver.cpp:138] Iteration 28040, lr = 2.5e-05
I0521 11:01:31.780727  3675 solver.cpp:243] Iteration 28060, loss = 0.00287751
I0521 11:01:31.780759  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0028774 (* 1 = 0.0028774 loss)
I0521 11:01:31.780766  3675 sgd_solver.cpp:138] Iteration 28060, lr = 2.5e-05
I0521 11:01:35.301430  3675 solver.cpp:243] Iteration 28080, loss = 0.00244724
I0521 11:01:35.301479  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00244714 (* 1 = 0.00244714 loss)
I0521 11:01:35.301484  3675 sgd_solver.cpp:138] Iteration 28080, lr = 2.5e-05
I0521 11:01:38.821511  3675 solver.cpp:243] Iteration 28100, loss = 0.00202499
I0521 11:01:38.821542  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00202488 (* 1 = 0.00202488 loss)
I0521 11:01:38.821548  3675 sgd_solver.cpp:138] Iteration 28100, lr = 2.5e-05
I0521 11:01:42.341056  3675 solver.cpp:243] Iteration 28120, loss = 0.00202524
I0521 11:01:42.341087  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00202513 (* 1 = 0.00202513 loss)
I0521 11:01:42.341092  3675 sgd_solver.cpp:138] Iteration 28120, lr = 2.5e-05
I0521 11:01:45.866056  3675 solver.cpp:243] Iteration 28140, loss = 0.00292365
I0521 11:01:45.866089  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00292355 (* 1 = 0.00292355 loss)
I0521 11:01:45.866111  3675 sgd_solver.cpp:138] Iteration 28140, lr = 2.5e-05
I0521 11:01:49.385385  3675 solver.cpp:243] Iteration 28160, loss = 0.00270241
I0521 11:01:49.385416  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00270231 (* 1 = 0.00270231 loss)
I0521 11:01:49.385438  3675 sgd_solver.cpp:138] Iteration 28160, lr = 2.5e-05
I0521 11:01:52.904852  3675 solver.cpp:243] Iteration 28180, loss = 0.00165149
I0521 11:01:52.904883  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00165139 (* 1 = 0.00165139 loss)
I0521 11:01:52.904904  3675 sgd_solver.cpp:138] Iteration 28180, lr = 2.5e-05
I0521 11:01:56.427057  3675 solver.cpp:243] Iteration 28200, loss = 0.00266718
I0521 11:01:56.427243  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00266707 (* 1 = 0.00266707 loss)
I0521 11:01:56.427251  3675 sgd_solver.cpp:138] Iteration 28200, lr = 2.5e-05
I0521 11:01:59.946854  3675 solver.cpp:243] Iteration 28220, loss = 0.00212588
I0521 11:01:59.946885  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00212578 (* 1 = 0.00212578 loss)
I0521 11:01:59.946890  3675 sgd_solver.cpp:138] Iteration 28220, lr = 2.5e-05
I0521 11:02:03.468683  3675 solver.cpp:243] Iteration 28240, loss = 0.00256372
I0521 11:02:03.468714  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00256362 (* 1 = 0.00256362 loss)
I0521 11:02:03.468719  3675 sgd_solver.cpp:138] Iteration 28240, lr = 2.5e-05
I0521 11:02:06.986182  3675 solver.cpp:243] Iteration 28260, loss = 0.0025976
I0521 11:02:06.986213  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0025975 (* 1 = 0.0025975 loss)
I0521 11:02:06.986219  3675 sgd_solver.cpp:138] Iteration 28260, lr = 2.5e-05
I0521 11:02:10.500919  3675 solver.cpp:243] Iteration 28280, loss = 0.00259703
I0521 11:02:10.500955  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00259693 (* 1 = 0.00259693 loss)
I0521 11:02:10.500962  3675 sgd_solver.cpp:138] Iteration 28280, lr = 2.5e-05
I0521 11:02:14.024268  3675 solver.cpp:243] Iteration 28300, loss = 0.00233072
I0521 11:02:14.024302  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00233062 (* 1 = 0.00233062 loss)
I0521 11:02:14.024307  3675 sgd_solver.cpp:138] Iteration 28300, lr = 2.5e-05
I0521 11:02:17.539923  3675 solver.cpp:243] Iteration 28320, loss = 0.00228381
I0521 11:02:17.539954  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0022837 (* 1 = 0.0022837 loss)
I0521 11:02:17.539959  3675 sgd_solver.cpp:138] Iteration 28320, lr = 2.5e-05
I0521 11:02:21.053865  3675 solver.cpp:243] Iteration 28340, loss = 0.00382886
I0521 11:02:21.053898  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00382876 (* 1 = 0.00382876 loss)
I0521 11:02:21.053905  3675 sgd_solver.cpp:138] Iteration 28340, lr = 2.5e-05
I0521 11:02:24.571877  3675 solver.cpp:243] Iteration 28360, loss = 0.00219316
I0521 11:02:24.571908  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00219306 (* 1 = 0.00219306 loss)
I0521 11:02:24.571913  3675 sgd_solver.cpp:138] Iteration 28360, lr = 2.5e-05
I0521 11:02:28.089306  3675 solver.cpp:243] Iteration 28380, loss = 0.00249924
I0521 11:02:28.089401  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00249913 (* 1 = 0.00249913 loss)
I0521 11:02:28.089407  3675 sgd_solver.cpp:138] Iteration 28380, lr = 2.5e-05
I0521 11:02:31.603518  3675 solver.cpp:243] Iteration 28400, loss = 0.00250032
I0521 11:02:31.603549  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00250022 (* 1 = 0.00250022 loss)
I0521 11:02:31.603554  3675 sgd_solver.cpp:138] Iteration 28400, lr = 2.5e-05
I0521 11:02:35.116423  3675 solver.cpp:243] Iteration 28420, loss = 0.00193524
I0521 11:02:35.116454  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00193513 (* 1 = 0.00193513 loss)
I0521 11:02:35.116461  3675 sgd_solver.cpp:138] Iteration 28420, lr = 2.5e-05
I0521 11:02:38.635861  3675 solver.cpp:243] Iteration 28440, loss = 0.00177697
I0521 11:02:38.635892  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00177686 (* 1 = 0.00177686 loss)
I0521 11:02:38.635913  3675 sgd_solver.cpp:138] Iteration 28440, lr = 2.5e-05
I0521 11:02:42.153168  3675 solver.cpp:243] Iteration 28460, loss = 0.00284891
I0521 11:02:42.153200  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00284881 (* 1 = 0.00284881 loss)
I0521 11:02:42.153205  3675 sgd_solver.cpp:138] Iteration 28460, lr = 2.5e-05
I0521 11:02:45.668893  3675 solver.cpp:243] Iteration 28480, loss = 0.00173281
I0521 11:02:45.668926  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0017327 (* 1 = 0.0017327 loss)
I0521 11:02:45.668932  3675 sgd_solver.cpp:138] Iteration 28480, lr = 2.5e-05
I0521 11:02:49.185142  3675 solver.cpp:243] Iteration 28500, loss = 0.00223059
I0521 11:02:49.185173  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00223049 (* 1 = 0.00223049 loss)
I0521 11:02:49.185178  3675 sgd_solver.cpp:138] Iteration 28500, lr = 2.5e-05
I0521 11:02:52.697727  3675 solver.cpp:243] Iteration 28520, loss = 0.00304929
I0521 11:02:52.697762  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00304919 (* 1 = 0.00304919 loss)
I0521 11:02:52.697768  3675 sgd_solver.cpp:138] Iteration 28520, lr = 2.5e-05
I0521 11:02:56.216341  3675 solver.cpp:243] Iteration 28540, loss = 0.0026859
I0521 11:02:56.216372  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00268579 (* 1 = 0.00268579 loss)
I0521 11:02:56.216378  3675 sgd_solver.cpp:138] Iteration 28540, lr = 2.5e-05
I0521 11:02:59.732653  3675 solver.cpp:243] Iteration 28560, loss = 0.00191257
I0521 11:02:59.732815  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00191246 (* 1 = 0.00191246 loss)
I0521 11:02:59.732825  3675 sgd_solver.cpp:138] Iteration 28560, lr = 2.5e-05
I0521 11:03:03.247920  3675 solver.cpp:243] Iteration 28580, loss = 0.00231962
I0521 11:03:03.247949  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00231952 (* 1 = 0.00231952 loss)
I0521 11:03:03.247954  3675 sgd_solver.cpp:138] Iteration 28580, lr = 2.5e-05
I0521 11:03:06.764791  3675 solver.cpp:243] Iteration 28600, loss = 0.0029053
I0521 11:03:06.764822  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0029052 (* 1 = 0.0029052 loss)
I0521 11:03:06.764828  3675 sgd_solver.cpp:138] Iteration 28600, lr = 2.5e-05
I0521 11:03:10.280789  3675 solver.cpp:243] Iteration 28620, loss = 0.0020942
I0521 11:03:10.280822  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0020941 (* 1 = 0.0020941 loss)
I0521 11:03:10.280844  3675 sgd_solver.cpp:138] Iteration 28620, lr = 2.5e-05
I0521 11:03:13.798189  3675 solver.cpp:243] Iteration 28640, loss = 0.00283562
I0521 11:03:13.798221  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00283552 (* 1 = 0.00283552 loss)
I0521 11:03:13.798228  3675 sgd_solver.cpp:138] Iteration 28640, lr = 2.5e-05
I0521 11:03:17.319037  3675 solver.cpp:243] Iteration 28660, loss = 0.00209127
I0521 11:03:17.319068  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00209117 (* 1 = 0.00209117 loss)
I0521 11:03:17.319074  3675 sgd_solver.cpp:138] Iteration 28660, lr = 2.5e-05
I0521 11:03:20.767670  3675 solver.cpp:243] Iteration 28680, loss = 0.00374113
I0521 11:03:20.767702  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00374103 (* 1 = 0.00374103 loss)
I0521 11:03:20.767707  3675 sgd_solver.cpp:138] Iteration 28680, lr = 2.5e-05
I0521 11:03:24.282980  3675 solver.cpp:243] Iteration 28700, loss = 0.00255724
I0521 11:03:24.283011  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00255714 (* 1 = 0.00255714 loss)
I0521 11:03:24.283016  3675 sgd_solver.cpp:138] Iteration 28700, lr = 2.5e-05
I0521 11:03:27.799036  3675 solver.cpp:243] Iteration 28720, loss = 0.00228515
I0521 11:03:27.799067  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00228504 (* 1 = 0.00228504 loss)
I0521 11:03:27.799072  3675 sgd_solver.cpp:138] Iteration 28720, lr = 2.5e-05
I0521 11:03:31.314357  3675 solver.cpp:243] Iteration 28740, loss = 0.00213018
I0521 11:03:31.314517  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00213007 (* 1 = 0.00213007 loss)
I0521 11:03:31.314525  3675 sgd_solver.cpp:138] Iteration 28740, lr = 2.5e-05
I0521 11:03:34.829999  3675 solver.cpp:243] Iteration 28760, loss = 0.00224935
I0521 11:03:34.830031  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00224925 (* 1 = 0.00224925 loss)
I0521 11:03:34.830036  3675 sgd_solver.cpp:138] Iteration 28760, lr = 2.5e-05
I0521 11:03:38.348453  3675 solver.cpp:243] Iteration 28780, loss = 0.00241343
I0521 11:03:38.348484  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00241333 (* 1 = 0.00241333 loss)
I0521 11:03:38.348490  3675 sgd_solver.cpp:138] Iteration 28780, lr = 2.5e-05
I0521 11:03:41.862604  3675 solver.cpp:243] Iteration 28800, loss = 0.00162441
I0521 11:03:41.862635  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00162431 (* 1 = 0.00162431 loss)
I0521 11:03:41.862640  3675 sgd_solver.cpp:138] Iteration 28800, lr = 2.5e-05
I0521 11:03:45.376338  3675 solver.cpp:243] Iteration 28820, loss = 0.00246234
I0521 11:03:45.376368  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00246223 (* 1 = 0.00246223 loss)
I0521 11:03:45.376374  3675 sgd_solver.cpp:138] Iteration 28820, lr = 2.5e-05
I0521 11:03:48.892689  3675 solver.cpp:243] Iteration 28840, loss = 0.00396675
I0521 11:03:48.892735  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00396664 (* 1 = 0.00396664 loss)
I0521 11:03:48.892741  3675 sgd_solver.cpp:138] Iteration 28840, lr = 2.5e-05
I0521 11:03:52.405937  3675 solver.cpp:243] Iteration 28860, loss = 0.00342303
I0521 11:03:52.405969  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00342292 (* 1 = 0.00342292 loss)
I0521 11:03:52.405990  3675 sgd_solver.cpp:138] Iteration 28860, lr = 2.5e-05
I0521 11:03:55.925567  3675 solver.cpp:243] Iteration 28880, loss = 0.00192709
I0521 11:03:55.925598  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00192699 (* 1 = 0.00192699 loss)
I0521 11:03:55.925603  3675 sgd_solver.cpp:138] Iteration 28880, lr = 2.5e-05
I0521 11:03:59.447427  3675 solver.cpp:243] Iteration 28900, loss = 0.00180307
I0521 11:03:59.447459  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00180297 (* 1 = 0.00180297 loss)
I0521 11:03:59.447465  3675 sgd_solver.cpp:138] Iteration 28900, lr = 2.5e-05
I0521 11:04:02.968704  3675 solver.cpp:243] Iteration 28920, loss = 0.00279213
I0521 11:04:02.968850  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00279202 (* 1 = 0.00279202 loss)
I0521 11:04:02.968858  3675 sgd_solver.cpp:138] Iteration 28920, lr = 2.5e-05
I0521 11:04:06.483474  3675 solver.cpp:243] Iteration 28940, loss = 0.00272706
I0521 11:04:06.483505  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00272695 (* 1 = 0.00272695 loss)
I0521 11:04:06.483510  3675 sgd_solver.cpp:138] Iteration 28940, lr = 2.5e-05
I0521 11:04:10.000253  3675 solver.cpp:243] Iteration 28960, loss = 0.00158995
I0521 11:04:10.000285  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00158985 (* 1 = 0.00158985 loss)
I0521 11:04:10.000291  3675 sgd_solver.cpp:138] Iteration 28960, lr = 2.5e-05
I0521 11:04:13.515581  3675 solver.cpp:243] Iteration 28980, loss = 0.00220751
I0521 11:04:13.515610  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00220741 (* 1 = 0.00220741 loss)
I0521 11:04:13.515615  3675 sgd_solver.cpp:138] Iteration 28980, lr = 2.5e-05
I0521 11:04:16.899674  3675 solver.cpp:358] Iteration 29000, Testing net (#0)
I0521 11:04:21.631280  3675 solver.cpp:425]     Test net output #0: acc = 1
I0521 11:04:21.631309  3675 solver.cpp:425]     Test net output #1: acc = 1
I0521 11:04:21.631314  3675 solver.cpp:425]     Test net output #2: ctcloss = 0.000742557 (* 1 = 0.000742557 loss)
I0521 11:04:21.765826  3675 solver.cpp:243] Iteration 29000, loss = 0.00213471
I0521 11:04:21.765854  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00213461 (* 1 = 0.00213461 loss)
I0521 11:04:21.765861  3675 sgd_solver.cpp:138] Iteration 29000, lr = 2.5e-05
I0521 11:04:25.283249  3675 solver.cpp:243] Iteration 29020, loss = 0.00243155
I0521 11:04:25.283282  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00243145 (* 1 = 0.00243145 loss)
I0521 11:04:25.283288  3675 sgd_solver.cpp:138] Iteration 29020, lr = 2.5e-05
I0521 11:04:28.801415  3675 solver.cpp:243] Iteration 29040, loss = 0.0021896
I0521 11:04:28.801446  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00218949 (* 1 = 0.00218949 loss)
I0521 11:04:28.801452  3675 sgd_solver.cpp:138] Iteration 29040, lr = 2.5e-05
I0521 11:04:32.313897  3675 solver.cpp:243] Iteration 29060, loss = 0.00174261
I0521 11:04:32.313928  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00174251 (* 1 = 0.00174251 loss)
I0521 11:04:32.313935  3675 sgd_solver.cpp:138] Iteration 29060, lr = 2.5e-05
I0521 11:04:35.832293  3675 solver.cpp:243] Iteration 29080, loss = 0.00230675
I0521 11:04:35.832458  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00230664 (* 1 = 0.00230664 loss)
I0521 11:04:35.832465  3675 sgd_solver.cpp:138] Iteration 29080, lr = 2.5e-05
I0521 11:04:39.355000  3675 solver.cpp:243] Iteration 29100, loss = 0.00331127
I0521 11:04:39.355031  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00331116 (* 1 = 0.00331116 loss)
I0521 11:04:39.355037  3675 sgd_solver.cpp:138] Iteration 29100, lr = 2.5e-05
I0521 11:04:42.874097  3675 solver.cpp:243] Iteration 29120, loss = 0.00146001
I0521 11:04:42.874128  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0014599 (* 1 = 0.0014599 loss)
I0521 11:04:42.874135  3675 sgd_solver.cpp:138] Iteration 29120, lr = 2.5e-05
I0521 11:04:46.388583  3675 solver.cpp:243] Iteration 29140, loss = 0.00216572
I0521 11:04:46.388615  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00216561 (* 1 = 0.00216561 loss)
I0521 11:04:46.388622  3675 sgd_solver.cpp:138] Iteration 29140, lr = 2.5e-05
I0521 11:04:49.902001  3675 solver.cpp:243] Iteration 29160, loss = 0.00150632
I0521 11:04:49.902034  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00150622 (* 1 = 0.00150622 loss)
I0521 11:04:49.902040  3675 sgd_solver.cpp:138] Iteration 29160, lr = 2.5e-05
I0521 11:04:53.420150  3675 solver.cpp:243] Iteration 29180, loss = 0.00203506
I0521 11:04:53.420182  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00203495 (* 1 = 0.00203495 loss)
I0521 11:04:53.420188  3675 sgd_solver.cpp:138] Iteration 29180, lr = 2.5e-05
I0521 11:04:56.940551  3675 solver.cpp:243] Iteration 29200, loss = 0.0017434
I0521 11:04:56.940582  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00174329 (* 1 = 0.00174329 loss)
I0521 11:04:56.940588  3675 sgd_solver.cpp:138] Iteration 29200, lr = 2.5e-05
I0521 11:05:00.459715  3675 solver.cpp:243] Iteration 29220, loss = 0.00291551
I0521 11:05:00.459748  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00291541 (* 1 = 0.00291541 loss)
I0521 11:05:00.459753  3675 sgd_solver.cpp:138] Iteration 29220, lr = 2.5e-05
I0521 11:05:03.974654  3675 solver.cpp:243] Iteration 29240, loss = 0.00286846
I0521 11:05:03.974685  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00286836 (* 1 = 0.00286836 loss)
I0521 11:05:03.974691  3675 sgd_solver.cpp:138] Iteration 29240, lr = 2.5e-05
I0521 11:05:07.492339  3675 solver.cpp:243] Iteration 29260, loss = 0.00151433
I0521 11:05:07.492419  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00151423 (* 1 = 0.00151423 loss)
I0521 11:05:07.492426  3675 sgd_solver.cpp:138] Iteration 29260, lr = 2.5e-05
I0521 11:05:11.007879  3675 solver.cpp:243] Iteration 29280, loss = 0.0014243
I0521 11:05:11.007910  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0014242 (* 1 = 0.0014242 loss)
I0521 11:05:11.007915  3675 sgd_solver.cpp:138] Iteration 29280, lr = 2.5e-05
I0521 11:05:14.522832  3675 solver.cpp:243] Iteration 29300, loss = 0.00169021
I0521 11:05:14.522863  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0016901 (* 1 = 0.0016901 loss)
I0521 11:05:14.522886  3675 sgd_solver.cpp:138] Iteration 29300, lr = 2.5e-05
I0521 11:05:18.040202  3675 solver.cpp:243] Iteration 29320, loss = 0.00174442
I0521 11:05:18.040233  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00174432 (* 1 = 0.00174432 loss)
I0521 11:05:18.040238  3675 sgd_solver.cpp:138] Iteration 29320, lr = 2.5e-05
I0521 11:05:21.558383  3675 solver.cpp:243] Iteration 29340, loss = 0.00176529
I0521 11:05:21.558415  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00176518 (* 1 = 0.00176518 loss)
I0521 11:05:21.558420  3675 sgd_solver.cpp:138] Iteration 29340, lr = 2.5e-05
I0521 11:05:25.072232  3675 solver.cpp:243] Iteration 29360, loss = 0.00228474
I0521 11:05:25.072264  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00228463 (* 1 = 0.00228463 loss)
I0521 11:05:25.072270  3675 sgd_solver.cpp:138] Iteration 29360, lr = 2.5e-05
I0521 11:05:28.586091  3675 solver.cpp:243] Iteration 29380, loss = 0.00231624
I0521 11:05:28.586122  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00231613 (* 1 = 0.00231613 loss)
I0521 11:05:28.586127  3675 sgd_solver.cpp:138] Iteration 29380, lr = 2.5e-05
I0521 11:05:32.097951  3675 solver.cpp:243] Iteration 29400, loss = 0.00282429
I0521 11:05:32.097985  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00282419 (* 1 = 0.00282419 loss)
I0521 11:05:32.097990  3675 sgd_solver.cpp:138] Iteration 29400, lr = 2.5e-05
I0521 11:05:35.609510  3675 solver.cpp:243] Iteration 29420, loss = 0.00260549
I0521 11:05:35.609542  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00260539 (* 1 = 0.00260539 loss)
I0521 11:05:35.609547  3675 sgd_solver.cpp:138] Iteration 29420, lr = 2.5e-05
I0521 11:05:39.126505  3675 solver.cpp:243] Iteration 29440, loss = 0.00239626
I0521 11:05:39.126698  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00239616 (* 1 = 0.00239616 loss)
I0521 11:05:39.126706  3675 sgd_solver.cpp:138] Iteration 29440, lr = 2.5e-05
I0521 11:05:42.642066  3675 solver.cpp:243] Iteration 29460, loss = 0.00244014
I0521 11:05:42.642096  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00244003 (* 1 = 0.00244003 loss)
I0521 11:05:42.642102  3675 sgd_solver.cpp:138] Iteration 29460, lr = 2.5e-05
I0521 11:05:46.158706  3675 solver.cpp:243] Iteration 29480, loss = 0.00314634
I0521 11:05:46.158737  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00314624 (* 1 = 0.00314624 loss)
I0521 11:05:46.158743  3675 sgd_solver.cpp:138] Iteration 29480, lr = 2.5e-05
I0521 11:05:49.673275  3675 solver.cpp:243] Iteration 29500, loss = 0.00274748
I0521 11:05:49.673306  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00274737 (* 1 = 0.00274737 loss)
I0521 11:05:49.673327  3675 sgd_solver.cpp:138] Iteration 29500, lr = 2.5e-05
I0521 11:05:53.189604  3675 solver.cpp:243] Iteration 29520, loss = 0.00207081
I0521 11:05:53.189635  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00207071 (* 1 = 0.00207071 loss)
I0521 11:05:53.189640  3675 sgd_solver.cpp:138] Iteration 29520, lr = 2.5e-05
I0521 11:05:56.702071  3675 solver.cpp:243] Iteration 29540, loss = 0.00609872
I0521 11:05:56.702101  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00609862 (* 1 = 0.00609862 loss)
I0521 11:05:56.702122  3675 sgd_solver.cpp:138] Iteration 29540, lr = 2.5e-05
I0521 11:06:00.218664  3675 solver.cpp:243] Iteration 29560, loss = 0.00226778
I0521 11:06:00.218696  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00226767 (* 1 = 0.00226767 loss)
I0521 11:06:00.218701  3675 sgd_solver.cpp:138] Iteration 29560, lr = 2.5e-05
I0521 11:06:03.734457  3675 solver.cpp:243] Iteration 29580, loss = 0.00252806
I0521 11:06:03.734488  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00252795 (* 1 = 0.00252795 loss)
I0521 11:06:03.734494  3675 sgd_solver.cpp:138] Iteration 29580, lr = 2.5e-05
I0521 11:06:07.249153  3675 solver.cpp:243] Iteration 29600, loss = 0.00208877
I0521 11:06:07.249186  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00208866 (* 1 = 0.00208866 loss)
I0521 11:06:07.249191  3675 sgd_solver.cpp:138] Iteration 29600, lr = 2.5e-05
I0521 11:06:10.765213  3675 solver.cpp:243] Iteration 29620, loss = 0.00192981
I0521 11:06:10.765339  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00192971 (* 1 = 0.00192971 loss)
I0521 11:06:10.765347  3675 sgd_solver.cpp:138] Iteration 29620, lr = 2.5e-05
I0521 11:06:14.281098  3675 solver.cpp:243] Iteration 29640, loss = 0.0017669
I0521 11:06:14.281128  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0017668 (* 1 = 0.0017668 loss)
I0521 11:06:14.281150  3675 sgd_solver.cpp:138] Iteration 29640, lr = 2.5e-05
I0521 11:06:17.796572  3675 solver.cpp:243] Iteration 29660, loss = 0.00198277
I0521 11:06:17.796603  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00198267 (* 1 = 0.00198267 loss)
I0521 11:06:17.796609  3675 sgd_solver.cpp:138] Iteration 29660, lr = 2.5e-05
I0521 11:06:21.308496  3675 solver.cpp:243] Iteration 29680, loss = 0.00142171
I0521 11:06:21.308527  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00142161 (* 1 = 0.00142161 loss)
I0521 11:06:21.308532  3675 sgd_solver.cpp:138] Iteration 29680, lr = 2.5e-05
I0521 11:06:24.829229  3675 solver.cpp:243] Iteration 29700, loss = 0.00279185
I0521 11:06:24.829262  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00279175 (* 1 = 0.00279175 loss)
I0521 11:06:24.829268  3675 sgd_solver.cpp:138] Iteration 29700, lr = 2.5e-05
I0521 11:06:28.348453  3675 solver.cpp:243] Iteration 29720, loss = 0.00149457
I0521 11:06:28.348484  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00149447 (* 1 = 0.00149447 loss)
I0521 11:06:28.348506  3675 sgd_solver.cpp:138] Iteration 29720, lr = 2.5e-05
I0521 11:06:31.861701  3675 solver.cpp:243] Iteration 29740, loss = 0.00278342
I0521 11:06:31.861733  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00278332 (* 1 = 0.00278332 loss)
I0521 11:06:31.861739  3675 sgd_solver.cpp:138] Iteration 29740, lr = 2.5e-05
I0521 11:06:35.374488  3675 solver.cpp:243] Iteration 29760, loss = 0.00188864
I0521 11:06:35.374519  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00188854 (* 1 = 0.00188854 loss)
I0521 11:06:35.374524  3675 sgd_solver.cpp:138] Iteration 29760, lr = 2.5e-05
I0521 11:06:38.884680  3675 solver.cpp:243] Iteration 29780, loss = 0.00188
I0521 11:06:38.884711  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0018799 (* 1 = 0.0018799 loss)
I0521 11:06:38.884732  3675 sgd_solver.cpp:138] Iteration 29780, lr = 2.5e-05
I0521 11:06:42.395607  3675 solver.cpp:243] Iteration 29800, loss = 0.00217637
I0521 11:06:42.395732  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00217627 (* 1 = 0.00217627 loss)
I0521 11:06:42.395740  3675 sgd_solver.cpp:138] Iteration 29800, lr = 2.5e-05
I0521 11:06:45.911069  3675 solver.cpp:243] Iteration 29820, loss = 0.00217527
I0521 11:06:45.911100  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00217516 (* 1 = 0.00217516 loss)
I0521 11:06:45.911105  3675 sgd_solver.cpp:138] Iteration 29820, lr = 2.5e-05
I0521 11:06:49.430488  3675 solver.cpp:243] Iteration 29840, loss = 0.00203051
I0521 11:06:49.430517  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0020304 (* 1 = 0.0020304 loss)
I0521 11:06:49.430523  3675 sgd_solver.cpp:138] Iteration 29840, lr = 2.5e-05
I0521 11:06:52.944140  3675 solver.cpp:243] Iteration 29860, loss = 0.00286477
I0521 11:06:52.944169  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00286466 (* 1 = 0.00286466 loss)
I0521 11:06:52.944175  3675 sgd_solver.cpp:138] Iteration 29860, lr = 2.5e-05
I0521 11:06:56.460837  3675 solver.cpp:243] Iteration 29880, loss = 0.00203817
I0521 11:06:56.460870  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00203807 (* 1 = 0.00203807 loss)
I0521 11:06:56.460875  3675 sgd_solver.cpp:138] Iteration 29880, lr = 2.5e-05
I0521 11:06:59.979146  3675 solver.cpp:243] Iteration 29900, loss = 0.00176576
I0521 11:06:59.979178  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00176565 (* 1 = 0.00176565 loss)
I0521 11:06:59.979184  3675 sgd_solver.cpp:138] Iteration 29900, lr = 2.5e-05
I0521 11:07:03.499963  3675 solver.cpp:243] Iteration 29920, loss = 0.00205836
I0521 11:07:03.499992  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00205825 (* 1 = 0.00205825 loss)
I0521 11:07:03.500013  3675 sgd_solver.cpp:138] Iteration 29920, lr = 2.5e-05
I0521 11:07:07.014367  3675 solver.cpp:243] Iteration 29940, loss = 0.00192906
I0521 11:07:07.014400  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00192895 (* 1 = 0.00192895 loss)
I0521 11:07:07.014406  3675 sgd_solver.cpp:138] Iteration 29940, lr = 2.5e-05
I0521 11:07:10.532843  3675 solver.cpp:243] Iteration 29960, loss = 0.00228241
I0521 11:07:10.532876  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00228231 (* 1 = 0.00228231 loss)
I0521 11:07:10.532881  3675 sgd_solver.cpp:138] Iteration 29960, lr = 2.5e-05
I0521 11:07:13.986667  3675 solver.cpp:243] Iteration 29980, loss = 0.00209534
I0521 11:07:13.986824  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00209523 (* 1 = 0.00209523 loss)
I0521 11:07:13.986832  3675 sgd_solver.cpp:138] Iteration 29980, lr = 2.5e-05
I0521 11:07:17.368896  3675 solver.cpp:596] Snapshotting to binary proto file models/LPR/lpr_resnet_lstm_iter_30000.caffemodel
I0521 11:07:17.398030  3675 sgd_solver.cpp:307] Snapshotting solver state to binary proto file models/LPR/lpr_resnet_lstm_iter_30000.solverstate
I0521 11:07:17.415638  3675 solver.cpp:358] Iteration 30000, Testing net (#0)
I0521 11:07:22.152020  3675 solver.cpp:425]     Test net output #0: acc = 1
I0521 11:07:22.152048  3675 solver.cpp:425]     Test net output #1: acc = 1
I0521 11:07:22.152055  3675 solver.cpp:425]     Test net output #2: ctcloss = 0.000725568 (* 1 = 0.000725568 loss)
I0521 11:07:22.287623  3675 solver.cpp:243] Iteration 30000, loss = 0.00244848
I0521 11:07:22.287653  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00244838 (* 1 = 0.00244838 loss)
I0521 11:07:22.287683  3675 sgd_solver.cpp:138] Iteration 30000, lr = 1.25e-05
I0521 11:07:25.804838  3675 solver.cpp:243] Iteration 30020, loss = 0.00212139
I0521 11:07:25.804870  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00212129 (* 1 = 0.00212129 loss)
I0521 11:07:25.804877  3675 sgd_solver.cpp:138] Iteration 30020, lr = 1.25e-05
I0521 11:07:29.318948  3675 solver.cpp:243] Iteration 30040, loss = 0.00177566
I0521 11:07:29.318979  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00177556 (* 1 = 0.00177556 loss)
I0521 11:07:29.318984  3675 sgd_solver.cpp:138] Iteration 30040, lr = 1.25e-05
I0521 11:07:32.841760  3675 solver.cpp:243] Iteration 30060, loss = 0.00193462
I0521 11:07:32.841791  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00193452 (* 1 = 0.00193452 loss)
I0521 11:07:32.841797  3675 sgd_solver.cpp:138] Iteration 30060, lr = 1.25e-05
I0521 11:07:36.357412  3675 solver.cpp:243] Iteration 30080, loss = 0.00161891
I0521 11:07:36.357445  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00161881 (* 1 = 0.00161881 loss)
I0521 11:07:36.357450  3675 sgd_solver.cpp:138] Iteration 30080, lr = 1.25e-05
I0521 11:07:39.873950  3675 solver.cpp:243] Iteration 30100, loss = 0.00224609
I0521 11:07:39.873982  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00224598 (* 1 = 0.00224598 loss)
I0521 11:07:39.874004  3675 sgd_solver.cpp:138] Iteration 30100, lr = 1.25e-05
I0521 11:07:43.388489  3675 solver.cpp:243] Iteration 30120, loss = 0.00153273
I0521 11:07:43.388520  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00153263 (* 1 = 0.00153263 loss)
I0521 11:07:43.388525  3675 sgd_solver.cpp:138] Iteration 30120, lr = 1.25e-05
I0521 11:07:46.902734  3675 solver.cpp:243] Iteration 30140, loss = 0.00208092
I0521 11:07:46.902850  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00208081 (* 1 = 0.00208081 loss)
I0521 11:07:46.902858  3675 sgd_solver.cpp:138] Iteration 30140, lr = 1.25e-05
I0521 11:07:50.420723  3675 solver.cpp:243] Iteration 30160, loss = 0.00163398
I0521 11:07:50.420754  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00163387 (* 1 = 0.00163387 loss)
I0521 11:07:50.420760  3675 sgd_solver.cpp:138] Iteration 30160, lr = 1.25e-05
I0521 11:07:53.935386  3675 solver.cpp:243] Iteration 30180, loss = 0.00233537
I0521 11:07:53.935417  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00233527 (* 1 = 0.00233527 loss)
I0521 11:07:53.935423  3675 sgd_solver.cpp:138] Iteration 30180, lr = 1.25e-05
I0521 11:07:57.447438  3675 solver.cpp:243] Iteration 30200, loss = 0.001869
I0521 11:07:57.447468  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0018689 (* 1 = 0.0018689 loss)
I0521 11:07:57.447474  3675 sgd_solver.cpp:138] Iteration 30200, lr = 1.25e-05
I0521 11:08:00.966441  3675 solver.cpp:243] Iteration 30220, loss = 0.00168647
I0521 11:08:00.966472  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00168636 (* 1 = 0.00168636 loss)
I0521 11:08:00.966478  3675 sgd_solver.cpp:138] Iteration 30220, lr = 1.25e-05
I0521 11:08:04.484035  3675 solver.cpp:243] Iteration 30240, loss = 0.00235478
I0521 11:08:04.484066  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00235467 (* 1 = 0.00235467 loss)
I0521 11:08:04.484073  3675 sgd_solver.cpp:138] Iteration 30240, lr = 1.25e-05
I0521 11:08:07.996758  3675 solver.cpp:243] Iteration 30260, loss = 0.00212538
I0521 11:08:07.996806  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00212528 (* 1 = 0.00212528 loss)
I0521 11:08:07.996812  3675 sgd_solver.cpp:138] Iteration 30260, lr = 1.25e-05
I0521 11:08:11.506773  3675 solver.cpp:243] Iteration 30280, loss = 0.0030098
I0521 11:08:11.506804  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00300969 (* 1 = 0.00300969 loss)
I0521 11:08:11.506810  3675 sgd_solver.cpp:138] Iteration 30280, lr = 1.25e-05
I0521 11:08:15.024960  3675 solver.cpp:243] Iteration 30300, loss = 0.00254706
I0521 11:08:15.024989  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00254696 (* 1 = 0.00254696 loss)
I0521 11:08:15.024996  3675 sgd_solver.cpp:138] Iteration 30300, lr = 1.25e-05
I0521 11:08:18.545524  3675 solver.cpp:243] Iteration 30320, loss = 0.00176268
I0521 11:08:18.545701  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00176257 (* 1 = 0.00176257 loss)
I0521 11:08:18.545709  3675 sgd_solver.cpp:138] Iteration 30320, lr = 1.25e-05
I0521 11:08:22.063706  3675 solver.cpp:243] Iteration 30340, loss = 0.00271764
I0521 11:08:22.063736  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00271753 (* 1 = 0.00271753 loss)
I0521 11:08:22.063741  3675 sgd_solver.cpp:138] Iteration 30340, lr = 1.25e-05
I0521 11:08:25.582507  3675 solver.cpp:243] Iteration 30360, loss = 0.00172394
I0521 11:08:25.582537  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00172383 (* 1 = 0.00172383 loss)
I0521 11:08:25.582543  3675 sgd_solver.cpp:138] Iteration 30360, lr = 1.25e-05
I0521 11:08:29.099119  3675 solver.cpp:243] Iteration 30380, loss = 0.00225376
I0521 11:08:29.099151  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00225366 (* 1 = 0.00225366 loss)
I0521 11:08:29.099159  3675 sgd_solver.cpp:138] Iteration 30380, lr = 1.25e-05
I0521 11:08:32.616219  3675 solver.cpp:243] Iteration 30400, loss = 0.00187886
I0521 11:08:32.616251  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00187876 (* 1 = 0.00187876 loss)
I0521 11:08:32.616257  3675 sgd_solver.cpp:138] Iteration 30400, lr = 1.25e-05
I0521 11:08:36.135565  3675 solver.cpp:243] Iteration 30420, loss = 0.00351192
I0521 11:08:36.135597  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00351181 (* 1 = 0.00351181 loss)
I0521 11:08:36.135604  3675 sgd_solver.cpp:138] Iteration 30420, lr = 1.25e-05
I0521 11:08:39.652575  3675 solver.cpp:243] Iteration 30440, loss = 0.00190747
I0521 11:08:39.652606  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00190737 (* 1 = 0.00190737 loss)
I0521 11:08:39.652612  3675 sgd_solver.cpp:138] Iteration 30440, lr = 1.25e-05
I0521 11:08:43.171151  3675 solver.cpp:243] Iteration 30460, loss = 0.00239173
I0521 11:08:43.171183  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00239162 (* 1 = 0.00239162 loss)
I0521 11:08:43.171205  3675 sgd_solver.cpp:138] Iteration 30460, lr = 1.25e-05
I0521 11:08:46.684648  3675 solver.cpp:243] Iteration 30480, loss = 0.00197247
I0521 11:08:46.684679  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00197236 (* 1 = 0.00197236 loss)
I0521 11:08:46.684684  3675 sgd_solver.cpp:138] Iteration 30480, lr = 1.25e-05
I0521 11:08:50.206403  3675 solver.cpp:243] Iteration 30500, loss = 0.00219119
I0521 11:08:50.206562  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00219109 (* 1 = 0.00219109 loss)
I0521 11:08:50.206573  3675 sgd_solver.cpp:138] Iteration 30500, lr = 1.25e-05
I0521 11:08:53.723304  3675 solver.cpp:243] Iteration 30520, loss = 0.00160081
I0521 11:08:53.723333  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00160071 (* 1 = 0.00160071 loss)
I0521 11:08:53.723340  3675 sgd_solver.cpp:138] Iteration 30520, lr = 1.25e-05
I0521 11:08:57.244792  3675 solver.cpp:243] Iteration 30540, loss = 0.00197314
I0521 11:08:57.244823  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00197303 (* 1 = 0.00197303 loss)
I0521 11:08:57.244845  3675 sgd_solver.cpp:138] Iteration 30540, lr = 1.25e-05
I0521 11:09:00.758615  3675 solver.cpp:243] Iteration 30560, loss = 0.00173344
I0521 11:09:00.758646  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00173334 (* 1 = 0.00173334 loss)
I0521 11:09:00.758651  3675 sgd_solver.cpp:138] Iteration 30560, lr = 1.25e-05
I0521 11:09:04.279124  3675 solver.cpp:243] Iteration 30580, loss = 0.00239616
I0521 11:09:04.279155  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00239605 (* 1 = 0.00239605 loss)
I0521 11:09:04.279161  3675 sgd_solver.cpp:138] Iteration 30580, lr = 1.25e-05
I0521 11:09:07.794394  3675 solver.cpp:243] Iteration 30600, loss = 0.00154857
I0521 11:09:07.794425  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00154847 (* 1 = 0.00154847 loss)
I0521 11:09:07.794430  3675 sgd_solver.cpp:138] Iteration 30600, lr = 1.25e-05
I0521 11:09:11.315145  3675 solver.cpp:243] Iteration 30620, loss = 0.00153979
I0521 11:09:11.315177  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00153968 (* 1 = 0.00153968 loss)
I0521 11:09:11.315183  3675 sgd_solver.cpp:138] Iteration 30620, lr = 1.25e-05
I0521 11:09:14.831995  3675 solver.cpp:243] Iteration 30640, loss = 0.00208223
I0521 11:09:14.832027  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00208213 (* 1 = 0.00208213 loss)
I0521 11:09:14.832033  3675 sgd_solver.cpp:138] Iteration 30640, lr = 1.25e-05
I0521 11:09:18.347092  3675 solver.cpp:243] Iteration 30660, loss = 0.00251939
I0521 11:09:18.347121  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00251928 (* 1 = 0.00251928 loss)
I0521 11:09:18.347127  3675 sgd_solver.cpp:138] Iteration 30660, lr = 1.25e-05
I0521 11:09:21.862663  3675 solver.cpp:243] Iteration 30680, loss = 0.00640783
I0521 11:09:21.862828  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00640773 (* 1 = 0.00640773 loss)
I0521 11:09:21.862835  3675 sgd_solver.cpp:138] Iteration 30680, lr = 1.25e-05
I0521 11:09:25.378336  3675 solver.cpp:243] Iteration 30700, loss = 0.00271845
I0521 11:09:25.378368  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00271835 (* 1 = 0.00271835 loss)
I0521 11:09:25.378376  3675 sgd_solver.cpp:138] Iteration 30700, lr = 1.25e-05
I0521 11:09:28.901072  3675 solver.cpp:243] Iteration 30720, loss = 0.00259627
I0521 11:09:28.901103  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00259617 (* 1 = 0.00259617 loss)
I0521 11:09:28.901109  3675 sgd_solver.cpp:138] Iteration 30720, lr = 1.25e-05
I0521 11:09:32.415505  3675 solver.cpp:243] Iteration 30740, loss = 0.00255909
I0521 11:09:32.415537  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00255899 (* 1 = 0.00255899 loss)
I0521 11:09:32.415544  3675 sgd_solver.cpp:138] Iteration 30740, lr = 1.25e-05
I0521 11:09:35.935075  3675 solver.cpp:243] Iteration 30760, loss = 0.00217986
I0521 11:09:35.935106  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00217975 (* 1 = 0.00217975 loss)
I0521 11:09:35.935112  3675 sgd_solver.cpp:138] Iteration 30760, lr = 1.25e-05
I0521 11:09:39.451185  3675 solver.cpp:243] Iteration 30780, loss = 0.00210133
I0521 11:09:39.451216  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00210123 (* 1 = 0.00210123 loss)
I0521 11:09:39.451222  3675 sgd_solver.cpp:138] Iteration 30780, lr = 1.25e-05
I0521 11:09:42.968742  3675 solver.cpp:243] Iteration 30800, loss = 0.00240574
I0521 11:09:42.968772  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00240564 (* 1 = 0.00240564 loss)
I0521 11:09:42.968778  3675 sgd_solver.cpp:138] Iteration 30800, lr = 1.25e-05
I0521 11:09:46.485101  3675 solver.cpp:243] Iteration 30820, loss = 0.00226023
I0521 11:09:46.485131  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00226012 (* 1 = 0.00226012 loss)
I0521 11:09:46.485138  3675 sgd_solver.cpp:138] Iteration 30820, lr = 1.25e-05
I0521 11:09:50.001809  3675 solver.cpp:243] Iteration 30840, loss = 0.00259566
I0521 11:09:50.001839  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00259555 (* 1 = 0.00259555 loss)
I0521 11:09:50.001845  3675 sgd_solver.cpp:138] Iteration 30840, lr = 1.25e-05
I0521 11:09:53.514811  3675 solver.cpp:243] Iteration 30860, loss = 0.0023308
I0521 11:09:53.514983  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00233069 (* 1 = 0.00233069 loss)
I0521 11:09:53.514991  3675 sgd_solver.cpp:138] Iteration 30860, lr = 1.25e-05
I0521 11:09:57.032883  3675 solver.cpp:243] Iteration 30880, loss = 0.00202083
I0521 11:09:57.032913  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00202073 (* 1 = 0.00202073 loss)
I0521 11:09:57.032918  3675 sgd_solver.cpp:138] Iteration 30880, lr = 1.25e-05
I0521 11:10:00.550324  3675 solver.cpp:243] Iteration 30900, loss = 0.00234521
I0521 11:10:00.550354  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00234511 (* 1 = 0.00234511 loss)
I0521 11:10:00.550360  3675 sgd_solver.cpp:138] Iteration 30900, lr = 1.25e-05
I0521 11:10:04.069219  3675 solver.cpp:243] Iteration 30920, loss = 0.00179984
I0521 11:10:04.069252  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00179974 (* 1 = 0.00179974 loss)
I0521 11:10:04.069257  3675 sgd_solver.cpp:138] Iteration 30920, lr = 1.25e-05
I0521 11:10:07.581543  3675 solver.cpp:243] Iteration 30940, loss = 0.00262274
I0521 11:10:07.581574  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00262264 (* 1 = 0.00262264 loss)
I0521 11:10:07.581596  3675 sgd_solver.cpp:138] Iteration 30940, lr = 1.25e-05
I0521 11:10:11.100037  3675 solver.cpp:243] Iteration 30960, loss = 0.00176501
I0521 11:10:11.100069  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0017649 (* 1 = 0.0017649 loss)
I0521 11:10:11.100075  3675 sgd_solver.cpp:138] Iteration 30960, lr = 1.25e-05
I0521 11:10:14.619170  3675 solver.cpp:243] Iteration 30980, loss = 0.00218495
I0521 11:10:14.619199  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00218485 (* 1 = 0.00218485 loss)
I0521 11:10:14.619205  3675 sgd_solver.cpp:138] Iteration 30980, lr = 1.25e-05
I0521 11:10:18.007227  3675 solver.cpp:358] Iteration 31000, Testing net (#0)
I0521 11:10:22.738487  3675 solver.cpp:425]     Test net output #0: acc = 1
I0521 11:10:22.738515  3675 solver.cpp:425]     Test net output #1: acc = 1
I0521 11:10:22.738523  3675 solver.cpp:425]     Test net output #2: ctcloss = 0.000720684 (* 1 = 0.000720684 loss)
I0521 11:10:22.872872  3675 solver.cpp:243] Iteration 31000, loss = 0.00232767
I0521 11:10:22.872902  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00232757 (* 1 = 0.00232757 loss)
I0521 11:10:22.872910  3675 sgd_solver.cpp:138] Iteration 31000, lr = 1.25e-05
I0521 11:10:26.392105  3675 solver.cpp:243] Iteration 31020, loss = 0.00247822
I0521 11:10:26.392266  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00247812 (* 1 = 0.00247812 loss)
I0521 11:10:26.392273  3675 sgd_solver.cpp:138] Iteration 31020, lr = 1.25e-05
I0521 11:10:29.914132  3675 solver.cpp:243] Iteration 31040, loss = 0.0133926
I0521 11:10:29.914161  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0133925 (* 1 = 0.0133925 loss)
I0521 11:10:29.914170  3675 sgd_solver.cpp:138] Iteration 31040, lr = 1.25e-05
I0521 11:10:33.436848  3675 solver.cpp:243] Iteration 31060, loss = 0.001822
I0521 11:10:33.436878  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00182189 (* 1 = 0.00182189 loss)
I0521 11:10:33.436902  3675 sgd_solver.cpp:138] Iteration 31060, lr = 1.25e-05
I0521 11:10:36.954001  3675 solver.cpp:243] Iteration 31080, loss = 0.00187975
I0521 11:10:36.954032  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00187964 (* 1 = 0.00187964 loss)
I0521 11:10:36.954038  3675 sgd_solver.cpp:138] Iteration 31080, lr = 1.25e-05
I0521 11:10:40.473397  3675 solver.cpp:243] Iteration 31100, loss = 0.00199369
I0521 11:10:40.473428  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00199358 (* 1 = 0.00199358 loss)
I0521 11:10:40.473433  3675 sgd_solver.cpp:138] Iteration 31100, lr = 1.25e-05
I0521 11:10:43.987177  3675 solver.cpp:243] Iteration 31120, loss = 0.00190043
I0521 11:10:43.987206  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00190032 (* 1 = 0.00190032 loss)
I0521 11:10:43.987212  3675 sgd_solver.cpp:138] Iteration 31120, lr = 1.25e-05
I0521 11:10:47.508574  3675 solver.cpp:243] Iteration 31140, loss = 0.00222046
I0521 11:10:47.508605  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00222035 (* 1 = 0.00222035 loss)
I0521 11:10:47.508612  3675 sgd_solver.cpp:138] Iteration 31140, lr = 1.25e-05
I0521 11:10:51.027915  3675 solver.cpp:243] Iteration 31160, loss = 0.00257707
I0521 11:10:51.027945  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00257697 (* 1 = 0.00257697 loss)
I0521 11:10:51.027951  3675 sgd_solver.cpp:138] Iteration 31160, lr = 1.25e-05
I0521 11:10:54.550261  3675 solver.cpp:243] Iteration 31180, loss = 0.0022748
I0521 11:10:54.550292  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00227469 (* 1 = 0.00227469 loss)
I0521 11:10:54.550298  3675 sgd_solver.cpp:138] Iteration 31180, lr = 1.25e-05
I0521 11:10:58.075100  3675 solver.cpp:243] Iteration 31200, loss = 0.00172238
I0521 11:10:58.075260  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00172228 (* 1 = 0.00172228 loss)
I0521 11:10:58.075268  3675 sgd_solver.cpp:138] Iteration 31200, lr = 1.25e-05
I0521 11:11:01.599495  3675 solver.cpp:243] Iteration 31220, loss = 0.00186296
I0521 11:11:01.599526  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00186286 (* 1 = 0.00186286 loss)
I0521 11:11:01.599548  3675 sgd_solver.cpp:138] Iteration 31220, lr = 1.25e-05
I0521 11:11:05.121193  3675 solver.cpp:243] Iteration 31240, loss = 0.00277255
I0521 11:11:05.121224  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00277245 (* 1 = 0.00277245 loss)
I0521 11:11:05.121248  3675 sgd_solver.cpp:138] Iteration 31240, lr = 1.25e-05
I0521 11:11:08.638620  3675 solver.cpp:243] Iteration 31260, loss = 0.0017867
I0521 11:11:08.638651  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0017866 (* 1 = 0.0017866 loss)
I0521 11:11:08.638659  3675 sgd_solver.cpp:138] Iteration 31260, lr = 1.25e-05
I0521 11:11:12.095803  3675 solver.cpp:243] Iteration 31280, loss = 0.00211041
I0521 11:11:12.095834  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00211031 (* 1 = 0.00211031 loss)
I0521 11:11:12.095840  3675 sgd_solver.cpp:138] Iteration 31280, lr = 1.25e-05
I0521 11:11:15.615010  3675 solver.cpp:243] Iteration 31300, loss = 0.00185779
I0521 11:11:15.615041  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00185769 (* 1 = 0.00185769 loss)
I0521 11:11:15.615047  3675 sgd_solver.cpp:138] Iteration 31300, lr = 1.25e-05
I0521 11:11:19.134440  3675 solver.cpp:243] Iteration 31320, loss = 0.00214719
I0521 11:11:19.134472  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00214709 (* 1 = 0.00214709 loss)
I0521 11:11:19.134479  3675 sgd_solver.cpp:138] Iteration 31320, lr = 1.25e-05
I0521 11:11:22.651130  3675 solver.cpp:243] Iteration 31340, loss = 0.0052442
I0521 11:11:22.651160  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00524409 (* 1 = 0.00524409 loss)
I0521 11:11:22.651165  3675 sgd_solver.cpp:138] Iteration 31340, lr = 1.25e-05
I0521 11:11:26.171129  3675 solver.cpp:243] Iteration 31360, loss = 0.00212272
I0521 11:11:26.171160  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00212261 (* 1 = 0.00212261 loss)
I0521 11:11:26.171166  3675 sgd_solver.cpp:138] Iteration 31360, lr = 1.25e-05
I0521 11:11:29.695137  3675 solver.cpp:243] Iteration 31380, loss = 0.00157318
I0521 11:11:29.695295  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00157308 (* 1 = 0.00157308 loss)
I0521 11:11:29.695304  3675 sgd_solver.cpp:138] Iteration 31380, lr = 1.25e-05
I0521 11:11:33.216234  3675 solver.cpp:243] Iteration 31400, loss = 0.00192479
I0521 11:11:33.216264  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00192468 (* 1 = 0.00192468 loss)
I0521 11:11:33.216271  3675 sgd_solver.cpp:138] Iteration 31400, lr = 1.25e-05
I0521 11:11:36.738782  3675 solver.cpp:243] Iteration 31420, loss = 0.00198221
I0521 11:11:36.738813  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00198211 (* 1 = 0.00198211 loss)
I0521 11:11:36.738819  3675 sgd_solver.cpp:138] Iteration 31420, lr = 1.25e-05
I0521 11:11:40.255121  3675 solver.cpp:243] Iteration 31440, loss = 0.00150799
I0521 11:11:40.255151  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00150789 (* 1 = 0.00150789 loss)
I0521 11:11:40.255173  3675 sgd_solver.cpp:138] Iteration 31440, lr = 1.25e-05
I0521 11:11:43.771425  3675 solver.cpp:243] Iteration 31460, loss = 0.00160016
I0521 11:11:43.771456  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00160006 (* 1 = 0.00160006 loss)
I0521 11:11:43.771462  3675 sgd_solver.cpp:138] Iteration 31460, lr = 1.25e-05
I0521 11:11:47.292909  3675 solver.cpp:243] Iteration 31480, loss = 0.00191906
I0521 11:11:47.292939  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00191895 (* 1 = 0.00191895 loss)
I0521 11:11:47.292945  3675 sgd_solver.cpp:138] Iteration 31480, lr = 1.25e-05
I0521 11:11:50.811354  3675 solver.cpp:243] Iteration 31500, loss = 0.00175211
I0521 11:11:50.811384  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00175201 (* 1 = 0.00175201 loss)
I0521 11:11:50.811406  3675 sgd_solver.cpp:138] Iteration 31500, lr = 1.25e-05
I0521 11:11:54.328373  3675 solver.cpp:243] Iteration 31520, loss = 0.00206368
I0521 11:11:54.328403  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00206358 (* 1 = 0.00206358 loss)
I0521 11:11:54.328425  3675 sgd_solver.cpp:138] Iteration 31520, lr = 1.25e-05
I0521 11:11:57.846093  3675 solver.cpp:243] Iteration 31540, loss = 0.00202357
I0521 11:11:57.846129  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00202347 (* 1 = 0.00202347 loss)
I0521 11:11:57.846137  3675 sgd_solver.cpp:138] Iteration 31540, lr = 1.25e-05
I0521 11:12:01.366863  3675 solver.cpp:243] Iteration 31560, loss = 0.00236281
I0521 11:12:01.366986  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0023627 (* 1 = 0.0023627 loss)
I0521 11:12:01.366992  3675 sgd_solver.cpp:138] Iteration 31560, lr = 1.25e-05
I0521 11:12:04.886139  3675 solver.cpp:243] Iteration 31580, loss = 0.00168872
I0521 11:12:04.886170  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00168862 (* 1 = 0.00168862 loss)
I0521 11:12:04.886175  3675 sgd_solver.cpp:138] Iteration 31580, lr = 1.25e-05
I0521 11:12:08.409802  3675 solver.cpp:243] Iteration 31600, loss = 0.00196556
I0521 11:12:08.409834  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00196546 (* 1 = 0.00196546 loss)
I0521 11:12:08.409842  3675 sgd_solver.cpp:138] Iteration 31600, lr = 1.25e-05
I0521 11:12:11.931470  3675 solver.cpp:243] Iteration 31620, loss = 0.00168859
I0521 11:12:11.931502  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00168848 (* 1 = 0.00168848 loss)
I0521 11:12:11.931509  3675 sgd_solver.cpp:138] Iteration 31620, lr = 1.25e-05
I0521 11:12:15.453795  3675 solver.cpp:243] Iteration 31640, loss = 0.00169174
I0521 11:12:15.453826  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00169164 (* 1 = 0.00169164 loss)
I0521 11:12:15.453832  3675 sgd_solver.cpp:138] Iteration 31640, lr = 1.25e-05
I0521 11:12:18.974740  3675 solver.cpp:243] Iteration 31660, loss = 0.00235304
I0521 11:12:18.974771  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00235293 (* 1 = 0.00235293 loss)
I0521 11:12:18.974776  3675 sgd_solver.cpp:138] Iteration 31660, lr = 1.25e-05
I0521 11:12:22.491967  3675 solver.cpp:243] Iteration 31680, loss = 0.00320881
I0521 11:12:22.491998  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00320871 (* 1 = 0.00320871 loss)
I0521 11:12:22.492005  3675 sgd_solver.cpp:138] Iteration 31680, lr = 1.25e-05
I0521 11:12:26.012897  3675 solver.cpp:243] Iteration 31700, loss = 0.00240602
I0521 11:12:26.012928  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00240591 (* 1 = 0.00240591 loss)
I0521 11:12:26.012933  3675 sgd_solver.cpp:138] Iteration 31700, lr = 1.25e-05
I0521 11:12:29.537580  3675 solver.cpp:243] Iteration 31720, loss = 0.00210172
I0521 11:12:29.537609  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00210162 (* 1 = 0.00210162 loss)
I0521 11:12:29.537616  3675 sgd_solver.cpp:138] Iteration 31720, lr = 1.25e-05
I0521 11:12:33.054883  3675 solver.cpp:243] Iteration 31740, loss = 0.00223741
I0521 11:12:33.055055  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0022373 (* 1 = 0.0022373 loss)
I0521 11:12:33.055063  3675 sgd_solver.cpp:138] Iteration 31740, lr = 1.25e-05
I0521 11:12:36.574765  3675 solver.cpp:243] Iteration 31760, loss = 0.00171583
I0521 11:12:36.574797  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00171572 (* 1 = 0.00171572 loss)
I0521 11:12:36.574802  3675 sgd_solver.cpp:138] Iteration 31760, lr = 1.25e-05
I0521 11:12:40.094233  3675 solver.cpp:243] Iteration 31780, loss = 0.00186141
I0521 11:12:40.094262  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0018613 (* 1 = 0.0018613 loss)
I0521 11:12:40.094269  3675 sgd_solver.cpp:138] Iteration 31780, lr = 1.25e-05
I0521 11:12:43.611250  3675 solver.cpp:243] Iteration 31800, loss = 0.00169356
I0521 11:12:43.611280  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00169346 (* 1 = 0.00169346 loss)
I0521 11:12:43.611286  3675 sgd_solver.cpp:138] Iteration 31800, lr = 1.25e-05
I0521 11:12:47.131304  3675 solver.cpp:243] Iteration 31820, loss = 0.00134308
I0521 11:12:47.131335  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00134298 (* 1 = 0.00134298 loss)
I0521 11:12:47.131342  3675 sgd_solver.cpp:138] Iteration 31820, lr = 1.25e-05
I0521 11:12:50.655716  3675 solver.cpp:243] Iteration 31840, loss = 0.00203059
I0521 11:12:50.655747  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00203049 (* 1 = 0.00203049 loss)
I0521 11:12:50.655768  3675 sgd_solver.cpp:138] Iteration 31840, lr = 1.25e-05
I0521 11:12:54.174224  3675 solver.cpp:243] Iteration 31860, loss = 0.00156194
I0521 11:12:54.174257  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00156184 (* 1 = 0.00156184 loss)
I0521 11:12:54.174262  3675 sgd_solver.cpp:138] Iteration 31860, lr = 1.25e-05
I0521 11:12:57.686909  3675 solver.cpp:243] Iteration 31880, loss = 0.00371034
I0521 11:12:57.686940  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00371023 (* 1 = 0.00371023 loss)
I0521 11:12:57.686947  3675 sgd_solver.cpp:138] Iteration 31880, lr = 1.25e-05
I0521 11:13:01.212558  3675 solver.cpp:243] Iteration 31900, loss = 0.00163736
I0521 11:13:01.212589  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00163726 (* 1 = 0.00163726 loss)
I0521 11:13:01.212595  3675 sgd_solver.cpp:138] Iteration 31900, lr = 1.25e-05
I0521 11:13:04.733764  3675 solver.cpp:243] Iteration 31920, loss = 0.00198783
I0521 11:13:04.733913  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00198773 (* 1 = 0.00198773 loss)
I0521 11:13:04.733922  3675 sgd_solver.cpp:138] Iteration 31920, lr = 1.25e-05
I0521 11:13:08.254938  3675 solver.cpp:243] Iteration 31940, loss = 0.00241999
I0521 11:13:08.254969  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00241988 (* 1 = 0.00241988 loss)
I0521 11:13:08.254976  3675 sgd_solver.cpp:138] Iteration 31940, lr = 1.25e-05
I0521 11:13:11.775126  3675 solver.cpp:243] Iteration 31960, loss = 0.00252572
I0521 11:13:11.775157  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00252562 (* 1 = 0.00252562 loss)
I0521 11:13:11.775163  3675 sgd_solver.cpp:138] Iteration 31960, lr = 1.25e-05
I0521 11:13:15.298105  3675 solver.cpp:243] Iteration 31980, loss = 0.00161728
I0521 11:13:15.298138  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00161718 (* 1 = 0.00161718 loss)
I0521 11:13:15.298161  3675 sgd_solver.cpp:138] Iteration 31980, lr = 1.25e-05
I0521 11:13:18.685302  3675 solver.cpp:596] Snapshotting to binary proto file models/LPR/lpr_resnet_lstm_iter_32000.caffemodel
I0521 11:13:18.714370  3675 sgd_solver.cpp:307] Snapshotting solver state to binary proto file models/LPR/lpr_resnet_lstm_iter_32000.solverstate
I0521 11:13:18.730437  3675 solver.cpp:358] Iteration 32000, Testing net (#0)
I0521 11:13:23.463367  3675 solver.cpp:425]     Test net output #0: acc = 1
I0521 11:13:23.463392  3675 solver.cpp:425]     Test net output #1: acc = 1
I0521 11:13:23.463399  3675 solver.cpp:425]     Test net output #2: ctcloss = 0.00071775 (* 1 = 0.00071775 loss)
I0521 11:13:23.598314  3675 solver.cpp:243] Iteration 32000, loss = 0.00208187
I0521 11:13:23.598343  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00208177 (* 1 = 0.00208177 loss)
I0521 11:13:23.598351  3675 sgd_solver.cpp:138] Iteration 32000, lr = 1.25e-05
I0521 11:13:27.118140  3675 solver.cpp:243] Iteration 32020, loss = 0.00244322
I0521 11:13:27.118170  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00244312 (* 1 = 0.00244312 loss)
I0521 11:13:27.118176  3675 sgd_solver.cpp:138] Iteration 32020, lr = 1.25e-05
I0521 11:13:30.636996  3675 solver.cpp:243] Iteration 32040, loss = 0.00186407
I0521 11:13:30.637027  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00186397 (* 1 = 0.00186397 loss)
I0521 11:13:30.637034  3675 sgd_solver.cpp:138] Iteration 32040, lr = 1.25e-05
I0521 11:13:34.154486  3675 solver.cpp:243] Iteration 32060, loss = 0.00194152
I0521 11:13:34.154517  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00194142 (* 1 = 0.00194142 loss)
I0521 11:13:34.154525  3675 sgd_solver.cpp:138] Iteration 32060, lr = 1.25e-05
I0521 11:13:37.676975  3675 solver.cpp:243] Iteration 32080, loss = 0.0019134
I0521 11:13:37.677150  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0019133 (* 1 = 0.0019133 loss)
I0521 11:13:37.677158  3675 sgd_solver.cpp:138] Iteration 32080, lr = 1.25e-05
I0521 11:13:41.190279  3675 solver.cpp:243] Iteration 32100, loss = 0.00249625
I0521 11:13:41.190310  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00249615 (* 1 = 0.00249615 loss)
I0521 11:13:41.190315  3675 sgd_solver.cpp:138] Iteration 32100, lr = 1.25e-05
I0521 11:13:44.701822  3675 solver.cpp:243] Iteration 32120, loss = 0.002467
I0521 11:13:44.701853  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00246689 (* 1 = 0.00246689 loss)
I0521 11:13:44.701859  3675 sgd_solver.cpp:138] Iteration 32120, lr = 1.25e-05
I0521 11:13:48.216918  3675 solver.cpp:243] Iteration 32140, loss = 0.00176665
I0521 11:13:48.216959  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00176655 (* 1 = 0.00176655 loss)
I0521 11:13:48.216965  3675 sgd_solver.cpp:138] Iteration 32140, lr = 1.25e-05
I0521 11:13:51.732924  3675 solver.cpp:243] Iteration 32160, loss = 0.00224033
I0521 11:13:51.732955  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00224022 (* 1 = 0.00224022 loss)
I0521 11:13:51.732961  3675 sgd_solver.cpp:138] Iteration 32160, lr = 1.25e-05
I0521 11:13:55.249179  3675 solver.cpp:243] Iteration 32180, loss = 0.00497045
I0521 11:13:55.249210  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00497035 (* 1 = 0.00497035 loss)
I0521 11:13:55.249217  3675 sgd_solver.cpp:138] Iteration 32180, lr = 1.25e-05
I0521 11:13:58.765779  3675 solver.cpp:243] Iteration 32200, loss = 0.00190151
I0521 11:13:58.765811  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00190141 (* 1 = 0.00190141 loss)
I0521 11:13:58.765833  3675 sgd_solver.cpp:138] Iteration 32200, lr = 1.25e-05
I0521 11:14:02.282593  3675 solver.cpp:243] Iteration 32220, loss = 0.00585372
I0521 11:14:02.282624  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00585362 (* 1 = 0.00585362 loss)
I0521 11:14:02.282629  3675 sgd_solver.cpp:138] Iteration 32220, lr = 1.25e-05
I0521 11:14:05.799106  3675 solver.cpp:243] Iteration 32240, loss = 0.00207959
I0521 11:14:05.799139  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00207949 (* 1 = 0.00207949 loss)
I0521 11:14:05.799144  3675 sgd_solver.cpp:138] Iteration 32240, lr = 1.25e-05
I0521 11:14:09.314208  3675 solver.cpp:243] Iteration 32260, loss = 0.00231761
I0521 11:14:09.314332  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00231751 (* 1 = 0.00231751 loss)
I0521 11:14:09.314340  3675 sgd_solver.cpp:138] Iteration 32260, lr = 1.25e-05
I0521 11:14:12.835103  3675 solver.cpp:243] Iteration 32280, loss = 0.00178632
I0521 11:14:12.835134  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00178622 (* 1 = 0.00178622 loss)
I0521 11:14:12.835155  3675 sgd_solver.cpp:138] Iteration 32280, lr = 1.25e-05
I0521 11:14:16.348659  3675 solver.cpp:243] Iteration 32300, loss = 0.00177834
I0521 11:14:16.348691  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00177823 (* 1 = 0.00177823 loss)
I0521 11:14:16.348697  3675 sgd_solver.cpp:138] Iteration 32300, lr = 1.25e-05
I0521 11:14:19.868710  3675 solver.cpp:243] Iteration 32320, loss = 0.00196782
I0521 11:14:19.868741  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00196772 (* 1 = 0.00196772 loss)
I0521 11:14:19.868746  3675 sgd_solver.cpp:138] Iteration 32320, lr = 1.25e-05
I0521 11:14:23.386938  3675 solver.cpp:243] Iteration 32340, loss = 0.00227629
I0521 11:14:23.386971  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00227619 (* 1 = 0.00227619 loss)
I0521 11:14:23.386994  3675 sgd_solver.cpp:138] Iteration 32340, lr = 1.25e-05
I0521 11:14:26.900876  3675 solver.cpp:243] Iteration 32360, loss = 0.00289812
I0521 11:14:26.900907  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00289802 (* 1 = 0.00289802 loss)
I0521 11:14:26.900913  3675 sgd_solver.cpp:138] Iteration 32360, lr = 1.25e-05
I0521 11:14:30.413311  3675 solver.cpp:243] Iteration 32380, loss = 0.00231558
I0521 11:14:30.413342  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00231547 (* 1 = 0.00231547 loss)
I0521 11:14:30.413364  3675 sgd_solver.cpp:138] Iteration 32380, lr = 1.25e-05
I0521 11:14:33.926090  3675 solver.cpp:243] Iteration 32400, loss = 0.00162518
I0521 11:14:33.926121  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00162508 (* 1 = 0.00162508 loss)
I0521 11:14:33.926128  3675 sgd_solver.cpp:138] Iteration 32400, lr = 1.25e-05
I0521 11:14:37.441344  3675 solver.cpp:243] Iteration 32420, loss = 0.00217385
I0521 11:14:37.441377  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00217375 (* 1 = 0.00217375 loss)
I0521 11:14:37.441385  3675 sgd_solver.cpp:138] Iteration 32420, lr = 1.25e-05
I0521 11:14:40.957979  3675 solver.cpp:243] Iteration 32440, loss = 0.00215964
I0521 11:14:40.958146  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00215953 (* 1 = 0.00215953 loss)
I0521 11:14:40.958153  3675 sgd_solver.cpp:138] Iteration 32440, lr = 1.25e-05
I0521 11:14:44.474684  3675 solver.cpp:243] Iteration 32460, loss = 0.00209398
I0521 11:14:44.474716  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00209388 (* 1 = 0.00209388 loss)
I0521 11:14:44.474722  3675 sgd_solver.cpp:138] Iteration 32460, lr = 1.25e-05
I0521 11:14:47.988919  3675 solver.cpp:243] Iteration 32480, loss = 0.00180073
I0521 11:14:47.988950  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00180063 (* 1 = 0.00180063 loss)
I0521 11:14:47.988957  3675 sgd_solver.cpp:138] Iteration 32480, lr = 1.25e-05
I0521 11:14:51.506312  3675 solver.cpp:243] Iteration 32500, loss = 0.00296212
I0521 11:14:51.506345  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00296202 (* 1 = 0.00296202 loss)
I0521 11:14:51.506352  3675 sgd_solver.cpp:138] Iteration 32500, lr = 1.25e-05
I0521 11:14:55.026072  3675 solver.cpp:243] Iteration 32520, loss = 0.00192887
I0521 11:14:55.026104  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00192876 (* 1 = 0.00192876 loss)
I0521 11:14:55.026111  3675 sgd_solver.cpp:138] Iteration 32520, lr = 1.25e-05
I0521 11:14:58.538146  3675 solver.cpp:243] Iteration 32540, loss = 0.00230017
I0521 11:14:58.538177  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00230006 (* 1 = 0.00230006 loss)
I0521 11:14:58.538183  3675 sgd_solver.cpp:138] Iteration 32540, lr = 1.25e-05
I0521 11:15:02.055155  3675 solver.cpp:243] Iteration 32560, loss = 0.00210813
I0521 11:15:02.055186  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00210802 (* 1 = 0.00210802 loss)
I0521 11:15:02.055193  3675 sgd_solver.cpp:138] Iteration 32560, lr = 1.25e-05
I0521 11:15:05.501504  3675 solver.cpp:243] Iteration 32580, loss = 0.00215305
I0521 11:15:05.501535  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00215294 (* 1 = 0.00215294 loss)
I0521 11:15:05.501540  3675 sgd_solver.cpp:138] Iteration 32580, lr = 1.25e-05
I0521 11:15:09.012464  3675 solver.cpp:243] Iteration 32600, loss = 0.00349829
I0521 11:15:09.012495  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00349819 (* 1 = 0.00349819 loss)
I0521 11:15:09.012501  3675 sgd_solver.cpp:138] Iteration 32600, lr = 1.25e-05
I0521 11:15:12.530925  3675 solver.cpp:243] Iteration 32620, loss = 0.00299151
I0521 11:15:12.531086  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0029914 (* 1 = 0.0029914 loss)
I0521 11:15:12.531095  3675 sgd_solver.cpp:138] Iteration 32620, lr = 1.25e-05
I0521 11:15:16.043478  3675 solver.cpp:243] Iteration 32640, loss = 0.00170737
I0521 11:15:16.043509  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00170727 (* 1 = 0.00170727 loss)
I0521 11:15:16.043515  3675 sgd_solver.cpp:138] Iteration 32640, lr = 1.25e-05
I0521 11:15:19.556831  3675 solver.cpp:243] Iteration 32660, loss = 0.00139893
I0521 11:15:19.556862  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00139883 (* 1 = 0.00139883 loss)
I0521 11:15:19.556869  3675 sgd_solver.cpp:138] Iteration 32660, lr = 1.25e-05
I0521 11:15:23.071991  3675 solver.cpp:243] Iteration 32680, loss = 0.00235238
I0521 11:15:23.072024  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00235227 (* 1 = 0.00235227 loss)
I0521 11:15:23.072031  3675 sgd_solver.cpp:138] Iteration 32680, lr = 1.25e-05
I0521 11:15:26.584931  3675 solver.cpp:243] Iteration 32700, loss = 0.00299001
I0521 11:15:26.584962  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0029899 (* 1 = 0.0029899 loss)
I0521 11:15:26.584970  3675 sgd_solver.cpp:138] Iteration 32700, lr = 1.25e-05
I0521 11:15:30.101115  3675 solver.cpp:243] Iteration 32720, loss = 0.00238379
I0521 11:15:30.101146  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00238369 (* 1 = 0.00238369 loss)
I0521 11:15:30.101153  3675 sgd_solver.cpp:138] Iteration 32720, lr = 1.25e-05
I0521 11:15:33.615238  3675 solver.cpp:243] Iteration 32740, loss = 0.00174014
I0521 11:15:33.615268  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00174004 (* 1 = 0.00174004 loss)
I0521 11:15:33.615290  3675 sgd_solver.cpp:138] Iteration 32740, lr = 1.25e-05
I0521 11:15:37.129245  3675 solver.cpp:243] Iteration 32760, loss = 0.00164426
I0521 11:15:37.129276  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00164416 (* 1 = 0.00164416 loss)
I0521 11:15:37.129281  3675 sgd_solver.cpp:138] Iteration 32760, lr = 1.25e-05
I0521 11:15:40.644686  3675 solver.cpp:243] Iteration 32780, loss = 0.00295602
I0521 11:15:40.644716  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00295591 (* 1 = 0.00295591 loss)
I0521 11:15:40.644722  3675 sgd_solver.cpp:138] Iteration 32780, lr = 1.25e-05
I0521 11:15:44.157301  3675 solver.cpp:243] Iteration 32800, loss = 0.00252763
I0521 11:15:44.157424  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00252753 (* 1 = 0.00252753 loss)
I0521 11:15:44.157433  3675 sgd_solver.cpp:138] Iteration 32800, lr = 1.25e-05
I0521 11:15:47.674731  3675 solver.cpp:243] Iteration 32820, loss = 0.00156988
I0521 11:15:47.674764  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00156978 (* 1 = 0.00156978 loss)
I0521 11:15:47.674770  3675 sgd_solver.cpp:138] Iteration 32820, lr = 1.25e-05
I0521 11:15:51.191107  3675 solver.cpp:243] Iteration 32840, loss = 0.00241829
I0521 11:15:51.191154  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00241819 (* 1 = 0.00241819 loss)
I0521 11:15:51.191160  3675 sgd_solver.cpp:138] Iteration 32840, lr = 1.25e-05
I0521 11:15:54.708565  3675 solver.cpp:243] Iteration 32860, loss = 0.00197061
I0521 11:15:54.708596  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0019705 (* 1 = 0.0019705 loss)
I0521 11:15:54.708603  3675 sgd_solver.cpp:138] Iteration 32860, lr = 1.25e-05
I0521 11:15:58.224910  3675 solver.cpp:243] Iteration 32880, loss = 0.0016769
I0521 11:15:58.224942  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00167679 (* 1 = 0.00167679 loss)
I0521 11:15:58.224948  3675 sgd_solver.cpp:138] Iteration 32880, lr = 1.25e-05
I0521 11:16:01.739940  3675 solver.cpp:243] Iteration 32900, loss = 0.00202561
I0521 11:16:01.739972  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0020255 (* 1 = 0.0020255 loss)
I0521 11:16:01.739979  3675 sgd_solver.cpp:138] Iteration 32900, lr = 1.25e-05
I0521 11:16:05.252081  3675 solver.cpp:243] Iteration 32920, loss = 0.00189421
I0521 11:16:05.252112  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0018941 (* 1 = 0.0018941 loss)
I0521 11:16:05.252120  3675 sgd_solver.cpp:138] Iteration 32920, lr = 1.25e-05
I0521 11:16:08.774302  3675 solver.cpp:243] Iteration 32940, loss = 0.00244609
I0521 11:16:08.774333  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00244599 (* 1 = 0.00244599 loss)
I0521 11:16:08.774339  3675 sgd_solver.cpp:138] Iteration 32940, lr = 1.25e-05
I0521 11:16:12.287084  3675 solver.cpp:243] Iteration 32960, loss = 0.00295017
I0521 11:16:12.287115  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00295007 (* 1 = 0.00295007 loss)
I0521 11:16:12.287122  3675 sgd_solver.cpp:138] Iteration 32960, lr = 1.25e-05
I0521 11:16:15.803580  3675 solver.cpp:243] Iteration 32980, loss = 0.00191411
I0521 11:16:15.803691  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00191401 (* 1 = 0.00191401 loss)
I0521 11:16:15.803700  3675 sgd_solver.cpp:138] Iteration 32980, lr = 1.25e-05
I0521 11:16:19.182538  3675 solver.cpp:358] Iteration 33000, Testing net (#0)
I0521 11:16:23.915108  3675 solver.cpp:425]     Test net output #0: acc = 1
I0521 11:16:23.915136  3675 solver.cpp:425]     Test net output #1: acc = 1
I0521 11:16:23.915143  3675 solver.cpp:425]     Test net output #2: ctcloss = 0.000707547 (* 1 = 0.000707547 loss)
I0521 11:16:24.050640  3675 solver.cpp:243] Iteration 33000, loss = 0.0012634
I0521 11:16:24.050670  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0012633 (* 1 = 0.0012633 loss)
I0521 11:16:24.050676  3675 sgd_solver.cpp:138] Iteration 33000, lr = 1.25e-05
I0521 11:16:27.569103  3675 solver.cpp:243] Iteration 33020, loss = 0.00167394
I0521 11:16:27.569133  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00167384 (* 1 = 0.00167384 loss)
I0521 11:16:27.569154  3675 sgd_solver.cpp:138] Iteration 33020, lr = 1.25e-05
I0521 11:16:31.085710  3675 solver.cpp:243] Iteration 33040, loss = 0.00211437
I0521 11:16:31.085741  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00211426 (* 1 = 0.00211426 loss)
I0521 11:16:31.085747  3675 sgd_solver.cpp:138] Iteration 33040, lr = 1.25e-05
I0521 11:16:34.604331  3675 solver.cpp:243] Iteration 33060, loss = 0.00209566
I0521 11:16:34.604363  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00209556 (* 1 = 0.00209556 loss)
I0521 11:16:34.604369  3675 sgd_solver.cpp:138] Iteration 33060, lr = 1.25e-05
I0521 11:16:38.122881  3675 solver.cpp:243] Iteration 33080, loss = 0.0019575
I0521 11:16:38.122911  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00195739 (* 1 = 0.00195739 loss)
I0521 11:16:38.122917  3675 sgd_solver.cpp:138] Iteration 33080, lr = 1.25e-05
I0521 11:16:41.644300  3675 solver.cpp:243] Iteration 33100, loss = 0.00286888
I0521 11:16:41.644330  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00286878 (* 1 = 0.00286878 loss)
I0521 11:16:41.644336  3675 sgd_solver.cpp:138] Iteration 33100, lr = 1.25e-05
I0521 11:16:45.160437  3675 solver.cpp:243] Iteration 33120, loss = 0.00247433
I0521 11:16:45.160468  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00247422 (* 1 = 0.00247422 loss)
I0521 11:16:45.160475  3675 sgd_solver.cpp:138] Iteration 33120, lr = 1.25e-05
I0521 11:16:48.674440  3675 solver.cpp:243] Iteration 33140, loss = 0.00198238
I0521 11:16:48.674608  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00198228 (* 1 = 0.00198228 loss)
I0521 11:16:48.674618  3675 sgd_solver.cpp:138] Iteration 33140, lr = 1.25e-05
I0521 11:16:52.190631  3675 solver.cpp:243] Iteration 33160, loss = 0.00212313
I0521 11:16:52.190661  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00212302 (* 1 = 0.00212302 loss)
I0521 11:16:52.190667  3675 sgd_solver.cpp:138] Iteration 33160, lr = 1.25e-05
I0521 11:16:55.701702  3675 solver.cpp:243] Iteration 33180, loss = 0.00171987
I0521 11:16:55.701731  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00171977 (* 1 = 0.00171977 loss)
I0521 11:16:55.701752  3675 sgd_solver.cpp:138] Iteration 33180, lr = 1.25e-05
I0521 11:16:59.218431  3675 solver.cpp:243] Iteration 33200, loss = 0.00178772
I0521 11:16:59.218463  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00178761 (* 1 = 0.00178761 loss)
I0521 11:16:59.218469  3675 sgd_solver.cpp:138] Iteration 33200, lr = 1.25e-05
I0521 11:17:02.738833  3675 solver.cpp:243] Iteration 33220, loss = 0.00201302
I0521 11:17:02.738864  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00201291 (* 1 = 0.00201291 loss)
I0521 11:17:02.738869  3675 sgd_solver.cpp:138] Iteration 33220, lr = 1.25e-05
I0521 11:17:06.257896  3675 solver.cpp:243] Iteration 33240, loss = 0.00267593
I0521 11:17:06.257928  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00267582 (* 1 = 0.00267582 loss)
I0521 11:17:06.257936  3675 sgd_solver.cpp:138] Iteration 33240, lr = 1.25e-05
I0521 11:17:09.775167  3675 solver.cpp:243] Iteration 33260, loss = 0.00185606
I0521 11:17:09.775198  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00185595 (* 1 = 0.00185595 loss)
I0521 11:17:09.775204  3675 sgd_solver.cpp:138] Iteration 33260, lr = 1.25e-05
I0521 11:17:13.298786  3675 solver.cpp:243] Iteration 33280, loss = 0.00240186
I0521 11:17:13.298817  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00240176 (* 1 = 0.00240176 loss)
I0521 11:17:13.298825  3675 sgd_solver.cpp:138] Iteration 33280, lr = 1.25e-05
I0521 11:17:16.816263  3675 solver.cpp:243] Iteration 33300, loss = 0.00273563
I0521 11:17:16.816296  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00273553 (* 1 = 0.00273553 loss)
I0521 11:17:16.816318  3675 sgd_solver.cpp:138] Iteration 33300, lr = 1.25e-05
I0521 11:17:20.331033  3675 solver.cpp:243] Iteration 33320, loss = 0.00238872
I0521 11:17:20.331194  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00238861 (* 1 = 0.00238861 loss)
I0521 11:17:20.331202  3675 sgd_solver.cpp:138] Iteration 33320, lr = 1.25e-05
I0521 11:17:23.844133  3675 solver.cpp:243] Iteration 33340, loss = 0.00327654
I0521 11:17:23.844164  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00327643 (* 1 = 0.00327643 loss)
I0521 11:17:23.844182  3675 sgd_solver.cpp:138] Iteration 33340, lr = 1.25e-05
I0521 11:17:27.361534  3675 solver.cpp:243] Iteration 33360, loss = 0.00161954
I0521 11:17:27.361564  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00161944 (* 1 = 0.00161944 loss)
I0521 11:17:27.361570  3675 sgd_solver.cpp:138] Iteration 33360, lr = 1.25e-05
I0521 11:17:30.883224  3675 solver.cpp:243] Iteration 33380, loss = 0.00172581
I0521 11:17:30.883255  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0017257 (* 1 = 0.0017257 loss)
I0521 11:17:30.883260  3675 sgd_solver.cpp:138] Iteration 33380, lr = 1.25e-05
I0521 11:17:34.397670  3675 solver.cpp:243] Iteration 33400, loss = 0.00166815
I0521 11:17:34.397701  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00166805 (* 1 = 0.00166805 loss)
I0521 11:17:34.397706  3675 sgd_solver.cpp:138] Iteration 33400, lr = 1.25e-05
I0521 11:17:37.917862  3675 solver.cpp:243] Iteration 33420, loss = 0.00238052
I0521 11:17:37.917893  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00238041 (* 1 = 0.00238041 loss)
I0521 11:17:37.917899  3675 sgd_solver.cpp:138] Iteration 33420, lr = 1.25e-05
I0521 11:17:41.437850  3675 solver.cpp:243] Iteration 33440, loss = 0.00207817
I0521 11:17:41.437885  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00207807 (* 1 = 0.00207807 loss)
I0521 11:17:41.437891  3675 sgd_solver.cpp:138] Iteration 33440, lr = 1.25e-05
I0521 11:17:44.954013  3675 solver.cpp:243] Iteration 33460, loss = 0.00302113
I0521 11:17:44.954046  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00302102 (* 1 = 0.00302102 loss)
I0521 11:17:44.954051  3675 sgd_solver.cpp:138] Iteration 33460, lr = 1.25e-05
I0521 11:17:48.475828  3675 solver.cpp:243] Iteration 33480, loss = 0.00238907
I0521 11:17:48.475859  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00238897 (* 1 = 0.00238897 loss)
I0521 11:17:48.475867  3675 sgd_solver.cpp:138] Iteration 33480, lr = 1.25e-05
I0521 11:17:51.990252  3675 solver.cpp:243] Iteration 33500, loss = 0.001525
I0521 11:17:51.990388  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00152489 (* 1 = 0.00152489 loss)
I0521 11:17:51.990398  3675 sgd_solver.cpp:138] Iteration 33500, lr = 1.25e-05
I0521 11:17:55.507213  3675 solver.cpp:243] Iteration 33520, loss = 0.00227834
I0521 11:17:55.507244  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00227823 (* 1 = 0.00227823 loss)
I0521 11:17:55.507251  3675 sgd_solver.cpp:138] Iteration 33520, lr = 1.25e-05
I0521 11:17:59.021499  3675 solver.cpp:243] Iteration 33540, loss = 0.00228854
I0521 11:17:59.021530  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00228844 (* 1 = 0.00228844 loss)
I0521 11:17:59.021538  3675 sgd_solver.cpp:138] Iteration 33540, lr = 1.25e-05
I0521 11:18:02.545007  3675 solver.cpp:243] Iteration 33560, loss = 0.00226275
I0521 11:18:02.545039  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00226264 (* 1 = 0.00226264 loss)
I0521 11:18:02.545045  3675 sgd_solver.cpp:138] Iteration 33560, lr = 1.25e-05
I0521 11:18:06.067322  3675 solver.cpp:243] Iteration 33580, loss = 0.00159073
I0521 11:18:06.067354  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00159062 (* 1 = 0.00159062 loss)
I0521 11:18:06.067360  3675 sgd_solver.cpp:138] Iteration 33580, lr = 1.25e-05
I0521 11:18:09.583559  3675 solver.cpp:243] Iteration 33600, loss = 0.00252069
I0521 11:18:09.583590  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00252058 (* 1 = 0.00252058 loss)
I0521 11:18:09.583611  3675 sgd_solver.cpp:138] Iteration 33600, lr = 1.25e-05
I0521 11:18:13.104156  3675 solver.cpp:243] Iteration 33620, loss = 0.00174961
I0521 11:18:13.104187  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00174951 (* 1 = 0.00174951 loss)
I0521 11:18:13.104193  3675 sgd_solver.cpp:138] Iteration 33620, lr = 1.25e-05
I0521 11:18:16.623708  3675 solver.cpp:243] Iteration 33640, loss = 0.00177904
I0521 11:18:16.623739  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00177893 (* 1 = 0.00177893 loss)
I0521 11:18:16.623745  3675 sgd_solver.cpp:138] Iteration 33640, lr = 1.25e-05
I0521 11:18:20.140516  3675 solver.cpp:243] Iteration 33660, loss = 0.00232269
I0521 11:18:20.140547  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00232258 (* 1 = 0.00232258 loss)
I0521 11:18:20.140553  3675 sgd_solver.cpp:138] Iteration 33660, lr = 1.25e-05
I0521 11:18:23.660764  3675 solver.cpp:243] Iteration 33680, loss = 0.00219118
I0521 11:18:23.660914  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00219108 (* 1 = 0.00219108 loss)
I0521 11:18:23.660921  3675 sgd_solver.cpp:138] Iteration 33680, lr = 1.25e-05
I0521 11:18:27.175858  3675 solver.cpp:243] Iteration 33700, loss = 0.00191137
I0521 11:18:27.175887  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00191127 (* 1 = 0.00191127 loss)
I0521 11:18:27.175894  3675 sgd_solver.cpp:138] Iteration 33700, lr = 1.25e-05
I0521 11:18:30.693251  3675 solver.cpp:243] Iteration 33720, loss = 0.00255573
I0521 11:18:30.693282  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00255562 (* 1 = 0.00255562 loss)
I0521 11:18:30.693289  3675 sgd_solver.cpp:138] Iteration 33720, lr = 1.25e-05
I0521 11:18:34.213011  3675 solver.cpp:243] Iteration 33740, loss = 0.00170906
I0521 11:18:34.213042  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00170896 (* 1 = 0.00170896 loss)
I0521 11:18:34.213048  3675 sgd_solver.cpp:138] Iteration 33740, lr = 1.25e-05
I0521 11:18:37.733464  3675 solver.cpp:243] Iteration 33760, loss = 0.00153348
I0521 11:18:37.733496  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00153338 (* 1 = 0.00153338 loss)
I0521 11:18:37.733520  3675 sgd_solver.cpp:138] Iteration 33760, lr = 1.25e-05
I0521 11:18:41.252972  3675 solver.cpp:243] Iteration 33780, loss = 0.00156419
I0521 11:18:41.253002  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00156409 (* 1 = 0.00156409 loss)
I0521 11:18:41.253010  3675 sgd_solver.cpp:138] Iteration 33780, lr = 1.25e-05
I0521 11:18:44.770531  3675 solver.cpp:243] Iteration 33800, loss = 0.00180669
I0521 11:18:44.770562  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00180659 (* 1 = 0.00180659 loss)
I0521 11:18:44.770570  3675 sgd_solver.cpp:138] Iteration 33800, lr = 1.25e-05
I0521 11:18:48.289527  3675 solver.cpp:243] Iteration 33820, loss = 0.00269797
I0521 11:18:48.289558  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00269786 (* 1 = 0.00269786 loss)
I0521 11:18:48.289566  3675 sgd_solver.cpp:138] Iteration 33820, lr = 1.25e-05
I0521 11:18:51.807412  3675 solver.cpp:243] Iteration 33840, loss = 0.00287447
I0521 11:18:51.807442  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00287437 (* 1 = 0.00287437 loss)
I0521 11:18:51.807449  3675 sgd_solver.cpp:138] Iteration 33840, lr = 1.25e-05
I0521 11:18:55.328727  3675 solver.cpp:243] Iteration 33860, loss = 0.00221624
I0521 11:18:55.328902  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00221614 (* 1 = 0.00221614 loss)
I0521 11:18:55.328912  3675 sgd_solver.cpp:138] Iteration 33860, lr = 1.25e-05
I0521 11:18:58.779625  3675 solver.cpp:243] Iteration 33880, loss = 0.00242349
I0521 11:18:58.779656  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00242339 (* 1 = 0.00242339 loss)
I0521 11:18:58.779664  3675 sgd_solver.cpp:138] Iteration 33880, lr = 1.25e-05
I0521 11:19:02.299424  3675 solver.cpp:243] Iteration 33900, loss = 0.00165
I0521 11:19:02.299453  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00164989 (* 1 = 0.00164989 loss)
I0521 11:19:02.299460  3675 sgd_solver.cpp:138] Iteration 33900, lr = 1.25e-05
I0521 11:19:05.812149  3675 solver.cpp:243] Iteration 33920, loss = 0.00140022
I0521 11:19:05.812178  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00140011 (* 1 = 0.00140011 loss)
I0521 11:19:05.812184  3675 sgd_solver.cpp:138] Iteration 33920, lr = 1.25e-05
I0521 11:19:09.325515  3675 solver.cpp:243] Iteration 33940, loss = 0.00191985
I0521 11:19:09.325546  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00191975 (* 1 = 0.00191975 loss)
I0521 11:19:09.325569  3675 sgd_solver.cpp:138] Iteration 33940, lr = 1.25e-05
I0521 11:19:12.840370  3675 solver.cpp:243] Iteration 33960, loss = 0.00190914
I0521 11:19:12.840401  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00190903 (* 1 = 0.00190903 loss)
I0521 11:19:12.840407  3675 sgd_solver.cpp:138] Iteration 33960, lr = 1.25e-05
I0521 11:19:16.354966  3675 solver.cpp:243] Iteration 33980, loss = 0.00218604
I0521 11:19:16.354997  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00218593 (* 1 = 0.00218593 loss)
I0521 11:19:16.355003  3675 sgd_solver.cpp:138] Iteration 33980, lr = 1.25e-05
I0521 11:19:19.741379  3675 solver.cpp:596] Snapshotting to binary proto file models/LPR/lpr_resnet_lstm_iter_34000.caffemodel
I0521 11:19:19.768319  3675 sgd_solver.cpp:307] Snapshotting solver state to binary proto file models/LPR/lpr_resnet_lstm_iter_34000.solverstate
I0521 11:19:19.783182  3675 solver.cpp:358] Iteration 34000, Testing net (#0)
I0521 11:19:24.516814  3675 solver.cpp:425]     Test net output #0: acc = 1
I0521 11:19:24.516856  3675 solver.cpp:425]     Test net output #1: acc = 1
I0521 11:19:24.516863  3675 solver.cpp:425]     Test net output #2: ctcloss = 0.000701662 (* 1 = 0.000701662 loss)
I0521 11:19:24.651345  3675 solver.cpp:243] Iteration 34000, loss = 0.00186879
I0521 11:19:24.651373  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00186868 (* 1 = 0.00186868 loss)
I0521 11:19:24.651379  3675 sgd_solver.cpp:138] Iteration 34000, lr = 1.25e-05
I0521 11:19:28.172559  3675 solver.cpp:243] Iteration 34020, loss = 0.00256114
I0521 11:19:28.172701  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00256104 (* 1 = 0.00256104 loss)
I0521 11:19:28.172709  3675 sgd_solver.cpp:138] Iteration 34020, lr = 1.25e-05
I0521 11:19:31.685480  3675 solver.cpp:243] Iteration 34040, loss = 0.00203621
I0521 11:19:31.685513  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0020361 (* 1 = 0.0020361 loss)
I0521 11:19:31.685518  3675 sgd_solver.cpp:138] Iteration 34040, lr = 1.25e-05
I0521 11:19:35.200759  3675 solver.cpp:243] Iteration 34060, loss = 0.00250673
I0521 11:19:35.200793  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00250662 (* 1 = 0.00250662 loss)
I0521 11:19:35.200798  3675 sgd_solver.cpp:138] Iteration 34060, lr = 1.25e-05
I0521 11:19:38.720743  3675 solver.cpp:243] Iteration 34080, loss = 0.00281952
I0521 11:19:38.720773  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00281941 (* 1 = 0.00281941 loss)
I0521 11:19:38.720798  3675 sgd_solver.cpp:138] Iteration 34080, lr = 1.25e-05
I0521 11:19:42.237411  3675 solver.cpp:243] Iteration 34100, loss = 0.00257385
I0521 11:19:42.237442  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00257374 (* 1 = 0.00257374 loss)
I0521 11:19:42.237464  3675 sgd_solver.cpp:138] Iteration 34100, lr = 1.25e-05
I0521 11:19:45.756386  3675 solver.cpp:243] Iteration 34120, loss = 0.00248759
I0521 11:19:45.756417  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00248748 (* 1 = 0.00248748 loss)
I0521 11:19:45.756422  3675 sgd_solver.cpp:138] Iteration 34120, lr = 1.25e-05
I0521 11:19:49.276033  3675 solver.cpp:243] Iteration 34140, loss = 0.00208465
I0521 11:19:49.276063  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00208455 (* 1 = 0.00208455 loss)
I0521 11:19:49.276087  3675 sgd_solver.cpp:138] Iteration 34140, lr = 1.25e-05
I0521 11:19:52.793220  3675 solver.cpp:243] Iteration 34160, loss = 0.00195469
I0521 11:19:52.793251  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00195459 (* 1 = 0.00195459 loss)
I0521 11:19:52.793256  3675 sgd_solver.cpp:138] Iteration 34160, lr = 1.25e-05
I0521 11:19:56.312057  3675 solver.cpp:243] Iteration 34180, loss = 0.00216199
I0521 11:19:56.312088  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00216189 (* 1 = 0.00216189 loss)
I0521 11:19:56.312093  3675 sgd_solver.cpp:138] Iteration 34180, lr = 1.25e-05
I0521 11:19:59.826033  3675 solver.cpp:243] Iteration 34200, loss = 0.00169099
I0521 11:19:59.826153  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00169089 (* 1 = 0.00169089 loss)
I0521 11:19:59.826159  3675 sgd_solver.cpp:138] Iteration 34200, lr = 1.25e-05
I0521 11:20:03.345125  3675 solver.cpp:243] Iteration 34220, loss = 0.00219804
I0521 11:20:03.345157  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00219793 (* 1 = 0.00219793 loss)
I0521 11:20:03.345163  3675 sgd_solver.cpp:138] Iteration 34220, lr = 1.25e-05
I0521 11:20:06.865728  3675 solver.cpp:243] Iteration 34240, loss = 0.00148313
I0521 11:20:06.865759  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00148303 (* 1 = 0.00148303 loss)
I0521 11:20:06.865782  3675 sgd_solver.cpp:138] Iteration 34240, lr = 1.25e-05
I0521 11:20:10.383463  3675 solver.cpp:243] Iteration 34260, loss = 0.0020556
I0521 11:20:10.383496  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00205549 (* 1 = 0.00205549 loss)
I0521 11:20:10.383518  3675 sgd_solver.cpp:138] Iteration 34260, lr = 1.25e-05
I0521 11:20:13.902765  3675 solver.cpp:243] Iteration 34280, loss = 0.00237722
I0521 11:20:13.902797  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00237711 (* 1 = 0.00237711 loss)
I0521 11:20:13.902802  3675 sgd_solver.cpp:138] Iteration 34280, lr = 1.25e-05
I0521 11:20:17.421449  3675 solver.cpp:243] Iteration 34300, loss = 0.00192442
I0521 11:20:17.421483  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00192431 (* 1 = 0.00192431 loss)
I0521 11:20:17.421504  3675 sgd_solver.cpp:138] Iteration 34300, lr = 1.25e-05
I0521 11:20:20.936450  3675 solver.cpp:243] Iteration 34320, loss = 0.0028565
I0521 11:20:20.936480  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0028564 (* 1 = 0.0028564 loss)
I0521 11:20:20.936486  3675 sgd_solver.cpp:138] Iteration 34320, lr = 1.25e-05
I0521 11:20:24.450316  3675 solver.cpp:243] Iteration 34340, loss = 0.00181869
I0521 11:20:24.450345  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00181858 (* 1 = 0.00181858 loss)
I0521 11:20:24.450351  3675 sgd_solver.cpp:138] Iteration 34340, lr = 1.25e-05
I0521 11:20:27.967003  3675 solver.cpp:243] Iteration 34360, loss = 0.00192191
I0521 11:20:27.967034  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0019218 (* 1 = 0.0019218 loss)
I0521 11:20:27.967041  3675 sgd_solver.cpp:138] Iteration 34360, lr = 1.25e-05
I0521 11:20:31.482964  3675 solver.cpp:243] Iteration 34380, loss = 0.00161955
I0521 11:20:31.483121  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00161944 (* 1 = 0.00161944 loss)
I0521 11:20:31.483130  3675 sgd_solver.cpp:138] Iteration 34380, lr = 1.25e-05
I0521 11:20:35.002478  3675 solver.cpp:243] Iteration 34400, loss = 0.00200616
I0521 11:20:35.002508  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00200605 (* 1 = 0.00200605 loss)
I0521 11:20:35.002514  3675 sgd_solver.cpp:138] Iteration 34400, lr = 1.25e-05
I0521 11:20:38.521188  3675 solver.cpp:243] Iteration 34420, loss = 0.00390702
I0521 11:20:38.521219  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00390692 (* 1 = 0.00390692 loss)
I0521 11:20:38.521225  3675 sgd_solver.cpp:138] Iteration 34420, lr = 1.25e-05
I0521 11:20:42.038879  3675 solver.cpp:243] Iteration 34440, loss = 0.00249956
I0521 11:20:42.038909  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00249945 (* 1 = 0.00249945 loss)
I0521 11:20:42.038915  3675 sgd_solver.cpp:138] Iteration 34440, lr = 1.25e-05
I0521 11:20:45.552253  3675 solver.cpp:243] Iteration 34460, loss = 0.00157
I0521 11:20:45.552283  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00156989 (* 1 = 0.00156989 loss)
I0521 11:20:45.552289  3675 sgd_solver.cpp:138] Iteration 34460, lr = 1.25e-05
I0521 11:20:49.064429  3675 solver.cpp:243] Iteration 34480, loss = 0.00207227
I0521 11:20:49.064460  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00207217 (* 1 = 0.00207217 loss)
I0521 11:20:49.064466  3675 sgd_solver.cpp:138] Iteration 34480, lr = 1.25e-05
I0521 11:20:52.579901  3675 solver.cpp:243] Iteration 34500, loss = 0.00143263
I0521 11:20:52.579932  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00143253 (* 1 = 0.00143253 loss)
I0521 11:20:52.579938  3675 sgd_solver.cpp:138] Iteration 34500, lr = 1.25e-05
I0521 11:20:56.095599  3675 solver.cpp:243] Iteration 34520, loss = 0.0020151
I0521 11:20:56.095630  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00201499 (* 1 = 0.00201499 loss)
I0521 11:20:56.095636  3675 sgd_solver.cpp:138] Iteration 34520, lr = 1.25e-05
I0521 11:20:59.609917  3675 solver.cpp:243] Iteration 34540, loss = 0.00817673
I0521 11:20:59.609948  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00817663 (* 1 = 0.00817663 loss)
I0521 11:20:59.609954  3675 sgd_solver.cpp:138] Iteration 34540, lr = 1.25e-05
I0521 11:21:03.127593  3675 solver.cpp:243] Iteration 34560, loss = 0.00259157
I0521 11:21:03.127764  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00259147 (* 1 = 0.00259147 loss)
I0521 11:21:03.127773  3675 sgd_solver.cpp:138] Iteration 34560, lr = 1.25e-05
I0521 11:21:06.646170  3675 solver.cpp:243] Iteration 34580, loss = 0.00201587
I0521 11:21:06.646203  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00201576 (* 1 = 0.00201576 loss)
I0521 11:21:06.646209  3675 sgd_solver.cpp:138] Iteration 34580, lr = 1.25e-05
I0521 11:21:10.162431  3675 solver.cpp:243] Iteration 34600, loss = 0.00189416
I0521 11:21:10.162463  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00189405 (* 1 = 0.00189405 loss)
I0521 11:21:10.162469  3675 sgd_solver.cpp:138] Iteration 34600, lr = 1.25e-05
I0521 11:21:13.684895  3675 solver.cpp:243] Iteration 34620, loss = 0.0017191
I0521 11:21:13.684924  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00171899 (* 1 = 0.00171899 loss)
I0521 11:21:13.684947  3675 sgd_solver.cpp:138] Iteration 34620, lr = 1.25e-05
I0521 11:21:17.204890  3675 solver.cpp:243] Iteration 34640, loss = 0.00300605
I0521 11:21:17.204922  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00300595 (* 1 = 0.00300595 loss)
I0521 11:21:17.204929  3675 sgd_solver.cpp:138] Iteration 34640, lr = 1.25e-05
I0521 11:21:20.725638  3675 solver.cpp:243] Iteration 34660, loss = 0.00213472
I0521 11:21:20.725669  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00213462 (* 1 = 0.00213462 loss)
I0521 11:21:20.725675  3675 sgd_solver.cpp:138] Iteration 34660, lr = 1.25e-05
I0521 11:21:24.239707  3675 solver.cpp:243] Iteration 34680, loss = 0.00221268
I0521 11:21:24.239738  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00221258 (* 1 = 0.00221258 loss)
I0521 11:21:24.239745  3675 sgd_solver.cpp:138] Iteration 34680, lr = 1.25e-05
I0521 11:21:27.756969  3675 solver.cpp:243] Iteration 34700, loss = 0.00215667
I0521 11:21:27.757001  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00215656 (* 1 = 0.00215656 loss)
I0521 11:21:27.757009  3675 sgd_solver.cpp:138] Iteration 34700, lr = 1.25e-05
I0521 11:21:31.276407  3675 solver.cpp:243] Iteration 34720, loss = 0.00161868
I0521 11:21:31.276437  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00161857 (* 1 = 0.00161857 loss)
I0521 11:21:31.276444  3675 sgd_solver.cpp:138] Iteration 34720, lr = 1.25e-05
I0521 11:21:34.791398  3675 solver.cpp:243] Iteration 34740, loss = 0.00196905
I0521 11:21:34.791563  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00196894 (* 1 = 0.00196894 loss)
I0521 11:21:34.791570  3675 sgd_solver.cpp:138] Iteration 34740, lr = 1.25e-05
I0521 11:21:38.308730  3675 solver.cpp:243] Iteration 34760, loss = 0.00208821
I0521 11:21:38.308761  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00208811 (* 1 = 0.00208811 loss)
I0521 11:21:38.308768  3675 sgd_solver.cpp:138] Iteration 34760, lr = 1.25e-05
I0521 11:21:41.823855  3675 solver.cpp:243] Iteration 34780, loss = 0.00187212
I0521 11:21:41.823886  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00187201 (* 1 = 0.00187201 loss)
I0521 11:21:41.823892  3675 sgd_solver.cpp:138] Iteration 34780, lr = 1.25e-05
I0521 11:21:45.341310  3675 solver.cpp:243] Iteration 34800, loss = 0.00222609
I0521 11:21:45.341341  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00222598 (* 1 = 0.00222598 loss)
I0521 11:21:45.341346  3675 sgd_solver.cpp:138] Iteration 34800, lr = 1.25e-05
I0521 11:21:48.858188  3675 solver.cpp:243] Iteration 34820, loss = 0.00185299
I0521 11:21:48.858218  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00185288 (* 1 = 0.00185288 loss)
I0521 11:21:48.858224  3675 sgd_solver.cpp:138] Iteration 34820, lr = 1.25e-05
I0521 11:21:52.375062  3675 solver.cpp:243] Iteration 34840, loss = 0.00306046
I0521 11:21:52.375092  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00306036 (* 1 = 0.00306036 loss)
I0521 11:21:52.375098  3675 sgd_solver.cpp:138] Iteration 34840, lr = 1.25e-05
I0521 11:21:55.893188  3675 solver.cpp:243] Iteration 34860, loss = 0.00181806
I0521 11:21:55.893219  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00181795 (* 1 = 0.00181795 loss)
I0521 11:21:55.893225  3675 sgd_solver.cpp:138] Iteration 34860, lr = 1.25e-05
I0521 11:21:59.407863  3675 solver.cpp:243] Iteration 34880, loss = 0.00168951
I0521 11:21:59.407896  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0016894 (* 1 = 0.0016894 loss)
I0521 11:21:59.407902  3675 sgd_solver.cpp:138] Iteration 34880, lr = 1.25e-05
I0521 11:22:02.932281  3675 solver.cpp:243] Iteration 34900, loss = 0.00190624
I0521 11:22:02.932312  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00190613 (* 1 = 0.00190613 loss)
I0521 11:22:02.932317  3675 sgd_solver.cpp:138] Iteration 34900, lr = 1.25e-05
I0521 11:22:06.449973  3675 solver.cpp:243] Iteration 34920, loss = 0.00216232
I0521 11:22:06.450130  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00216221 (* 1 = 0.00216221 loss)
I0521 11:22:06.450139  3675 sgd_solver.cpp:138] Iteration 34920, lr = 1.25e-05
I0521 11:22:09.966275  3675 solver.cpp:243] Iteration 34940, loss = 0.00194926
I0521 11:22:09.966305  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00194915 (* 1 = 0.00194915 loss)
I0521 11:22:09.966310  3675 sgd_solver.cpp:138] Iteration 34940, lr = 1.25e-05
I0521 11:22:13.487321  3675 solver.cpp:243] Iteration 34960, loss = 0.00228185
I0521 11:22:13.487352  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00228174 (* 1 = 0.00228174 loss)
I0521 11:22:13.487360  3675 sgd_solver.cpp:138] Iteration 34960, lr = 1.25e-05
I0521 11:22:17.005468  3675 solver.cpp:243] Iteration 34980, loss = 0.00145208
I0521 11:22:17.005501  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00145197 (* 1 = 0.00145197 loss)
I0521 11:22:17.005506  3675 sgd_solver.cpp:138] Iteration 34980, lr = 1.25e-05
I0521 11:22:20.390470  3675 solver.cpp:358] Iteration 35000, Testing net (#0)
I0521 11:22:25.123888  3675 solver.cpp:425]     Test net output #0: acc = 1
I0521 11:22:25.123915  3675 solver.cpp:425]     Test net output #1: acc = 1
I0521 11:22:25.123922  3675 solver.cpp:425]     Test net output #2: ctcloss = 0.000694203 (* 1 = 0.000694203 loss)
I0521 11:22:25.258669  3675 solver.cpp:243] Iteration 35000, loss = 0.00333704
I0521 11:22:25.258700  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00333693 (* 1 = 0.00333693 loss)
I0521 11:22:25.258723  3675 sgd_solver.cpp:138] Iteration 35000, lr = 1.25e-05
I0521 11:22:28.772903  3675 solver.cpp:243] Iteration 35020, loss = 0.00232899
I0521 11:22:28.772933  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00232888 (* 1 = 0.00232888 loss)
I0521 11:22:28.772940  3675 sgd_solver.cpp:138] Iteration 35020, lr = 1.25e-05
I0521 11:22:32.284659  3675 solver.cpp:243] Iteration 35040, loss = 0.00209711
I0521 11:22:32.284691  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.002097 (* 1 = 0.002097 loss)
I0521 11:22:32.284698  3675 sgd_solver.cpp:138] Iteration 35040, lr = 1.25e-05
I0521 11:22:35.800786  3675 solver.cpp:243] Iteration 35060, loss = 0.00182181
I0521 11:22:35.800817  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0018217 (* 1 = 0.0018217 loss)
I0521 11:22:35.800823  3675 sgd_solver.cpp:138] Iteration 35060, lr = 1.25e-05
I0521 11:22:39.316754  3675 solver.cpp:243] Iteration 35080, loss = 0.00195633
I0521 11:22:39.316921  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00195622 (* 1 = 0.00195622 loss)
I0521 11:22:39.316931  3675 sgd_solver.cpp:138] Iteration 35080, lr = 1.25e-05
I0521 11:22:42.827788  3675 solver.cpp:243] Iteration 35100, loss = 0.00203904
I0521 11:22:42.827821  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00203893 (* 1 = 0.00203893 loss)
I0521 11:22:42.827827  3675 sgd_solver.cpp:138] Iteration 35100, lr = 1.25e-05
I0521 11:22:46.348014  3675 solver.cpp:243] Iteration 35120, loss = 0.00227882
I0521 11:22:46.348045  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00227872 (* 1 = 0.00227872 loss)
I0521 11:22:46.348068  3675 sgd_solver.cpp:138] Iteration 35120, lr = 1.25e-05
I0521 11:22:49.860886  3675 solver.cpp:243] Iteration 35140, loss = 0.00295018
I0521 11:22:49.860930  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00295007 (* 1 = 0.00295007 loss)
I0521 11:22:49.860937  3675 sgd_solver.cpp:138] Iteration 35140, lr = 1.25e-05
I0521 11:22:53.374506  3675 solver.cpp:243] Iteration 35160, loss = 0.00195377
I0521 11:22:53.374538  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00195366 (* 1 = 0.00195366 loss)
I0521 11:22:53.374545  3675 sgd_solver.cpp:138] Iteration 35160, lr = 1.25e-05
I0521 11:22:56.821889  3675 solver.cpp:243] Iteration 35180, loss = 0.00278039
I0521 11:22:56.821919  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00278028 (* 1 = 0.00278028 loss)
I0521 11:22:56.821941  3675 sgd_solver.cpp:138] Iteration 35180, lr = 1.25e-05
I0521 11:23:00.336488  3675 solver.cpp:243] Iteration 35200, loss = 0.00266076
I0521 11:23:00.336520  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00266065 (* 1 = 0.00266065 loss)
I0521 11:23:00.336527  3675 sgd_solver.cpp:138] Iteration 35200, lr = 1.25e-05
I0521 11:23:03.853137  3675 solver.cpp:243] Iteration 35220, loss = 0.00213697
I0521 11:23:03.853168  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00213686 (* 1 = 0.00213686 loss)
I0521 11:23:03.853173  3675 sgd_solver.cpp:138] Iteration 35220, lr = 1.25e-05
I0521 11:23:07.364125  3675 solver.cpp:243] Iteration 35240, loss = 0.00201813
I0521 11:23:07.364156  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00201802 (* 1 = 0.00201802 loss)
I0521 11:23:07.364162  3675 sgd_solver.cpp:138] Iteration 35240, lr = 1.25e-05
I0521 11:23:10.877514  3675 solver.cpp:243] Iteration 35260, loss = 0.00188366
I0521 11:23:10.877703  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00188355 (* 1 = 0.00188355 loss)
I0521 11:23:10.877712  3675 sgd_solver.cpp:138] Iteration 35260, lr = 1.25e-05
I0521 11:23:14.388034  3675 solver.cpp:243] Iteration 35280, loss = 0.00198693
I0521 11:23:14.388067  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00198682 (* 1 = 0.00198682 loss)
I0521 11:23:14.388073  3675 sgd_solver.cpp:138] Iteration 35280, lr = 1.25e-05
I0521 11:23:17.892637  3675 solver.cpp:243] Iteration 35300, loss = 0.00146326
I0521 11:23:17.892668  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00146316 (* 1 = 0.00146316 loss)
I0521 11:23:17.892690  3675 sgd_solver.cpp:138] Iteration 35300, lr = 1.25e-05
I0521 11:23:21.408128  3675 solver.cpp:243] Iteration 35320, loss = 0.00221136
I0521 11:23:21.408159  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00221125 (* 1 = 0.00221125 loss)
I0521 11:23:21.408165  3675 sgd_solver.cpp:138] Iteration 35320, lr = 1.25e-05
I0521 11:23:24.917563  3675 solver.cpp:243] Iteration 35340, loss = 0.00286739
I0521 11:23:24.917595  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00286728 (* 1 = 0.00286728 loss)
I0521 11:23:24.917603  3675 sgd_solver.cpp:138] Iteration 35340, lr = 1.25e-05
I0521 11:23:28.430446  3675 solver.cpp:243] Iteration 35360, loss = 0.00208134
I0521 11:23:28.430477  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00208123 (* 1 = 0.00208123 loss)
I0521 11:23:28.430483  3675 sgd_solver.cpp:138] Iteration 35360, lr = 1.25e-05
I0521 11:23:31.940773  3675 solver.cpp:243] Iteration 35380, loss = 0.00174037
I0521 11:23:31.940809  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00174026 (* 1 = 0.00174026 loss)
I0521 11:23:31.940815  3675 sgd_solver.cpp:138] Iteration 35380, lr = 1.25e-05
I0521 11:23:35.452242  3675 solver.cpp:243] Iteration 35400, loss = 0.00149799
I0521 11:23:35.452271  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00149788 (* 1 = 0.00149788 loss)
I0521 11:23:35.452278  3675 sgd_solver.cpp:138] Iteration 35400, lr = 1.25e-05
I0521 11:23:38.965015  3675 solver.cpp:243] Iteration 35420, loss = 0.00223986
I0521 11:23:38.965045  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00223975 (* 1 = 0.00223975 loss)
I0521 11:23:38.965067  3675 sgd_solver.cpp:138] Iteration 35420, lr = 1.25e-05
I0521 11:23:42.479207  3675 solver.cpp:243] Iteration 35440, loss = 0.00239238
I0521 11:23:42.479360  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00239227 (* 1 = 0.00239227 loss)
I0521 11:23:42.479369  3675 sgd_solver.cpp:138] Iteration 35440, lr = 1.25e-05
I0521 11:23:45.992367  3675 solver.cpp:243] Iteration 35460, loss = 0.00160424
I0521 11:23:45.992398  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00160413 (* 1 = 0.00160413 loss)
I0521 11:23:45.992405  3675 sgd_solver.cpp:138] Iteration 35460, lr = 1.25e-05
I0521 11:23:49.505200  3675 solver.cpp:243] Iteration 35480, loss = 0.00193936
I0521 11:23:49.505231  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00193925 (* 1 = 0.00193925 loss)
I0521 11:23:49.505237  3675 sgd_solver.cpp:138] Iteration 35480, lr = 1.25e-05
I0521 11:23:53.022181  3675 solver.cpp:243] Iteration 35500, loss = 0.00350262
I0521 11:23:53.022212  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00350251 (* 1 = 0.00350251 loss)
I0521 11:23:53.022234  3675 sgd_solver.cpp:138] Iteration 35500, lr = 1.25e-05
I0521 11:23:56.535965  3675 solver.cpp:243] Iteration 35520, loss = 0.00234706
I0521 11:23:56.535995  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00234695 (* 1 = 0.00234695 loss)
I0521 11:23:56.536001  3675 sgd_solver.cpp:138] Iteration 35520, lr = 1.25e-05
I0521 11:24:00.051908  3675 solver.cpp:243] Iteration 35540, loss = 0.00215672
I0521 11:24:00.051939  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00215661 (* 1 = 0.00215661 loss)
I0521 11:24:00.051946  3675 sgd_solver.cpp:138] Iteration 35540, lr = 1.25e-05
I0521 11:24:03.567955  3675 solver.cpp:243] Iteration 35560, loss = 0.0016691
I0521 11:24:03.567986  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00166899 (* 1 = 0.00166899 loss)
I0521 11:24:03.567992  3675 sgd_solver.cpp:138] Iteration 35560, lr = 1.25e-05
I0521 11:24:07.084036  3675 solver.cpp:243] Iteration 35580, loss = 0.00171674
I0521 11:24:07.084067  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00171663 (* 1 = 0.00171663 loss)
I0521 11:24:07.084074  3675 sgd_solver.cpp:138] Iteration 35580, lr = 1.25e-05
I0521 11:24:10.597990  3675 solver.cpp:243] Iteration 35600, loss = 0.00214426
I0521 11:24:10.598019  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00214415 (* 1 = 0.00214415 loss)
I0521 11:24:10.598026  3675 sgd_solver.cpp:138] Iteration 35600, lr = 1.25e-05
I0521 11:24:14.118038  3675 solver.cpp:243] Iteration 35620, loss = 0.00168505
I0521 11:24:14.118162  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00168494 (* 1 = 0.00168494 loss)
I0521 11:24:14.118170  3675 sgd_solver.cpp:138] Iteration 35620, lr = 1.25e-05
I0521 11:24:17.628360  3675 solver.cpp:243] Iteration 35640, loss = 0.00189398
I0521 11:24:17.628391  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00189387 (* 1 = 0.00189387 loss)
I0521 11:24:17.628397  3675 sgd_solver.cpp:138] Iteration 35640, lr = 1.25e-05
I0521 11:24:21.140790  3675 solver.cpp:243] Iteration 35660, loss = 0.00158109
I0521 11:24:21.140821  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00158099 (* 1 = 0.00158099 loss)
I0521 11:24:21.140827  3675 sgd_solver.cpp:138] Iteration 35660, lr = 1.25e-05
I0521 11:24:24.657336  3675 solver.cpp:243] Iteration 35680, loss = 0.00182434
I0521 11:24:24.657367  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00182423 (* 1 = 0.00182423 loss)
I0521 11:24:24.657388  3675 sgd_solver.cpp:138] Iteration 35680, lr = 1.25e-05
I0521 11:24:28.170053  3675 solver.cpp:243] Iteration 35700, loss = 0.00172985
I0521 11:24:28.170083  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00172974 (* 1 = 0.00172974 loss)
I0521 11:24:28.170105  3675 sgd_solver.cpp:138] Iteration 35700, lr = 1.25e-05
I0521 11:24:31.682720  3675 solver.cpp:243] Iteration 35720, loss = 0.00269809
I0521 11:24:31.682752  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00269798 (* 1 = 0.00269798 loss)
I0521 11:24:31.682759  3675 sgd_solver.cpp:138] Iteration 35720, lr = 1.25e-05
I0521 11:24:35.196763  3675 solver.cpp:243] Iteration 35740, loss = 0.00286311
I0521 11:24:35.196796  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.002863 (* 1 = 0.002863 loss)
I0521 11:24:35.196802  3675 sgd_solver.cpp:138] Iteration 35740, lr = 1.25e-05
I0521 11:24:38.714159  3675 solver.cpp:243] Iteration 35760, loss = 0.00161007
I0521 11:24:38.714190  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00160996 (* 1 = 0.00160996 loss)
I0521 11:24:38.714196  3675 sgd_solver.cpp:138] Iteration 35760, lr = 1.25e-05
I0521 11:24:42.225325  3675 solver.cpp:243] Iteration 35780, loss = 0.00159512
I0521 11:24:42.225358  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00159501 (* 1 = 0.00159501 loss)
I0521 11:24:42.225365  3675 sgd_solver.cpp:138] Iteration 35780, lr = 1.25e-05
I0521 11:24:45.744436  3675 solver.cpp:243] Iteration 35800, loss = 0.00167181
I0521 11:24:45.744602  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0016717 (* 1 = 0.0016717 loss)
I0521 11:24:45.744611  3675 sgd_solver.cpp:138] Iteration 35800, lr = 1.25e-05
I0521 11:24:49.256335  3675 solver.cpp:243] Iteration 35820, loss = 0.0016394
I0521 11:24:49.256366  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00163929 (* 1 = 0.00163929 loss)
I0521 11:24:49.256371  3675 sgd_solver.cpp:138] Iteration 35820, lr = 1.25e-05
I0521 11:24:52.766054  3675 solver.cpp:243] Iteration 35840, loss = 0.00199999
I0521 11:24:52.766085  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00199988 (* 1 = 0.00199988 loss)
I0521 11:24:52.766091  3675 sgd_solver.cpp:138] Iteration 35840, lr = 1.25e-05
I0521 11:24:56.279160  3675 solver.cpp:243] Iteration 35860, loss = 0.00219444
I0521 11:24:56.279191  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00219433 (* 1 = 0.00219433 loss)
I0521 11:24:56.279212  3675 sgd_solver.cpp:138] Iteration 35860, lr = 1.25e-05
I0521 11:24:59.795984  3675 solver.cpp:243] Iteration 35880, loss = 0.00172363
I0521 11:24:59.796015  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00172352 (* 1 = 0.00172352 loss)
I0521 11:24:59.796020  3675 sgd_solver.cpp:138] Iteration 35880, lr = 1.25e-05
I0521 11:25:03.308230  3675 solver.cpp:243] Iteration 35900, loss = 0.00245399
I0521 11:25:03.308260  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00245388 (* 1 = 0.00245388 loss)
I0521 11:25:03.308282  3675 sgd_solver.cpp:138] Iteration 35900, lr = 1.25e-05
I0521 11:25:06.824877  3675 solver.cpp:243] Iteration 35920, loss = 0.0021123
I0521 11:25:06.824908  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00211219 (* 1 = 0.00211219 loss)
I0521 11:25:06.824914  3675 sgd_solver.cpp:138] Iteration 35920, lr = 1.25e-05
I0521 11:25:10.345917  3675 solver.cpp:243] Iteration 35940, loss = 0.00227102
I0521 11:25:10.345950  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00227091 (* 1 = 0.00227091 loss)
I0521 11:25:10.345957  3675 sgd_solver.cpp:138] Iteration 35940, lr = 1.25e-05
I0521 11:25:13.863459  3675 solver.cpp:243] Iteration 35960, loss = 0.0021658
I0521 11:25:13.863490  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00216569 (* 1 = 0.00216569 loss)
I0521 11:25:13.863512  3675 sgd_solver.cpp:138] Iteration 35960, lr = 1.25e-05
I0521 11:25:17.375731  3675 solver.cpp:243] Iteration 35980, loss = 0.00277317
I0521 11:25:17.375843  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00277306 (* 1 = 0.00277306 loss)
I0521 11:25:17.375849  3675 sgd_solver.cpp:138] Iteration 35980, lr = 1.25e-05
I0521 11:25:20.756300  3675 solver.cpp:596] Snapshotting to binary proto file models/LPR/lpr_resnet_lstm_iter_36000.caffemodel
I0521 11:25:20.783561  3675 sgd_solver.cpp:307] Snapshotting solver state to binary proto file models/LPR/lpr_resnet_lstm_iter_36000.solverstate
I0521 11:25:20.798321  3675 solver.cpp:358] Iteration 36000, Testing net (#0)
I0521 11:25:25.531690  3675 solver.cpp:425]     Test net output #0: acc = 1
I0521 11:25:25.531718  3675 solver.cpp:425]     Test net output #1: acc = 1
I0521 11:25:25.531724  3675 solver.cpp:425]     Test net output #2: ctcloss = 0.00068813 (* 1 = 0.00068813 loss)
I0521 11:25:25.667119  3675 solver.cpp:243] Iteration 36000, loss = 0.0023266
I0521 11:25:25.667161  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00232649 (* 1 = 0.00232649 loss)
I0521 11:25:25.667183  3675 sgd_solver.cpp:138] Iteration 36000, lr = 1.25e-05
I0521 11:25:29.191423  3675 solver.cpp:243] Iteration 36020, loss = 0.00217643
I0521 11:25:29.191453  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00217632 (* 1 = 0.00217632 loss)
I0521 11:25:29.191460  3675 sgd_solver.cpp:138] Iteration 36020, lr = 1.25e-05
I0521 11:25:32.711647  3675 solver.cpp:243] Iteration 36040, loss = 0.00576926
I0521 11:25:32.711678  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00576915 (* 1 = 0.00576915 loss)
I0521 11:25:32.711685  3675 sgd_solver.cpp:138] Iteration 36040, lr = 1.25e-05
I0521 11:25:36.237404  3675 solver.cpp:243] Iteration 36060, loss = 0.0023678
I0521 11:25:36.237435  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00236769 (* 1 = 0.00236769 loss)
I0521 11:25:36.237442  3675 sgd_solver.cpp:138] Iteration 36060, lr = 1.25e-05
I0521 11:25:39.757140  3675 solver.cpp:243] Iteration 36080, loss = 0.00202933
I0521 11:25:39.757172  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00202922 (* 1 = 0.00202922 loss)
I0521 11:25:39.757179  3675 sgd_solver.cpp:138] Iteration 36080, lr = 1.25e-05
I0521 11:25:43.274194  3675 solver.cpp:243] Iteration 36100, loss = 0.00222673
I0521 11:25:43.274224  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00222662 (* 1 = 0.00222662 loss)
I0521 11:25:43.274230  3675 sgd_solver.cpp:138] Iteration 36100, lr = 1.25e-05
I0521 11:25:46.787987  3675 solver.cpp:243] Iteration 36120, loss = 0.00174937
I0521 11:25:46.788018  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00174927 (* 1 = 0.00174927 loss)
I0521 11:25:46.788024  3675 sgd_solver.cpp:138] Iteration 36120, lr = 1.25e-05
I0521 11:25:50.306193  3675 solver.cpp:243] Iteration 36140, loss = 0.0019889
I0521 11:25:50.306383  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00198879 (* 1 = 0.00198879 loss)
I0521 11:25:50.306392  3675 sgd_solver.cpp:138] Iteration 36140, lr = 1.25e-05
I0521 11:25:53.822336  3675 solver.cpp:243] Iteration 36160, loss = 0.00199931
I0521 11:25:53.822367  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0019992 (* 1 = 0.0019992 loss)
I0521 11:25:53.822373  3675 sgd_solver.cpp:138] Iteration 36160, lr = 1.25e-05
I0521 11:25:57.340217  3675 solver.cpp:243] Iteration 36180, loss = 0.00168816
I0521 11:25:57.340250  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00168805 (* 1 = 0.00168805 loss)
I0521 11:25:57.340255  3675 sgd_solver.cpp:138] Iteration 36180, lr = 1.25e-05
I0521 11:26:00.860844  3675 solver.cpp:243] Iteration 36200, loss = 0.00238297
I0521 11:26:00.860874  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00238286 (* 1 = 0.00238286 loss)
I0521 11:26:00.860880  3675 sgd_solver.cpp:138] Iteration 36200, lr = 1.25e-05
I0521 11:26:04.373689  3675 solver.cpp:243] Iteration 36220, loss = 0.0019697
I0521 11:26:04.373720  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00196959 (* 1 = 0.00196959 loss)
I0521 11:26:04.373726  3675 sgd_solver.cpp:138] Iteration 36220, lr = 1.25e-05
I0521 11:26:07.881357  3675 solver.cpp:243] Iteration 36240, loss = 0.00278096
I0521 11:26:07.881386  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00278085 (* 1 = 0.00278085 loss)
I0521 11:26:07.881392  3675 sgd_solver.cpp:138] Iteration 36240, lr = 1.25e-05
I0521 11:26:11.397810  3675 solver.cpp:243] Iteration 36260, loss = 0.00178421
I0521 11:26:11.397840  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00178411 (* 1 = 0.00178411 loss)
I0521 11:26:11.397847  3675 sgd_solver.cpp:138] Iteration 36260, lr = 1.25e-05
I0521 11:26:14.909289  3675 solver.cpp:243] Iteration 36280, loss = 0.00219575
I0521 11:26:14.909319  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00219564 (* 1 = 0.00219564 loss)
I0521 11:26:14.909325  3675 sgd_solver.cpp:138] Iteration 36280, lr = 1.25e-05
I0521 11:26:18.426287  3675 solver.cpp:243] Iteration 36300, loss = 0.00225696
I0521 11:26:18.426318  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00225685 (* 1 = 0.00225685 loss)
I0521 11:26:18.426324  3675 sgd_solver.cpp:138] Iteration 36300, lr = 1.25e-05
I0521 11:26:21.942643  3675 solver.cpp:243] Iteration 36320, loss = 0.00198877
I0521 11:26:21.942790  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00198866 (* 1 = 0.00198866 loss)
I0521 11:26:21.942800  3675 sgd_solver.cpp:138] Iteration 36320, lr = 1.25e-05
I0521 11:26:25.457350  3675 solver.cpp:243] Iteration 36340, loss = 0.00166805
I0521 11:26:25.457379  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00166794 (* 1 = 0.00166794 loss)
I0521 11:26:25.457386  3675 sgd_solver.cpp:138] Iteration 36340, lr = 1.25e-05
I0521 11:26:28.970376  3675 solver.cpp:243] Iteration 36360, loss = 0.00184535
I0521 11:26:28.970408  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00184524 (* 1 = 0.00184524 loss)
I0521 11:26:28.970414  3675 sgd_solver.cpp:138] Iteration 36360, lr = 1.25e-05
I0521 11:26:32.482401  3675 solver.cpp:243] Iteration 36380, loss = 0.00214999
I0521 11:26:32.482434  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00214988 (* 1 = 0.00214988 loss)
I0521 11:26:32.482439  3675 sgd_solver.cpp:138] Iteration 36380, lr = 1.25e-05
I0521 11:26:36.002889  3675 solver.cpp:243] Iteration 36400, loss = 0.00210606
I0521 11:26:36.002919  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00210595 (* 1 = 0.00210595 loss)
I0521 11:26:36.002926  3675 sgd_solver.cpp:138] Iteration 36400, lr = 1.25e-05
I0521 11:26:39.519295  3675 solver.cpp:243] Iteration 36420, loss = 0.00265376
I0521 11:26:39.519326  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00265365 (* 1 = 0.00265365 loss)
I0521 11:26:39.519332  3675 sgd_solver.cpp:138] Iteration 36420, lr = 1.25e-05
I0521 11:26:43.034947  3675 solver.cpp:243] Iteration 36440, loss = 0.00217791
I0521 11:26:43.034981  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0021778 (* 1 = 0.0021778 loss)
I0521 11:26:43.034987  3675 sgd_solver.cpp:138] Iteration 36440, lr = 1.25e-05
I0521 11:26:46.554628  3675 solver.cpp:243] Iteration 36460, loss = 0.00256153
I0521 11:26:46.554659  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00256142 (* 1 = 0.00256142 loss)
I0521 11:26:46.554666  3675 sgd_solver.cpp:138] Iteration 36460, lr = 1.25e-05
I0521 11:26:50.010745  3675 solver.cpp:243] Iteration 36480, loss = 0.00220161
I0521 11:26:50.010776  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0022015 (* 1 = 0.0022015 loss)
I0521 11:26:50.010782  3675 sgd_solver.cpp:138] Iteration 36480, lr = 1.25e-05
I0521 11:26:53.523231  3675 solver.cpp:243] Iteration 36500, loss = 0.0023482
I0521 11:26:53.523391  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00234809 (* 1 = 0.00234809 loss)
I0521 11:26:53.523399  3675 sgd_solver.cpp:138] Iteration 36500, lr = 1.25e-05
I0521 11:26:57.040766  3675 solver.cpp:243] Iteration 36520, loss = 0.00186673
I0521 11:26:57.040801  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00186662 (* 1 = 0.00186662 loss)
I0521 11:26:57.040807  3675 sgd_solver.cpp:138] Iteration 36520, lr = 1.25e-05
I0521 11:27:00.556463  3675 solver.cpp:243] Iteration 36540, loss = 0.00154832
I0521 11:27:00.556494  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00154821 (* 1 = 0.00154821 loss)
I0521 11:27:00.556499  3675 sgd_solver.cpp:138] Iteration 36540, lr = 1.25e-05
I0521 11:27:04.072847  3675 solver.cpp:243] Iteration 36560, loss = 0.00174162
I0521 11:27:04.072878  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00174151 (* 1 = 0.00174151 loss)
I0521 11:27:04.072885  3675 sgd_solver.cpp:138] Iteration 36560, lr = 1.25e-05
I0521 11:27:07.593236  3675 solver.cpp:243] Iteration 36580, loss = 0.0021975
I0521 11:27:07.593266  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00219739 (* 1 = 0.00219739 loss)
I0521 11:27:07.593272  3675 sgd_solver.cpp:138] Iteration 36580, lr = 1.25e-05
I0521 11:27:11.104897  3675 solver.cpp:243] Iteration 36600, loss = 0.00206899
I0521 11:27:11.104926  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00206888 (* 1 = 0.00206888 loss)
I0521 11:27:11.104933  3675 sgd_solver.cpp:138] Iteration 36600, lr = 1.25e-05
I0521 11:27:14.621121  3675 solver.cpp:243] Iteration 36620, loss = 0.00130729
I0521 11:27:14.621155  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00130718 (* 1 = 0.00130718 loss)
I0521 11:27:14.621161  3675 sgd_solver.cpp:138] Iteration 36620, lr = 1.25e-05
I0521 11:27:18.139204  3675 solver.cpp:243] Iteration 36640, loss = 0.00181637
I0521 11:27:18.139236  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00181626 (* 1 = 0.00181626 loss)
I0521 11:27:18.139242  3675 sgd_solver.cpp:138] Iteration 36640, lr = 1.25e-05
I0521 11:27:21.658344  3675 solver.cpp:243] Iteration 36660, loss = 0.00175332
I0521 11:27:21.658375  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00175322 (* 1 = 0.00175322 loss)
I0521 11:27:21.658381  3675 sgd_solver.cpp:138] Iteration 36660, lr = 1.25e-05
I0521 11:27:25.170706  3675 solver.cpp:243] Iteration 36680, loss = 0.00201772
I0521 11:27:25.172549  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00201761 (* 1 = 0.00201761 loss)
I0521 11:27:25.172559  3675 sgd_solver.cpp:138] Iteration 36680, lr = 1.25e-05
I0521 11:27:28.683341  3675 solver.cpp:243] Iteration 36700, loss = 0.00185811
I0521 11:27:28.683372  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.001858 (* 1 = 0.001858 loss)
I0521 11:27:28.683377  3675 sgd_solver.cpp:138] Iteration 36700, lr = 1.25e-05
I0521 11:27:32.203027  3675 solver.cpp:243] Iteration 36720, loss = 0.00180217
I0521 11:27:32.203058  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00180206 (* 1 = 0.00180206 loss)
I0521 11:27:32.203063  3675 sgd_solver.cpp:138] Iteration 36720, lr = 1.25e-05
I0521 11:27:35.719174  3675 solver.cpp:243] Iteration 36740, loss = 0.00171559
I0521 11:27:35.719207  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00171548 (* 1 = 0.00171548 loss)
I0521 11:27:35.719213  3675 sgd_solver.cpp:138] Iteration 36740, lr = 1.25e-05
I0521 11:27:39.237668  3675 solver.cpp:243] Iteration 36760, loss = 0.00181899
I0521 11:27:39.237701  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00181888 (* 1 = 0.00181888 loss)
I0521 11:27:39.237707  3675 sgd_solver.cpp:138] Iteration 36760, lr = 1.25e-05
I0521 11:27:42.757031  3675 solver.cpp:243] Iteration 36780, loss = 0.00250164
I0521 11:27:42.757063  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00250153 (* 1 = 0.00250153 loss)
I0521 11:27:42.757069  3675 sgd_solver.cpp:138] Iteration 36780, lr = 1.25e-05
I0521 11:27:46.269189  3675 solver.cpp:243] Iteration 36800, loss = 0.00226008
I0521 11:27:46.269222  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00225997 (* 1 = 0.00225997 loss)
I0521 11:27:46.269227  3675 sgd_solver.cpp:138] Iteration 36800, lr = 1.25e-05
I0521 11:27:49.786557  3675 solver.cpp:243] Iteration 36820, loss = 0.0020891
I0521 11:27:49.786587  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00208899 (* 1 = 0.00208899 loss)
I0521 11:27:49.786593  3675 sgd_solver.cpp:138] Iteration 36820, lr = 1.25e-05
I0521 11:27:53.300254  3675 solver.cpp:243] Iteration 36840, loss = 0.00218728
I0521 11:27:53.300287  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00218717 (* 1 = 0.00218717 loss)
I0521 11:27:53.300292  3675 sgd_solver.cpp:138] Iteration 36840, lr = 1.25e-05
I0521 11:27:56.819463  3675 solver.cpp:243] Iteration 36860, loss = 0.00135982
I0521 11:27:56.819620  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00135971 (* 1 = 0.00135971 loss)
I0521 11:27:56.819628  3675 sgd_solver.cpp:138] Iteration 36860, lr = 1.25e-05
I0521 11:28:00.344467  3675 solver.cpp:243] Iteration 36880, loss = 0.0018913
I0521 11:28:00.344498  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00189119 (* 1 = 0.00189119 loss)
I0521 11:28:00.344521  3675 sgd_solver.cpp:138] Iteration 36880, lr = 1.25e-05
I0521 11:28:03.857784  3675 solver.cpp:243] Iteration 36900, loss = 0.00176828
I0521 11:28:03.857813  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00176817 (* 1 = 0.00176817 loss)
I0521 11:28:03.857820  3675 sgd_solver.cpp:138] Iteration 36900, lr = 1.25e-05
I0521 11:28:07.376395  3675 solver.cpp:243] Iteration 36920, loss = 0.00290356
I0521 11:28:07.376426  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00290345 (* 1 = 0.00290345 loss)
I0521 11:28:07.376432  3675 sgd_solver.cpp:138] Iteration 36920, lr = 1.25e-05
I0521 11:28:10.898281  3675 solver.cpp:243] Iteration 36940, loss = 0.00142156
I0521 11:28:10.898313  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00142145 (* 1 = 0.00142145 loss)
I0521 11:28:10.898320  3675 sgd_solver.cpp:138] Iteration 36940, lr = 1.25e-05
I0521 11:28:14.412436  3675 solver.cpp:243] Iteration 36960, loss = 0.00191878
I0521 11:28:14.412468  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00191867 (* 1 = 0.00191867 loss)
I0521 11:28:14.412474  3675 sgd_solver.cpp:138] Iteration 36960, lr = 1.25e-05
I0521 11:28:17.930025  3675 solver.cpp:243] Iteration 36980, loss = 0.00179368
I0521 11:28:17.930058  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00179357 (* 1 = 0.00179357 loss)
I0521 11:28:17.930079  3675 sgd_solver.cpp:138] Iteration 36980, lr = 1.25e-05
I0521 11:28:21.319113  3675 solver.cpp:358] Iteration 37000, Testing net (#0)
I0521 11:28:26.052263  3675 solver.cpp:425]     Test net output #0: acc = 1
I0521 11:28:26.052289  3675 solver.cpp:425]     Test net output #1: acc = 1
I0521 11:28:26.052296  3675 solver.cpp:425]     Test net output #2: ctcloss = 0.000686122 (* 1 = 0.000686122 loss)
I0521 11:28:26.187520  3675 solver.cpp:243] Iteration 37000, loss = 0.00207916
I0521 11:28:26.187549  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00207905 (* 1 = 0.00207905 loss)
I0521 11:28:26.187556  3675 sgd_solver.cpp:138] Iteration 37000, lr = 1.25e-05
I0521 11:28:29.707399  3675 solver.cpp:243] Iteration 37020, loss = 0.00169132
I0521 11:28:29.707554  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00169121 (* 1 = 0.00169121 loss)
I0521 11:28:29.707563  3675 sgd_solver.cpp:138] Iteration 37020, lr = 1.25e-05
I0521 11:28:33.230331  3675 solver.cpp:243] Iteration 37040, loss = 0.00196546
I0521 11:28:33.230361  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00196535 (* 1 = 0.00196535 loss)
I0521 11:28:33.230368  3675 sgd_solver.cpp:138] Iteration 37040, lr = 1.25e-05
I0521 11:28:36.749876  3675 solver.cpp:243] Iteration 37060, loss = 0.00159193
I0521 11:28:36.749907  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00159182 (* 1 = 0.00159182 loss)
I0521 11:28:36.749913  3675 sgd_solver.cpp:138] Iteration 37060, lr = 1.25e-05
I0521 11:28:40.271953  3675 solver.cpp:243] Iteration 37080, loss = 0.00205962
I0521 11:28:40.271984  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00205951 (* 1 = 0.00205951 loss)
I0521 11:28:40.271991  3675 sgd_solver.cpp:138] Iteration 37080, lr = 1.25e-05
I0521 11:28:43.795168  3675 solver.cpp:243] Iteration 37100, loss = 0.00166337
I0521 11:28:43.795200  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00166326 (* 1 = 0.00166326 loss)
I0521 11:28:43.795207  3675 sgd_solver.cpp:138] Iteration 37100, lr = 1.25e-05
I0521 11:28:47.315615  3675 solver.cpp:243] Iteration 37120, loss = 0.00149687
I0521 11:28:47.315647  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00149676 (* 1 = 0.00149676 loss)
I0521 11:28:47.315654  3675 sgd_solver.cpp:138] Iteration 37120, lr = 1.25e-05
I0521 11:28:50.836552  3675 solver.cpp:243] Iteration 37140, loss = 0.0016426
I0521 11:28:50.836585  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00164249 (* 1 = 0.00164249 loss)
I0521 11:28:50.836589  3675 sgd_solver.cpp:138] Iteration 37140, lr = 1.25e-05
I0521 11:28:54.356637  3675 solver.cpp:243] Iteration 37160, loss = 0.00197031
I0521 11:28:54.356669  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0019702 (* 1 = 0.0019702 loss)
I0521 11:28:54.356675  3675 sgd_solver.cpp:138] Iteration 37160, lr = 1.25e-05
I0521 11:28:57.877296  3675 solver.cpp:243] Iteration 37180, loss = 0.00640505
I0521 11:28:57.877329  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00640494 (* 1 = 0.00640494 loss)
I0521 11:28:57.877336  3675 sgd_solver.cpp:138] Iteration 37180, lr = 1.25e-05
I0521 11:29:01.396873  3675 solver.cpp:243] Iteration 37200, loss = 0.00206807
I0521 11:29:01.397042  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00206796 (* 1 = 0.00206796 loss)
I0521 11:29:01.397050  3675 sgd_solver.cpp:138] Iteration 37200, lr = 1.25e-05
I0521 11:29:04.914762  3675 solver.cpp:243] Iteration 37220, loss = 0.00202094
I0521 11:29:04.914793  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00202083 (* 1 = 0.00202083 loss)
I0521 11:29:04.914799  3675 sgd_solver.cpp:138] Iteration 37220, lr = 1.25e-05
I0521 11:29:08.435850  3675 solver.cpp:243] Iteration 37240, loss = 0.00329175
I0521 11:29:08.435883  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00329164 (* 1 = 0.00329164 loss)
I0521 11:29:08.435889  3675 sgd_solver.cpp:138] Iteration 37240, lr = 1.25e-05
I0521 11:29:11.958425  3675 solver.cpp:243] Iteration 37260, loss = 0.00209013
I0521 11:29:11.958458  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00209002 (* 1 = 0.00209002 loss)
I0521 11:29:11.958464  3675 sgd_solver.cpp:138] Iteration 37260, lr = 1.25e-05
I0521 11:29:15.477813  3675 solver.cpp:243] Iteration 37280, loss = 0.00189465
I0521 11:29:15.477846  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00189454 (* 1 = 0.00189454 loss)
I0521 11:29:15.477852  3675 sgd_solver.cpp:138] Iteration 37280, lr = 1.25e-05
I0521 11:29:18.999624  3675 solver.cpp:243] Iteration 37300, loss = 0.00369497
I0521 11:29:18.999655  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00369486 (* 1 = 0.00369486 loss)
I0521 11:29:18.999661  3675 sgd_solver.cpp:138] Iteration 37300, lr = 1.25e-05
I0521 11:29:22.520112  3675 solver.cpp:243] Iteration 37320, loss = 0.00246509
I0521 11:29:22.520141  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00246498 (* 1 = 0.00246498 loss)
I0521 11:29:22.520164  3675 sgd_solver.cpp:138] Iteration 37320, lr = 1.25e-05
I0521 11:29:26.038484  3675 solver.cpp:243] Iteration 37340, loss = 0.00232987
I0521 11:29:26.038517  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00232976 (* 1 = 0.00232976 loss)
I0521 11:29:26.038523  3675 sgd_solver.cpp:138] Iteration 37340, lr = 1.25e-05
I0521 11:29:29.561069  3675 solver.cpp:243] Iteration 37360, loss = 0.0019889
I0521 11:29:29.561100  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00198879 (* 1 = 0.00198879 loss)
I0521 11:29:29.561106  3675 sgd_solver.cpp:138] Iteration 37360, lr = 1.25e-05
I0521 11:29:33.081442  3675 solver.cpp:243] Iteration 37380, loss = 0.00270476
I0521 11:29:33.081526  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00270465 (* 1 = 0.00270465 loss)
I0521 11:29:33.081533  3675 sgd_solver.cpp:138] Iteration 37380, lr = 1.25e-05
I0521 11:29:36.604598  3675 solver.cpp:243] Iteration 37400, loss = 0.00215955
I0521 11:29:36.604629  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00215944 (* 1 = 0.00215944 loss)
I0521 11:29:36.604635  3675 sgd_solver.cpp:138] Iteration 37400, lr = 1.25e-05
I0521 11:29:40.122735  3675 solver.cpp:243] Iteration 37420, loss = 0.00173994
I0521 11:29:40.122766  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00173982 (* 1 = 0.00173982 loss)
I0521 11:29:40.122772  3675 sgd_solver.cpp:138] Iteration 37420, lr = 1.25e-05
I0521 11:29:43.647645  3675 solver.cpp:243] Iteration 37440, loss = 0.0020603
I0521 11:29:43.647676  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00206019 (* 1 = 0.00206019 loss)
I0521 11:29:43.647682  3675 sgd_solver.cpp:138] Iteration 37440, lr = 1.25e-05
I0521 11:29:47.168961  3675 solver.cpp:243] Iteration 37460, loss = 0.00200911
I0521 11:29:47.168992  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.002009 (* 1 = 0.002009 loss)
I0521 11:29:47.168998  3675 sgd_solver.cpp:138] Iteration 37460, lr = 1.25e-05
I0521 11:29:50.690234  3675 solver.cpp:243] Iteration 37480, loss = 0.00195424
I0521 11:29:50.690266  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00195413 (* 1 = 0.00195413 loss)
I0521 11:29:50.690273  3675 sgd_solver.cpp:138] Iteration 37480, lr = 1.25e-05
I0521 11:29:54.208550  3675 solver.cpp:243] Iteration 37500, loss = 0.0021731
I0521 11:29:54.208582  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00217299 (* 1 = 0.00217299 loss)
I0521 11:29:54.208588  3675 sgd_solver.cpp:138] Iteration 37500, lr = 1.25e-05
I0521 11:29:57.727613  3675 solver.cpp:243] Iteration 37520, loss = 0.00236223
I0521 11:29:57.727643  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00236212 (* 1 = 0.00236212 loss)
I0521 11:29:57.727650  3675 sgd_solver.cpp:138] Iteration 37520, lr = 1.25e-05
I0521 11:30:01.252606  3675 solver.cpp:243] Iteration 37540, loss = 0.005035
I0521 11:30:01.252638  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00503489 (* 1 = 0.00503489 loss)
I0521 11:30:01.252645  3675 sgd_solver.cpp:138] Iteration 37540, lr = 1.25e-05
I0521 11:30:04.776192  3675 solver.cpp:243] Iteration 37560, loss = 0.0016605
I0521 11:30:04.776407  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00166038 (* 1 = 0.00166038 loss)
I0521 11:30:04.776414  3675 sgd_solver.cpp:138] Iteration 37560, lr = 1.25e-05
I0521 11:30:08.293139  3675 solver.cpp:243] Iteration 37580, loss = 0.00168361
I0521 11:30:08.293172  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0016835 (* 1 = 0.0016835 loss)
I0521 11:30:08.293179  3675 sgd_solver.cpp:138] Iteration 37580, lr = 1.25e-05
I0521 11:30:11.812324  3675 solver.cpp:243] Iteration 37600, loss = 0.00284887
I0521 11:30:11.812355  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00284876 (* 1 = 0.00284876 loss)
I0521 11:30:11.812361  3675 sgd_solver.cpp:138] Iteration 37600, lr = 1.25e-05
I0521 11:30:15.331753  3675 solver.cpp:243] Iteration 37620, loss = 0.0014411
I0521 11:30:15.331784  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00144099 (* 1 = 0.00144099 loss)
I0521 11:30:15.331806  3675 sgd_solver.cpp:138] Iteration 37620, lr = 1.25e-05
I0521 11:30:18.851119  3675 solver.cpp:243] Iteration 37640, loss = 0.00187794
I0521 11:30:18.851153  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00187783 (* 1 = 0.00187783 loss)
I0521 11:30:18.851161  3675 sgd_solver.cpp:138] Iteration 37640, lr = 1.25e-05
I0521 11:30:22.365954  3675 solver.cpp:243] Iteration 37660, loss = 0.00235283
I0521 11:30:22.365985  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00235272 (* 1 = 0.00235272 loss)
I0521 11:30:22.365991  3675 sgd_solver.cpp:138] Iteration 37660, lr = 1.25e-05
I0521 11:30:25.883211  3675 solver.cpp:243] Iteration 37680, loss = 0.00192271
I0521 11:30:25.883242  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0019226 (* 1 = 0.0019226 loss)
I0521 11:30:25.883249  3675 sgd_solver.cpp:138] Iteration 37680, lr = 1.25e-05
I0521 11:30:29.397644  3675 solver.cpp:243] Iteration 37700, loss = 0.00140322
I0521 11:30:29.397675  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00140311 (* 1 = 0.00140311 loss)
I0521 11:30:29.397682  3675 sgd_solver.cpp:138] Iteration 37700, lr = 1.25e-05
I0521 11:30:32.915524  3675 solver.cpp:243] Iteration 37720, loss = 0.00165313
I0521 11:30:32.915555  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00165301 (* 1 = 0.00165301 loss)
I0521 11:30:32.915562  3675 sgd_solver.cpp:138] Iteration 37720, lr = 1.25e-05
I0521 11:30:36.437589  3675 solver.cpp:243] Iteration 37740, loss = 0.00220311
I0521 11:30:36.437757  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.002203 (* 1 = 0.002203 loss)
I0521 11:30:36.437767  3675 sgd_solver.cpp:138] Iteration 37740, lr = 1.25e-05
I0521 11:30:39.954494  3675 solver.cpp:243] Iteration 37760, loss = 0.00167491
I0521 11:30:39.954525  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0016748 (* 1 = 0.0016748 loss)
I0521 11:30:39.954548  3675 sgd_solver.cpp:138] Iteration 37760, lr = 1.25e-05
I0521 11:30:43.408638  3675 solver.cpp:243] Iteration 37780, loss = 0.00155488
I0521 11:30:43.408670  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00155477 (* 1 = 0.00155477 loss)
I0521 11:30:43.408676  3675 sgd_solver.cpp:138] Iteration 37780, lr = 1.25e-05
I0521 11:30:46.928433  3675 solver.cpp:243] Iteration 37800, loss = 0.00227526
I0521 11:30:46.928465  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00227515 (* 1 = 0.00227515 loss)
I0521 11:30:46.928472  3675 sgd_solver.cpp:138] Iteration 37800, lr = 1.25e-05
I0521 11:30:50.446192  3675 solver.cpp:243] Iteration 37820, loss = 0.00207734
I0521 11:30:50.446223  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00207723 (* 1 = 0.00207723 loss)
I0521 11:30:50.446228  3675 sgd_solver.cpp:138] Iteration 37820, lr = 1.25e-05
I0521 11:30:53.962623  3675 solver.cpp:243] Iteration 37840, loss = 0.0021425
I0521 11:30:53.962654  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00214239 (* 1 = 0.00214239 loss)
I0521 11:30:53.962661  3675 sgd_solver.cpp:138] Iteration 37840, lr = 1.25e-05
I0521 11:30:57.483400  3675 solver.cpp:243] Iteration 37860, loss = 0.00185192
I0521 11:30:57.483433  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00185181 (* 1 = 0.00185181 loss)
I0521 11:30:57.483439  3675 sgd_solver.cpp:138] Iteration 37860, lr = 1.25e-05
I0521 11:31:01.003109  3675 solver.cpp:243] Iteration 37880, loss = 0.00152796
I0521 11:31:01.003141  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00152785 (* 1 = 0.00152785 loss)
I0521 11:31:01.003149  3675 sgd_solver.cpp:138] Iteration 37880, lr = 1.25e-05
I0521 11:31:04.524116  3675 solver.cpp:243] Iteration 37900, loss = 0.00167442
I0521 11:31:04.524145  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0016743 (* 1 = 0.0016743 loss)
I0521 11:31:04.524152  3675 sgd_solver.cpp:138] Iteration 37900, lr = 1.25e-05
I0521 11:31:08.044549  3675 solver.cpp:243] Iteration 37920, loss = 0.00256918
I0521 11:31:08.044715  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00256907 (* 1 = 0.00256907 loss)
I0521 11:31:08.044723  3675 sgd_solver.cpp:138] Iteration 37920, lr = 1.25e-05
I0521 11:31:11.559013  3675 solver.cpp:243] Iteration 37940, loss = 0.00127384
I0521 11:31:11.559044  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00127373 (* 1 = 0.00127373 loss)
I0521 11:31:11.559051  3675 sgd_solver.cpp:138] Iteration 37940, lr = 1.25e-05
I0521 11:31:15.082720  3675 solver.cpp:243] Iteration 37960, loss = 0.00139322
I0521 11:31:15.082751  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00139311 (* 1 = 0.00139311 loss)
I0521 11:31:15.082757  3675 sgd_solver.cpp:138] Iteration 37960, lr = 1.25e-05
I0521 11:31:18.594074  3675 solver.cpp:243] Iteration 37980, loss = 0.00183154
I0521 11:31:18.594105  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00183143 (* 1 = 0.00183143 loss)
I0521 11:31:18.594111  3675 sgd_solver.cpp:138] Iteration 37980, lr = 1.25e-05
I0521 11:31:21.976933  3675 solver.cpp:596] Snapshotting to binary proto file models/LPR/lpr_resnet_lstm_iter_38000.caffemodel
I0521 11:31:22.003798  3675 sgd_solver.cpp:307] Snapshotting solver state to binary proto file models/LPR/lpr_resnet_lstm_iter_38000.solverstate
I0521 11:31:22.018230  3675 solver.cpp:358] Iteration 38000, Testing net (#0)
I0521 11:31:26.751444  3675 solver.cpp:425]     Test net output #0: acc = 1
I0521 11:31:26.751471  3675 solver.cpp:425]     Test net output #1: acc = 1
I0521 11:31:26.751478  3675 solver.cpp:425]     Test net output #2: ctcloss = 0.000681079 (* 1 = 0.000681079 loss)
I0521 11:31:26.886283  3675 solver.cpp:243] Iteration 38000, loss = 0.0025318
I0521 11:31:26.886310  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00253169 (* 1 = 0.00253169 loss)
I0521 11:31:26.886317  3675 sgd_solver.cpp:138] Iteration 38000, lr = 1.25e-05
I0521 11:31:30.402066  3675 solver.cpp:243] Iteration 38020, loss = 0.00252128
I0521 11:31:30.402098  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00252116 (* 1 = 0.00252116 loss)
I0521 11:31:30.402104  3675 sgd_solver.cpp:138] Iteration 38020, lr = 1.25e-05
I0521 11:31:33.923763  3675 solver.cpp:243] Iteration 38040, loss = 0.00261788
I0521 11:31:33.923794  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00261777 (* 1 = 0.00261777 loss)
I0521 11:31:33.923799  3675 sgd_solver.cpp:138] Iteration 38040, lr = 1.25e-05
I0521 11:31:37.438239  3675 solver.cpp:243] Iteration 38060, loss = 0.00208146
I0521 11:31:37.438269  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00208135 (* 1 = 0.00208135 loss)
I0521 11:31:37.438277  3675 sgd_solver.cpp:138] Iteration 38060, lr = 1.25e-05
I0521 11:31:40.954768  3675 solver.cpp:243] Iteration 38080, loss = 0.00168546
I0521 11:31:40.954943  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00168535 (* 1 = 0.00168535 loss)
I0521 11:31:40.954952  3675 sgd_solver.cpp:138] Iteration 38080, lr = 1.25e-05
I0521 11:31:44.470512  3675 solver.cpp:243] Iteration 38100, loss = 0.00173146
I0521 11:31:44.470543  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00173135 (* 1 = 0.00173135 loss)
I0521 11:31:44.470551  3675 sgd_solver.cpp:138] Iteration 38100, lr = 1.25e-05
I0521 11:31:47.984258  3675 solver.cpp:243] Iteration 38120, loss = 0.00228675
I0521 11:31:47.984289  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00228664 (* 1 = 0.00228664 loss)
I0521 11:31:47.984295  3675 sgd_solver.cpp:138] Iteration 38120, lr = 1.25e-05
I0521 11:31:51.502624  3675 solver.cpp:243] Iteration 38140, loss = 0.00190749
I0521 11:31:51.502655  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00190738 (* 1 = 0.00190738 loss)
I0521 11:31:51.502660  3675 sgd_solver.cpp:138] Iteration 38140, lr = 1.25e-05
I0521 11:31:55.014389  3675 solver.cpp:243] Iteration 38160, loss = 0.00245519
I0521 11:31:55.014420  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00245508 (* 1 = 0.00245508 loss)
I0521 11:31:55.014426  3675 sgd_solver.cpp:138] Iteration 38160, lr = 1.25e-05
I0521 11:31:58.527989  3675 solver.cpp:243] Iteration 38180, loss = 0.00290317
I0521 11:31:58.528020  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00290305 (* 1 = 0.00290305 loss)
I0521 11:31:58.528026  3675 sgd_solver.cpp:138] Iteration 38180, lr = 1.25e-05
I0521 11:32:02.048300  3675 solver.cpp:243] Iteration 38200, loss = 0.00215276
I0521 11:32:02.048331  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00215265 (* 1 = 0.00215265 loss)
I0521 11:32:02.048336  3675 sgd_solver.cpp:138] Iteration 38200, lr = 1.25e-05
I0521 11:32:05.563388  3675 solver.cpp:243] Iteration 38220, loss = 0.00184104
I0521 11:32:05.563419  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00184093 (* 1 = 0.00184093 loss)
I0521 11:32:05.563426  3675 sgd_solver.cpp:138] Iteration 38220, lr = 1.25e-05
I0521 11:32:09.077409  3675 solver.cpp:243] Iteration 38240, loss = 0.0024878
I0521 11:32:09.077440  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00248769 (* 1 = 0.00248769 loss)
I0521 11:32:09.077445  3675 sgd_solver.cpp:138] Iteration 38240, lr = 1.25e-05
I0521 11:32:12.588093  3675 solver.cpp:243] Iteration 38260, loss = 0.00145931
I0521 11:32:12.588210  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0014592 (* 1 = 0.0014592 loss)
I0521 11:32:12.588218  3675 sgd_solver.cpp:138] Iteration 38260, lr = 1.25e-05
I0521 11:32:16.104066  3675 solver.cpp:243] Iteration 38280, loss = 0.00158483
I0521 11:32:16.104097  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00158472 (* 1 = 0.00158472 loss)
I0521 11:32:16.104104  3675 sgd_solver.cpp:138] Iteration 38280, lr = 1.25e-05
I0521 11:32:19.621997  3675 solver.cpp:243] Iteration 38300, loss = 0.0016393
I0521 11:32:19.622028  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00163919 (* 1 = 0.00163919 loss)
I0521 11:32:19.622035  3675 sgd_solver.cpp:138] Iteration 38300, lr = 1.25e-05
I0521 11:32:23.136433  3675 solver.cpp:243] Iteration 38320, loss = 0.00147379
I0521 11:32:23.136462  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00147368 (* 1 = 0.00147368 loss)
I0521 11:32:23.136468  3675 sgd_solver.cpp:138] Iteration 38320, lr = 1.25e-05
I0521 11:32:26.653024  3675 solver.cpp:243] Iteration 38340, loss = 0.00186465
I0521 11:32:26.653056  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00186454 (* 1 = 0.00186454 loss)
I0521 11:32:26.653062  3675 sgd_solver.cpp:138] Iteration 38340, lr = 1.25e-05
I0521 11:32:30.165478  3675 solver.cpp:243] Iteration 38360, loss = 0.00167997
I0521 11:32:30.165511  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00167986 (* 1 = 0.00167986 loss)
I0521 11:32:30.165518  3675 sgd_solver.cpp:138] Iteration 38360, lr = 1.25e-05
I0521 11:32:33.681089  3675 solver.cpp:243] Iteration 38380, loss = 0.002797
I0521 11:32:33.681120  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00279689 (* 1 = 0.00279689 loss)
I0521 11:32:33.681125  3675 sgd_solver.cpp:138] Iteration 38380, lr = 1.25e-05
I0521 11:32:37.194255  3675 solver.cpp:243] Iteration 38400, loss = 0.00178329
I0521 11:32:37.194288  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00178318 (* 1 = 0.00178318 loss)
I0521 11:32:37.194294  3675 sgd_solver.cpp:138] Iteration 38400, lr = 1.25e-05
I0521 11:32:40.708921  3675 solver.cpp:243] Iteration 38420, loss = 0.00196646
I0521 11:32:40.708952  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00196635 (* 1 = 0.00196635 loss)
I0521 11:32:40.708959  3675 sgd_solver.cpp:138] Iteration 38420, lr = 1.25e-05
I0521 11:32:44.224375  3675 solver.cpp:243] Iteration 38440, loss = 0.0021278
I0521 11:32:44.224550  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00212769 (* 1 = 0.00212769 loss)
I0521 11:32:44.224560  3675 sgd_solver.cpp:138] Iteration 38440, lr = 1.25e-05
I0521 11:32:47.744067  3675 solver.cpp:243] Iteration 38460, loss = 0.00201014
I0521 11:32:47.744098  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00201003 (* 1 = 0.00201003 loss)
I0521 11:32:47.744104  3675 sgd_solver.cpp:138] Iteration 38460, lr = 1.25e-05
I0521 11:32:51.257033  3675 solver.cpp:243] Iteration 38480, loss = 0.00168803
I0521 11:32:51.257066  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00168792 (* 1 = 0.00168792 loss)
I0521 11:32:51.257072  3675 sgd_solver.cpp:138] Iteration 38480, lr = 1.25e-05
I0521 11:32:54.777088  3675 solver.cpp:243] Iteration 38500, loss = 0.00191898
I0521 11:32:54.777119  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00191887 (* 1 = 0.00191887 loss)
I0521 11:32:54.777125  3675 sgd_solver.cpp:138] Iteration 38500, lr = 1.25e-05
I0521 11:32:58.286883  3675 solver.cpp:243] Iteration 38520, loss = 0.00263616
I0521 11:32:58.286914  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00263605 (* 1 = 0.00263605 loss)
I0521 11:32:58.286921  3675 sgd_solver.cpp:138] Iteration 38520, lr = 1.25e-05
I0521 11:33:01.803823  3675 solver.cpp:243] Iteration 38540, loss = 0.00179861
I0521 11:33:01.803854  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0017985 (* 1 = 0.0017985 loss)
I0521 11:33:01.803860  3675 sgd_solver.cpp:138] Iteration 38540, lr = 1.25e-05
I0521 11:33:05.325660  3675 solver.cpp:243] Iteration 38560, loss = 0.00164503
I0521 11:33:05.325693  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00164492 (* 1 = 0.00164492 loss)
I0521 11:33:05.325700  3675 sgd_solver.cpp:138] Iteration 38560, lr = 1.25e-05
I0521 11:33:08.839148  3675 solver.cpp:243] Iteration 38580, loss = 0.00188205
I0521 11:33:08.839203  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00188194 (* 1 = 0.00188194 loss)
I0521 11:33:08.839212  3675 sgd_solver.cpp:138] Iteration 38580, lr = 1.25e-05
I0521 11:33:12.353245  3675 solver.cpp:243] Iteration 38600, loss = 0.00226772
I0521 11:33:12.353277  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00226761 (* 1 = 0.00226761 loss)
I0521 11:33:12.353283  3675 sgd_solver.cpp:138] Iteration 38600, lr = 1.25e-05
I0521 11:33:15.872455  3675 solver.cpp:243] Iteration 38620, loss = 0.00259078
I0521 11:33:15.872584  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00259067 (* 1 = 0.00259067 loss)
I0521 11:33:15.872591  3675 sgd_solver.cpp:138] Iteration 38620, lr = 1.25e-05
I0521 11:33:19.387174  3675 solver.cpp:243] Iteration 38640, loss = 0.00247363
I0521 11:33:19.387205  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00247352 (* 1 = 0.00247352 loss)
I0521 11:33:19.387228  3675 sgd_solver.cpp:138] Iteration 38640, lr = 1.25e-05
I0521 11:33:22.898425  3675 solver.cpp:243] Iteration 38660, loss = 0.00188248
I0521 11:33:22.898456  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00188237 (* 1 = 0.00188237 loss)
I0521 11:33:22.898463  3675 sgd_solver.cpp:138] Iteration 38660, lr = 1.25e-05
I0521 11:33:26.415046  3675 solver.cpp:243] Iteration 38680, loss = 0.0061097
I0521 11:33:26.415079  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00610959 (* 1 = 0.00610959 loss)
I0521 11:33:26.415086  3675 sgd_solver.cpp:138] Iteration 38680, lr = 1.25e-05
I0521 11:33:29.925930  3675 solver.cpp:243] Iteration 38700, loss = 0.00194875
I0521 11:33:29.925962  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00194864 (* 1 = 0.00194864 loss)
I0521 11:33:29.925968  3675 sgd_solver.cpp:138] Iteration 38700, lr = 1.25e-05
I0521 11:33:33.437896  3675 solver.cpp:243] Iteration 38720, loss = 0.00525574
I0521 11:33:33.437927  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00525563 (* 1 = 0.00525563 loss)
I0521 11:33:33.437948  3675 sgd_solver.cpp:138] Iteration 38720, lr = 1.25e-05
I0521 11:33:36.955544  3675 solver.cpp:243] Iteration 38740, loss = 0.00339116
I0521 11:33:36.955576  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00339105 (* 1 = 0.00339105 loss)
I0521 11:33:36.955581  3675 sgd_solver.cpp:138] Iteration 38740, lr = 1.25e-05
I0521 11:33:40.472548  3675 solver.cpp:243] Iteration 38760, loss = 0.00177779
I0521 11:33:40.472579  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00177768 (* 1 = 0.00177768 loss)
I0521 11:33:40.472586  3675 sgd_solver.cpp:138] Iteration 38760, lr = 1.25e-05
I0521 11:33:43.988265  3675 solver.cpp:243] Iteration 38780, loss = 0.00198214
I0521 11:33:43.988296  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00198203 (* 1 = 0.00198203 loss)
I0521 11:33:43.988302  3675 sgd_solver.cpp:138] Iteration 38780, lr = 1.25e-05
I0521 11:33:47.506835  3675 solver.cpp:243] Iteration 38800, loss = 0.00175072
I0521 11:33:47.507004  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00175061 (* 1 = 0.00175061 loss)
I0521 11:33:47.507011  3675 sgd_solver.cpp:138] Iteration 38800, lr = 1.25e-05
I0521 11:33:51.026690  3675 solver.cpp:243] Iteration 38820, loss = 0.00159358
I0521 11:33:51.026721  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00159347 (* 1 = 0.00159347 loss)
I0521 11:33:51.026743  3675 sgd_solver.cpp:138] Iteration 38820, lr = 1.25e-05
I0521 11:33:54.539499  3675 solver.cpp:243] Iteration 38840, loss = 0.0018914
I0521 11:33:54.539530  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00189129 (* 1 = 0.00189129 loss)
I0521 11:33:54.539551  3675 sgd_solver.cpp:138] Iteration 38840, lr = 1.25e-05
I0521 11:33:58.053369  3675 solver.cpp:243] Iteration 38860, loss = 0.00251569
I0521 11:33:58.053397  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00251558 (* 1 = 0.00251558 loss)
I0521 11:33:58.053405  3675 sgd_solver.cpp:138] Iteration 38860, lr = 1.25e-05
I0521 11:34:01.568931  3675 solver.cpp:243] Iteration 38880, loss = 0.00203865
I0521 11:34:01.568964  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00203854 (* 1 = 0.00203854 loss)
I0521 11:34:01.568970  3675 sgd_solver.cpp:138] Iteration 38880, lr = 1.25e-05
I0521 11:34:05.079334  3675 solver.cpp:243] Iteration 38900, loss = 0.0024517
I0521 11:34:05.079366  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00245158 (* 1 = 0.00245158 loss)
I0521 11:34:05.079387  3675 sgd_solver.cpp:138] Iteration 38900, lr = 1.25e-05
I0521 11:34:08.596171  3675 solver.cpp:243] Iteration 38920, loss = 0.00148849
I0521 11:34:08.596200  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00148838 (* 1 = 0.00148838 loss)
I0521 11:34:08.596206  3675 sgd_solver.cpp:138] Iteration 38920, lr = 1.25e-05
I0521 11:34:12.112078  3675 solver.cpp:243] Iteration 38940, loss = 0.0017977
I0521 11:34:12.112108  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00179759 (* 1 = 0.00179759 loss)
I0521 11:34:12.112114  3675 sgd_solver.cpp:138] Iteration 38940, lr = 1.25e-05
I0521 11:34:15.625622  3675 solver.cpp:243] Iteration 38960, loss = 0.00166111
I0521 11:34:15.625653  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.001661 (* 1 = 0.001661 loss)
I0521 11:34:15.625659  3675 sgd_solver.cpp:138] Iteration 38960, lr = 1.25e-05
I0521 11:34:19.138774  3675 solver.cpp:243] Iteration 38980, loss = 0.00164715
I0521 11:34:19.138937  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00164704 (* 1 = 0.00164704 loss)
I0521 11:34:19.138945  3675 sgd_solver.cpp:138] Iteration 38980, lr = 1.25e-05
I0521 11:34:22.455698  3675 solver.cpp:358] Iteration 39000, Testing net (#0)
I0521 11:34:27.187561  3675 solver.cpp:425]     Test net output #0: acc = 1
I0521 11:34:27.187589  3675 solver.cpp:425]     Test net output #1: acc = 1
I0521 11:34:27.187595  3675 solver.cpp:425]     Test net output #2: ctcloss = 0.000672526 (* 1 = 0.000672526 loss)
I0521 11:34:27.385671  3675 solver.cpp:243] Iteration 39000, loss = 0.00224032
I0521 11:34:27.385702  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0022402 (* 1 = 0.0022402 loss)
I0521 11:34:27.385709  3675 sgd_solver.cpp:138] Iteration 39000, lr = 1.25e-05
I0521 11:34:30.903091  3675 solver.cpp:243] Iteration 39020, loss = 0.00172648
I0521 11:34:30.903123  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00172636 (* 1 = 0.00172636 loss)
I0521 11:34:30.903129  3675 sgd_solver.cpp:138] Iteration 39020, lr = 1.25e-05
I0521 11:34:34.417544  3675 solver.cpp:243] Iteration 39040, loss = 0.00284716
I0521 11:34:34.417577  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00284704 (* 1 = 0.00284704 loss)
I0521 11:34:34.417583  3675 sgd_solver.cpp:138] Iteration 39040, lr = 1.25e-05
I0521 11:34:37.928295  3675 solver.cpp:243] Iteration 39060, loss = 0.0023815
I0521 11:34:37.928326  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00238139 (* 1 = 0.00238139 loss)
I0521 11:34:37.928333  3675 sgd_solver.cpp:138] Iteration 39060, lr = 1.25e-05
I0521 11:34:41.377432  3675 solver.cpp:243] Iteration 39080, loss = 0.00232047
I0521 11:34:41.377463  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00232036 (* 1 = 0.00232036 loss)
I0521 11:34:41.377470  3675 sgd_solver.cpp:138] Iteration 39080, lr = 1.25e-05
I0521 11:34:44.895006  3675 solver.cpp:243] Iteration 39100, loss = 0.00224199
I0521 11:34:44.895037  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00224188 (* 1 = 0.00224188 loss)
I0521 11:34:44.895043  3675 sgd_solver.cpp:138] Iteration 39100, lr = 1.25e-05
I0521 11:34:48.406798  3675 solver.cpp:243] Iteration 39120, loss = 0.00306446
I0521 11:34:48.406831  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00306435 (* 1 = 0.00306435 loss)
I0521 11:34:48.406836  3675 sgd_solver.cpp:138] Iteration 39120, lr = 1.25e-05
I0521 11:34:51.925578  3675 solver.cpp:243] Iteration 39140, loss = 0.00166958
I0521 11:34:51.925695  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00166947 (* 1 = 0.00166947 loss)
I0521 11:34:51.925702  3675 sgd_solver.cpp:138] Iteration 39140, lr = 1.25e-05
I0521 11:34:55.445541  3675 solver.cpp:243] Iteration 39160, loss = 0.00165286
I0521 11:34:55.445572  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00165275 (* 1 = 0.00165275 loss)
I0521 11:34:55.445578  3675 sgd_solver.cpp:138] Iteration 39160, lr = 1.25e-05
I0521 11:34:58.956792  3675 solver.cpp:243] Iteration 39180, loss = 0.00196469
I0521 11:34:58.956822  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00196457 (* 1 = 0.00196457 loss)
I0521 11:34:58.956828  3675 sgd_solver.cpp:138] Iteration 39180, lr = 1.25e-05
I0521 11:35:02.472950  3675 solver.cpp:243] Iteration 39200, loss = 0.00298702
I0521 11:35:02.472980  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00298691 (* 1 = 0.00298691 loss)
I0521 11:35:02.472985  3675 sgd_solver.cpp:138] Iteration 39200, lr = 1.25e-05
I0521 11:35:05.990840  3675 solver.cpp:243] Iteration 39220, loss = 0.00224952
I0521 11:35:05.990869  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00224941 (* 1 = 0.00224941 loss)
I0521 11:35:05.990876  3675 sgd_solver.cpp:138] Iteration 39220, lr = 1.25e-05
I0521 11:35:09.506391  3675 solver.cpp:243] Iteration 39240, loss = 0.00164492
I0521 11:35:09.506420  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00164481 (* 1 = 0.00164481 loss)
I0521 11:35:09.506428  3675 sgd_solver.cpp:138] Iteration 39240, lr = 1.25e-05
I0521 11:35:13.020279  3675 solver.cpp:243] Iteration 39260, loss = 0.00160385
I0521 11:35:13.020313  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00160374 (* 1 = 0.00160374 loss)
I0521 11:35:13.020318  3675 sgd_solver.cpp:138] Iteration 39260, lr = 1.25e-05
I0521 11:35:16.533108  3675 solver.cpp:243] Iteration 39280, loss = 0.00250716
I0521 11:35:16.533138  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00250705 (* 1 = 0.00250705 loss)
I0521 11:35:16.533144  3675 sgd_solver.cpp:138] Iteration 39280, lr = 1.25e-05
I0521 11:35:20.049188  3675 solver.cpp:243] Iteration 39300, loss = 0.00231155
I0521 11:35:20.049219  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00231144 (* 1 = 0.00231144 loss)
I0521 11:35:20.049226  3675 sgd_solver.cpp:138] Iteration 39300, lr = 1.25e-05
I0521 11:35:23.563345  3675 solver.cpp:243] Iteration 39320, loss = 0.00131445
I0521 11:35:23.563556  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00131434 (* 1 = 0.00131434 loss)
I0521 11:35:23.563565  3675 sgd_solver.cpp:138] Iteration 39320, lr = 1.25e-05
I0521 11:35:27.085695  3675 solver.cpp:243] Iteration 39340, loss = 0.00266891
I0521 11:35:27.085726  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0026688 (* 1 = 0.0026688 loss)
I0521 11:35:27.085731  3675 sgd_solver.cpp:138] Iteration 39340, lr = 1.25e-05
I0521 11:35:30.604634  3675 solver.cpp:243] Iteration 39360, loss = 0.00165077
I0521 11:35:30.604663  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00165066 (* 1 = 0.00165066 loss)
I0521 11:35:30.604670  3675 sgd_solver.cpp:138] Iteration 39360, lr = 1.25e-05
I0521 11:35:34.116806  3675 solver.cpp:243] Iteration 39380, loss = 0.00195569
I0521 11:35:34.116837  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00195558 (* 1 = 0.00195558 loss)
I0521 11:35:34.116858  3675 sgd_solver.cpp:138] Iteration 39380, lr = 1.25e-05
I0521 11:35:37.630385  3675 solver.cpp:243] Iteration 39400, loss = 0.00133946
I0521 11:35:37.630415  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00133935 (* 1 = 0.00133935 loss)
I0521 11:35:37.630421  3675 sgd_solver.cpp:138] Iteration 39400, lr = 1.25e-05
I0521 11:35:41.145941  3675 solver.cpp:243] Iteration 39420, loss = 0.00252649
I0521 11:35:41.145972  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00252638 (* 1 = 0.00252638 loss)
I0521 11:35:41.145978  3675 sgd_solver.cpp:138] Iteration 39420, lr = 1.25e-05
I0521 11:35:44.661574  3675 solver.cpp:243] Iteration 39440, loss = 0.00237048
I0521 11:35:44.661607  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00237037 (* 1 = 0.00237037 loss)
I0521 11:35:44.661612  3675 sgd_solver.cpp:138] Iteration 39440, lr = 1.25e-05
I0521 11:35:48.178840  3675 solver.cpp:243] Iteration 39460, loss = 0.00204488
I0521 11:35:48.178870  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00204477 (* 1 = 0.00204477 loss)
I0521 11:35:48.178877  3675 sgd_solver.cpp:138] Iteration 39460, lr = 1.25e-05
I0521 11:35:51.692765  3675 solver.cpp:243] Iteration 39480, loss = 0.00190695
I0521 11:35:51.692800  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00190684 (* 1 = 0.00190684 loss)
I0521 11:35:51.692806  3675 sgd_solver.cpp:138] Iteration 39480, lr = 1.25e-05
I0521 11:35:55.210109  3675 solver.cpp:243] Iteration 39500, loss = 0.00135494
I0521 11:35:55.210274  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00135483 (* 1 = 0.00135483 loss)
I0521 11:35:55.210283  3675 sgd_solver.cpp:138] Iteration 39500, lr = 1.25e-05
I0521 11:35:58.725056  3675 solver.cpp:243] Iteration 39520, loss = 0.00237992
I0521 11:35:58.725090  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00237981 (* 1 = 0.00237981 loss)
I0521 11:35:58.725096  3675 sgd_solver.cpp:138] Iteration 39520, lr = 1.25e-05
I0521 11:36:02.243649  3675 solver.cpp:243] Iteration 39540, loss = 0.00150287
I0521 11:36:02.243681  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00150276 (* 1 = 0.00150276 loss)
I0521 11:36:02.243687  3675 sgd_solver.cpp:138] Iteration 39540, lr = 1.25e-05
I0521 11:36:05.759150  3675 solver.cpp:243] Iteration 39560, loss = 0.00266424
I0521 11:36:05.759182  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00266413 (* 1 = 0.00266413 loss)
I0521 11:36:05.759204  3675 sgd_solver.cpp:138] Iteration 39560, lr = 1.25e-05
I0521 11:36:09.274497  3675 solver.cpp:243] Iteration 39580, loss = 0.00210785
I0521 11:36:09.274538  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00210774 (* 1 = 0.00210774 loss)
I0521 11:36:09.274547  3675 sgd_solver.cpp:138] Iteration 39580, lr = 1.25e-05
I0521 11:36:12.790025  3675 solver.cpp:243] Iteration 39600, loss = 0.00203314
I0521 11:36:12.790056  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00203303 (* 1 = 0.00203303 loss)
I0521 11:36:12.790062  3675 sgd_solver.cpp:138] Iteration 39600, lr = 1.25e-05
I0521 11:36:16.297969  3675 solver.cpp:243] Iteration 39620, loss = 0.00209157
I0521 11:36:16.298002  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00209146 (* 1 = 0.00209146 loss)
I0521 11:36:16.298009  3675 sgd_solver.cpp:138] Iteration 39620, lr = 1.25e-05
I0521 11:36:19.808991  3675 solver.cpp:243] Iteration 39640, loss = 0.0020589
I0521 11:36:19.809021  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00205879 (* 1 = 0.00205879 loss)
I0521 11:36:19.809027  3675 sgd_solver.cpp:138] Iteration 39640, lr = 1.25e-05
I0521 11:36:23.322286  3675 solver.cpp:243] Iteration 39660, loss = 0.00187953
I0521 11:36:23.322317  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00187942 (* 1 = 0.00187942 loss)
I0521 11:36:23.322324  3675 sgd_solver.cpp:138] Iteration 39660, lr = 1.25e-05
I0521 11:36:26.831703  3675 solver.cpp:243] Iteration 39680, loss = 0.00154799
I0521 11:36:26.831845  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00154788 (* 1 = 0.00154788 loss)
I0521 11:36:26.831852  3675 sgd_solver.cpp:138] Iteration 39680, lr = 1.25e-05
I0521 11:36:30.351018  3675 solver.cpp:243] Iteration 39700, loss = 0.00156213
I0521 11:36:30.351049  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00156202 (* 1 = 0.00156202 loss)
I0521 11:36:30.351055  3675 sgd_solver.cpp:138] Iteration 39700, lr = 1.25e-05
I0521 11:36:33.869197  3675 solver.cpp:243] Iteration 39720, loss = 0.0019529
I0521 11:36:33.869227  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00195279 (* 1 = 0.00195279 loss)
I0521 11:36:33.869233  3675 sgd_solver.cpp:138] Iteration 39720, lr = 1.25e-05
I0521 11:36:37.383613  3675 solver.cpp:243] Iteration 39740, loss = 0.00184924
I0521 11:36:37.383642  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00184913 (* 1 = 0.00184913 loss)
I0521 11:36:37.383649  3675 sgd_solver.cpp:138] Iteration 39740, lr = 1.25e-05
I0521 11:36:40.899709  3675 solver.cpp:243] Iteration 39760, loss = 0.00188365
I0521 11:36:40.899739  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00188354 (* 1 = 0.00188354 loss)
I0521 11:36:40.899745  3675 sgd_solver.cpp:138] Iteration 39760, lr = 1.25e-05
I0521 11:36:44.415189  3675 solver.cpp:243] Iteration 39780, loss = 0.00227145
I0521 11:36:44.415220  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00227134 (* 1 = 0.00227134 loss)
I0521 11:36:44.415226  3675 sgd_solver.cpp:138] Iteration 39780, lr = 1.25e-05
I0521 11:36:47.932253  3675 solver.cpp:243] Iteration 39800, loss = 0.00210239
I0521 11:36:47.932283  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00210228 (* 1 = 0.00210228 loss)
I0521 11:36:47.932291  3675 sgd_solver.cpp:138] Iteration 39800, lr = 1.25e-05
I0521 11:36:51.448981  3675 solver.cpp:243] Iteration 39820, loss = 0.00223247
I0521 11:36:51.449012  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00223236 (* 1 = 0.00223236 loss)
I0521 11:36:51.449018  3675 sgd_solver.cpp:138] Iteration 39820, lr = 1.25e-05
I0521 11:36:54.966365  3675 solver.cpp:243] Iteration 39840, loss = 0.00273041
I0521 11:36:54.966395  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0027303 (* 1 = 0.0027303 loss)
I0521 11:36:54.966401  3675 sgd_solver.cpp:138] Iteration 39840, lr = 1.25e-05
I0521 11:36:58.481032  3675 solver.cpp:243] Iteration 39860, loss = 0.00155119
I0521 11:36:58.481201  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00155108 (* 1 = 0.00155108 loss)
I0521 11:36:58.481212  3675 sgd_solver.cpp:138] Iteration 39860, lr = 1.25e-05
I0521 11:37:02.003877  3675 solver.cpp:243] Iteration 39880, loss = 0.00147412
I0521 11:37:02.003909  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00147401 (* 1 = 0.00147401 loss)
I0521 11:37:02.003916  3675 sgd_solver.cpp:138] Iteration 39880, lr = 1.25e-05
I0521 11:37:05.520560  3675 solver.cpp:243] Iteration 39900, loss = 0.00157609
I0521 11:37:05.520591  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00157599 (* 1 = 0.00157599 loss)
I0521 11:37:05.520599  3675 sgd_solver.cpp:138] Iteration 39900, lr = 1.25e-05
I0521 11:37:09.034135  3675 solver.cpp:243] Iteration 39920, loss = 0.00229287
I0521 11:37:09.034166  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00229276 (* 1 = 0.00229276 loss)
I0521 11:37:09.034173  3675 sgd_solver.cpp:138] Iteration 39920, lr = 1.25e-05
I0521 11:37:12.555322  3675 solver.cpp:243] Iteration 39940, loss = 0.0024274
I0521 11:37:12.555354  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00242729 (* 1 = 0.00242729 loss)
I0521 11:37:12.555361  3675 sgd_solver.cpp:138] Iteration 39940, lr = 1.25e-05
I0521 11:37:16.071223  3675 solver.cpp:243] Iteration 39960, loss = 0.00254019
I0521 11:37:16.071256  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00254008 (* 1 = 0.00254008 loss)
I0521 11:37:16.071264  3675 sgd_solver.cpp:138] Iteration 39960, lr = 1.25e-05
I0521 11:37:19.584759  3675 solver.cpp:243] Iteration 39980, loss = 0.00194156
I0521 11:37:19.584795  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00194145 (* 1 = 0.00194145 loss)
I0521 11:37:19.584802  3675 sgd_solver.cpp:138] Iteration 39980, lr = 1.25e-05
I0521 11:37:22.965754  3675 solver.cpp:596] Snapshotting to binary proto file models/LPR/lpr_resnet_lstm_iter_40000.caffemodel
I0521 11:37:22.992908  3675 sgd_solver.cpp:307] Snapshotting solver state to binary proto file models/LPR/lpr_resnet_lstm_iter_40000.solverstate
I0521 11:37:23.007319  3675 solver.cpp:358] Iteration 40000, Testing net (#0)
I0521 11:37:27.743206  3675 solver.cpp:425]     Test net output #0: acc = 1
I0521 11:37:27.743232  3675 solver.cpp:425]     Test net output #1: acc = 1
I0521 11:37:27.743240  3675 solver.cpp:425]     Test net output #2: ctcloss = 0.000670538 (* 1 = 0.000670538 loss)
I0521 11:37:27.879078  3675 solver.cpp:243] Iteration 40000, loss = 0.00176933
I0521 11:37:27.879110  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00176922 (* 1 = 0.00176922 loss)
I0521 11:37:27.879118  3675 sgd_solver.cpp:138] Iteration 40000, lr = 6.25e-06
I0521 11:37:31.400769  3675 solver.cpp:243] Iteration 40020, loss = 0.00194834
I0521 11:37:31.400923  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00194823 (* 1 = 0.00194823 loss)
I0521 11:37:31.400933  3675 sgd_solver.cpp:138] Iteration 40020, lr = 6.25e-06
I0521 11:37:34.919911  3675 solver.cpp:243] Iteration 40040, loss = 0.00229192
I0521 11:37:34.919945  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00229181 (* 1 = 0.00229181 loss)
I0521 11:37:34.919953  3675 sgd_solver.cpp:138] Iteration 40040, lr = 6.25e-06
I0521 11:37:38.439944  3675 solver.cpp:243] Iteration 40060, loss = 0.0015247
I0521 11:37:38.439975  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00152459 (* 1 = 0.00152459 loss)
I0521 11:37:38.439983  3675 sgd_solver.cpp:138] Iteration 40060, lr = 6.25e-06
I0521 11:37:41.951850  3675 solver.cpp:243] Iteration 40080, loss = 0.00195263
I0521 11:37:41.951884  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00195252 (* 1 = 0.00195252 loss)
I0521 11:37:41.951890  3675 sgd_solver.cpp:138] Iteration 40080, lr = 6.25e-06
I0521 11:37:45.473592  3675 solver.cpp:243] Iteration 40100, loss = 0.00208604
I0521 11:37:45.473625  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00208593 (* 1 = 0.00208593 loss)
I0521 11:37:45.473634  3675 sgd_solver.cpp:138] Iteration 40100, lr = 6.25e-06
I0521 11:37:48.995528  3675 solver.cpp:243] Iteration 40120, loss = 0.00161957
I0521 11:37:48.995559  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00161946 (* 1 = 0.00161946 loss)
I0521 11:37:48.995565  3675 sgd_solver.cpp:138] Iteration 40120, lr = 6.25e-06
I0521 11:37:52.515622  3675 solver.cpp:243] Iteration 40140, loss = 0.0018891
I0521 11:37:52.515655  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00188899 (* 1 = 0.00188899 loss)
I0521 11:37:52.515661  3675 sgd_solver.cpp:138] Iteration 40140, lr = 6.25e-06
I0521 11:37:56.038098  3675 solver.cpp:243] Iteration 40160, loss = 0.00205251
I0521 11:37:56.038128  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0020524 (* 1 = 0.0020524 loss)
I0521 11:37:56.038134  3675 sgd_solver.cpp:138] Iteration 40160, lr = 6.25e-06
I0521 11:37:59.560727  3675 solver.cpp:243] Iteration 40180, loss = 0.0019965
I0521 11:37:59.560760  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0019964 (* 1 = 0.0019964 loss)
I0521 11:37:59.560783  3675 sgd_solver.cpp:138] Iteration 40180, lr = 6.25e-06
I0521 11:38:03.081897  3675 solver.cpp:243] Iteration 40200, loss = 0.00188173
I0521 11:38:03.082059  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00188162 (* 1 = 0.00188162 loss)
I0521 11:38:03.082068  3675 sgd_solver.cpp:138] Iteration 40200, lr = 6.25e-06
I0521 11:38:06.596967  3675 solver.cpp:243] Iteration 40220, loss = 0.00205829
I0521 11:38:06.596998  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00205818 (* 1 = 0.00205818 loss)
I0521 11:38:06.597004  3675 sgd_solver.cpp:138] Iteration 40220, lr = 6.25e-06
I0521 11:38:10.120004  3675 solver.cpp:243] Iteration 40240, loss = 0.00177781
I0521 11:38:10.120033  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00177771 (* 1 = 0.00177771 loss)
I0521 11:38:10.120039  3675 sgd_solver.cpp:138] Iteration 40240, lr = 6.25e-06
I0521 11:38:13.638592  3675 solver.cpp:243] Iteration 40260, loss = 0.00178547
I0521 11:38:13.638622  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00178536 (* 1 = 0.00178536 loss)
I0521 11:38:13.638645  3675 sgd_solver.cpp:138] Iteration 40260, lr = 6.25e-06
I0521 11:38:17.157047  3675 solver.cpp:243] Iteration 40280, loss = 0.00159815
I0521 11:38:17.157078  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00159804 (* 1 = 0.00159804 loss)
I0521 11:38:17.157084  3675 sgd_solver.cpp:138] Iteration 40280, lr = 6.25e-06
I0521 11:38:20.678012  3675 solver.cpp:243] Iteration 40300, loss = 0.00182335
I0521 11:38:20.678045  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00182324 (* 1 = 0.00182324 loss)
I0521 11:38:20.678051  3675 sgd_solver.cpp:138] Iteration 40300, lr = 6.25e-06
I0521 11:38:24.200320  3675 solver.cpp:243] Iteration 40320, loss = 0.00222694
I0521 11:38:24.200350  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00222683 (* 1 = 0.00222683 loss)
I0521 11:38:24.200356  3675 sgd_solver.cpp:138] Iteration 40320, lr = 6.25e-06
I0521 11:38:27.723181  3675 solver.cpp:243] Iteration 40340, loss = 0.00186484
I0521 11:38:27.723212  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00186474 (* 1 = 0.00186474 loss)
I0521 11:38:27.723218  3675 sgd_solver.cpp:138] Iteration 40340, lr = 6.25e-06
I0521 11:38:31.240082  3675 solver.cpp:243] Iteration 40360, loss = 0.00199715
I0521 11:38:31.240113  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00199704 (* 1 = 0.00199704 loss)
I0521 11:38:31.240119  3675 sgd_solver.cpp:138] Iteration 40360, lr = 6.25e-06
I0521 11:38:34.693604  3675 solver.cpp:243] Iteration 40380, loss = 0.0018883
I0521 11:38:34.693774  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00188819 (* 1 = 0.00188819 loss)
I0521 11:38:34.693783  3675 sgd_solver.cpp:138] Iteration 40380, lr = 6.25e-06
I0521 11:38:38.210975  3675 solver.cpp:243] Iteration 40400, loss = 0.0013754
I0521 11:38:38.211006  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0013753 (* 1 = 0.0013753 loss)
I0521 11:38:38.211012  3675 sgd_solver.cpp:138] Iteration 40400, lr = 6.25e-06
I0521 11:38:41.726409  3675 solver.cpp:243] Iteration 40420, loss = 0.00283819
I0521 11:38:41.726439  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00283808 (* 1 = 0.00283808 loss)
I0521 11:38:41.726446  3675 sgd_solver.cpp:138] Iteration 40420, lr = 6.25e-06
I0521 11:38:45.249105  3675 solver.cpp:243] Iteration 40440, loss = 0.00173028
I0521 11:38:45.249136  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00173018 (* 1 = 0.00173018 loss)
I0521 11:38:45.249141  3675 sgd_solver.cpp:138] Iteration 40440, lr = 6.25e-06
I0521 11:38:48.770620  3675 solver.cpp:243] Iteration 40460, loss = 0.0018934
I0521 11:38:48.770651  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00189329 (* 1 = 0.00189329 loss)
I0521 11:38:48.770658  3675 sgd_solver.cpp:138] Iteration 40460, lr = 6.25e-06
I0521 11:38:52.294432  3675 solver.cpp:243] Iteration 40480, loss = 0.00215709
I0521 11:38:52.294463  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00215699 (* 1 = 0.00215699 loss)
I0521 11:38:52.294468  3675 sgd_solver.cpp:138] Iteration 40480, lr = 6.25e-06
I0521 11:38:55.816438  3675 solver.cpp:243] Iteration 40500, loss = 0.0018663
I0521 11:38:55.816468  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00186619 (* 1 = 0.00186619 loss)
I0521 11:38:55.816474  3675 sgd_solver.cpp:138] Iteration 40500, lr = 6.25e-06
I0521 11:38:59.338135  3675 solver.cpp:243] Iteration 40520, loss = 0.00211939
I0521 11:38:59.338166  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00211928 (* 1 = 0.00211928 loss)
I0521 11:38:59.338188  3675 sgd_solver.cpp:138] Iteration 40520, lr = 6.25e-06
I0521 11:39:02.860510  3675 solver.cpp:243] Iteration 40540, loss = 0.00204497
I0521 11:39:02.860543  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00204486 (* 1 = 0.00204486 loss)
I0521 11:39:02.860549  3675 sgd_solver.cpp:138] Iteration 40540, lr = 6.25e-06
I0521 11:39:06.378295  3675 solver.cpp:243] Iteration 40560, loss = 0.00221212
I0521 11:39:06.378461  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00221201 (* 1 = 0.00221201 loss)
I0521 11:39:06.378469  3675 sgd_solver.cpp:138] Iteration 40560, lr = 6.25e-06
I0521 11:39:09.896775  3675 solver.cpp:243] Iteration 40580, loss = 0.00246751
I0521 11:39:09.896807  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0024674 (* 1 = 0.0024674 loss)
I0521 11:39:09.896813  3675 sgd_solver.cpp:138] Iteration 40580, lr = 6.25e-06
I0521 11:39:13.412137  3675 solver.cpp:243] Iteration 40600, loss = 0.00204267
I0521 11:39:13.412168  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00204257 (* 1 = 0.00204257 loss)
I0521 11:39:13.412175  3675 sgd_solver.cpp:138] Iteration 40600, lr = 6.25e-06
I0521 11:39:16.931577  3675 solver.cpp:243] Iteration 40620, loss = 0.00199276
I0521 11:39:16.931610  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00199265 (* 1 = 0.00199265 loss)
I0521 11:39:16.931617  3675 sgd_solver.cpp:138] Iteration 40620, lr = 6.25e-06
I0521 11:39:20.446192  3675 solver.cpp:243] Iteration 40640, loss = 0.00186875
I0521 11:39:20.446223  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00186864 (* 1 = 0.00186864 loss)
I0521 11:39:20.446230  3675 sgd_solver.cpp:138] Iteration 40640, lr = 6.25e-06
I0521 11:39:23.968552  3675 solver.cpp:243] Iteration 40660, loss = 0.00199105
I0521 11:39:23.968585  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00199094 (* 1 = 0.00199094 loss)
I0521 11:39:23.968590  3675 sgd_solver.cpp:138] Iteration 40660, lr = 6.25e-06
I0521 11:39:27.488005  3675 solver.cpp:243] Iteration 40680, loss = 0.00260033
I0521 11:39:27.488035  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00260022 (* 1 = 0.00260022 loss)
I0521 11:39:27.488040  3675 sgd_solver.cpp:138] Iteration 40680, lr = 6.25e-06
I0521 11:39:31.009204  3675 solver.cpp:243] Iteration 40700, loss = 0.00172966
I0521 11:39:31.009234  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00172955 (* 1 = 0.00172955 loss)
I0521 11:39:31.009240  3675 sgd_solver.cpp:138] Iteration 40700, lr = 6.25e-06
I0521 11:39:34.529021  3675 solver.cpp:243] Iteration 40720, loss = 0.00179066
I0521 11:39:34.529052  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00179055 (* 1 = 0.00179055 loss)
I0521 11:39:34.529057  3675 sgd_solver.cpp:138] Iteration 40720, lr = 6.25e-06
I0521 11:39:38.045547  3675 solver.cpp:243] Iteration 40740, loss = 0.00129039
I0521 11:39:38.045709  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00129028 (* 1 = 0.00129028 loss)
I0521 11:39:38.045718  3675 sgd_solver.cpp:138] Iteration 40740, lr = 6.25e-06
I0521 11:39:41.565562  3675 solver.cpp:243] Iteration 40760, loss = 0.00182378
I0521 11:39:41.565593  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00182367 (* 1 = 0.00182367 loss)
I0521 11:39:41.565600  3675 sgd_solver.cpp:138] Iteration 40760, lr = 6.25e-06
I0521 11:39:45.086510  3675 solver.cpp:243] Iteration 40780, loss = 0.00228043
I0521 11:39:45.086542  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00228032 (* 1 = 0.00228032 loss)
I0521 11:39:45.086547  3675 sgd_solver.cpp:138] Iteration 40780, lr = 6.25e-06
I0521 11:39:48.600455  3675 solver.cpp:243] Iteration 40800, loss = 0.00207701
I0521 11:39:48.600487  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0020769 (* 1 = 0.0020769 loss)
I0521 11:39:48.600494  3675 sgd_solver.cpp:138] Iteration 40800, lr = 6.25e-06
I0521 11:39:52.120177  3675 solver.cpp:243] Iteration 40820, loss = 0.00239763
I0521 11:39:52.120208  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00239752 (* 1 = 0.00239752 loss)
I0521 11:39:52.120214  3675 sgd_solver.cpp:138] Iteration 40820, lr = 6.25e-06
I0521 11:39:55.638463  3675 solver.cpp:243] Iteration 40840, loss = 0.00217394
I0521 11:39:55.638494  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00217383 (* 1 = 0.00217383 loss)
I0521 11:39:55.638499  3675 sgd_solver.cpp:138] Iteration 40840, lr = 6.25e-06
I0521 11:39:59.162511  3675 solver.cpp:243] Iteration 40860, loss = 0.0019661
I0521 11:39:59.162542  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00196599 (* 1 = 0.00196599 loss)
I0521 11:39:59.162547  3675 sgd_solver.cpp:138] Iteration 40860, lr = 6.25e-06
I0521 11:40:02.681463  3675 solver.cpp:243] Iteration 40880, loss = 0.00170402
I0521 11:40:02.681495  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00170391 (* 1 = 0.00170391 loss)
I0521 11:40:02.681502  3675 sgd_solver.cpp:138] Iteration 40880, lr = 6.25e-06
I0521 11:40:06.201100  3675 solver.cpp:243] Iteration 40900, loss = 0.00179881
I0521 11:40:06.201133  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0017987 (* 1 = 0.0017987 loss)
I0521 11:40:06.201138  3675 sgd_solver.cpp:138] Iteration 40900, lr = 6.25e-06
I0521 11:40:09.719310  3675 solver.cpp:243] Iteration 40920, loss = 0.00170691
I0521 11:40:09.719394  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00170681 (* 1 = 0.00170681 loss)
I0521 11:40:09.719401  3675 sgd_solver.cpp:138] Iteration 40920, lr = 6.25e-06
I0521 11:40:13.236039  3675 solver.cpp:243] Iteration 40940, loss = 0.00291471
I0521 11:40:13.236070  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0029146 (* 1 = 0.0029146 loss)
I0521 11:40:13.236093  3675 sgd_solver.cpp:138] Iteration 40940, lr = 6.25e-06
I0521 11:40:16.757869  3675 solver.cpp:243] Iteration 40960, loss = 0.00138709
I0521 11:40:16.757899  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00138698 (* 1 = 0.00138698 loss)
I0521 11:40:16.757905  3675 sgd_solver.cpp:138] Iteration 40960, lr = 6.25e-06
I0521 11:40:20.277989  3675 solver.cpp:243] Iteration 40980, loss = 0.002261
I0521 11:40:20.278023  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00226089 (* 1 = 0.00226089 loss)
I0521 11:40:20.278028  3675 sgd_solver.cpp:138] Iteration 40980, lr = 6.25e-06
I0521 11:40:23.663084  3675 solver.cpp:358] Iteration 41000, Testing net (#0)
I0521 11:40:28.396849  3675 solver.cpp:425]     Test net output #0: acc = 1
I0521 11:40:28.396878  3675 solver.cpp:425]     Test net output #1: acc = 1
I0521 11:40:28.396884  3675 solver.cpp:425]     Test net output #2: ctcloss = 0.000664423 (* 1 = 0.000664423 loss)
I0521 11:40:28.532807  3675 solver.cpp:243] Iteration 41000, loss = 0.00168814
I0521 11:40:28.532840  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00168803 (* 1 = 0.00168803 loss)
I0521 11:40:28.532847  3675 sgd_solver.cpp:138] Iteration 41000, lr = 6.25e-06
I0521 11:40:32.057024  3675 solver.cpp:243] Iteration 41020, loss = 0.00180233
I0521 11:40:32.057056  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00180222 (* 1 = 0.00180222 loss)
I0521 11:40:32.057063  3675 sgd_solver.cpp:138] Iteration 41020, lr = 6.25e-06
I0521 11:40:35.582471  3675 solver.cpp:243] Iteration 41040, loss = 0.00508568
I0521 11:40:35.582504  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00508557 (* 1 = 0.00508557 loss)
I0521 11:40:35.582509  3675 sgd_solver.cpp:138] Iteration 41040, lr = 6.25e-06
I0521 11:40:39.105442  3675 solver.cpp:243] Iteration 41060, loss = 0.00253649
I0521 11:40:39.105473  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00253638 (* 1 = 0.00253638 loss)
I0521 11:40:39.105480  3675 sgd_solver.cpp:138] Iteration 41060, lr = 6.25e-06
I0521 11:40:42.627943  3675 solver.cpp:243] Iteration 41080, loss = 0.00207343
I0521 11:40:42.628119  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00207332 (* 1 = 0.00207332 loss)
I0521 11:40:42.628127  3675 sgd_solver.cpp:138] Iteration 41080, lr = 6.25e-06
I0521 11:40:46.155836  3675 solver.cpp:243] Iteration 41100, loss = 0.00207805
I0521 11:40:46.155867  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00207794 (* 1 = 0.00207794 loss)
I0521 11:40:46.155889  3675 sgd_solver.cpp:138] Iteration 41100, lr = 6.25e-06
I0521 11:40:49.678375  3675 solver.cpp:243] Iteration 41120, loss = 0.00167878
I0521 11:40:49.678406  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00167867 (* 1 = 0.00167867 loss)
I0521 11:40:49.678413  3675 sgd_solver.cpp:138] Iteration 41120, lr = 6.25e-06
I0521 11:40:53.205700  3675 solver.cpp:243] Iteration 41140, loss = 0.0025665
I0521 11:40:53.205731  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00256639 (* 1 = 0.00256639 loss)
I0521 11:40:53.205737  3675 sgd_solver.cpp:138] Iteration 41140, lr = 6.25e-06
I0521 11:40:56.732961  3675 solver.cpp:243] Iteration 41160, loss = 0.00234277
I0521 11:40:56.732993  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00234266 (* 1 = 0.00234266 loss)
I0521 11:40:56.733000  3675 sgd_solver.cpp:138] Iteration 41160, lr = 6.25e-06
I0521 11:41:00.256995  3675 solver.cpp:243] Iteration 41180, loss = 0.00137496
I0521 11:41:00.257026  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00137485 (* 1 = 0.00137485 loss)
I0521 11:41:00.257035  3675 sgd_solver.cpp:138] Iteration 41180, lr = 6.25e-06
I0521 11:41:03.777679  3675 solver.cpp:243] Iteration 41200, loss = 0.00348717
I0521 11:41:03.777711  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00348706 (* 1 = 0.00348706 loss)
I0521 11:41:03.777734  3675 sgd_solver.cpp:138] Iteration 41200, lr = 6.25e-06
I0521 11:41:07.303099  3675 solver.cpp:243] Iteration 41220, loss = 0.00163025
I0521 11:41:07.303130  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00163014 (* 1 = 0.00163014 loss)
I0521 11:41:07.303136  3675 sgd_solver.cpp:138] Iteration 41220, lr = 6.25e-06
I0521 11:41:10.823951  3675 solver.cpp:243] Iteration 41240, loss = 0.00200734
I0521 11:41:10.823983  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00200723 (* 1 = 0.00200723 loss)
I0521 11:41:10.823989  3675 sgd_solver.cpp:138] Iteration 41240, lr = 6.25e-06
I0521 11:41:14.346758  3675 solver.cpp:243] Iteration 41260, loss = 0.00242429
I0521 11:41:14.346910  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00242418 (* 1 = 0.00242418 loss)
I0521 11:41:14.346920  3675 sgd_solver.cpp:138] Iteration 41260, lr = 6.25e-06
I0521 11:41:17.867717  3675 solver.cpp:243] Iteration 41280, loss = 0.00220303
I0521 11:41:17.867749  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00220292 (* 1 = 0.00220292 loss)
I0521 11:41:17.867771  3675 sgd_solver.cpp:138] Iteration 41280, lr = 6.25e-06
I0521 11:41:21.387660  3675 solver.cpp:243] Iteration 41300, loss = 0.0018849
I0521 11:41:21.387689  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00188479 (* 1 = 0.00188479 loss)
I0521 11:41:21.387712  3675 sgd_solver.cpp:138] Iteration 41300, lr = 6.25e-06
I0521 11:41:24.905418  3675 solver.cpp:243] Iteration 41320, loss = 0.00187998
I0521 11:41:24.905447  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00187987 (* 1 = 0.00187987 loss)
I0521 11:41:24.905453  3675 sgd_solver.cpp:138] Iteration 41320, lr = 6.25e-06
I0521 11:41:28.427275  3675 solver.cpp:243] Iteration 41340, loss = 0.00196422
I0521 11:41:28.427306  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00196411 (* 1 = 0.00196411 loss)
I0521 11:41:28.427311  3675 sgd_solver.cpp:138] Iteration 41340, lr = 6.25e-06
I0521 11:41:31.947093  3675 solver.cpp:243] Iteration 41360, loss = 0.00191449
I0521 11:41:31.947124  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00191438 (* 1 = 0.00191438 loss)
I0521 11:41:31.947129  3675 sgd_solver.cpp:138] Iteration 41360, lr = 6.25e-06
I0521 11:41:35.472698  3675 solver.cpp:243] Iteration 41380, loss = 0.00174475
I0521 11:41:35.472726  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00174464 (* 1 = 0.00174464 loss)
I0521 11:41:35.472733  3675 sgd_solver.cpp:138] Iteration 41380, lr = 6.25e-06
I0521 11:41:38.999604  3675 solver.cpp:243] Iteration 41400, loss = 0.00165236
I0521 11:41:38.999634  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00165225 (* 1 = 0.00165225 loss)
I0521 11:41:38.999640  3675 sgd_solver.cpp:138] Iteration 41400, lr = 6.25e-06
I0521 11:41:42.521495  3675 solver.cpp:243] Iteration 41420, loss = 0.00214674
I0521 11:41:42.521526  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00214663 (* 1 = 0.00214663 loss)
I0521 11:41:42.521531  3675 sgd_solver.cpp:138] Iteration 41420, lr = 6.25e-06
I0521 11:41:46.039170  3675 solver.cpp:243] Iteration 41440, loss = 0.00150949
I0521 11:41:46.039285  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00150938 (* 1 = 0.00150938 loss)
I0521 11:41:46.039294  3675 sgd_solver.cpp:138] Iteration 41440, lr = 6.25e-06
I0521 11:41:49.558226  3675 solver.cpp:243] Iteration 41460, loss = 0.0020905
I0521 11:41:49.558257  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00209039 (* 1 = 0.00209039 loss)
I0521 11:41:49.558264  3675 sgd_solver.cpp:138] Iteration 41460, lr = 6.25e-06
I0521 11:41:53.073568  3675 solver.cpp:243] Iteration 41480, loss = 0.0013871
I0521 11:41:53.073599  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00138699 (* 1 = 0.00138699 loss)
I0521 11:41:53.073606  3675 sgd_solver.cpp:138] Iteration 41480, lr = 6.25e-06
I0521 11:41:56.593188  3675 solver.cpp:243] Iteration 41500, loss = 0.00244451
I0521 11:41:56.593219  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00244441 (* 1 = 0.00244441 loss)
I0521 11:41:56.593225  3675 sgd_solver.cpp:138] Iteration 41500, lr = 6.25e-06
I0521 11:42:00.113328  3675 solver.cpp:243] Iteration 41520, loss = 0.0022056
I0521 11:42:00.113358  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00220549 (* 1 = 0.00220549 loss)
I0521 11:42:00.113365  3675 sgd_solver.cpp:138] Iteration 41520, lr = 6.25e-06
I0521 11:42:03.632962  3675 solver.cpp:243] Iteration 41540, loss = 0.0019945
I0521 11:42:03.632993  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00199439 (* 1 = 0.00199439 loss)
I0521 11:42:03.633000  3675 sgd_solver.cpp:138] Iteration 41540, lr = 6.25e-06
I0521 11:42:07.151291  3675 solver.cpp:243] Iteration 41560, loss = 0.00157813
I0521 11:42:07.151322  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00157802 (* 1 = 0.00157802 loss)
I0521 11:42:07.151329  3675 sgd_solver.cpp:138] Iteration 41560, lr = 6.25e-06
I0521 11:42:10.673801  3675 solver.cpp:243] Iteration 41580, loss = 0.00197617
I0521 11:42:10.673833  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00197606 (* 1 = 0.00197606 loss)
I0521 11:42:10.673840  3675 sgd_solver.cpp:138] Iteration 41580, lr = 6.25e-06
I0521 11:42:14.197508  3675 solver.cpp:243] Iteration 41600, loss = 0.00206493
I0521 11:42:14.197541  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00206482 (* 1 = 0.00206482 loss)
I0521 11:42:14.197548  3675 sgd_solver.cpp:138] Iteration 41600, lr = 6.25e-06
I0521 11:42:17.721382  3675 solver.cpp:243] Iteration 41620, loss = 0.00167913
I0521 11:42:17.721570  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00167902 (* 1 = 0.00167902 loss)
I0521 11:42:17.721578  3675 sgd_solver.cpp:138] Iteration 41620, lr = 6.25e-06
I0521 11:42:21.244529  3675 solver.cpp:243] Iteration 41640, loss = 0.0029425
I0521 11:42:21.244561  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00294239 (* 1 = 0.00294239 loss)
I0521 11:42:21.244567  3675 sgd_solver.cpp:138] Iteration 41640, lr = 6.25e-06
I0521 11:42:24.763764  3675 solver.cpp:243] Iteration 41660, loss = 0.00167884
I0521 11:42:24.763797  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00167873 (* 1 = 0.00167873 loss)
I0521 11:42:24.763818  3675 sgd_solver.cpp:138] Iteration 41660, lr = 6.25e-06
I0521 11:42:28.223999  3675 solver.cpp:243] Iteration 41680, loss = 0.00334117
I0521 11:42:28.224031  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00334106 (* 1 = 0.00334106 loss)
I0521 11:42:28.224038  3675 sgd_solver.cpp:138] Iteration 41680, lr = 6.25e-06
I0521 11:42:31.747243  3675 solver.cpp:243] Iteration 41700, loss = 0.00215651
I0521 11:42:31.747275  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0021564 (* 1 = 0.0021564 loss)
I0521 11:42:31.747280  3675 sgd_solver.cpp:138] Iteration 41700, lr = 6.25e-06
I0521 11:42:35.270077  3675 solver.cpp:243] Iteration 41720, loss = 0.00188626
I0521 11:42:35.270109  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00188616 (* 1 = 0.00188616 loss)
I0521 11:42:35.270115  3675 sgd_solver.cpp:138] Iteration 41720, lr = 6.25e-06
I0521 11:42:38.790601  3675 solver.cpp:243] Iteration 41740, loss = 0.00217068
I0521 11:42:38.790633  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00217057 (* 1 = 0.00217057 loss)
I0521 11:42:38.790640  3675 sgd_solver.cpp:138] Iteration 41740, lr = 6.25e-06
I0521 11:42:42.313228  3675 solver.cpp:243] Iteration 41760, loss = 0.0021566
I0521 11:42:42.313261  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00215649 (* 1 = 0.00215649 loss)
I0521 11:42:42.313282  3675 sgd_solver.cpp:138] Iteration 41760, lr = 6.25e-06
I0521 11:42:45.832870  3675 solver.cpp:243] Iteration 41780, loss = 0.00214512
I0521 11:42:45.832902  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00214501 (* 1 = 0.00214501 loss)
I0521 11:42:45.832924  3675 sgd_solver.cpp:138] Iteration 41780, lr = 6.25e-06
I0521 11:42:49.351966  3675 solver.cpp:243] Iteration 41800, loss = 0.00139725
I0521 11:42:49.352097  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00139715 (* 1 = 0.00139715 loss)
I0521 11:42:49.352103  3675 sgd_solver.cpp:138] Iteration 41800, lr = 6.25e-06
I0521 11:42:52.873404  3675 solver.cpp:243] Iteration 41820, loss = 0.00240529
I0521 11:42:52.873435  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00240518 (* 1 = 0.00240518 loss)
I0521 11:42:52.873457  3675 sgd_solver.cpp:138] Iteration 41820, lr = 6.25e-06
I0521 11:42:56.393261  3675 solver.cpp:243] Iteration 41840, loss = 0.00219149
I0521 11:42:56.393293  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00219138 (* 1 = 0.00219138 loss)
I0521 11:42:56.393299  3675 sgd_solver.cpp:138] Iteration 41840, lr = 6.25e-06
I0521 11:42:59.914793  3675 solver.cpp:243] Iteration 41860, loss = 0.00193861
I0521 11:42:59.914824  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0019385 (* 1 = 0.0019385 loss)
I0521 11:42:59.914831  3675 sgd_solver.cpp:138] Iteration 41860, lr = 6.25e-06
I0521 11:43:03.436007  3675 solver.cpp:243] Iteration 41880, loss = 0.00197398
I0521 11:43:03.436038  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00197387 (* 1 = 0.00197387 loss)
I0521 11:43:03.436044  3675 sgd_solver.cpp:138] Iteration 41880, lr = 6.25e-06
I0521 11:43:06.954165  3675 solver.cpp:243] Iteration 41900, loss = 0.00143573
I0521 11:43:06.954196  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00143562 (* 1 = 0.00143562 loss)
I0521 11:43:06.954202  3675 sgd_solver.cpp:138] Iteration 41900, lr = 6.25e-06
I0521 11:43:10.474802  3675 solver.cpp:243] Iteration 41920, loss = 0.00343453
I0521 11:43:10.474835  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00343442 (* 1 = 0.00343442 loss)
I0521 11:43:10.474843  3675 sgd_solver.cpp:138] Iteration 41920, lr = 6.25e-06
I0521 11:43:13.998008  3675 solver.cpp:243] Iteration 41940, loss = 0.00259557
I0521 11:43:13.998040  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00259546 (* 1 = 0.00259546 loss)
I0521 11:43:13.998045  3675 sgd_solver.cpp:138] Iteration 41940, lr = 6.25e-06
I0521 11:43:17.520592  3675 solver.cpp:243] Iteration 41960, loss = 0.00142412
I0521 11:43:17.520622  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00142402 (* 1 = 0.00142402 loss)
I0521 11:43:17.520629  3675 sgd_solver.cpp:138] Iteration 41960, lr = 6.25e-06
I0521 11:43:21.038298  3675 solver.cpp:243] Iteration 41980, loss = 0.00254882
I0521 11:43:21.038511  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00254872 (* 1 = 0.00254872 loss)
I0521 11:43:21.038520  3675 sgd_solver.cpp:138] Iteration 41980, lr = 6.25e-06
I0521 11:43:24.427599  3675 solver.cpp:596] Snapshotting to binary proto file models/LPR/lpr_resnet_lstm_iter_42000.caffemodel
I0521 11:43:24.458660  3675 sgd_solver.cpp:307] Snapshotting solver state to binary proto file models/LPR/lpr_resnet_lstm_iter_42000.solverstate
I0521 11:43:24.474874  3675 solver.cpp:358] Iteration 42000, Testing net (#0)
I0521 11:43:29.211292  3675 solver.cpp:425]     Test net output #0: acc = 1
I0521 11:43:29.211318  3675 solver.cpp:425]     Test net output #1: acc = 1
I0521 11:43:29.211325  3675 solver.cpp:425]     Test net output #2: ctcloss = 0.000662843 (* 1 = 0.000662843 loss)
I0521 11:43:29.346271  3675 solver.cpp:243] Iteration 42000, loss = 0.0019082
I0521 11:43:29.346302  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00190809 (* 1 = 0.00190809 loss)
I0521 11:43:29.346308  3675 sgd_solver.cpp:138] Iteration 42000, lr = 6.25e-06
I0521 11:43:32.866731  3675 solver.cpp:243] Iteration 42020, loss = 0.00302156
I0521 11:43:32.866763  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00302145 (* 1 = 0.00302145 loss)
I0521 11:43:32.866770  3675 sgd_solver.cpp:138] Iteration 42020, lr = 6.25e-06
I0521 11:43:36.386479  3675 solver.cpp:243] Iteration 42040, loss = 0.00178102
I0521 11:43:36.386510  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00178091 (* 1 = 0.00178091 loss)
I0521 11:43:36.386517  3675 sgd_solver.cpp:138] Iteration 42040, lr = 6.25e-06
I0521 11:43:39.905669  3675 solver.cpp:243] Iteration 42060, loss = 0.00193171
I0521 11:43:39.905704  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0019316 (* 1 = 0.0019316 loss)
I0521 11:43:39.905709  3675 sgd_solver.cpp:138] Iteration 42060, lr = 6.25e-06
I0521 11:43:43.423987  3675 solver.cpp:243] Iteration 42080, loss = 0.00215316
I0521 11:43:43.424017  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00215305 (* 1 = 0.00215305 loss)
I0521 11:43:43.424023  3675 sgd_solver.cpp:138] Iteration 42080, lr = 6.25e-06
I0521 11:43:46.943181  3675 solver.cpp:243] Iteration 42100, loss = 0.00280972
I0521 11:43:46.943212  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00280961 (* 1 = 0.00280961 loss)
I0521 11:43:46.943218  3675 sgd_solver.cpp:138] Iteration 42100, lr = 6.25e-06
I0521 11:43:50.462411  3675 solver.cpp:243] Iteration 42120, loss = 0.00156955
I0521 11:43:50.462445  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00156944 (* 1 = 0.00156944 loss)
I0521 11:43:50.462450  3675 sgd_solver.cpp:138] Iteration 42120, lr = 6.25e-06
I0521 11:43:53.980161  3675 solver.cpp:243] Iteration 42140, loss = 0.00230885
I0521 11:43:53.980309  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00230874 (* 1 = 0.00230874 loss)
I0521 11:43:53.980317  3675 sgd_solver.cpp:138] Iteration 42140, lr = 6.25e-06
I0521 11:43:57.502858  3675 solver.cpp:243] Iteration 42160, loss = 0.00138556
I0521 11:43:57.502889  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00138545 (* 1 = 0.00138545 loss)
I0521 11:43:57.502895  3675 sgd_solver.cpp:138] Iteration 42160, lr = 6.25e-06
I0521 11:44:01.025648  3675 solver.cpp:243] Iteration 42180, loss = 0.00173299
I0521 11:44:01.025682  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00173288 (* 1 = 0.00173288 loss)
I0521 11:44:01.025704  3675 sgd_solver.cpp:138] Iteration 42180, lr = 6.25e-06
I0521 11:44:04.543964  3675 solver.cpp:243] Iteration 42200, loss = 0.0018154
I0521 11:44:04.543995  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00181529 (* 1 = 0.00181529 loss)
I0521 11:44:04.544000  3675 sgd_solver.cpp:138] Iteration 42200, lr = 6.25e-06
I0521 11:44:08.064594  3675 solver.cpp:243] Iteration 42220, loss = 0.0027087
I0521 11:44:08.064623  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00270859 (* 1 = 0.00270859 loss)
I0521 11:44:08.064630  3675 sgd_solver.cpp:138] Iteration 42220, lr = 6.25e-06
I0521 11:44:11.587154  3675 solver.cpp:243] Iteration 42240, loss = 0.00302661
I0521 11:44:11.587186  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0030265 (* 1 = 0.0030265 loss)
I0521 11:44:11.587193  3675 sgd_solver.cpp:138] Iteration 42240, lr = 6.25e-06
I0521 11:44:15.106925  3675 solver.cpp:243] Iteration 42260, loss = 0.00147946
I0521 11:44:15.106957  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00147935 (* 1 = 0.00147935 loss)
I0521 11:44:15.106963  3675 sgd_solver.cpp:138] Iteration 42260, lr = 6.25e-06
I0521 11:44:18.633666  3675 solver.cpp:243] Iteration 42280, loss = 0.00132291
I0521 11:44:18.633697  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0013228 (* 1 = 0.0013228 loss)
I0521 11:44:18.633703  3675 sgd_solver.cpp:138] Iteration 42280, lr = 6.25e-06
I0521 11:44:22.152580  3675 solver.cpp:243] Iteration 42300, loss = 0.00177917
I0521 11:44:22.152611  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00177907 (* 1 = 0.00177907 loss)
I0521 11:44:22.152618  3675 sgd_solver.cpp:138] Iteration 42300, lr = 6.25e-06
I0521 11:44:25.670614  3675 solver.cpp:243] Iteration 42320, loss = 0.00182249
I0521 11:44:25.670734  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00182239 (* 1 = 0.00182239 loss)
I0521 11:44:25.670742  3675 sgd_solver.cpp:138] Iteration 42320, lr = 6.25e-06
I0521 11:44:29.192188  3675 solver.cpp:243] Iteration 42340, loss = 0.00155416
I0521 11:44:29.192217  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00155406 (* 1 = 0.00155406 loss)
I0521 11:44:29.192224  3675 sgd_solver.cpp:138] Iteration 42340, lr = 6.25e-06
I0521 11:44:32.716696  3675 solver.cpp:243] Iteration 42360, loss = 0.00288224
I0521 11:44:32.716727  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00288213 (* 1 = 0.00288213 loss)
I0521 11:44:32.716733  3675 sgd_solver.cpp:138] Iteration 42360, lr = 6.25e-06
I0521 11:44:36.231326  3675 solver.cpp:243] Iteration 42380, loss = 0.0016726
I0521 11:44:36.231357  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00167249 (* 1 = 0.00167249 loss)
I0521 11:44:36.231364  3675 sgd_solver.cpp:138] Iteration 42380, lr = 6.25e-06
I0521 11:44:39.747486  3675 solver.cpp:243] Iteration 42400, loss = 0.0025459
I0521 11:44:39.747516  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00254579 (* 1 = 0.00254579 loss)
I0521 11:44:39.747522  3675 sgd_solver.cpp:138] Iteration 42400, lr = 6.25e-06
I0521 11:44:43.266474  3675 solver.cpp:243] Iteration 42420, loss = 0.00237532
I0521 11:44:43.266503  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00237521 (* 1 = 0.00237521 loss)
I0521 11:44:43.266510  3675 sgd_solver.cpp:138] Iteration 42420, lr = 6.25e-06
I0521 11:44:46.786049  3675 solver.cpp:243] Iteration 42440, loss = 0.00213084
I0521 11:44:46.786078  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00213073 (* 1 = 0.00213073 loss)
I0521 11:44:46.786084  3675 sgd_solver.cpp:138] Iteration 42440, lr = 6.25e-06
I0521 11:44:50.306800  3675 solver.cpp:243] Iteration 42460, loss = 0.00218378
I0521 11:44:50.306831  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00218367 (* 1 = 0.00218367 loss)
I0521 11:44:50.306854  3675 sgd_solver.cpp:138] Iteration 42460, lr = 6.25e-06
I0521 11:44:53.823254  3675 solver.cpp:243] Iteration 42480, loss = 0.00299639
I0521 11:44:53.823285  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00299628 (* 1 = 0.00299628 loss)
I0521 11:44:53.823292  3675 sgd_solver.cpp:138] Iteration 42480, lr = 6.25e-06
I0521 11:44:57.336827  3675 solver.cpp:243] Iteration 42500, loss = 0.00213194
I0521 11:44:57.336993  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00213183 (* 1 = 0.00213183 loss)
I0521 11:44:57.337002  3675 sgd_solver.cpp:138] Iteration 42500, lr = 6.25e-06
I0521 11:45:00.858748  3675 solver.cpp:243] Iteration 42520, loss = 0.00191001
I0521 11:45:00.858778  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0019099 (* 1 = 0.0019099 loss)
I0521 11:45:00.858785  3675 sgd_solver.cpp:138] Iteration 42520, lr = 6.25e-06
I0521 11:45:04.375516  3675 solver.cpp:243] Iteration 42540, loss = 0.00390995
I0521 11:45:04.375547  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00390984 (* 1 = 0.00390984 loss)
I0521 11:45:04.375552  3675 sgd_solver.cpp:138] Iteration 42540, lr = 6.25e-06
I0521 11:45:07.889462  3675 solver.cpp:243] Iteration 42560, loss = 0.00222644
I0521 11:45:07.889492  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00222633 (* 1 = 0.00222633 loss)
I0521 11:45:07.889498  3675 sgd_solver.cpp:138] Iteration 42560, lr = 6.25e-06
I0521 11:45:11.413987  3675 solver.cpp:243] Iteration 42580, loss = 0.00177837
I0521 11:45:11.414018  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00177826 (* 1 = 0.00177826 loss)
I0521 11:45:11.414026  3675 sgd_solver.cpp:138] Iteration 42580, lr = 6.25e-06
I0521 11:45:14.934648  3675 solver.cpp:243] Iteration 42600, loss = 0.0020926
I0521 11:45:14.934679  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00209249 (* 1 = 0.00209249 loss)
I0521 11:45:14.934684  3675 sgd_solver.cpp:138] Iteration 42600, lr = 6.25e-06
I0521 11:45:18.456727  3675 solver.cpp:243] Iteration 42620, loss = 0.00157784
I0521 11:45:18.456756  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00157773 (* 1 = 0.00157773 loss)
I0521 11:45:18.456763  3675 sgd_solver.cpp:138] Iteration 42620, lr = 6.25e-06
I0521 11:45:21.976855  3675 solver.cpp:243] Iteration 42640, loss = 0.00182498
I0521 11:45:21.976884  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00182487 (* 1 = 0.00182487 loss)
I0521 11:45:21.976905  3675 sgd_solver.cpp:138] Iteration 42640, lr = 6.25e-06
I0521 11:45:25.492990  3675 solver.cpp:243] Iteration 42660, loss = 0.00244469
I0521 11:45:25.493019  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00244458 (* 1 = 0.00244458 loss)
I0521 11:45:25.493026  3675 sgd_solver.cpp:138] Iteration 42660, lr = 6.25e-06
I0521 11:45:29.014888  3675 solver.cpp:243] Iteration 42680, loss = 0.00141624
I0521 11:45:29.015035  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00141613 (* 1 = 0.00141613 loss)
I0521 11:45:29.015043  3675 sgd_solver.cpp:138] Iteration 42680, lr = 6.25e-06
I0521 11:45:32.534106  3675 solver.cpp:243] Iteration 42700, loss = 0.0020762
I0521 11:45:32.534137  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0020761 (* 1 = 0.0020761 loss)
I0521 11:45:32.534142  3675 sgd_solver.cpp:138] Iteration 42700, lr = 6.25e-06
I0521 11:45:36.052382  3675 solver.cpp:243] Iteration 42720, loss = 0.00165738
I0521 11:45:36.052412  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00165727 (* 1 = 0.00165727 loss)
I0521 11:45:36.052418  3675 sgd_solver.cpp:138] Iteration 42720, lr = 6.25e-06
I0521 11:45:39.570544  3675 solver.cpp:243] Iteration 42740, loss = 0.00209618
I0521 11:45:39.570576  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00209608 (* 1 = 0.00209608 loss)
I0521 11:45:39.570582  3675 sgd_solver.cpp:138] Iteration 42740, lr = 6.25e-06
I0521 11:45:43.093011  3675 solver.cpp:243] Iteration 42760, loss = 0.00203011
I0521 11:45:43.093044  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00203 (* 1 = 0.00203 loss)
I0521 11:45:43.093051  3675 sgd_solver.cpp:138] Iteration 42760, lr = 6.25e-06
I0521 11:45:46.610816  3675 solver.cpp:243] Iteration 42780, loss = 0.00149704
I0521 11:45:46.610846  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00149693 (* 1 = 0.00149693 loss)
I0521 11:45:46.610852  3675 sgd_solver.cpp:138] Iteration 42780, lr = 6.25e-06
I0521 11:45:50.126154  3675 solver.cpp:243] Iteration 42800, loss = 0.00193294
I0521 11:45:50.126185  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00193283 (* 1 = 0.00193283 loss)
I0521 11:45:50.126191  3675 sgd_solver.cpp:138] Iteration 42800, lr = 6.25e-06
I0521 11:45:53.644714  3675 solver.cpp:243] Iteration 42820, loss = 0.00192224
I0521 11:45:53.644745  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00192213 (* 1 = 0.00192213 loss)
I0521 11:45:53.644752  3675 sgd_solver.cpp:138] Iteration 42820, lr = 6.25e-06
I0521 11:45:57.166038  3675 solver.cpp:243] Iteration 42840, loss = 0.00172551
I0521 11:45:57.166067  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0017254 (* 1 = 0.0017254 loss)
I0521 11:45:57.166074  3675 sgd_solver.cpp:138] Iteration 42840, lr = 6.25e-06
I0521 11:46:00.688359  3675 solver.cpp:243] Iteration 42860, loss = 0.00165074
I0521 11:46:00.688539  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00165063 (* 1 = 0.00165063 loss)
I0521 11:46:00.688549  3675 sgd_solver.cpp:138] Iteration 42860, lr = 6.25e-06
I0521 11:46:04.215320  3675 solver.cpp:243] Iteration 42880, loss = 0.00225269
I0521 11:46:04.215353  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00225258 (* 1 = 0.00225258 loss)
I0521 11:46:04.215359  3675 sgd_solver.cpp:138] Iteration 42880, lr = 6.25e-06
I0521 11:46:07.734313  3675 solver.cpp:243] Iteration 42900, loss = 0.0015025
I0521 11:46:07.734345  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00150239 (* 1 = 0.00150239 loss)
I0521 11:46:07.734352  3675 sgd_solver.cpp:138] Iteration 42900, lr = 6.25e-06
I0521 11:46:11.248628  3675 solver.cpp:243] Iteration 42920, loss = 0.00207493
I0521 11:46:11.248661  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00207482 (* 1 = 0.00207482 loss)
I0521 11:46:11.248667  3675 sgd_solver.cpp:138] Iteration 42920, lr = 6.25e-06
I0521 11:46:14.765579  3675 solver.cpp:243] Iteration 42940, loss = 0.00187374
I0521 11:46:14.765610  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00187364 (* 1 = 0.00187364 loss)
I0521 11:46:14.765617  3675 sgd_solver.cpp:138] Iteration 42940, lr = 6.25e-06
I0521 11:46:18.285600  3675 solver.cpp:243] Iteration 42960, loss = 0.00198034
I0521 11:46:18.285632  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00198023 (* 1 = 0.00198023 loss)
I0521 11:46:18.285640  3675 sgd_solver.cpp:138] Iteration 42960, lr = 6.25e-06
I0521 11:46:21.737375  3675 solver.cpp:243] Iteration 42980, loss = 0.00223723
I0521 11:46:21.737406  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00223712 (* 1 = 0.00223712 loss)
I0521 11:46:21.737412  3675 sgd_solver.cpp:138] Iteration 42980, lr = 6.25e-06
I0521 11:46:25.132170  3675 solver.cpp:358] Iteration 43000, Testing net (#0)
I0521 11:46:29.865186  3675 solver.cpp:425]     Test net output #0: acc = 1
I0521 11:46:29.865212  3675 solver.cpp:425]     Test net output #1: acc = 1
I0521 11:46:29.865236  3675 solver.cpp:425]     Test net output #2: ctcloss = 0.000656824 (* 1 = 0.000656824 loss)
I0521 11:46:30.001072  3675 solver.cpp:243] Iteration 43000, loss = 0.00222937
I0521 11:46:30.001102  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00222926 (* 1 = 0.00222926 loss)
I0521 11:46:30.001111  3675 sgd_solver.cpp:138] Iteration 43000, lr = 6.25e-06
I0521 11:46:33.519623  3675 solver.cpp:243] Iteration 43020, loss = 0.00220354
I0521 11:46:33.519798  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00220343 (* 1 = 0.00220343 loss)
I0521 11:46:33.519805  3675 sgd_solver.cpp:138] Iteration 43020, lr = 6.25e-06
I0521 11:46:37.031674  3675 solver.cpp:243] Iteration 43040, loss = 0.00137926
I0521 11:46:37.031703  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00137915 (* 1 = 0.00137915 loss)
I0521 11:46:37.031709  3675 sgd_solver.cpp:138] Iteration 43040, lr = 6.25e-06
I0521 11:46:40.549157  3675 solver.cpp:243] Iteration 43060, loss = 0.00155522
I0521 11:46:40.549187  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00155511 (* 1 = 0.00155511 loss)
I0521 11:46:40.549193  3675 sgd_solver.cpp:138] Iteration 43060, lr = 6.25e-06
I0521 11:46:44.067574  3675 solver.cpp:243] Iteration 43080, loss = 0.00267613
I0521 11:46:44.067605  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00267602 (* 1 = 0.00267602 loss)
I0521 11:46:44.067611  3675 sgd_solver.cpp:138] Iteration 43080, lr = 6.25e-06
I0521 11:46:47.587155  3675 solver.cpp:243] Iteration 43100, loss = 0.00185072
I0521 11:46:47.587184  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00185062 (* 1 = 0.00185062 loss)
I0521 11:46:47.587206  3675 sgd_solver.cpp:138] Iteration 43100, lr = 6.25e-06
I0521 11:46:51.103420  3675 solver.cpp:243] Iteration 43120, loss = 0.00130778
I0521 11:46:51.103451  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00130768 (* 1 = 0.00130768 loss)
I0521 11:46:51.103456  3675 sgd_solver.cpp:138] Iteration 43120, lr = 6.25e-06
I0521 11:46:54.615991  3675 solver.cpp:243] Iteration 43140, loss = 0.001931
I0521 11:46:54.616021  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00193089 (* 1 = 0.00193089 loss)
I0521 11:46:54.616027  3675 sgd_solver.cpp:138] Iteration 43140, lr = 6.25e-06
I0521 11:46:58.127657  3675 solver.cpp:243] Iteration 43160, loss = 0.00159603
I0521 11:46:58.127688  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00159593 (* 1 = 0.00159593 loss)
I0521 11:46:58.127709  3675 sgd_solver.cpp:138] Iteration 43160, lr = 6.25e-06
I0521 11:47:01.645203  3675 solver.cpp:243] Iteration 43180, loss = 0.00223348
I0521 11:47:01.645236  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00223338 (* 1 = 0.00223338 loss)
I0521 11:47:01.645242  3675 sgd_solver.cpp:138] Iteration 43180, lr = 6.25e-06
I0521 11:47:05.169842  3675 solver.cpp:243] Iteration 43200, loss = 0.00163754
I0521 11:47:05.169975  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00163743 (* 1 = 0.00163743 loss)
I0521 11:47:05.169983  3675 sgd_solver.cpp:138] Iteration 43200, lr = 6.25e-06
I0521 11:47:08.689661  3675 solver.cpp:243] Iteration 43220, loss = 0.00168673
I0521 11:47:08.689690  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00168662 (* 1 = 0.00168662 loss)
I0521 11:47:08.689697  3675 sgd_solver.cpp:138] Iteration 43220, lr = 6.25e-06
I0521 11:47:12.205340  3675 solver.cpp:243] Iteration 43240, loss = 0.00196235
I0521 11:47:12.205372  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00196224 (* 1 = 0.00196224 loss)
I0521 11:47:12.205379  3675 sgd_solver.cpp:138] Iteration 43240, lr = 6.25e-06
I0521 11:47:15.725608  3675 solver.cpp:243] Iteration 43260, loss = 0.00135792
I0521 11:47:15.725641  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00135782 (* 1 = 0.00135782 loss)
I0521 11:47:15.725646  3675 sgd_solver.cpp:138] Iteration 43260, lr = 6.25e-06
I0521 11:47:19.245834  3675 solver.cpp:243] Iteration 43280, loss = 0.00282235
I0521 11:47:19.245865  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00282224 (* 1 = 0.00282224 loss)
I0521 11:47:19.245887  3675 sgd_solver.cpp:138] Iteration 43280, lr = 6.25e-06
I0521 11:47:22.760499  3675 solver.cpp:243] Iteration 43300, loss = 0.00205403
I0521 11:47:22.760530  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00205392 (* 1 = 0.00205392 loss)
I0521 11:47:22.760552  3675 sgd_solver.cpp:138] Iteration 43300, lr = 6.25e-06
I0521 11:47:26.277704  3675 solver.cpp:243] Iteration 43320, loss = 0.00187434
I0521 11:47:26.277736  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00187423 (* 1 = 0.00187423 loss)
I0521 11:47:26.277742  3675 sgd_solver.cpp:138] Iteration 43320, lr = 6.25e-06
I0521 11:47:29.792232  3675 solver.cpp:243] Iteration 43340, loss = 0.00188469
I0521 11:47:29.792263  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00188459 (* 1 = 0.00188459 loss)
I0521 11:47:29.792268  3675 sgd_solver.cpp:138] Iteration 43340, lr = 6.25e-06
I0521 11:47:33.307065  3675 solver.cpp:243] Iteration 43360, loss = 0.001314
I0521 11:47:33.307096  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00131389 (* 1 = 0.00131389 loss)
I0521 11:47:33.307101  3675 sgd_solver.cpp:138] Iteration 43360, lr = 6.25e-06
I0521 11:47:36.825631  3675 solver.cpp:243] Iteration 43380, loss = 0.00167462
I0521 11:47:36.825762  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00167451 (* 1 = 0.00167451 loss)
I0521 11:47:36.825772  3675 sgd_solver.cpp:138] Iteration 43380, lr = 6.25e-06
I0521 11:47:40.341843  3675 solver.cpp:243] Iteration 43400, loss = 0.00139825
I0521 11:47:40.341873  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00139815 (* 1 = 0.00139815 loss)
I0521 11:47:40.341879  3675 sgd_solver.cpp:138] Iteration 43400, lr = 6.25e-06
I0521 11:47:43.862779  3675 solver.cpp:243] Iteration 43420, loss = 0.00275765
I0521 11:47:43.862810  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00275755 (* 1 = 0.00275755 loss)
I0521 11:47:43.862816  3675 sgd_solver.cpp:138] Iteration 43420, lr = 6.25e-06
I0521 11:47:47.382303  3675 solver.cpp:243] Iteration 43440, loss = 0.00153333
I0521 11:47:47.382334  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00153323 (* 1 = 0.00153323 loss)
I0521 11:47:47.382340  3675 sgd_solver.cpp:138] Iteration 43440, lr = 6.25e-06
I0521 11:47:50.903915  3675 solver.cpp:243] Iteration 43460, loss = 0.00241727
I0521 11:47:50.903945  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00241716 (* 1 = 0.00241716 loss)
I0521 11:47:50.903950  3675 sgd_solver.cpp:138] Iteration 43460, lr = 6.25e-06
I0521 11:47:54.416735  3675 solver.cpp:243] Iteration 43480, loss = 0.00192008
I0521 11:47:54.416767  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00191998 (* 1 = 0.00191998 loss)
I0521 11:47:54.416774  3675 sgd_solver.cpp:138] Iteration 43480, lr = 6.25e-06
I0521 11:47:57.931561  3675 solver.cpp:243] Iteration 43500, loss = 0.00197835
I0521 11:47:57.931591  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00197824 (* 1 = 0.00197824 loss)
I0521 11:47:57.931597  3675 sgd_solver.cpp:138] Iteration 43500, lr = 6.25e-06
I0521 11:48:01.450904  3675 solver.cpp:243] Iteration 43520, loss = 0.00192808
I0521 11:48:01.450953  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00192798 (* 1 = 0.00192798 loss)
I0521 11:48:01.450960  3675 sgd_solver.cpp:138] Iteration 43520, lr = 6.25e-06
I0521 11:48:04.974515  3675 solver.cpp:243] Iteration 43540, loss = 0.00177558
I0521 11:48:04.974545  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00177547 (* 1 = 0.00177547 loss)
I0521 11:48:04.974551  3675 sgd_solver.cpp:138] Iteration 43540, lr = 6.25e-06
I0521 11:48:08.488943  3675 solver.cpp:243] Iteration 43560, loss = 0.00157873
I0521 11:48:08.489055  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00157862 (* 1 = 0.00157862 loss)
I0521 11:48:08.489063  3675 sgd_solver.cpp:138] Iteration 43560, lr = 6.25e-06
I0521 11:48:12.000568  3675 solver.cpp:243] Iteration 43580, loss = 0.00246959
I0521 11:48:12.000599  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00246949 (* 1 = 0.00246949 loss)
I0521 11:48:12.000607  3675 sgd_solver.cpp:138] Iteration 43580, lr = 6.25e-06
I0521 11:48:15.516332  3675 solver.cpp:243] Iteration 43600, loss = 0.00127525
I0521 11:48:15.516362  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00127515 (* 1 = 0.00127515 loss)
I0521 11:48:15.516368  3675 sgd_solver.cpp:138] Iteration 43600, lr = 6.25e-06
I0521 11:48:19.033155  3675 solver.cpp:243] Iteration 43620, loss = 0.00155677
I0521 11:48:19.033185  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00155666 (* 1 = 0.00155666 loss)
I0521 11:48:19.033206  3675 sgd_solver.cpp:138] Iteration 43620, lr = 6.25e-06
I0521 11:48:22.544389  3675 solver.cpp:243] Iteration 43640, loss = 0.00163996
I0521 11:48:22.544420  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00163986 (* 1 = 0.00163986 loss)
I0521 11:48:22.544425  3675 sgd_solver.cpp:138] Iteration 43640, lr = 6.25e-06
I0521 11:48:26.062790  3675 solver.cpp:243] Iteration 43660, loss = 0.00216428
I0521 11:48:26.062821  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00216418 (* 1 = 0.00216418 loss)
I0521 11:48:26.062827  3675 sgd_solver.cpp:138] Iteration 43660, lr = 6.25e-06
I0521 11:48:29.577864  3675 solver.cpp:243] Iteration 43680, loss = 0.00542914
I0521 11:48:29.577893  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00542904 (* 1 = 0.00542904 loss)
I0521 11:48:29.577898  3675 sgd_solver.cpp:138] Iteration 43680, lr = 6.25e-06
I0521 11:48:33.092651  3675 solver.cpp:243] Iteration 43700, loss = 0.00220454
I0521 11:48:33.092681  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00220444 (* 1 = 0.00220444 loss)
I0521 11:48:33.092687  3675 sgd_solver.cpp:138] Iteration 43700, lr = 6.25e-06
I0521 11:48:36.611081  3675 solver.cpp:243] Iteration 43720, loss = 0.00230857
I0521 11:48:36.611111  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00230846 (* 1 = 0.00230846 loss)
I0521 11:48:36.611132  3675 sgd_solver.cpp:138] Iteration 43720, lr = 6.25e-06
I0521 11:48:40.120277  3675 solver.cpp:243] Iteration 43740, loss = 0.00247469
I0521 11:48:40.120456  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00247458 (* 1 = 0.00247458 loss)
I0521 11:48:40.120463  3675 sgd_solver.cpp:138] Iteration 43740, lr = 6.25e-06
I0521 11:48:43.637126  3675 solver.cpp:243] Iteration 43760, loss = 0.00189418
I0521 11:48:43.637157  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00189407 (* 1 = 0.00189407 loss)
I0521 11:48:43.637163  3675 sgd_solver.cpp:138] Iteration 43760, lr = 6.25e-06
I0521 11:48:47.153566  3675 solver.cpp:243] Iteration 43780, loss = 0.00242362
I0521 11:48:47.153596  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00242351 (* 1 = 0.00242351 loss)
I0521 11:48:47.153602  3675 sgd_solver.cpp:138] Iteration 43780, lr = 6.25e-06
I0521 11:48:50.667145  3675 solver.cpp:243] Iteration 43800, loss = 0.002049
I0521 11:48:50.667176  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0020489 (* 1 = 0.0020489 loss)
I0521 11:48:50.667182  3675 sgd_solver.cpp:138] Iteration 43800, lr = 6.25e-06
I0521 11:48:54.181075  3675 solver.cpp:243] Iteration 43820, loss = 0.00199519
I0521 11:48:54.181107  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00199509 (* 1 = 0.00199509 loss)
I0521 11:48:54.181113  3675 sgd_solver.cpp:138] Iteration 43820, lr = 6.25e-06
I0521 11:48:57.700326  3675 solver.cpp:243] Iteration 43840, loss = 0.00335832
I0521 11:48:57.700359  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00335822 (* 1 = 0.00335822 loss)
I0521 11:48:57.700366  3675 sgd_solver.cpp:138] Iteration 43840, lr = 6.25e-06
I0521 11:49:01.217239  3675 solver.cpp:243] Iteration 43860, loss = 0.00203768
I0521 11:49:01.217269  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00203757 (* 1 = 0.00203757 loss)
I0521 11:49:01.217291  3675 sgd_solver.cpp:138] Iteration 43860, lr = 6.25e-06
I0521 11:49:04.729264  3675 solver.cpp:243] Iteration 43880, loss = 0.00177615
I0521 11:49:04.729296  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00177604 (* 1 = 0.00177604 loss)
I0521 11:49:04.729302  3675 sgd_solver.cpp:138] Iteration 43880, lr = 6.25e-06
I0521 11:49:08.247776  3675 solver.cpp:243] Iteration 43900, loss = 0.00198907
I0521 11:49:08.247807  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00198896 (* 1 = 0.00198896 loss)
I0521 11:49:08.247812  3675 sgd_solver.cpp:138] Iteration 43900, lr = 6.25e-06
I0521 11:49:11.762832  3675 solver.cpp:243] Iteration 43920, loss = 0.00182311
I0521 11:49:11.763002  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.001823 (* 1 = 0.001823 loss)
I0521 11:49:11.763011  3675 sgd_solver.cpp:138] Iteration 43920, lr = 6.25e-06
I0521 11:49:15.277792  3675 solver.cpp:243] Iteration 43940, loss = 0.00157805
I0521 11:49:15.277822  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00157795 (* 1 = 0.00157795 loss)
I0521 11:49:15.277827  3675 sgd_solver.cpp:138] Iteration 43940, lr = 6.25e-06
I0521 11:49:18.795480  3675 solver.cpp:243] Iteration 43960, loss = 0.00153608
I0521 11:49:18.795509  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00153597 (* 1 = 0.00153597 loss)
I0521 11:49:18.795516  3675 sgd_solver.cpp:138] Iteration 43960, lr = 6.25e-06
I0521 11:49:22.306951  3675 solver.cpp:243] Iteration 43980, loss = 0.00191202
I0521 11:49:22.306982  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00191191 (* 1 = 0.00191191 loss)
I0521 11:49:22.307003  3675 sgd_solver.cpp:138] Iteration 43980, lr = 6.25e-06
I0521 11:49:25.692665  3675 solver.cpp:596] Snapshotting to binary proto file models/LPR/lpr_resnet_lstm_iter_44000.caffemodel
I0521 11:49:25.721567  3675 sgd_solver.cpp:307] Snapshotting solver state to binary proto file models/LPR/lpr_resnet_lstm_iter_44000.solverstate
I0521 11:49:25.737715  3675 solver.cpp:358] Iteration 44000, Testing net (#0)
I0521 11:49:30.470829  3675 solver.cpp:425]     Test net output #0: acc = 1
I0521 11:49:30.470855  3675 solver.cpp:425]     Test net output #1: acc = 1
I0521 11:49:30.470862  3675 solver.cpp:425]     Test net output #2: ctcloss = 0.000655252 (* 1 = 0.000655252 loss)
I0521 11:49:30.605135  3675 solver.cpp:243] Iteration 44000, loss = 0.00205959
I0521 11:49:30.605166  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00205948 (* 1 = 0.00205948 loss)
I0521 11:49:30.605172  3675 sgd_solver.cpp:138] Iteration 44000, lr = 6.25e-06
I0521 11:49:34.121556  3675 solver.cpp:243] Iteration 44020, loss = 0.00217407
I0521 11:49:34.121584  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00217396 (* 1 = 0.00217396 loss)
I0521 11:49:34.121590  3675 sgd_solver.cpp:138] Iteration 44020, lr = 6.25e-06
I0521 11:49:37.636591  3675 solver.cpp:243] Iteration 44040, loss = 0.00954437
I0521 11:49:37.636622  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00954427 (* 1 = 0.00954427 loss)
I0521 11:49:37.636627  3675 sgd_solver.cpp:138] Iteration 44040, lr = 6.25e-06
I0521 11:49:41.153167  3675 solver.cpp:243] Iteration 44060, loss = 0.00166512
I0521 11:49:41.153199  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00166502 (* 1 = 0.00166502 loss)
I0521 11:49:41.153205  3675 sgd_solver.cpp:138] Iteration 44060, lr = 6.25e-06
I0521 11:49:44.670588  3675 solver.cpp:243] Iteration 44080, loss = 0.00198925
I0521 11:49:44.670712  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00198915 (* 1 = 0.00198915 loss)
I0521 11:49:44.670719  3675 sgd_solver.cpp:138] Iteration 44080, lr = 6.25e-06
I0521 11:49:48.184917  3675 solver.cpp:243] Iteration 44100, loss = 0.00193597
I0521 11:49:48.184949  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00193587 (* 1 = 0.00193587 loss)
I0521 11:49:48.184957  3675 sgd_solver.cpp:138] Iteration 44100, lr = 6.25e-06
I0521 11:49:51.691882  3675 solver.cpp:243] Iteration 44120, loss = 0.00304646
I0521 11:49:51.691912  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00304636 (* 1 = 0.00304636 loss)
I0521 11:49:51.691918  3675 sgd_solver.cpp:138] Iteration 44120, lr = 6.25e-06
I0521 11:49:55.209772  3675 solver.cpp:243] Iteration 44140, loss = 0.00238736
I0521 11:49:55.209803  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00238725 (* 1 = 0.00238725 loss)
I0521 11:49:55.209825  3675 sgd_solver.cpp:138] Iteration 44140, lr = 6.25e-06
I0521 11:49:58.724783  3675 solver.cpp:243] Iteration 44160, loss = 0.00192662
I0521 11:49:58.724813  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00192651 (* 1 = 0.00192651 loss)
I0521 11:49:58.724835  3675 sgd_solver.cpp:138] Iteration 44160, lr = 6.25e-06
I0521 11:50:02.241495  3675 solver.cpp:243] Iteration 44180, loss = 0.00202844
I0521 11:50:02.241526  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00202833 (* 1 = 0.00202833 loss)
I0521 11:50:02.241549  3675 sgd_solver.cpp:138] Iteration 44180, lr = 6.25e-06
I0521 11:50:05.754142  3675 solver.cpp:243] Iteration 44200, loss = 0.00146009
I0521 11:50:05.754173  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00145999 (* 1 = 0.00145999 loss)
I0521 11:50:05.754179  3675 sgd_solver.cpp:138] Iteration 44200, lr = 6.25e-06
I0521 11:50:09.273587  3675 solver.cpp:243] Iteration 44220, loss = 0.00169904
I0521 11:50:09.273618  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00169893 (* 1 = 0.00169893 loss)
I0521 11:50:09.273624  3675 sgd_solver.cpp:138] Iteration 44220, lr = 6.25e-06
I0521 11:50:12.787883  3675 solver.cpp:243] Iteration 44240, loss = 0.0020552
I0521 11:50:12.787915  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0020551 (* 1 = 0.0020551 loss)
I0521 11:50:12.787921  3675 sgd_solver.cpp:138] Iteration 44240, lr = 6.25e-06
I0521 11:50:16.300248  3675 solver.cpp:243] Iteration 44260, loss = 0.00214706
I0521 11:50:16.300426  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00214695 (* 1 = 0.00214695 loss)
I0521 11:50:16.300436  3675 sgd_solver.cpp:138] Iteration 44260, lr = 6.25e-06
I0521 11:50:19.744788  3675 solver.cpp:243] Iteration 44280, loss = 0.00148795
I0521 11:50:19.744817  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00148784 (* 1 = 0.00148784 loss)
I0521 11:50:19.744823  3675 sgd_solver.cpp:138] Iteration 44280, lr = 6.25e-06
I0521 11:50:23.262562  3675 solver.cpp:243] Iteration 44300, loss = 0.00172666
I0521 11:50:23.262593  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00172656 (* 1 = 0.00172656 loss)
I0521 11:50:23.262599  3675 sgd_solver.cpp:138] Iteration 44300, lr = 6.25e-06
I0521 11:50:26.777709  3675 solver.cpp:243] Iteration 44320, loss = 0.00222665
I0521 11:50:26.777741  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00222654 (* 1 = 0.00222654 loss)
I0521 11:50:26.777747  3675 sgd_solver.cpp:138] Iteration 44320, lr = 6.25e-06
I0521 11:50:30.294626  3675 solver.cpp:243] Iteration 44340, loss = 0.00224376
I0521 11:50:30.294657  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00224365 (* 1 = 0.00224365 loss)
I0521 11:50:30.294663  3675 sgd_solver.cpp:138] Iteration 44340, lr = 6.25e-06
I0521 11:50:33.809376  3675 solver.cpp:243] Iteration 44360, loss = 0.00211955
I0521 11:50:33.809407  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00211944 (* 1 = 0.00211944 loss)
I0521 11:50:33.809412  3675 sgd_solver.cpp:138] Iteration 44360, lr = 6.25e-06
I0521 11:50:37.321044  3675 solver.cpp:243] Iteration 44380, loss = 0.00149265
I0521 11:50:37.321074  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00149255 (* 1 = 0.00149255 loss)
I0521 11:50:37.321079  3675 sgd_solver.cpp:138] Iteration 44380, lr = 6.25e-06
I0521 11:50:40.831826  3675 solver.cpp:243] Iteration 44400, loss = 0.0016821
I0521 11:50:40.831856  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00168199 (* 1 = 0.00168199 loss)
I0521 11:50:40.831862  3675 sgd_solver.cpp:138] Iteration 44400, lr = 6.25e-06
I0521 11:50:44.344223  3675 solver.cpp:243] Iteration 44420, loss = 0.0023779
I0521 11:50:44.344252  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00237779 (* 1 = 0.00237779 loss)
I0521 11:50:44.344259  3675 sgd_solver.cpp:138] Iteration 44420, lr = 6.25e-06
I0521 11:50:47.856017  3675 solver.cpp:243] Iteration 44440, loss = 0.0014276
I0521 11:50:47.856146  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0014275 (* 1 = 0.0014275 loss)
I0521 11:50:47.856154  3675 sgd_solver.cpp:138] Iteration 44440, lr = 6.25e-06
I0521 11:50:51.365362  3675 solver.cpp:243] Iteration 44460, loss = 0.00164097
I0521 11:50:51.365392  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00164086 (* 1 = 0.00164086 loss)
I0521 11:50:51.365398  3675 sgd_solver.cpp:138] Iteration 44460, lr = 6.25e-06
I0521 11:50:54.882308  3675 solver.cpp:243] Iteration 44480, loss = 0.00166932
I0521 11:50:54.882339  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00166921 (* 1 = 0.00166921 loss)
I0521 11:50:54.882345  3675 sgd_solver.cpp:138] Iteration 44480, lr = 6.25e-06
I0521 11:50:58.394347  3675 solver.cpp:243] Iteration 44500, loss = 0.00205572
I0521 11:50:58.394377  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00205562 (* 1 = 0.00205562 loss)
I0521 11:50:58.394382  3675 sgd_solver.cpp:138] Iteration 44500, lr = 6.25e-06
I0521 11:51:01.911309  3675 solver.cpp:243] Iteration 44520, loss = 0.00194943
I0521 11:51:01.911339  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00194932 (* 1 = 0.00194932 loss)
I0521 11:51:01.911345  3675 sgd_solver.cpp:138] Iteration 44520, lr = 6.25e-06
I0521 11:51:05.429566  3675 solver.cpp:243] Iteration 44540, loss = 0.00184805
I0521 11:51:05.429595  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00184794 (* 1 = 0.00184794 loss)
I0521 11:51:05.429617  3675 sgd_solver.cpp:138] Iteration 44540, lr = 6.25e-06
I0521 11:51:08.940702  3675 solver.cpp:243] Iteration 44560, loss = 0.00240239
I0521 11:51:08.940732  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00240228 (* 1 = 0.00240228 loss)
I0521 11:51:08.940738  3675 sgd_solver.cpp:138] Iteration 44560, lr = 6.25e-06
I0521 11:51:12.455621  3675 solver.cpp:243] Iteration 44580, loss = 0.00173351
I0521 11:51:12.455651  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0017334 (* 1 = 0.0017334 loss)
I0521 11:51:12.455657  3675 sgd_solver.cpp:138] Iteration 44580, lr = 6.25e-06
I0521 11:51:15.969976  3675 solver.cpp:243] Iteration 44600, loss = 0.00172667
I0521 11:51:15.970006  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00172657 (* 1 = 0.00172657 loss)
I0521 11:51:15.970011  3675 sgd_solver.cpp:138] Iteration 44600, lr = 6.25e-06
I0521 11:51:19.486449  3675 solver.cpp:243] Iteration 44620, loss = 0.00194938
I0521 11:51:19.486590  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00194927 (* 1 = 0.00194927 loss)
I0521 11:51:19.486598  3675 sgd_solver.cpp:138] Iteration 44620, lr = 6.25e-06
I0521 11:51:22.992862  3675 solver.cpp:243] Iteration 44640, loss = 0.00162837
I0521 11:51:22.992893  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00162827 (* 1 = 0.00162827 loss)
I0521 11:51:22.992899  3675 sgd_solver.cpp:138] Iteration 44640, lr = 6.25e-06
I0521 11:51:26.506960  3675 solver.cpp:243] Iteration 44660, loss = 0.00289204
I0521 11:51:26.506992  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00289193 (* 1 = 0.00289193 loss)
I0521 11:51:26.506999  3675 sgd_solver.cpp:138] Iteration 44660, lr = 6.25e-06
I0521 11:51:30.024642  3675 solver.cpp:243] Iteration 44680, loss = 0.0043225
I0521 11:51:30.024673  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00432239 (* 1 = 0.00432239 loss)
I0521 11:51:30.024678  3675 sgd_solver.cpp:138] Iteration 44680, lr = 6.25e-06
I0521 11:51:33.538069  3675 solver.cpp:243] Iteration 44700, loss = 0.00185738
I0521 11:51:33.538100  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00185728 (* 1 = 0.00185728 loss)
I0521 11:51:33.538106  3675 sgd_solver.cpp:138] Iteration 44700, lr = 6.25e-06
I0521 11:51:37.053326  3675 solver.cpp:243] Iteration 44720, loss = 0.00224981
I0521 11:51:37.053356  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0022497 (* 1 = 0.0022497 loss)
I0521 11:51:37.053377  3675 sgd_solver.cpp:138] Iteration 44720, lr = 6.25e-06
I0521 11:51:40.569159  3675 solver.cpp:243] Iteration 44740, loss = 0.00214891
I0521 11:51:40.569190  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0021488 (* 1 = 0.0021488 loss)
I0521 11:51:40.569197  3675 sgd_solver.cpp:138] Iteration 44740, lr = 6.25e-06
I0521 11:51:44.082093  3675 solver.cpp:243] Iteration 44760, loss = 0.00167686
I0521 11:51:44.082123  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00167675 (* 1 = 0.00167675 loss)
I0521 11:51:44.082129  3675 sgd_solver.cpp:138] Iteration 44760, lr = 6.25e-06
I0521 11:51:47.595502  3675 solver.cpp:243] Iteration 44780, loss = 0.00180529
I0521 11:51:47.595533  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00180518 (* 1 = 0.00180518 loss)
I0521 11:51:47.595541  3675 sgd_solver.cpp:138] Iteration 44780, lr = 6.25e-06
I0521 11:51:51.109493  3675 solver.cpp:243] Iteration 44800, loss = 0.001581
I0521 11:51:51.109658  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00158089 (* 1 = 0.00158089 loss)
I0521 11:51:51.109666  3675 sgd_solver.cpp:138] Iteration 44800, lr = 6.25e-06
I0521 11:51:54.629679  3675 solver.cpp:243] Iteration 44820, loss = 0.00140146
I0521 11:51:54.629710  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00140135 (* 1 = 0.00140135 loss)
I0521 11:51:54.629716  3675 sgd_solver.cpp:138] Iteration 44820, lr = 6.25e-06
I0521 11:51:58.143366  3675 solver.cpp:243] Iteration 44840, loss = 0.00182414
I0521 11:51:58.143398  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00182403 (* 1 = 0.00182403 loss)
I0521 11:51:58.143419  3675 sgd_solver.cpp:138] Iteration 44840, lr = 6.25e-06
I0521 11:52:01.659011  3675 solver.cpp:243] Iteration 44860, loss = 0.00161185
I0521 11:52:01.659042  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00161174 (* 1 = 0.00161174 loss)
I0521 11:52:01.659049  3675 sgd_solver.cpp:138] Iteration 44860, lr = 6.25e-06
I0521 11:52:05.172423  3675 solver.cpp:243] Iteration 44880, loss = 0.00358344
I0521 11:52:05.172453  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00358333 (* 1 = 0.00358333 loss)
I0521 11:52:05.172459  3675 sgd_solver.cpp:138] Iteration 44880, lr = 6.25e-06
I0521 11:52:08.685240  3675 solver.cpp:243] Iteration 44900, loss = 0.00174727
I0521 11:52:08.685271  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00174716 (* 1 = 0.00174716 loss)
I0521 11:52:08.685277  3675 sgd_solver.cpp:138] Iteration 44900, lr = 6.25e-06
I0521 11:52:12.200407  3675 solver.cpp:243] Iteration 44920, loss = 0.00213956
I0521 11:52:12.200436  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00213946 (* 1 = 0.00213946 loss)
I0521 11:52:12.200443  3675 sgd_solver.cpp:138] Iteration 44920, lr = 6.25e-06
I0521 11:52:15.713793  3675 solver.cpp:243] Iteration 44940, loss = 0.00191251
I0521 11:52:15.713822  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0019124 (* 1 = 0.0019124 loss)
I0521 11:52:15.713829  3675 sgd_solver.cpp:138] Iteration 44940, lr = 6.25e-06
I0521 11:52:19.228870  3675 solver.cpp:243] Iteration 44960, loss = 0.00152857
I0521 11:52:19.228902  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00152847 (* 1 = 0.00152847 loss)
I0521 11:52:19.228909  3675 sgd_solver.cpp:138] Iteration 44960, lr = 6.25e-06
I0521 11:52:22.744350  3675 solver.cpp:243] Iteration 44980, loss = 0.00148256
I0521 11:52:22.744474  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00148246 (* 1 = 0.00148246 loss)
I0521 11:52:22.744482  3675 sgd_solver.cpp:138] Iteration 44980, lr = 6.25e-06
I0521 11:52:26.128470  3675 solver.cpp:358] Iteration 45000, Testing net (#0)
I0521 11:52:30.861126  3675 solver.cpp:425]     Test net output #0: acc = 1
I0521 11:52:30.861155  3675 solver.cpp:425]     Test net output #1: acc = 1
I0521 11:52:30.861160  3675 solver.cpp:425]     Test net output #2: ctcloss = 0.000649478 (* 1 = 0.000649478 loss)
I0521 11:52:30.996773  3675 solver.cpp:243] Iteration 45000, loss = 0.0017888
I0521 11:52:30.996806  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0017887 (* 1 = 0.0017887 loss)
I0521 11:52:30.996814  3675 sgd_solver.cpp:138] Iteration 45000, lr = 6.25e-06
I0521 11:52:34.517693  3675 solver.cpp:243] Iteration 45020, loss = 0.00174886
I0521 11:52:34.517725  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00174875 (* 1 = 0.00174875 loss)
I0521 11:52:34.517731  3675 sgd_solver.cpp:138] Iteration 45020, lr = 6.25e-06
I0521 11:52:38.037250  3675 solver.cpp:243] Iteration 45040, loss = 0.0020223
I0521 11:52:38.037282  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00202219 (* 1 = 0.00202219 loss)
I0521 11:52:38.037288  3675 sgd_solver.cpp:138] Iteration 45040, lr = 6.25e-06
I0521 11:52:41.550406  3675 solver.cpp:243] Iteration 45060, loss = 0.00154977
I0521 11:52:41.550436  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00154967 (* 1 = 0.00154967 loss)
I0521 11:52:41.550441  3675 sgd_solver.cpp:138] Iteration 45060, lr = 6.25e-06
I0521 11:52:45.070310  3675 solver.cpp:243] Iteration 45080, loss = 0.00178367
I0521 11:52:45.070341  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00178356 (* 1 = 0.00178356 loss)
I0521 11:52:45.070348  3675 sgd_solver.cpp:138] Iteration 45080, lr = 6.25e-06
I0521 11:52:48.584844  3675 solver.cpp:243] Iteration 45100, loss = 0.00247382
I0521 11:52:48.584875  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00247371 (* 1 = 0.00247371 loss)
I0521 11:52:48.584882  3675 sgd_solver.cpp:138] Iteration 45100, lr = 6.25e-06
I0521 11:52:52.099030  3675 solver.cpp:243] Iteration 45120, loss = 0.00287755
I0521 11:52:52.099061  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00287744 (* 1 = 0.00287744 loss)
I0521 11:52:52.099067  3675 sgd_solver.cpp:138] Iteration 45120, lr = 6.25e-06
I0521 11:52:55.618671  3675 solver.cpp:243] Iteration 45140, loss = 0.00216229
I0521 11:52:55.618856  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00216218 (* 1 = 0.00216218 loss)
I0521 11:52:55.618865  3675 sgd_solver.cpp:138] Iteration 45140, lr = 6.25e-06
I0521 11:52:59.135609  3675 solver.cpp:243] Iteration 45160, loss = 0.00201075
I0521 11:52:59.135639  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00201064 (* 1 = 0.00201064 loss)
I0521 11:52:59.135645  3675 sgd_solver.cpp:138] Iteration 45160, lr = 6.25e-06
I0521 11:53:02.651721  3675 solver.cpp:243] Iteration 45180, loss = 0.00497114
I0521 11:53:02.651753  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00497103 (* 1 = 0.00497103 loss)
I0521 11:53:02.651760  3675 sgd_solver.cpp:138] Iteration 45180, lr = 6.25e-06
I0521 11:53:06.170188  3675 solver.cpp:243] Iteration 45200, loss = 0.00204915
I0521 11:53:06.170219  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00204904 (* 1 = 0.00204904 loss)
I0521 11:53:06.170225  3675 sgd_solver.cpp:138] Iteration 45200, lr = 6.25e-06
I0521 11:53:09.687451  3675 solver.cpp:243] Iteration 45220, loss = 0.00433017
I0521 11:53:09.687481  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00433006 (* 1 = 0.00433006 loss)
I0521 11:53:09.687489  3675 sgd_solver.cpp:138] Iteration 45220, lr = 6.25e-06
I0521 11:53:13.203639  3675 solver.cpp:243] Iteration 45240, loss = 0.00171268
I0521 11:53:13.203668  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00171257 (* 1 = 0.00171257 loss)
I0521 11:53:13.203675  3675 sgd_solver.cpp:138] Iteration 45240, lr = 6.25e-06
I0521 11:53:16.723306  3675 solver.cpp:243] Iteration 45260, loss = 0.00152473
I0521 11:53:16.723337  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00152462 (* 1 = 0.00152462 loss)
I0521 11:53:16.723343  3675 sgd_solver.cpp:138] Iteration 45260, lr = 6.25e-06
I0521 11:53:20.239845  3675 solver.cpp:243] Iteration 45280, loss = 0.00145841
I0521 11:53:20.239876  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0014583 (* 1 = 0.0014583 loss)
I0521 11:53:20.239881  3675 sgd_solver.cpp:138] Iteration 45280, lr = 6.25e-06
I0521 11:53:23.755403  3675 solver.cpp:243] Iteration 45300, loss = 0.00148451
I0521 11:53:23.755434  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00148441 (* 1 = 0.00148441 loss)
I0521 11:53:23.755440  3675 sgd_solver.cpp:138] Iteration 45300, lr = 6.25e-06
I0521 11:53:27.271220  3675 solver.cpp:243] Iteration 45320, loss = 0.00199098
I0521 11:53:27.271399  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00199087 (* 1 = 0.00199087 loss)
I0521 11:53:27.271407  3675 sgd_solver.cpp:138] Iteration 45320, lr = 6.25e-06
I0521 11:53:30.790423  3675 solver.cpp:243] Iteration 45340, loss = 0.00191214
I0521 11:53:30.790453  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00191204 (* 1 = 0.00191204 loss)
I0521 11:53:30.790459  3675 sgd_solver.cpp:138] Iteration 45340, lr = 6.25e-06
I0521 11:53:34.309433  3675 solver.cpp:243] Iteration 45360, loss = 0.00186413
I0521 11:53:34.309464  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00186402 (* 1 = 0.00186402 loss)
I0521 11:53:34.309471  3675 sgd_solver.cpp:138] Iteration 45360, lr = 6.25e-06
I0521 11:53:37.829376  3675 solver.cpp:243] Iteration 45380, loss = 0.0019915
I0521 11:53:37.829407  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00199139 (* 1 = 0.00199139 loss)
I0521 11:53:37.829414  3675 sgd_solver.cpp:138] Iteration 45380, lr = 6.25e-06
I0521 11:53:41.345259  3675 solver.cpp:243] Iteration 45400, loss = 0.00156586
I0521 11:53:41.345290  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00156575 (* 1 = 0.00156575 loss)
I0521 11:53:41.345297  3675 sgd_solver.cpp:138] Iteration 45400, lr = 6.25e-06
I0521 11:53:44.862363  3675 solver.cpp:243] Iteration 45420, loss = 0.00155956
I0521 11:53:44.862393  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00155945 (* 1 = 0.00155945 loss)
I0521 11:53:44.862398  3675 sgd_solver.cpp:138] Iteration 45420, lr = 6.25e-06
I0521 11:53:48.379181  3675 solver.cpp:243] Iteration 45440, loss = 0.00221229
I0521 11:53:48.379211  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00221218 (* 1 = 0.00221218 loss)
I0521 11:53:48.379220  3675 sgd_solver.cpp:138] Iteration 45440, lr = 6.25e-06
I0521 11:53:51.899616  3675 solver.cpp:243] Iteration 45460, loss = 0.00200997
I0521 11:53:51.899647  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00200987 (* 1 = 0.00200987 loss)
I0521 11:53:51.899653  3675 sgd_solver.cpp:138] Iteration 45460, lr = 6.25e-06
I0521 11:53:55.422358  3675 solver.cpp:243] Iteration 45480, loss = 0.00183029
I0521 11:53:55.422389  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00183018 (* 1 = 0.00183018 loss)
I0521 11:53:55.422395  3675 sgd_solver.cpp:138] Iteration 45480, lr = 6.25e-06
I0521 11:53:58.943354  3675 solver.cpp:243] Iteration 45500, loss = 0.00292437
I0521 11:53:58.943480  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00292427 (* 1 = 0.00292427 loss)
I0521 11:53:58.943487  3675 sgd_solver.cpp:138] Iteration 45500, lr = 6.25e-06
I0521 11:54:02.463028  3675 solver.cpp:243] Iteration 45520, loss = 0.00172959
I0521 11:54:02.463062  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00172948 (* 1 = 0.00172948 loss)
I0521 11:54:02.463068  3675 sgd_solver.cpp:138] Iteration 45520, lr = 6.25e-06
I0521 11:54:05.982524  3675 solver.cpp:243] Iteration 45540, loss = 0.00318492
I0521 11:54:05.982558  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00318482 (* 1 = 0.00318482 loss)
I0521 11:54:05.982564  3675 sgd_solver.cpp:138] Iteration 45540, lr = 6.25e-06
I0521 11:54:09.496757  3675 solver.cpp:243] Iteration 45560, loss = 0.00240157
I0521 11:54:09.496789  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00240147 (* 1 = 0.00240147 loss)
I0521 11:54:09.496796  3675 sgd_solver.cpp:138] Iteration 45560, lr = 6.25e-06
I0521 11:54:12.948559  3675 solver.cpp:243] Iteration 45580, loss = 0.00230607
I0521 11:54:12.948591  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00230596 (* 1 = 0.00230596 loss)
I0521 11:54:12.948597  3675 sgd_solver.cpp:138] Iteration 45580, lr = 6.25e-06
I0521 11:54:16.469970  3675 solver.cpp:243] Iteration 45600, loss = 0.00260271
I0521 11:54:16.470002  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0026026 (* 1 = 0.0026026 loss)
I0521 11:54:16.470007  3675 sgd_solver.cpp:138] Iteration 45600, lr = 6.25e-06
I0521 11:54:19.988776  3675 solver.cpp:243] Iteration 45620, loss = 0.00220347
I0521 11:54:19.988811  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00220336 (* 1 = 0.00220336 loss)
I0521 11:54:19.988832  3675 sgd_solver.cpp:138] Iteration 45620, lr = 6.25e-06
I0521 11:54:23.505635  3675 solver.cpp:243] Iteration 45640, loss = 0.00193108
I0521 11:54:23.505666  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00193097 (* 1 = 0.00193097 loss)
I0521 11:54:23.505672  3675 sgd_solver.cpp:138] Iteration 45640, lr = 6.25e-06
I0521 11:54:27.024098  3675 solver.cpp:243] Iteration 45660, loss = 0.00154143
I0521 11:54:27.024130  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00154133 (* 1 = 0.00154133 loss)
I0521 11:54:27.024153  3675 sgd_solver.cpp:138] Iteration 45660, lr = 6.25e-06
I0521 11:54:30.541157  3675 solver.cpp:243] Iteration 45680, loss = 0.00219436
I0521 11:54:30.541306  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00219426 (* 1 = 0.00219426 loss)
I0521 11:54:30.541313  3675 sgd_solver.cpp:138] Iteration 45680, lr = 6.25e-06
I0521 11:54:34.059432  3675 solver.cpp:243] Iteration 45700, loss = 0.0028256
I0521 11:54:34.059463  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0028255 (* 1 = 0.0028255 loss)
I0521 11:54:34.059468  3675 sgd_solver.cpp:138] Iteration 45700, lr = 6.25e-06
I0521 11:54:37.576098  3675 solver.cpp:243] Iteration 45720, loss = 0.00239354
I0521 11:54:37.576128  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00239343 (* 1 = 0.00239343 loss)
I0521 11:54:37.576134  3675 sgd_solver.cpp:138] Iteration 45720, lr = 6.25e-06
I0521 11:54:41.093370  3675 solver.cpp:243] Iteration 45740, loss = 0.00162253
I0521 11:54:41.093401  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00162243 (* 1 = 0.00162243 loss)
I0521 11:54:41.093407  3675 sgd_solver.cpp:138] Iteration 45740, lr = 6.25e-06
I0521 11:54:44.615078  3675 solver.cpp:243] Iteration 45760, loss = 0.00152708
I0521 11:54:44.615110  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00152697 (* 1 = 0.00152697 loss)
I0521 11:54:44.615116  3675 sgd_solver.cpp:138] Iteration 45760, lr = 6.25e-06
I0521 11:54:48.133301  3675 solver.cpp:243] Iteration 45780, loss = 0.00248549
I0521 11:54:48.133332  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00248538 (* 1 = 0.00248538 loss)
I0521 11:54:48.133353  3675 sgd_solver.cpp:138] Iteration 45780, lr = 6.25e-06
I0521 11:54:51.649602  3675 solver.cpp:243] Iteration 45800, loss = 0.00190486
I0521 11:54:51.649633  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00190475 (* 1 = 0.00190475 loss)
I0521 11:54:51.649655  3675 sgd_solver.cpp:138] Iteration 45800, lr = 6.25e-06
I0521 11:54:55.167006  3675 solver.cpp:243] Iteration 45820, loss = 0.00115926
I0521 11:54:55.167038  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00115916 (* 1 = 0.00115916 loss)
I0521 11:54:55.167044  3675 sgd_solver.cpp:138] Iteration 45820, lr = 6.25e-06
I0521 11:54:58.677129  3675 solver.cpp:243] Iteration 45840, loss = 0.00196518
I0521 11:54:58.677160  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00196508 (* 1 = 0.00196508 loss)
I0521 11:54:58.677165  3675 sgd_solver.cpp:138] Iteration 45840, lr = 6.25e-06
I0521 11:55:02.194705  3675 solver.cpp:243] Iteration 45860, loss = 0.00231722
I0521 11:55:02.194866  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00231712 (* 1 = 0.00231712 loss)
I0521 11:55:02.194875  3675 sgd_solver.cpp:138] Iteration 45860, lr = 6.25e-06
I0521 11:55:05.714135  3675 solver.cpp:243] Iteration 45880, loss = 0.0021335
I0521 11:55:05.714166  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00213339 (* 1 = 0.00213339 loss)
I0521 11:55:05.714171  3675 sgd_solver.cpp:138] Iteration 45880, lr = 6.25e-06
I0521 11:55:09.229065  3675 solver.cpp:243] Iteration 45900, loss = 0.00139689
I0521 11:55:09.229096  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00139679 (* 1 = 0.00139679 loss)
I0521 11:55:09.229118  3675 sgd_solver.cpp:138] Iteration 45900, lr = 6.25e-06
I0521 11:55:12.746574  3675 solver.cpp:243] Iteration 45920, loss = 0.00200824
I0521 11:55:12.746604  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00200813 (* 1 = 0.00200813 loss)
I0521 11:55:12.746610  3675 sgd_solver.cpp:138] Iteration 45920, lr = 6.25e-06
I0521 11:55:16.263203  3675 solver.cpp:243] Iteration 45940, loss = 0.00264358
I0521 11:55:16.263234  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00264348 (* 1 = 0.00264348 loss)
I0521 11:55:16.263257  3675 sgd_solver.cpp:138] Iteration 45940, lr = 6.25e-06
I0521 11:55:19.783402  3675 solver.cpp:243] Iteration 45960, loss = 0.00178171
I0521 11:55:19.783432  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0017816 (* 1 = 0.0017816 loss)
I0521 11:55:19.783438  3675 sgd_solver.cpp:138] Iteration 45960, lr = 6.25e-06
I0521 11:55:23.298887  3675 solver.cpp:243] Iteration 45980, loss = 0.00189313
I0521 11:55:23.298918  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00189302 (* 1 = 0.00189302 loss)
I0521 11:55:23.298924  3675 sgd_solver.cpp:138] Iteration 45980, lr = 6.25e-06
I0521 11:55:26.686169  3675 solver.cpp:596] Snapshotting to binary proto file models/LPR/lpr_resnet_lstm_iter_46000.caffemodel
I0521 11:55:26.715381  3675 sgd_solver.cpp:307] Snapshotting solver state to binary proto file models/LPR/lpr_resnet_lstm_iter_46000.solverstate
I0521 11:55:26.731384  3675 solver.cpp:358] Iteration 46000, Testing net (#0)
I0521 11:55:31.465909  3675 solver.cpp:425]     Test net output #0: acc = 1
I0521 11:55:31.465936  3675 solver.cpp:425]     Test net output #1: acc = 1
I0521 11:55:31.465943  3675 solver.cpp:425]     Test net output #2: ctcloss = 0.000646999 (* 1 = 0.000646999 loss)
I0521 11:55:31.601423  3675 solver.cpp:243] Iteration 46000, loss = 0.00119915
I0521 11:55:31.601451  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00119904 (* 1 = 0.00119904 loss)
I0521 11:55:31.601457  3675 sgd_solver.cpp:138] Iteration 46000, lr = 6.25e-06
I0521 11:55:35.120425  3675 solver.cpp:243] Iteration 46020, loss = 0.00165588
I0521 11:55:35.120613  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00165577 (* 1 = 0.00165577 loss)
I0521 11:55:35.120622  3675 sgd_solver.cpp:138] Iteration 46020, lr = 6.25e-06
I0521 11:55:38.638180  3675 solver.cpp:243] Iteration 46040, loss = 0.00164672
I0521 11:55:38.638211  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00164662 (* 1 = 0.00164662 loss)
I0521 11:55:38.638217  3675 sgd_solver.cpp:138] Iteration 46040, lr = 6.25e-06
I0521 11:55:42.152999  3675 solver.cpp:243] Iteration 46060, loss = 0.00209685
I0521 11:55:42.153029  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00209674 (* 1 = 0.00209674 loss)
I0521 11:55:42.153034  3675 sgd_solver.cpp:138] Iteration 46060, lr = 6.25e-06
I0521 11:55:45.674863  3675 solver.cpp:243] Iteration 46080, loss = 0.00169153
I0521 11:55:45.674895  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00169143 (* 1 = 0.00169143 loss)
I0521 11:55:45.674916  3675 sgd_solver.cpp:138] Iteration 46080, lr = 6.25e-06
I0521 11:55:49.188920  3675 solver.cpp:243] Iteration 46100, loss = 0.00259418
I0521 11:55:49.188949  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00259407 (* 1 = 0.00259407 loss)
I0521 11:55:49.188971  3675 sgd_solver.cpp:138] Iteration 46100, lr = 6.25e-06
I0521 11:55:52.709955  3675 solver.cpp:243] Iteration 46120, loss = 0.00215197
I0521 11:55:52.709985  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00215187 (* 1 = 0.00215187 loss)
I0521 11:55:52.709991  3675 sgd_solver.cpp:138] Iteration 46120, lr = 6.25e-06
I0521 11:55:56.226151  3675 solver.cpp:243] Iteration 46140, loss = 0.00175938
I0521 11:55:56.226181  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00175927 (* 1 = 0.00175927 loss)
I0521 11:55:56.226187  3675 sgd_solver.cpp:138] Iteration 46140, lr = 6.25e-06
I0521 11:55:59.739869  3675 solver.cpp:243] Iteration 46160, loss = 0.00307329
I0521 11:55:59.739898  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00307318 (* 1 = 0.00307318 loss)
I0521 11:55:59.739904  3675 sgd_solver.cpp:138] Iteration 46160, lr = 6.25e-06
I0521 11:56:03.258812  3675 solver.cpp:243] Iteration 46180, loss = 0.00134793
I0521 11:56:03.258846  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00134782 (* 1 = 0.00134782 loss)
I0521 11:56:03.258854  3675 sgd_solver.cpp:138] Iteration 46180, lr = 6.25e-06
I0521 11:56:06.774796  3675 solver.cpp:243] Iteration 46200, loss = 0.00180294
I0521 11:56:06.774971  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00180284 (* 1 = 0.00180284 loss)
I0521 11:56:06.774979  3675 sgd_solver.cpp:138] Iteration 46200, lr = 6.25e-06
I0521 11:56:10.295615  3675 solver.cpp:243] Iteration 46220, loss = 0.00232779
I0521 11:56:10.295707  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00232769 (* 1 = 0.00232769 loss)
I0521 11:56:10.295727  3675 sgd_solver.cpp:138] Iteration 46220, lr = 6.25e-06
I0521 11:56:13.815166  3675 solver.cpp:243] Iteration 46240, loss = 0.001874
I0521 11:56:13.815196  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0018739 (* 1 = 0.0018739 loss)
I0521 11:56:13.815202  3675 sgd_solver.cpp:138] Iteration 46240, lr = 6.25e-06
I0521 11:56:17.330163  3675 solver.cpp:243] Iteration 46260, loss = 0.00159285
I0521 11:56:17.330194  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00159275 (* 1 = 0.00159275 loss)
I0521 11:56:17.330200  3675 sgd_solver.cpp:138] Iteration 46260, lr = 6.25e-06
I0521 11:56:20.846417  3675 solver.cpp:243] Iteration 46280, loss = 0.00211204
I0521 11:56:20.846448  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00211193 (* 1 = 0.00211193 loss)
I0521 11:56:20.846454  3675 sgd_solver.cpp:138] Iteration 46280, lr = 6.25e-06
I0521 11:56:24.364642  3675 solver.cpp:243] Iteration 46300, loss = 0.00202649
I0521 11:56:24.364673  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00202638 (* 1 = 0.00202638 loss)
I0521 11:56:24.364678  3675 sgd_solver.cpp:138] Iteration 46300, lr = 6.25e-06
I0521 11:56:27.883375  3675 solver.cpp:243] Iteration 46320, loss = 0.0024148
I0521 11:56:27.883406  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00241469 (* 1 = 0.00241469 loss)
I0521 11:56:27.883412  3675 sgd_solver.cpp:138] Iteration 46320, lr = 6.25e-06
I0521 11:56:31.403808  3675 solver.cpp:243] Iteration 46340, loss = 0.00290514
I0521 11:56:31.403839  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00290503 (* 1 = 0.00290503 loss)
I0521 11:56:31.403846  3675 sgd_solver.cpp:138] Iteration 46340, lr = 6.25e-06
I0521 11:56:34.925853  3675 solver.cpp:243] Iteration 46360, loss = 0.00164912
I0521 11:56:34.925886  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00164902 (* 1 = 0.00164902 loss)
I0521 11:56:34.925894  3675 sgd_solver.cpp:138] Iteration 46360, lr = 6.25e-06
I0521 11:56:38.445843  3675 solver.cpp:243] Iteration 46380, loss = 0.00180639
I0521 11:56:38.445952  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00180629 (* 1 = 0.00180629 loss)
I0521 11:56:38.445960  3675 sgd_solver.cpp:138] Iteration 46380, lr = 6.25e-06
I0521 11:56:41.962636  3675 solver.cpp:243] Iteration 46400, loss = 0.00172294
I0521 11:56:41.962668  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00172283 (* 1 = 0.00172283 loss)
I0521 11:56:41.962674  3675 sgd_solver.cpp:138] Iteration 46400, lr = 6.25e-06
I0521 11:56:45.487481  3675 solver.cpp:243] Iteration 46420, loss = 0.00226517
I0521 11:56:45.487511  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00226506 (* 1 = 0.00226506 loss)
I0521 11:56:45.487516  3675 sgd_solver.cpp:138] Iteration 46420, lr = 6.25e-06
I0521 11:56:49.002797  3675 solver.cpp:243] Iteration 46440, loss = 0.00195037
I0521 11:56:49.002828  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00195027 (* 1 = 0.00195027 loss)
I0521 11:56:49.002835  3675 sgd_solver.cpp:138] Iteration 46440, lr = 6.25e-06
I0521 11:56:52.521689  3675 solver.cpp:243] Iteration 46460, loss = 0.00344599
I0521 11:56:52.521719  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00344588 (* 1 = 0.00344588 loss)
I0521 11:56:52.521724  3675 sgd_solver.cpp:138] Iteration 46460, lr = 6.25e-06
I0521 11:56:56.040786  3675 solver.cpp:243] Iteration 46480, loss = 0.0022497
I0521 11:56:56.040817  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0022496 (* 1 = 0.0022496 loss)
I0521 11:56:56.040822  3675 sgd_solver.cpp:138] Iteration 46480, lr = 6.25e-06
I0521 11:56:59.556473  3675 solver.cpp:243] Iteration 46500, loss = 0.00135568
I0521 11:56:59.556504  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00135557 (* 1 = 0.00135557 loss)
I0521 11:56:59.556510  3675 sgd_solver.cpp:138] Iteration 46500, lr = 6.25e-06
I0521 11:57:03.076648  3675 solver.cpp:243] Iteration 46520, loss = 0.00217634
I0521 11:57:03.076678  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00217623 (* 1 = 0.00217623 loss)
I0521 11:57:03.076683  3675 sgd_solver.cpp:138] Iteration 46520, lr = 6.25e-06
I0521 11:57:06.592995  3675 solver.cpp:243] Iteration 46540, loss = 0.00206768
I0521 11:57:06.593026  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00206758 (* 1 = 0.00206758 loss)
I0521 11:57:06.593032  3675 sgd_solver.cpp:138] Iteration 46540, lr = 6.25e-06
I0521 11:57:10.109422  3675 solver.cpp:243] Iteration 46560, loss = 0.00153951
I0521 11:57:10.109544  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0015394 (* 1 = 0.0015394 loss)
I0521 11:57:10.109550  3675 sgd_solver.cpp:138] Iteration 46560, lr = 6.25e-06
I0521 11:57:13.621328  3675 solver.cpp:243] Iteration 46580, loss = 0.00164048
I0521 11:57:13.621361  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00164037 (* 1 = 0.00164037 loss)
I0521 11:57:13.621366  3675 sgd_solver.cpp:138] Iteration 46580, lr = 6.25e-06
I0521 11:57:17.139259  3675 solver.cpp:243] Iteration 46600, loss = 0.00202225
I0521 11:57:17.139291  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00202214 (* 1 = 0.00202214 loss)
I0521 11:57:17.139297  3675 sgd_solver.cpp:138] Iteration 46600, lr = 6.25e-06
I0521 11:57:20.655127  3675 solver.cpp:243] Iteration 46620, loss = 0.00143317
I0521 11:57:20.655156  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00143307 (* 1 = 0.00143307 loss)
I0521 11:57:20.655164  3675 sgd_solver.cpp:138] Iteration 46620, lr = 6.25e-06
I0521 11:57:24.173938  3675 solver.cpp:243] Iteration 46640, loss = 0.00156742
I0521 11:57:24.173981  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00156731 (* 1 = 0.00156731 loss)
I0521 11:57:24.174003  3675 sgd_solver.cpp:138] Iteration 46640, lr = 6.25e-06
I0521 11:57:27.690315  3675 solver.cpp:243] Iteration 46660, loss = 0.00162208
I0521 11:57:27.690346  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00162197 (* 1 = 0.00162197 loss)
I0521 11:57:27.690353  3675 sgd_solver.cpp:138] Iteration 46660, lr = 6.25e-06
I0521 11:57:31.204831  3675 solver.cpp:243] Iteration 46680, loss = 0.00202444
I0521 11:57:31.204864  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00202433 (* 1 = 0.00202433 loss)
I0521 11:57:31.204886  3675 sgd_solver.cpp:138] Iteration 46680, lr = 6.25e-06
I0521 11:57:34.720777  3675 solver.cpp:243] Iteration 46700, loss = 0.00147204
I0521 11:57:34.720810  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00147193 (* 1 = 0.00147193 loss)
I0521 11:57:34.720816  3675 sgd_solver.cpp:138] Iteration 46700, lr = 6.25e-06
I0521 11:57:38.233448  3675 solver.cpp:243] Iteration 46720, loss = 0.00226249
I0521 11:57:38.233477  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00226238 (* 1 = 0.00226238 loss)
I0521 11:57:38.233484  3675 sgd_solver.cpp:138] Iteration 46720, lr = 6.25e-06
I0521 11:57:41.753655  3675 solver.cpp:243] Iteration 46740, loss = 0.00181459
I0521 11:57:41.753819  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00181449 (* 1 = 0.00181449 loss)
I0521 11:57:41.753827  3675 sgd_solver.cpp:138] Iteration 46740, lr = 6.25e-06
I0521 11:57:45.270565  3675 solver.cpp:243] Iteration 46760, loss = 0.0014137
I0521 11:57:45.270596  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00141359 (* 1 = 0.00141359 loss)
I0521 11:57:45.270602  3675 sgd_solver.cpp:138] Iteration 46760, lr = 6.25e-06
I0521 11:57:48.789029  3675 solver.cpp:243] Iteration 46780, loss = 0.00165231
I0521 11:57:48.789060  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00165221 (* 1 = 0.00165221 loss)
I0521 11:57:48.789067  3675 sgd_solver.cpp:138] Iteration 46780, lr = 6.25e-06
I0521 11:57:52.307262  3675 solver.cpp:243] Iteration 46800, loss = 0.00178329
I0521 11:57:52.307294  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00178319 (* 1 = 0.00178319 loss)
I0521 11:57:52.307301  3675 sgd_solver.cpp:138] Iteration 46800, lr = 6.25e-06
I0521 11:57:55.826454  3675 solver.cpp:243] Iteration 46820, loss = 0.00238196
I0521 11:57:55.826486  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00238186 (* 1 = 0.00238186 loss)
I0521 11:57:55.826493  3675 sgd_solver.cpp:138] Iteration 46820, lr = 6.25e-06
I0521 11:57:59.341943  3675 solver.cpp:243] Iteration 46840, loss = 0.00223858
I0521 11:57:59.341975  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00223847 (* 1 = 0.00223847 loss)
I0521 11:57:59.341982  3675 sgd_solver.cpp:138] Iteration 46840, lr = 6.25e-06
I0521 11:58:02.859762  3675 solver.cpp:243] Iteration 46860, loss = 0.00176972
I0521 11:58:02.859793  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00176962 (* 1 = 0.00176962 loss)
I0521 11:58:02.859800  3675 sgd_solver.cpp:138] Iteration 46860, lr = 6.25e-06
I0521 11:58:06.302868  3675 solver.cpp:243] Iteration 46880, loss = 0.00230268
I0521 11:58:06.302898  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00230258 (* 1 = 0.00230258 loss)
I0521 11:58:06.302904  3675 sgd_solver.cpp:138] Iteration 46880, lr = 6.25e-06
I0521 11:58:09.819335  3675 solver.cpp:243] Iteration 46900, loss = 0.00181627
I0521 11:58:09.819365  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00181616 (* 1 = 0.00181616 loss)
I0521 11:58:09.819371  3675 sgd_solver.cpp:138] Iteration 46900, lr = 6.25e-06
I0521 11:58:13.339674  3675 solver.cpp:243] Iteration 46920, loss = 0.0017712
I0521 11:58:13.339848  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00177109 (* 1 = 0.00177109 loss)
I0521 11:58:13.339857  3675 sgd_solver.cpp:138] Iteration 46920, lr = 6.25e-06
I0521 11:58:16.858151  3675 solver.cpp:243] Iteration 46940, loss = 0.00146263
I0521 11:58:16.858183  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00146252 (* 1 = 0.00146252 loss)
I0521 11:58:16.858189  3675 sgd_solver.cpp:138] Iteration 46940, lr = 6.25e-06
I0521 11:58:20.372244  3675 solver.cpp:243] Iteration 46960, loss = 0.00167878
I0521 11:58:20.372275  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00167868 (* 1 = 0.00167868 loss)
I0521 11:58:20.372282  3675 sgd_solver.cpp:138] Iteration 46960, lr = 6.25e-06
I0521 11:58:23.888130  3675 solver.cpp:243] Iteration 46980, loss = 0.00204388
I0521 11:58:23.888164  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00204377 (* 1 = 0.00204377 loss)
I0521 11:58:23.888170  3675 sgd_solver.cpp:138] Iteration 46980, lr = 6.25e-06
I0521 11:58:27.274546  3675 solver.cpp:358] Iteration 47000, Testing net (#0)
I0521 11:58:32.007341  3675 solver.cpp:425]     Test net output #0: acc = 1
I0521 11:58:32.007369  3675 solver.cpp:425]     Test net output #1: acc = 1
I0521 11:58:32.007376  3675 solver.cpp:425]     Test net output #2: ctcloss = 0.000644566 (* 1 = 0.000644566 loss)
I0521 11:58:32.142401  3675 solver.cpp:243] Iteration 47000, loss = 0.00154373
I0521 11:58:32.142433  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00154363 (* 1 = 0.00154363 loss)
I0521 11:58:32.142441  3675 sgd_solver.cpp:138] Iteration 47000, lr = 6.25e-06
I0521 11:58:35.659751  3675 solver.cpp:243] Iteration 47020, loss = 0.00189776
I0521 11:58:35.659782  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00189765 (* 1 = 0.00189765 loss)
I0521 11:58:35.659804  3675 sgd_solver.cpp:138] Iteration 47020, lr = 6.25e-06
I0521 11:58:39.180284  3675 solver.cpp:243] Iteration 47040, loss = 0.00204214
I0521 11:58:39.180315  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00204204 (* 1 = 0.00204204 loss)
I0521 11:58:39.180320  3675 sgd_solver.cpp:138] Iteration 47040, lr = 6.25e-06
I0521 11:58:42.698644  3675 solver.cpp:243] Iteration 47060, loss = 0.00276963
I0521 11:58:42.698676  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00276952 (* 1 = 0.00276952 loss)
I0521 11:58:42.698696  3675 sgd_solver.cpp:138] Iteration 47060, lr = 6.25e-06
I0521 11:58:46.215937  3675 solver.cpp:243] Iteration 47080, loss = 0.00201381
I0521 11:58:46.216145  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00201371 (* 1 = 0.00201371 loss)
I0521 11:58:46.216153  3675 sgd_solver.cpp:138] Iteration 47080, lr = 6.25e-06
I0521 11:58:49.734921  3675 solver.cpp:243] Iteration 47100, loss = 0.00181974
I0521 11:58:49.734952  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00181963 (* 1 = 0.00181963 loss)
I0521 11:58:49.734958  3675 sgd_solver.cpp:138] Iteration 47100, lr = 6.25e-06
I0521 11:58:53.254004  3675 solver.cpp:243] Iteration 47120, loss = 0.00201712
I0521 11:58:53.254036  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00201702 (* 1 = 0.00201702 loss)
I0521 11:58:53.254058  3675 sgd_solver.cpp:138] Iteration 47120, lr = 6.25e-06
I0521 11:58:56.770542  3675 solver.cpp:243] Iteration 47140, loss = 0.00204504
I0521 11:58:56.770572  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00204493 (* 1 = 0.00204493 loss)
I0521 11:58:56.770578  3675 sgd_solver.cpp:138] Iteration 47140, lr = 6.25e-06
I0521 11:59:00.294493  3675 solver.cpp:243] Iteration 47160, loss = 0.00190887
I0521 11:59:00.294525  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00190876 (* 1 = 0.00190876 loss)
I0521 11:59:00.294533  3675 sgd_solver.cpp:138] Iteration 47160, lr = 6.25e-06
I0521 11:59:03.811308  3675 solver.cpp:243] Iteration 47180, loss = 0.00170526
I0521 11:59:03.811341  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00170516 (* 1 = 0.00170516 loss)
I0521 11:59:03.811347  3675 sgd_solver.cpp:138] Iteration 47180, lr = 6.25e-06
I0521 11:59:07.328944  3675 solver.cpp:243] Iteration 47200, loss = 0.0017199
I0521 11:59:07.328976  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00171979 (* 1 = 0.00171979 loss)
I0521 11:59:07.328982  3675 sgd_solver.cpp:138] Iteration 47200, lr = 6.25e-06
I0521 11:59:10.849973  3675 solver.cpp:243] Iteration 47220, loss = 0.0013869
I0521 11:59:10.850006  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0013868 (* 1 = 0.0013868 loss)
I0521 11:59:10.850013  3675 sgd_solver.cpp:138] Iteration 47220, lr = 6.25e-06
I0521 11:59:14.369048  3675 solver.cpp:243] Iteration 47240, loss = 0.00126893
I0521 11:59:14.369079  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00126882 (* 1 = 0.00126882 loss)
I0521 11:59:14.369086  3675 sgd_solver.cpp:138] Iteration 47240, lr = 6.25e-06
I0521 11:59:17.886615  3675 solver.cpp:243] Iteration 47260, loss = 0.00251749
I0521 11:59:17.886781  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00251738 (* 1 = 0.00251738 loss)
I0521 11:59:17.886790  3675 sgd_solver.cpp:138] Iteration 47260, lr = 6.25e-06
I0521 11:59:21.407213  3675 solver.cpp:243] Iteration 47280, loss = 0.00228827
I0521 11:59:21.407244  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00228816 (* 1 = 0.00228816 loss)
I0521 11:59:21.407266  3675 sgd_solver.cpp:138] Iteration 47280, lr = 6.25e-06
I0521 11:59:24.924710  3675 solver.cpp:243] Iteration 47300, loss = 0.00194719
I0521 11:59:24.924741  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00194708 (* 1 = 0.00194708 loss)
I0521 11:59:24.924746  3675 sgd_solver.cpp:138] Iteration 47300, lr = 6.25e-06
I0521 11:59:28.443209  3675 solver.cpp:243] Iteration 47320, loss = 0.00234417
I0521 11:59:28.443239  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00234406 (* 1 = 0.00234406 loss)
I0521 11:59:28.443245  3675 sgd_solver.cpp:138] Iteration 47320, lr = 6.25e-06
I0521 11:59:31.956713  3675 solver.cpp:243] Iteration 47340, loss = 0.00172748
I0521 11:59:31.956745  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00172737 (* 1 = 0.00172737 loss)
I0521 11:59:31.956753  3675 sgd_solver.cpp:138] Iteration 47340, lr = 6.25e-06
I0521 11:59:35.482141  3675 solver.cpp:243] Iteration 47360, loss = 0.00168963
I0521 11:59:35.482172  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00168953 (* 1 = 0.00168953 loss)
I0521 11:59:35.482177  3675 sgd_solver.cpp:138] Iteration 47360, lr = 6.25e-06
I0521 11:59:38.997602  3675 solver.cpp:243] Iteration 47380, loss = 0.00200888
I0521 11:59:38.997634  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00200877 (* 1 = 0.00200877 loss)
I0521 11:59:38.997642  3675 sgd_solver.cpp:138] Iteration 47380, lr = 6.25e-06
I0521 11:59:42.511528  3675 solver.cpp:243] Iteration 47400, loss = 0.00179124
I0521 11:59:42.511559  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00179114 (* 1 = 0.00179114 loss)
I0521 11:59:42.511566  3675 sgd_solver.cpp:138] Iteration 47400, lr = 6.25e-06
I0521 11:59:46.027956  3675 solver.cpp:243] Iteration 47420, loss = 0.0016641
I0521 11:59:46.027985  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00166399 (* 1 = 0.00166399 loss)
I0521 11:59:46.027992  3675 sgd_solver.cpp:138] Iteration 47420, lr = 6.25e-06
I0521 11:59:49.542052  3675 solver.cpp:243] Iteration 47440, loss = 0.00237858
I0521 11:59:49.542212  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00237848 (* 1 = 0.00237848 loss)
I0521 11:59:49.542220  3675 sgd_solver.cpp:138] Iteration 47440, lr = 6.25e-06
I0521 11:59:53.056485  3675 solver.cpp:243] Iteration 47460, loss = 0.0016663
I0521 11:59:53.056515  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0016662 (* 1 = 0.0016662 loss)
I0521 11:59:53.056536  3675 sgd_solver.cpp:138] Iteration 47460, lr = 6.25e-06
I0521 11:59:56.568506  3675 solver.cpp:243] Iteration 47480, loss = 0.00220521
I0521 11:59:56.568537  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0022051 (* 1 = 0.0022051 loss)
I0521 11:59:56.568544  3675 sgd_solver.cpp:138] Iteration 47480, lr = 6.25e-06
I0521 12:00:00.084749  3675 solver.cpp:243] Iteration 47500, loss = 0.00143223
I0521 12:00:00.084781  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00143213 (* 1 = 0.00143213 loss)
I0521 12:00:00.084789  3675 sgd_solver.cpp:138] Iteration 47500, lr = 6.25e-06
I0521 12:00:03.603019  3675 solver.cpp:243] Iteration 47520, loss = 0.00194405
I0521 12:00:03.603050  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00194395 (* 1 = 0.00194395 loss)
I0521 12:00:03.603056  3675 sgd_solver.cpp:138] Iteration 47520, lr = 6.25e-06
I0521 12:00:07.121361  3675 solver.cpp:243] Iteration 47540, loss = 0.00474833
I0521 12:00:07.121394  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00474823 (* 1 = 0.00474823 loss)
I0521 12:00:07.121400  3675 sgd_solver.cpp:138] Iteration 47540, lr = 6.25e-06
I0521 12:00:10.638643  3675 solver.cpp:243] Iteration 47560, loss = 0.00245605
I0521 12:00:10.638672  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00245594 (* 1 = 0.00245594 loss)
I0521 12:00:10.638679  3675 sgd_solver.cpp:138] Iteration 47560, lr = 6.25e-06
I0521 12:00:14.157027  3675 solver.cpp:243] Iteration 47580, loss = 0.00264084
I0521 12:00:14.157058  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00264073 (* 1 = 0.00264073 loss)
I0521 12:00:14.157064  3675 sgd_solver.cpp:138] Iteration 47580, lr = 6.25e-06
I0521 12:00:17.673174  3675 solver.cpp:243] Iteration 47600, loss = 0.00223275
I0521 12:00:17.673205  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00223265 (* 1 = 0.00223265 loss)
I0521 12:00:17.673213  3675 sgd_solver.cpp:138] Iteration 47600, lr = 6.25e-06
I0521 12:00:21.193120  3675 solver.cpp:243] Iteration 47620, loss = 0.00178111
I0521 12:00:21.193246  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00178101 (* 1 = 0.00178101 loss)
I0521 12:00:21.193254  3675 sgd_solver.cpp:138] Iteration 47620, lr = 6.25e-06
I0521 12:00:24.708165  3675 solver.cpp:243] Iteration 47640, loss = 0.00250138
I0521 12:00:24.708194  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00250127 (* 1 = 0.00250127 loss)
I0521 12:00:24.708200  3675 sgd_solver.cpp:138] Iteration 47640, lr = 6.25e-06
I0521 12:00:28.222903  3675 solver.cpp:243] Iteration 47660, loss = 0.00191892
I0521 12:00:28.222934  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00191881 (* 1 = 0.00191881 loss)
I0521 12:00:28.222956  3675 sgd_solver.cpp:138] Iteration 47660, lr = 6.25e-06
I0521 12:00:31.743130  3675 solver.cpp:243] Iteration 47680, loss = 0.00125081
I0521 12:00:31.743161  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0012507 (* 1 = 0.0012507 loss)
I0521 12:00:31.743183  3675 sgd_solver.cpp:138] Iteration 47680, lr = 6.25e-06
I0521 12:00:35.258437  3675 solver.cpp:243] Iteration 47700, loss = 0.00229723
I0521 12:00:35.258469  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00229712 (* 1 = 0.00229712 loss)
I0521 12:00:35.258476  3675 sgd_solver.cpp:138] Iteration 47700, lr = 6.25e-06
I0521 12:00:38.773916  3675 solver.cpp:243] Iteration 47720, loss = 0.00148618
I0521 12:00:38.773947  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00148608 (* 1 = 0.00148608 loss)
I0521 12:00:38.773952  3675 sgd_solver.cpp:138] Iteration 47720, lr = 6.25e-06
I0521 12:00:42.291041  3675 solver.cpp:243] Iteration 47740, loss = 0.00188544
I0521 12:00:42.291071  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00188534 (* 1 = 0.00188534 loss)
I0521 12:00:42.291077  3675 sgd_solver.cpp:138] Iteration 47740, lr = 6.25e-06
I0521 12:00:45.807579  3675 solver.cpp:243] Iteration 47760, loss = 0.00197878
I0521 12:00:45.807610  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00197867 (* 1 = 0.00197867 loss)
I0521 12:00:45.807616  3675 sgd_solver.cpp:138] Iteration 47760, lr = 6.25e-06
I0521 12:00:49.323647  3675 solver.cpp:243] Iteration 47780, loss = 0.00163703
I0521 12:00:49.323679  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00163693 (* 1 = 0.00163693 loss)
I0521 12:00:49.323685  3675 sgd_solver.cpp:138] Iteration 47780, lr = 6.25e-06
I0521 12:00:52.841356  3675 solver.cpp:243] Iteration 47800, loss = 0.00259444
I0521 12:00:52.841513  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00259433 (* 1 = 0.00259433 loss)
I0521 12:00:52.841521  3675 sgd_solver.cpp:138] Iteration 47800, lr = 6.25e-06
I0521 12:00:56.358217  3675 solver.cpp:243] Iteration 47820, loss = 0.00171046
I0521 12:00:56.358248  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00171036 (* 1 = 0.00171036 loss)
I0521 12:00:56.358255  3675 sgd_solver.cpp:138] Iteration 47820, lr = 6.25e-06
I0521 12:00:59.875346  3675 solver.cpp:243] Iteration 47840, loss = 0.0023325
I0521 12:00:59.875380  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00233239 (* 1 = 0.00233239 loss)
I0521 12:00:59.875386  3675 sgd_solver.cpp:138] Iteration 47840, lr = 6.25e-06
I0521 12:01:03.393085  3675 solver.cpp:243] Iteration 47860, loss = 0.00159391
I0521 12:01:03.393116  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0015938 (* 1 = 0.0015938 loss)
I0521 12:01:03.393138  3675 sgd_solver.cpp:138] Iteration 47860, lr = 6.25e-06
I0521 12:01:06.909179  3675 solver.cpp:243] Iteration 47880, loss = 0.00150592
I0521 12:01:06.909210  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00150581 (* 1 = 0.00150581 loss)
I0521 12:01:06.909216  3675 sgd_solver.cpp:138] Iteration 47880, lr = 6.25e-06
I0521 12:01:10.430874  3675 solver.cpp:243] Iteration 47900, loss = 0.00214828
I0521 12:01:10.430909  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00214817 (* 1 = 0.00214817 loss)
I0521 12:01:10.430917  3675 sgd_solver.cpp:138] Iteration 47900, lr = 6.25e-06
I0521 12:01:13.951488  3675 solver.cpp:243] Iteration 47920, loss = 0.00217941
I0521 12:01:13.951519  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00217931 (* 1 = 0.00217931 loss)
I0521 12:01:13.951525  3675 sgd_solver.cpp:138] Iteration 47920, lr = 6.25e-06
I0521 12:01:17.471129  3675 solver.cpp:243] Iteration 47940, loss = 0.00177069
I0521 12:01:17.471161  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00177058 (* 1 = 0.00177058 loss)
I0521 12:01:17.471168  3675 sgd_solver.cpp:138] Iteration 47940, lr = 6.25e-06
I0521 12:01:20.987865  3675 solver.cpp:243] Iteration 47960, loss = 0.00193184
I0521 12:01:20.987896  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00193173 (* 1 = 0.00193173 loss)
I0521 12:01:20.987902  3675 sgd_solver.cpp:138] Iteration 47960, lr = 6.25e-06
I0521 12:01:24.504515  3675 solver.cpp:243] Iteration 47980, loss = 0.00173408
I0521 12:01:24.504679  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00173398 (* 1 = 0.00173398 loss)
I0521 12:01:24.504688  3675 sgd_solver.cpp:138] Iteration 47980, lr = 6.25e-06
I0521 12:01:27.890024  3675 solver.cpp:596] Snapshotting to binary proto file models/LPR/lpr_resnet_lstm_iter_48000.caffemodel
I0521 12:01:27.917197  3675 sgd_solver.cpp:307] Snapshotting solver state to binary proto file models/LPR/lpr_resnet_lstm_iter_48000.solverstate
I0521 12:01:27.932065  3675 solver.cpp:358] Iteration 48000, Testing net (#0)
I0521 12:01:32.666851  3675 solver.cpp:425]     Test net output #0: acc = 1
I0521 12:01:32.666878  3675 solver.cpp:425]     Test net output #1: acc = 1
I0521 12:01:32.666885  3675 solver.cpp:425]     Test net output #2: ctcloss = 0.00064206 (* 1 = 0.00064206 loss)
I0521 12:01:32.802842  3675 solver.cpp:243] Iteration 48000, loss = 0.00246037
I0521 12:01:32.802872  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00246027 (* 1 = 0.00246027 loss)
I0521 12:01:32.802879  3675 sgd_solver.cpp:138] Iteration 48000, lr = 6.25e-06
I0521 12:01:36.318565  3675 solver.cpp:243] Iteration 48020, loss = 0.00218132
I0521 12:01:36.318596  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00218121 (* 1 = 0.00218121 loss)
I0521 12:01:36.318603  3675 sgd_solver.cpp:138] Iteration 48020, lr = 6.25e-06
I0521 12:01:39.837419  3675 solver.cpp:243] Iteration 48040, loss = 0.00196039
I0521 12:01:39.837448  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00196029 (* 1 = 0.00196029 loss)
I0521 12:01:39.837456  3675 sgd_solver.cpp:138] Iteration 48040, lr = 6.25e-06
I0521 12:01:43.354460  3675 solver.cpp:243] Iteration 48060, loss = 0.00155968
I0521 12:01:43.354491  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00155957 (* 1 = 0.00155957 loss)
I0521 12:01:43.354497  3675 sgd_solver.cpp:138] Iteration 48060, lr = 6.25e-06
I0521 12:01:46.876354  3675 solver.cpp:243] Iteration 48080, loss = 0.00203939
I0521 12:01:46.876384  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00203928 (* 1 = 0.00203928 loss)
I0521 12:01:46.876391  3675 sgd_solver.cpp:138] Iteration 48080, lr = 6.25e-06
I0521 12:01:50.399618  3675 solver.cpp:243] Iteration 48100, loss = 0.0019818
I0521 12:01:50.399650  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00198169 (* 1 = 0.00198169 loss)
I0521 12:01:50.399657  3675 sgd_solver.cpp:138] Iteration 48100, lr = 6.25e-06
I0521 12:01:53.914264  3675 solver.cpp:243] Iteration 48120, loss = 0.00214123
I0521 12:01:53.914296  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00214112 (* 1 = 0.00214112 loss)
I0521 12:01:53.914319  3675 sgd_solver.cpp:138] Iteration 48120, lr = 6.25e-06
I0521 12:01:57.432461  3675 solver.cpp:243] Iteration 48140, loss = 0.00318608
I0521 12:01:57.432626  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00318598 (* 1 = 0.00318598 loss)
I0521 12:01:57.432634  3675 sgd_solver.cpp:138] Iteration 48140, lr = 6.25e-06
I0521 12:02:00.959569  3675 solver.cpp:243] Iteration 48160, loss = 0.00155871
I0521 12:02:00.959601  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00155861 (* 1 = 0.00155861 loss)
I0521 12:02:00.959609  3675 sgd_solver.cpp:138] Iteration 48160, lr = 6.25e-06
I0521 12:02:04.411437  3675 solver.cpp:243] Iteration 48180, loss = 0.00273181
I0521 12:02:04.411468  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00273171 (* 1 = 0.00273171 loss)
I0521 12:02:04.411473  3675 sgd_solver.cpp:138] Iteration 48180, lr = 6.25e-06
I0521 12:02:07.927719  3675 solver.cpp:243] Iteration 48200, loss = 0.00197001
I0521 12:02:07.927750  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0019699 (* 1 = 0.0019699 loss)
I0521 12:02:07.927757  3675 sgd_solver.cpp:138] Iteration 48200, lr = 6.25e-06
I0521 12:02:11.448966  3675 solver.cpp:243] Iteration 48220, loss = 0.0023422
I0521 12:02:11.448998  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00234209 (* 1 = 0.00234209 loss)
I0521 12:02:11.449004  3675 sgd_solver.cpp:138] Iteration 48220, lr = 6.25e-06
I0521 12:02:14.964105  3675 solver.cpp:243] Iteration 48240, loss = 0.00207563
I0521 12:02:14.964134  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00207553 (* 1 = 0.00207553 loss)
I0521 12:02:14.964140  3675 sgd_solver.cpp:138] Iteration 48240, lr = 6.25e-06
I0521 12:02:18.487548  3675 solver.cpp:243] Iteration 48260, loss = 0.00163987
I0521 12:02:18.487579  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00163976 (* 1 = 0.00163976 loss)
I0521 12:02:18.487586  3675 sgd_solver.cpp:138] Iteration 48260, lr = 6.25e-06
I0521 12:02:22.007418  3675 solver.cpp:243] Iteration 48280, loss = 0.00251279
I0521 12:02:22.007448  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00251268 (* 1 = 0.00251268 loss)
I0521 12:02:22.007455  3675 sgd_solver.cpp:138] Iteration 48280, lr = 6.25e-06
I0521 12:02:25.525346  3675 solver.cpp:243] Iteration 48300, loss = 0.00147474
I0521 12:02:25.525377  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00147463 (* 1 = 0.00147463 loss)
I0521 12:02:25.525382  3675 sgd_solver.cpp:138] Iteration 48300, lr = 6.25e-06
I0521 12:02:29.047066  3675 solver.cpp:243] Iteration 48320, loss = 0.00226999
I0521 12:02:29.047255  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00226988 (* 1 = 0.00226988 loss)
I0521 12:02:29.047262  3675 sgd_solver.cpp:138] Iteration 48320, lr = 6.25e-06
I0521 12:02:32.563874  3675 solver.cpp:243] Iteration 48340, loss = 0.0027684
I0521 12:02:32.563907  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0027683 (* 1 = 0.0027683 loss)
I0521 12:02:32.563915  3675 sgd_solver.cpp:138] Iteration 48340, lr = 6.25e-06
I0521 12:02:36.083624  3675 solver.cpp:243] Iteration 48360, loss = 0.0020738
I0521 12:02:36.083654  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00207369 (* 1 = 0.00207369 loss)
I0521 12:02:36.083678  3675 sgd_solver.cpp:138] Iteration 48360, lr = 6.25e-06
I0521 12:02:39.602385  3675 solver.cpp:243] Iteration 48380, loss = 0.00135729
I0521 12:02:39.602416  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00135719 (* 1 = 0.00135719 loss)
I0521 12:02:39.602437  3675 sgd_solver.cpp:138] Iteration 48380, lr = 6.25e-06
I0521 12:02:43.120885  3675 solver.cpp:243] Iteration 48400, loss = 0.00142408
I0521 12:02:43.120918  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00142398 (* 1 = 0.00142398 loss)
I0521 12:02:43.120924  3675 sgd_solver.cpp:138] Iteration 48400, lr = 6.25e-06
I0521 12:02:46.639268  3675 solver.cpp:243] Iteration 48420, loss = 0.00274322
I0521 12:02:46.639299  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00274311 (* 1 = 0.00274311 loss)
I0521 12:02:46.639307  3675 sgd_solver.cpp:138] Iteration 48420, lr = 6.25e-06
I0521 12:02:50.153702  3675 solver.cpp:243] Iteration 48440, loss = 0.00251975
I0521 12:02:50.153731  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00251964 (* 1 = 0.00251964 loss)
I0521 12:02:50.153738  3675 sgd_solver.cpp:138] Iteration 48440, lr = 6.25e-06
I0521 12:02:53.669030  3675 solver.cpp:243] Iteration 48460, loss = 0.0014293
I0521 12:02:53.669062  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00142919 (* 1 = 0.00142919 loss)
I0521 12:02:53.669070  3675 sgd_solver.cpp:138] Iteration 48460, lr = 6.25e-06
I0521 12:02:57.180976  3675 solver.cpp:243] Iteration 48480, loss = 0.00193362
I0521 12:02:57.181007  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00193351 (* 1 = 0.00193351 loss)
I0521 12:02:57.181015  3675 sgd_solver.cpp:138] Iteration 48480, lr = 6.25e-06
I0521 12:03:00.695379  3675 solver.cpp:243] Iteration 48500, loss = 0.00186572
I0521 12:03:00.695499  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00186561 (* 1 = 0.00186561 loss)
I0521 12:03:00.695506  3675 sgd_solver.cpp:138] Iteration 48500, lr = 6.25e-06
I0521 12:03:04.212417  3675 solver.cpp:243] Iteration 48520, loss = 0.00242661
I0521 12:03:04.212450  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0024265 (* 1 = 0.0024265 loss)
I0521 12:03:04.212471  3675 sgd_solver.cpp:138] Iteration 48520, lr = 6.25e-06
I0521 12:03:07.728104  3675 solver.cpp:243] Iteration 48540, loss = 0.0021403
I0521 12:03:07.728134  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00214019 (* 1 = 0.00214019 loss)
I0521 12:03:07.728157  3675 sgd_solver.cpp:138] Iteration 48540, lr = 6.25e-06
I0521 12:03:11.247593  3675 solver.cpp:243] Iteration 48560, loss = 0.00159176
I0521 12:03:11.247624  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00159166 (* 1 = 0.00159166 loss)
I0521 12:03:11.247647  3675 sgd_solver.cpp:138] Iteration 48560, lr = 6.25e-06
I0521 12:03:14.762944  3675 solver.cpp:243] Iteration 48580, loss = 0.00229022
I0521 12:03:14.762974  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00229012 (* 1 = 0.00229012 loss)
I0521 12:03:14.762980  3675 sgd_solver.cpp:138] Iteration 48580, lr = 6.25e-06
I0521 12:03:18.281440  3675 solver.cpp:243] Iteration 48600, loss = 0.00276142
I0521 12:03:18.281471  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00276132 (* 1 = 0.00276132 loss)
I0521 12:03:18.281476  3675 sgd_solver.cpp:138] Iteration 48600, lr = 6.25e-06
I0521 12:03:21.793802  3675 solver.cpp:243] Iteration 48620, loss = 0.00169837
I0521 12:03:21.793833  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00169826 (* 1 = 0.00169826 loss)
I0521 12:03:21.793838  3675 sgd_solver.cpp:138] Iteration 48620, lr = 6.25e-06
I0521 12:03:25.310281  3675 solver.cpp:243] Iteration 48640, loss = 0.0016172
I0521 12:03:25.310312  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00161709 (* 1 = 0.00161709 loss)
I0521 12:03:25.310319  3675 sgd_solver.cpp:138] Iteration 48640, lr = 6.25e-06
I0521 12:03:28.827479  3675 solver.cpp:243] Iteration 48660, loss = 0.00142205
I0521 12:03:28.827510  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00142195 (* 1 = 0.00142195 loss)
I0521 12:03:28.827517  3675 sgd_solver.cpp:138] Iteration 48660, lr = 6.25e-06
I0521 12:03:32.354243  3675 solver.cpp:243] Iteration 48680, loss = 0.00192561
I0521 12:03:32.354379  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0019255 (* 1 = 0.0019255 loss)
I0521 12:03:32.354387  3675 sgd_solver.cpp:138] Iteration 48680, lr = 6.25e-06
I0521 12:03:35.869863  3675 solver.cpp:243] Iteration 48700, loss = 0.00159656
I0521 12:03:35.869895  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00159646 (* 1 = 0.00159646 loss)
I0521 12:03:35.869901  3675 sgd_solver.cpp:138] Iteration 48700, lr = 6.25e-06
I0521 12:03:39.387205  3675 solver.cpp:243] Iteration 48720, loss = 0.00259555
I0521 12:03:39.387236  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00259544 (* 1 = 0.00259544 loss)
I0521 12:03:39.387259  3675 sgd_solver.cpp:138] Iteration 48720, lr = 6.25e-06
I0521 12:03:42.906306  3675 solver.cpp:243] Iteration 48740, loss = 0.00236335
I0521 12:03:42.906338  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00236324 (* 1 = 0.00236324 loss)
I0521 12:03:42.906344  3675 sgd_solver.cpp:138] Iteration 48740, lr = 6.25e-06
I0521 12:03:46.428741  3675 solver.cpp:243] Iteration 48760, loss = 0.00159764
I0521 12:03:46.428773  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00159753 (* 1 = 0.00159753 loss)
I0521 12:03:46.428779  3675 sgd_solver.cpp:138] Iteration 48760, lr = 6.25e-06
I0521 12:03:49.952708  3675 solver.cpp:243] Iteration 48780, loss = 0.00141711
I0521 12:03:49.952739  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.001417 (* 1 = 0.001417 loss)
I0521 12:03:49.952744  3675 sgd_solver.cpp:138] Iteration 48780, lr = 6.25e-06
I0521 12:03:53.470118  3675 solver.cpp:243] Iteration 48800, loss = 0.00207191
I0521 12:03:53.470149  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0020718 (* 1 = 0.0020718 loss)
I0521 12:03:53.470155  3675 sgd_solver.cpp:138] Iteration 48800, lr = 6.25e-06
I0521 12:03:56.991842  3675 solver.cpp:243] Iteration 48820, loss = 0.00156947
I0521 12:03:56.991874  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00156936 (* 1 = 0.00156936 loss)
I0521 12:03:56.991879  3675 sgd_solver.cpp:138] Iteration 48820, lr = 6.25e-06
I0521 12:04:00.508366  3675 solver.cpp:243] Iteration 48840, loss = 0.00152788
I0521 12:04:00.508397  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00152777 (* 1 = 0.00152777 loss)
I0521 12:04:00.508420  3675 sgd_solver.cpp:138] Iteration 48840, lr = 6.25e-06
I0521 12:04:04.027901  3675 solver.cpp:243] Iteration 48860, loss = 0.00168851
I0521 12:04:04.028059  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00168841 (* 1 = 0.00168841 loss)
I0521 12:04:04.028067  3675 sgd_solver.cpp:138] Iteration 48860, lr = 6.25e-06
I0521 12:04:07.551430  3675 solver.cpp:243] Iteration 48880, loss = 0.0019517
I0521 12:04:07.551461  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0019516 (* 1 = 0.0019516 loss)
I0521 12:04:07.551468  3675 sgd_solver.cpp:138] Iteration 48880, lr = 6.25e-06
I0521 12:04:11.072154  3675 solver.cpp:243] Iteration 48900, loss = 0.00188208
I0521 12:04:11.072185  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00188197 (* 1 = 0.00188197 loss)
I0521 12:04:11.072190  3675 sgd_solver.cpp:138] Iteration 48900, lr = 6.25e-06
I0521 12:04:14.588363  3675 solver.cpp:243] Iteration 48920, loss = 0.00213403
I0521 12:04:14.588394  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00213392 (* 1 = 0.00213392 loss)
I0521 12:04:14.588400  3675 sgd_solver.cpp:138] Iteration 48920, lr = 6.25e-06
I0521 12:04:18.107637  3675 solver.cpp:243] Iteration 48940, loss = 0.00197186
I0521 12:04:18.107671  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00197175 (* 1 = 0.00197175 loss)
I0521 12:04:18.107676  3675 sgd_solver.cpp:138] Iteration 48940, lr = 6.25e-06
I0521 12:04:21.625170  3675 solver.cpp:243] Iteration 48960, loss = 0.00260903
I0521 12:04:21.625201  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00260892 (* 1 = 0.00260892 loss)
I0521 12:04:21.625207  3675 sgd_solver.cpp:138] Iteration 48960, lr = 6.25e-06
I0521 12:04:25.140442  3675 solver.cpp:243] Iteration 48980, loss = 0.00266226
I0521 12:04:25.140475  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00266216 (* 1 = 0.00266216 loss)
I0521 12:04:25.140480  3675 sgd_solver.cpp:138] Iteration 48980, lr = 6.25e-06
I0521 12:04:28.530997  3675 solver.cpp:358] Iteration 49000, Testing net (#0)
I0521 12:04:33.264106  3675 solver.cpp:425]     Test net output #0: acc = 1
I0521 12:04:33.264134  3675 solver.cpp:425]     Test net output #1: acc = 1
I0521 12:04:33.264140  3675 solver.cpp:425]     Test net output #2: ctcloss = 0.000640423 (* 1 = 0.000640423 loss)
I0521 12:04:33.398299  3675 solver.cpp:243] Iteration 49000, loss = 0.00266334
I0521 12:04:33.398329  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00266324 (* 1 = 0.00266324 loss)
I0521 12:04:33.398335  3675 sgd_solver.cpp:138] Iteration 49000, lr = 6.25e-06
I0521 12:04:36.913000  3675 solver.cpp:243] Iteration 49020, loss = 0.00172368
I0521 12:04:36.913127  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00172358 (* 1 = 0.00172358 loss)
I0521 12:04:36.913134  3675 sgd_solver.cpp:138] Iteration 49020, lr = 6.25e-06
I0521 12:04:40.423663  3675 solver.cpp:243] Iteration 49040, loss = 0.00419253
I0521 12:04:40.423694  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00419242 (* 1 = 0.00419242 loss)
I0521 12:04:40.423717  3675 sgd_solver.cpp:138] Iteration 49040, lr = 6.25e-06
I0521 12:04:43.943327  3675 solver.cpp:243] Iteration 49060, loss = 0.00273266
I0521 12:04:43.943359  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00273256 (* 1 = 0.00273256 loss)
I0521 12:04:43.943367  3675 sgd_solver.cpp:138] Iteration 49060, lr = 6.25e-06
I0521 12:04:47.457623  3675 solver.cpp:243] Iteration 49080, loss = 0.00180355
I0521 12:04:47.457653  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00180344 (* 1 = 0.00180344 loss)
I0521 12:04:47.457675  3675 sgd_solver.cpp:138] Iteration 49080, lr = 6.25e-06
I0521 12:04:50.972627  3675 solver.cpp:243] Iteration 49100, loss = 0.00185087
I0521 12:04:50.972658  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00185076 (* 1 = 0.00185076 loss)
I0521 12:04:50.972664  3675 sgd_solver.cpp:138] Iteration 49100, lr = 6.25e-06
I0521 12:04:54.486204  3675 solver.cpp:243] Iteration 49120, loss = 0.00148452
I0521 12:04:54.486238  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00148441 (* 1 = 0.00148441 loss)
I0521 12:04:54.486243  3675 sgd_solver.cpp:138] Iteration 49120, lr = 6.25e-06
I0521 12:04:58.001793  3675 solver.cpp:243] Iteration 49140, loss = 0.0015584
I0521 12:04:58.001833  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0015583 (* 1 = 0.0015583 loss)
I0521 12:04:58.001840  3675 sgd_solver.cpp:138] Iteration 49140, lr = 6.25e-06
I0521 12:05:01.508812  3675 solver.cpp:243] Iteration 49160, loss = 0.00179315
I0521 12:05:01.508844  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00179304 (* 1 = 0.00179304 loss)
I0521 12:05:01.508867  3675 sgd_solver.cpp:138] Iteration 49160, lr = 6.25e-06
I0521 12:05:05.024070  3675 solver.cpp:243] Iteration 49180, loss = 0.00157307
I0521 12:05:05.024099  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00157296 (* 1 = 0.00157296 loss)
I0521 12:05:05.024106  3675 sgd_solver.cpp:138] Iteration 49180, lr = 6.25e-06
I0521 12:05:08.538410  3675 solver.cpp:243] Iteration 49200, loss = 0.00206119
I0521 12:05:08.538600  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00206108 (* 1 = 0.00206108 loss)
I0521 12:05:08.538609  3675 sgd_solver.cpp:138] Iteration 49200, lr = 6.25e-06
I0521 12:05:12.048777  3675 solver.cpp:243] Iteration 49220, loss = 0.00167208
I0521 12:05:12.048810  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00167197 (* 1 = 0.00167197 loss)
I0521 12:05:12.048831  3675 sgd_solver.cpp:138] Iteration 49220, lr = 6.25e-06
I0521 12:05:15.564891  3675 solver.cpp:243] Iteration 49240, loss = 0.00221633
I0521 12:05:15.564923  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00221622 (* 1 = 0.00221622 loss)
I0521 12:05:15.564929  3675 sgd_solver.cpp:138] Iteration 49240, lr = 6.25e-06
I0521 12:05:19.082571  3675 solver.cpp:243] Iteration 49260, loss = 0.00199534
I0521 12:05:19.082602  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00199523 (* 1 = 0.00199523 loss)
I0521 12:05:19.082607  3675 sgd_solver.cpp:138] Iteration 49260, lr = 6.25e-06
I0521 12:05:22.589234  3675 solver.cpp:243] Iteration 49280, loss = 0.00157913
I0521 12:05:22.589265  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00157902 (* 1 = 0.00157902 loss)
I0521 12:05:22.589287  3675 sgd_solver.cpp:138] Iteration 49280, lr = 6.25e-06
I0521 12:05:26.100221  3675 solver.cpp:243] Iteration 49300, loss = 0.00191067
I0521 12:05:26.100251  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00191056 (* 1 = 0.00191056 loss)
I0521 12:05:26.100257  3675 sgd_solver.cpp:138] Iteration 49300, lr = 6.25e-06
I0521 12:05:29.610452  3675 solver.cpp:243] Iteration 49320, loss = 0.00189721
I0521 12:05:29.610484  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00189711 (* 1 = 0.00189711 loss)
I0521 12:05:29.610491  3675 sgd_solver.cpp:138] Iteration 49320, lr = 6.25e-06
I0521 12:05:33.123023  3675 solver.cpp:243] Iteration 49340, loss = 0.00164572
I0521 12:05:33.123054  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00164562 (* 1 = 0.00164562 loss)
I0521 12:05:33.123060  3675 sgd_solver.cpp:138] Iteration 49340, lr = 6.25e-06
I0521 12:05:36.639058  3675 solver.cpp:243] Iteration 49360, loss = 0.00165997
I0521 12:05:36.639091  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00165986 (* 1 = 0.00165986 loss)
I0521 12:05:36.639096  3675 sgd_solver.cpp:138] Iteration 49360, lr = 6.25e-06
I0521 12:05:40.150949  3675 solver.cpp:243] Iteration 49380, loss = 0.00150626
I0521 12:05:40.151021  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00150616 (* 1 = 0.00150616 loss)
I0521 12:05:40.151027  3675 sgd_solver.cpp:138] Iteration 49380, lr = 6.25e-06
I0521 12:05:43.663709  3675 solver.cpp:243] Iteration 49400, loss = 0.00156426
I0521 12:05:43.663740  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00156415 (* 1 = 0.00156415 loss)
I0521 12:05:43.663748  3675 sgd_solver.cpp:138] Iteration 49400, lr = 6.25e-06
I0521 12:05:47.174863  3675 solver.cpp:243] Iteration 49420, loss = 0.00194658
I0521 12:05:47.174895  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00194648 (* 1 = 0.00194648 loss)
I0521 12:05:47.174901  3675 sgd_solver.cpp:138] Iteration 49420, lr = 6.25e-06
I0521 12:05:50.686975  3675 solver.cpp:243] Iteration 49440, loss = 0.00174516
I0521 12:05:50.687007  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00174505 (* 1 = 0.00174505 loss)
I0521 12:05:50.687013  3675 sgd_solver.cpp:138] Iteration 49440, lr = 6.25e-06
I0521 12:05:54.199263  3675 solver.cpp:243] Iteration 49460, loss = 0.00174423
I0521 12:05:54.199296  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00174412 (* 1 = 0.00174412 loss)
I0521 12:05:54.199303  3675 sgd_solver.cpp:138] Iteration 49460, lr = 6.25e-06
I0521 12:05:57.641438  3675 solver.cpp:243] Iteration 49480, loss = 0.00217618
I0521 12:05:57.641471  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00217608 (* 1 = 0.00217608 loss)
I0521 12:05:57.641479  3675 sgd_solver.cpp:138] Iteration 49480, lr = 6.25e-06
I0521 12:06:01.154965  3675 solver.cpp:243] Iteration 49500, loss = 0.00220876
I0521 12:06:01.154997  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00220866 (* 1 = 0.00220866 loss)
I0521 12:06:01.155004  3675 sgd_solver.cpp:138] Iteration 49500, lr = 6.25e-06
I0521 12:06:04.670558  3675 solver.cpp:243] Iteration 49520, loss = 0.00160867
I0521 12:06:04.670589  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00160857 (* 1 = 0.00160857 loss)
I0521 12:06:04.670595  3675 sgd_solver.cpp:138] Iteration 49520, lr = 6.25e-06
I0521 12:06:08.180750  3675 solver.cpp:243] Iteration 49540, loss = 0.00218132
I0521 12:06:08.180780  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00218121 (* 1 = 0.00218121 loss)
I0521 12:06:08.180789  3675 sgd_solver.cpp:138] Iteration 49540, lr = 6.25e-06
I0521 12:06:11.694743  3675 solver.cpp:243] Iteration 49560, loss = 0.00198934
I0521 12:06:11.694877  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00198923 (* 1 = 0.00198923 loss)
I0521 12:06:11.694886  3675 sgd_solver.cpp:138] Iteration 49560, lr = 6.25e-06
I0521 12:06:15.208129  3675 solver.cpp:243] Iteration 49580, loss = 0.00144587
I0521 12:06:15.208160  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00144576 (* 1 = 0.00144576 loss)
I0521 12:06:15.208166  3675 sgd_solver.cpp:138] Iteration 49580, lr = 6.25e-06
I0521 12:06:18.721372  3675 solver.cpp:243] Iteration 49600, loss = 0.00197574
I0521 12:06:18.721405  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00197564 (* 1 = 0.00197564 loss)
I0521 12:06:18.721412  3675 sgd_solver.cpp:138] Iteration 49600, lr = 6.25e-06
I0521 12:06:22.234309  3675 solver.cpp:243] Iteration 49620, loss = 0.00116629
I0521 12:06:22.234341  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00116619 (* 1 = 0.00116619 loss)
I0521 12:06:22.234347  3675 sgd_solver.cpp:138] Iteration 49620, lr = 6.25e-06
I0521 12:06:25.745940  3675 solver.cpp:243] Iteration 49640, loss = 0.00177612
I0521 12:06:25.745972  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00177601 (* 1 = 0.00177601 loss)
I0521 12:06:25.745980  3675 sgd_solver.cpp:138] Iteration 49640, lr = 6.25e-06
I0521 12:06:29.257614  3675 solver.cpp:243] Iteration 49660, loss = 0.00135094
I0521 12:06:29.257645  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00135083 (* 1 = 0.00135083 loss)
I0521 12:06:29.257652  3675 sgd_solver.cpp:138] Iteration 49660, lr = 6.25e-06
I0521 12:06:32.768527  3675 solver.cpp:243] Iteration 49680, loss = 0.00194798
I0521 12:06:32.768558  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00194788 (* 1 = 0.00194788 loss)
I0521 12:06:32.768581  3675 sgd_solver.cpp:138] Iteration 49680, lr = 6.25e-06
I0521 12:06:36.279947  3675 solver.cpp:243] Iteration 49700, loss = 0.00180901
I0521 12:06:36.279978  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0018089 (* 1 = 0.0018089 loss)
I0521 12:06:36.279984  3675 sgd_solver.cpp:138] Iteration 49700, lr = 6.25e-06
I0521 12:06:39.799742  3675 solver.cpp:243] Iteration 49720, loss = 0.00173028
I0521 12:06:39.799773  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00173018 (* 1 = 0.00173018 loss)
I0521 12:06:39.799795  3675 sgd_solver.cpp:138] Iteration 49720, lr = 6.25e-06
I0521 12:06:43.310617  3675 solver.cpp:243] Iteration 49740, loss = 0.00146116
I0521 12:06:43.310750  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00146106 (* 1 = 0.00146106 loss)
I0521 12:06:43.310760  3675 sgd_solver.cpp:138] Iteration 49740, lr = 6.25e-06
I0521 12:06:46.825971  3675 solver.cpp:243] Iteration 49760, loss = 0.00224509
I0521 12:06:46.826004  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00224498 (* 1 = 0.00224498 loss)
I0521 12:06:46.826025  3675 sgd_solver.cpp:138] Iteration 49760, lr = 6.25e-06
I0521 12:06:50.337317  3675 solver.cpp:243] Iteration 49780, loss = 0.00258211
I0521 12:06:50.337348  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.002582 (* 1 = 0.002582 loss)
I0521 12:06:50.337354  3675 sgd_solver.cpp:138] Iteration 49780, lr = 6.25e-06
I0521 12:06:53.848405  3675 solver.cpp:243] Iteration 49800, loss = 0.00238952
I0521 12:06:53.848438  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00238941 (* 1 = 0.00238941 loss)
I0521 12:06:53.848443  3675 sgd_solver.cpp:138] Iteration 49800, lr = 6.25e-06
I0521 12:06:57.364241  3675 solver.cpp:243] Iteration 49820, loss = 0.0021077
I0521 12:06:57.364272  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0021076 (* 1 = 0.0021076 loss)
I0521 12:06:57.364279  3675 sgd_solver.cpp:138] Iteration 49820, lr = 6.25e-06
I0521 12:07:00.878846  3675 solver.cpp:243] Iteration 49840, loss = 0.00250362
I0521 12:07:00.878877  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00250352 (* 1 = 0.00250352 loss)
I0521 12:07:00.878882  3675 sgd_solver.cpp:138] Iteration 49840, lr = 6.25e-06
I0521 12:07:04.393184  3675 solver.cpp:243] Iteration 49860, loss = 0.00128086
I0521 12:07:04.393218  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00128075 (* 1 = 0.00128075 loss)
I0521 12:07:04.393224  3675 sgd_solver.cpp:138] Iteration 49860, lr = 6.25e-06
I0521 12:07:07.901224  3675 solver.cpp:243] Iteration 49880, loss = 0.00162007
I0521 12:07:07.901254  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00161996 (* 1 = 0.00161996 loss)
I0521 12:07:07.901259  3675 sgd_solver.cpp:138] Iteration 49880, lr = 6.25e-06
I0521 12:07:11.416846  3675 solver.cpp:243] Iteration 49900, loss = 0.00169314
I0521 12:07:11.416875  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00169303 (* 1 = 0.00169303 loss)
I0521 12:07:11.416882  3675 sgd_solver.cpp:138] Iteration 49900, lr = 6.25e-06
I0521 12:07:14.932284  3675 solver.cpp:243] Iteration 49920, loss = 0.0028863
I0521 12:07:14.932410  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00288619 (* 1 = 0.00288619 loss)
I0521 12:07:14.932418  3675 sgd_solver.cpp:138] Iteration 49920, lr = 6.25e-06
I0521 12:07:18.449801  3675 solver.cpp:243] Iteration 49940, loss = 0.00210969
I0521 12:07:18.449831  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00210959 (* 1 = 0.00210959 loss)
I0521 12:07:18.449853  3675 sgd_solver.cpp:138] Iteration 49940, lr = 6.25e-06
I0521 12:07:21.966198  3675 solver.cpp:243] Iteration 49960, loss = 0.00219695
I0521 12:07:21.966230  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00219685 (* 1 = 0.00219685 loss)
I0521 12:07:21.966238  3675 sgd_solver.cpp:138] Iteration 49960, lr = 6.25e-06
I0521 12:07:25.481020  3675 solver.cpp:243] Iteration 49980, loss = 0.00229138
I0521 12:07:25.481053  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00229127 (* 1 = 0.00229127 loss)
I0521 12:07:25.481058  3675 sgd_solver.cpp:138] Iteration 49980, lr = 6.25e-06
I0521 12:07:28.866230  3675 solver.cpp:596] Snapshotting to binary proto file models/LPR/lpr_resnet_lstm_iter_50000.caffemodel
I0521 12:07:28.893065  3675 sgd_solver.cpp:307] Snapshotting solver state to binary proto file models/LPR/lpr_resnet_lstm_iter_50000.solverstate
I0521 12:07:28.907725  3675 solver.cpp:358] Iteration 50000, Testing net (#0)
I0521 12:07:33.645159  3675 solver.cpp:425]     Test net output #0: acc = 1
I0521 12:07:33.645186  3675 solver.cpp:425]     Test net output #1: acc = 1
I0521 12:07:33.645193  3675 solver.cpp:425]     Test net output #2: ctcloss = 0.000638064 (* 1 = 0.000638064 loss)
I0521 12:07:33.779526  3675 solver.cpp:243] Iteration 50000, loss = 0.00186904
I0521 12:07:33.779557  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00186893 (* 1 = 0.00186893 loss)
I0521 12:07:33.779580  3675 sgd_solver.cpp:138] Iteration 50000, lr = 3.125e-06
I0521 12:07:37.294344  3675 solver.cpp:243] Iteration 50020, loss = 0.0013784
I0521 12:07:37.294375  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00137829 (* 1 = 0.00137829 loss)
I0521 12:07:37.294380  3675 sgd_solver.cpp:138] Iteration 50020, lr = 3.125e-06
I0521 12:07:40.805917  3675 solver.cpp:243] Iteration 50040, loss = 0.00167587
I0521 12:07:40.805949  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00167577 (* 1 = 0.00167577 loss)
I0521 12:07:40.805956  3675 sgd_solver.cpp:138] Iteration 50040, lr = 3.125e-06
I0521 12:07:44.313293  3675 solver.cpp:243] Iteration 50060, loss = 0.00170598
I0521 12:07:44.313323  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00170588 (* 1 = 0.00170588 loss)
I0521 12:07:44.313345  3675 sgd_solver.cpp:138] Iteration 50060, lr = 3.125e-06
I0521 12:07:47.824522  3675 solver.cpp:243] Iteration 50080, loss = 0.00238523
I0521 12:07:47.824692  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00238512 (* 1 = 0.00238512 loss)
I0521 12:07:47.824699  3675 sgd_solver.cpp:138] Iteration 50080, lr = 3.125e-06
I0521 12:07:51.338768  3675 solver.cpp:243] Iteration 50100, loss = 0.00124119
I0521 12:07:51.338798  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00124108 (* 1 = 0.00124108 loss)
I0521 12:07:51.338804  3675 sgd_solver.cpp:138] Iteration 50100, lr = 3.125e-06
I0521 12:07:54.849704  3675 solver.cpp:243] Iteration 50120, loss = 0.00171738
I0521 12:07:54.849735  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00171727 (* 1 = 0.00171727 loss)
I0521 12:07:54.849757  3675 sgd_solver.cpp:138] Iteration 50120, lr = 3.125e-06
I0521 12:07:58.361582  3675 solver.cpp:243] Iteration 50140, loss = 0.00161662
I0521 12:07:58.361610  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00161651 (* 1 = 0.00161651 loss)
I0521 12:07:58.361616  3675 sgd_solver.cpp:138] Iteration 50140, lr = 3.125e-06
I0521 12:08:01.876338  3675 solver.cpp:243] Iteration 50160, loss = 0.00186008
I0521 12:08:01.876370  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00185997 (* 1 = 0.00185997 loss)
I0521 12:08:01.876377  3675 sgd_solver.cpp:138] Iteration 50160, lr = 3.125e-06
I0521 12:08:05.388429  3675 solver.cpp:243] Iteration 50180, loss = 0.00625435
I0521 12:08:05.388460  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00625424 (* 1 = 0.00625424 loss)
I0521 12:08:05.388466  3675 sgd_solver.cpp:138] Iteration 50180, lr = 3.125e-06
I0521 12:08:08.897423  3675 solver.cpp:243] Iteration 50200, loss = 0.00215092
I0521 12:08:08.897452  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00215081 (* 1 = 0.00215081 loss)
I0521 12:08:08.897459  3675 sgd_solver.cpp:138] Iteration 50200, lr = 3.125e-06
I0521 12:08:12.412148  3675 solver.cpp:243] Iteration 50220, loss = 0.00204149
I0521 12:08:12.412180  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00204138 (* 1 = 0.00204138 loss)
I0521 12:08:12.412202  3675 sgd_solver.cpp:138] Iteration 50220, lr = 3.125e-06
I0521 12:08:15.925484  3675 solver.cpp:243] Iteration 50240, loss = 0.00244487
I0521 12:08:15.925515  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00244476 (* 1 = 0.00244476 loss)
I0521 12:08:15.925521  3675 sgd_solver.cpp:138] Iteration 50240, lr = 3.125e-06
I0521 12:08:19.439605  3675 solver.cpp:243] Iteration 50260, loss = 0.00215735
I0521 12:08:19.439862  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00215724 (* 1 = 0.00215724 loss)
I0521 12:08:19.439872  3675 sgd_solver.cpp:138] Iteration 50260, lr = 3.125e-06
I0521 12:08:22.950598  3675 solver.cpp:243] Iteration 50280, loss = 0.00177142
I0521 12:08:22.950628  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00177131 (* 1 = 0.00177131 loss)
I0521 12:08:22.950634  3675 sgd_solver.cpp:138] Iteration 50280, lr = 3.125e-06
I0521 12:08:26.459882  3675 solver.cpp:243] Iteration 50300, loss = 0.00189397
I0521 12:08:26.459914  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00189387 (* 1 = 0.00189387 loss)
I0521 12:08:26.459920  3675 sgd_solver.cpp:138] Iteration 50300, lr = 3.125e-06
I0521 12:08:29.973408  3675 solver.cpp:243] Iteration 50320, loss = 0.00220884
I0521 12:08:29.973438  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00220874 (* 1 = 0.00220874 loss)
I0521 12:08:29.973443  3675 sgd_solver.cpp:138] Iteration 50320, lr = 3.125e-06
I0521 12:08:33.488590  3675 solver.cpp:243] Iteration 50340, loss = 0.00198048
I0521 12:08:33.488620  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00198038 (* 1 = 0.00198038 loss)
I0521 12:08:33.488626  3675 sgd_solver.cpp:138] Iteration 50340, lr = 3.125e-06
I0521 12:08:36.998260  3675 solver.cpp:243] Iteration 50360, loss = 0.00246519
I0521 12:08:36.998289  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00246509 (* 1 = 0.00246509 loss)
I0521 12:08:36.998296  3675 sgd_solver.cpp:138] Iteration 50360, lr = 3.125e-06
I0521 12:08:40.510241  3675 solver.cpp:243] Iteration 50380, loss = 0.00158425
I0521 12:08:40.510272  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00158414 (* 1 = 0.00158414 loss)
I0521 12:08:40.510277  3675 sgd_solver.cpp:138] Iteration 50380, lr = 3.125e-06
I0521 12:08:44.020642  3675 solver.cpp:243] Iteration 50400, loss = 0.00178734
I0521 12:08:44.020673  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00178723 (* 1 = 0.00178723 loss)
I0521 12:08:44.020678  3675 sgd_solver.cpp:138] Iteration 50400, lr = 3.125e-06
I0521 12:08:47.532645  3675 solver.cpp:243] Iteration 50420, loss = 0.00155434
I0521 12:08:47.532675  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00155423 (* 1 = 0.00155423 loss)
I0521 12:08:47.532680  3675 sgd_solver.cpp:138] Iteration 50420, lr = 3.125e-06
I0521 12:08:51.047183  3675 solver.cpp:243] Iteration 50440, loss = 0.00182395
I0521 12:08:51.047348  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00182385 (* 1 = 0.00182385 loss)
I0521 12:08:51.047355  3675 sgd_solver.cpp:138] Iteration 50440, lr = 3.125e-06
I0521 12:08:54.565305  3675 solver.cpp:243] Iteration 50460, loss = 0.00175431
I0521 12:08:54.565337  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0017542 (* 1 = 0.0017542 loss)
I0521 12:08:54.565344  3675 sgd_solver.cpp:138] Iteration 50460, lr = 3.125e-06
I0521 12:08:58.081704  3675 solver.cpp:243] Iteration 50480, loss = 0.00168844
I0521 12:08:58.081737  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00168833 (* 1 = 0.00168833 loss)
I0521 12:08:58.081758  3675 sgd_solver.cpp:138] Iteration 50480, lr = 3.125e-06
I0521 12:09:01.596915  3675 solver.cpp:243] Iteration 50500, loss = 0.00196345
I0521 12:09:01.596946  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00196334 (* 1 = 0.00196334 loss)
I0521 12:09:01.596952  3675 sgd_solver.cpp:138] Iteration 50500, lr = 3.125e-06
I0521 12:09:05.110216  3675 solver.cpp:243] Iteration 50520, loss = 0.00217508
I0521 12:09:05.110247  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00217498 (* 1 = 0.00217498 loss)
I0521 12:09:05.110270  3675 sgd_solver.cpp:138] Iteration 50520, lr = 3.125e-06
I0521 12:09:08.625643  3675 solver.cpp:243] Iteration 50540, loss = 0.00842444
I0521 12:09:08.625674  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00842433 (* 1 = 0.00842433 loss)
I0521 12:09:08.625680  3675 sgd_solver.cpp:138] Iteration 50540, lr = 3.125e-06
I0521 12:09:12.143147  3675 solver.cpp:243] Iteration 50560, loss = 0.00143821
I0521 12:09:12.143180  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00143811 (* 1 = 0.00143811 loss)
I0521 12:09:12.143187  3675 sgd_solver.cpp:138] Iteration 50560, lr = 3.125e-06
I0521 12:09:15.653827  3675 solver.cpp:243] Iteration 50580, loss = 0.00176445
I0521 12:09:15.653858  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00176434 (* 1 = 0.00176434 loss)
I0521 12:09:15.653880  3675 sgd_solver.cpp:138] Iteration 50580, lr = 3.125e-06
I0521 12:09:19.160687  3675 solver.cpp:243] Iteration 50600, loss = 0.00201023
I0521 12:09:19.160719  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00201012 (* 1 = 0.00201012 loss)
I0521 12:09:19.160727  3675 sgd_solver.cpp:138] Iteration 50600, lr = 3.125e-06
I0521 12:09:22.666784  3675 solver.cpp:243] Iteration 50620, loss = 0.00139785
I0521 12:09:22.666937  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00139774 (* 1 = 0.00139774 loss)
I0521 12:09:22.666946  3675 sgd_solver.cpp:138] Iteration 50620, lr = 3.125e-06
I0521 12:09:26.177835  3675 solver.cpp:243] Iteration 50640, loss = 0.00194498
I0521 12:09:26.177866  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00194488 (* 1 = 0.00194488 loss)
I0521 12:09:26.177888  3675 sgd_solver.cpp:138] Iteration 50640, lr = 3.125e-06
I0521 12:09:29.684916  3675 solver.cpp:243] Iteration 50660, loss = 0.00212416
I0521 12:09:29.684947  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00212405 (* 1 = 0.00212405 loss)
I0521 12:09:29.684968  3675 sgd_solver.cpp:138] Iteration 50660, lr = 3.125e-06
I0521 12:09:33.195114  3675 solver.cpp:243] Iteration 50680, loss = 0.00232663
I0521 12:09:33.195143  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00232652 (* 1 = 0.00232652 loss)
I0521 12:09:33.195150  3675 sgd_solver.cpp:138] Iteration 50680, lr = 3.125e-06
I0521 12:09:36.707432  3675 solver.cpp:243] Iteration 50700, loss = 0.00139612
I0521 12:09:36.707463  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00139601 (* 1 = 0.00139601 loss)
I0521 12:09:36.707470  3675 sgd_solver.cpp:138] Iteration 50700, lr = 3.125e-06
I0521 12:09:40.212452  3675 solver.cpp:243] Iteration 50720, loss = 0.00195344
I0521 12:09:40.212483  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00195334 (* 1 = 0.00195334 loss)
I0521 12:09:40.212491  3675 sgd_solver.cpp:138] Iteration 50720, lr = 3.125e-06
I0521 12:09:43.724710  3675 solver.cpp:243] Iteration 50740, loss = 0.00171602
I0521 12:09:43.724742  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00171592 (* 1 = 0.00171592 loss)
I0521 12:09:43.724750  3675 sgd_solver.cpp:138] Iteration 50740, lr = 3.125e-06
I0521 12:09:47.235674  3675 solver.cpp:243] Iteration 50760, loss = 0.001683
I0521 12:09:47.235705  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00168289 (* 1 = 0.00168289 loss)
I0521 12:09:47.235713  3675 sgd_solver.cpp:138] Iteration 50760, lr = 3.125e-06
I0521 12:09:50.682358  3675 solver.cpp:243] Iteration 50780, loss = 0.00169148
I0521 12:09:50.682389  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00169137 (* 1 = 0.00169137 loss)
I0521 12:09:50.682394  3675 sgd_solver.cpp:138] Iteration 50780, lr = 3.125e-06
I0521 12:09:54.198199  3675 solver.cpp:243] Iteration 50800, loss = 0.00160747
I0521 12:09:54.198349  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00160736 (* 1 = 0.00160736 loss)
I0521 12:09:54.198356  3675 sgd_solver.cpp:138] Iteration 50800, lr = 3.125e-06
I0521 12:09:57.708555  3675 solver.cpp:243] Iteration 50820, loss = 0.0016241
I0521 12:09:57.708586  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.001624 (* 1 = 0.001624 loss)
I0521 12:09:57.708592  3675 sgd_solver.cpp:138] Iteration 50820, lr = 3.125e-06
I0521 12:10:01.222718  3675 solver.cpp:243] Iteration 50840, loss = 0.00239179
I0521 12:10:01.222749  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00239168 (* 1 = 0.00239168 loss)
I0521 12:10:01.222755  3675 sgd_solver.cpp:138] Iteration 50840, lr = 3.125e-06
I0521 12:10:04.738687  3675 solver.cpp:243] Iteration 50860, loss = 0.00206029
I0521 12:10:04.738716  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00206018 (* 1 = 0.00206018 loss)
I0521 12:10:04.738723  3675 sgd_solver.cpp:138] Iteration 50860, lr = 3.125e-06
I0521 12:10:08.249629  3675 solver.cpp:243] Iteration 50880, loss = 0.00151401
I0521 12:10:08.249660  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0015139 (* 1 = 0.0015139 loss)
I0521 12:10:08.249665  3675 sgd_solver.cpp:138] Iteration 50880, lr = 3.125e-06
I0521 12:10:11.758476  3675 solver.cpp:243] Iteration 50900, loss = 0.00141748
I0521 12:10:11.758507  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00141737 (* 1 = 0.00141737 loss)
I0521 12:10:11.758512  3675 sgd_solver.cpp:138] Iteration 50900, lr = 3.125e-06
I0521 12:10:15.269454  3675 solver.cpp:243] Iteration 50920, loss = 0.00200022
I0521 12:10:15.269482  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00200011 (* 1 = 0.00200011 loss)
I0521 12:10:15.269488  3675 sgd_solver.cpp:138] Iteration 50920, lr = 3.125e-06
I0521 12:10:18.778610  3675 solver.cpp:243] Iteration 50940, loss = 0.0015675
I0521 12:10:18.778642  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0015674 (* 1 = 0.0015674 loss)
I0521 12:10:18.778648  3675 sgd_solver.cpp:138] Iteration 50940, lr = 3.125e-06
I0521 12:10:22.287986  3675 solver.cpp:243] Iteration 50960, loss = 0.00160838
I0521 12:10:22.288017  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00160828 (* 1 = 0.00160828 loss)
I0521 12:10:22.288039  3675 sgd_solver.cpp:138] Iteration 50960, lr = 3.125e-06
I0521 12:10:25.797000  3675 solver.cpp:243] Iteration 50980, loss = 0.00161977
I0521 12:10:25.797173  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00161966 (* 1 = 0.00161966 loss)
I0521 12:10:25.797183  3675 sgd_solver.cpp:138] Iteration 50980, lr = 3.125e-06
I0521 12:10:29.179682  3675 solver.cpp:358] Iteration 51000, Testing net (#0)
I0521 12:10:33.914415  3675 solver.cpp:425]     Test net output #0: acc = 1
I0521 12:10:33.914443  3675 solver.cpp:425]     Test net output #1: acc = 1
I0521 12:10:33.914449  3675 solver.cpp:425]     Test net output #2: ctcloss = 0.000638733 (* 1 = 0.000638733 loss)
I0521 12:10:34.050118  3675 solver.cpp:243] Iteration 51000, loss = 0.001839
I0521 12:10:34.050148  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0018389 (* 1 = 0.0018389 loss)
I0521 12:10:34.050154  3675 sgd_solver.cpp:138] Iteration 51000, lr = 3.125e-06
I0521 12:10:37.568702  3675 solver.cpp:243] Iteration 51020, loss = 0.00194546
I0521 12:10:37.568732  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00194535 (* 1 = 0.00194535 loss)
I0521 12:10:37.568737  3675 sgd_solver.cpp:138] Iteration 51020, lr = 3.125e-06
I0521 12:10:41.093456  3675 solver.cpp:243] Iteration 51040, loss = 0.00163811
I0521 12:10:41.093487  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00163801 (* 1 = 0.00163801 loss)
I0521 12:10:41.093493  3675 sgd_solver.cpp:138] Iteration 51040, lr = 3.125e-06
I0521 12:10:44.614774  3675 solver.cpp:243] Iteration 51060, loss = 0.00218053
I0521 12:10:44.614806  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00218042 (* 1 = 0.00218042 loss)
I0521 12:10:44.614812  3675 sgd_solver.cpp:138] Iteration 51060, lr = 3.125e-06
I0521 12:10:48.134747  3675 solver.cpp:243] Iteration 51080, loss = 0.0016046
I0521 12:10:48.134778  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0016045 (* 1 = 0.0016045 loss)
I0521 12:10:48.134783  3675 sgd_solver.cpp:138] Iteration 51080, lr = 3.125e-06
I0521 12:10:51.657069  3675 solver.cpp:243] Iteration 51100, loss = 0.00166194
I0521 12:10:51.657100  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00166183 (* 1 = 0.00166183 loss)
I0521 12:10:51.657107  3675 sgd_solver.cpp:138] Iteration 51100, lr = 3.125e-06
I0521 12:10:55.181304  3675 solver.cpp:243] Iteration 51120, loss = 0.0019245
I0521 12:10:55.181336  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00192439 (* 1 = 0.00192439 loss)
I0521 12:10:55.181344  3675 sgd_solver.cpp:138] Iteration 51120, lr = 3.125e-06
I0521 12:10:58.702636  3675 solver.cpp:243] Iteration 51140, loss = 0.00159714
I0521 12:10:58.702801  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00159704 (* 1 = 0.00159704 loss)
I0521 12:10:58.702809  3675 sgd_solver.cpp:138] Iteration 51140, lr = 3.125e-06
I0521 12:11:02.223827  3675 solver.cpp:243] Iteration 51160, loss = 0.00261911
I0521 12:11:02.223858  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.002619 (* 1 = 0.002619 loss)
I0521 12:11:02.223865  3675 sgd_solver.cpp:138] Iteration 51160, lr = 3.125e-06
I0521 12:11:05.743211  3675 solver.cpp:243] Iteration 51180, loss = 0.00506027
I0521 12:11:05.743242  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00506017 (* 1 = 0.00506017 loss)
I0521 12:11:05.743247  3675 sgd_solver.cpp:138] Iteration 51180, lr = 3.125e-06
I0521 12:11:09.262348  3675 solver.cpp:243] Iteration 51200, loss = 0.00213594
I0521 12:11:09.262380  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00213583 (* 1 = 0.00213583 loss)
I0521 12:11:09.262385  3675 sgd_solver.cpp:138] Iteration 51200, lr = 3.125e-06
I0521 12:11:12.786602  3675 solver.cpp:243] Iteration 51220, loss = 0.00187305
I0521 12:11:12.786633  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00187295 (* 1 = 0.00187295 loss)
I0521 12:11:12.786654  3675 sgd_solver.cpp:138] Iteration 51220, lr = 3.125e-06
I0521 12:11:16.310694  3675 solver.cpp:243] Iteration 51240, loss = 0.00183947
I0521 12:11:16.310726  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00183937 (* 1 = 0.00183937 loss)
I0521 12:11:16.310732  3675 sgd_solver.cpp:138] Iteration 51240, lr = 3.125e-06
I0521 12:11:19.827756  3675 solver.cpp:243] Iteration 51260, loss = 0.00137617
I0521 12:11:19.827787  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00137606 (* 1 = 0.00137606 loss)
I0521 12:11:19.827792  3675 sgd_solver.cpp:138] Iteration 51260, lr = 3.125e-06
I0521 12:11:23.342481  3675 solver.cpp:243] Iteration 51280, loss = 0.00155477
I0521 12:11:23.342512  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00155466 (* 1 = 0.00155466 loss)
I0521 12:11:23.342519  3675 sgd_solver.cpp:138] Iteration 51280, lr = 3.125e-06
I0521 12:11:26.863124  3675 solver.cpp:243] Iteration 51300, loss = 0.00149553
I0521 12:11:26.863154  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00149543 (* 1 = 0.00149543 loss)
I0521 12:11:26.863160  3675 sgd_solver.cpp:138] Iteration 51300, lr = 3.125e-06
I0521 12:11:30.380169  3675 solver.cpp:243] Iteration 51320, loss = 0.00145896
I0521 12:11:30.380290  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00145885 (* 1 = 0.00145885 loss)
I0521 12:11:30.380298  3675 sgd_solver.cpp:138] Iteration 51320, lr = 3.125e-06
I0521 12:11:33.902467  3675 solver.cpp:243] Iteration 51340, loss = 0.00164626
I0521 12:11:33.902500  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00164615 (* 1 = 0.00164615 loss)
I0521 12:11:33.902508  3675 sgd_solver.cpp:138] Iteration 51340, lr = 3.125e-06
I0521 12:11:37.422484  3675 solver.cpp:243] Iteration 51360, loss = 0.00207657
I0521 12:11:37.422513  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00207646 (* 1 = 0.00207646 loss)
I0521 12:11:37.422518  3675 sgd_solver.cpp:138] Iteration 51360, lr = 3.125e-06
I0521 12:11:40.943029  3675 solver.cpp:243] Iteration 51380, loss = 0.00294403
I0521 12:11:40.943059  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00294393 (* 1 = 0.00294393 loss)
I0521 12:11:40.943065  3675 sgd_solver.cpp:138] Iteration 51380, lr = 3.125e-06
I0521 12:11:44.459388  3675 solver.cpp:243] Iteration 51400, loss = 0.00146028
I0521 12:11:44.459417  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00146018 (* 1 = 0.00146018 loss)
I0521 12:11:44.459424  3675 sgd_solver.cpp:138] Iteration 51400, lr = 3.125e-06
I0521 12:11:47.980159  3675 solver.cpp:243] Iteration 51420, loss = 0.00180979
I0521 12:11:47.980191  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00180968 (* 1 = 0.00180968 loss)
I0521 12:11:47.980197  3675 sgd_solver.cpp:138] Iteration 51420, lr = 3.125e-06
I0521 12:11:51.497385  3675 solver.cpp:243] Iteration 51440, loss = 0.00184475
I0521 12:11:51.497416  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00184465 (* 1 = 0.00184465 loss)
I0521 12:11:51.497423  3675 sgd_solver.cpp:138] Iteration 51440, lr = 3.125e-06
I0521 12:11:55.018007  3675 solver.cpp:243] Iteration 51460, loss = 0.00210819
I0521 12:11:55.018036  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00210808 (* 1 = 0.00210808 loss)
I0521 12:11:55.018041  3675 sgd_solver.cpp:138] Iteration 51460, lr = 3.125e-06
I0521 12:11:58.539191  3675 solver.cpp:243] Iteration 51480, loss = 0.00130892
I0521 12:11:58.539222  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00130882 (* 1 = 0.00130882 loss)
I0521 12:11:58.539228  3675 sgd_solver.cpp:138] Iteration 51480, lr = 3.125e-06
I0521 12:12:02.055943  3675 solver.cpp:243] Iteration 51500, loss = 0.0016732
I0521 12:12:02.056156  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00167309 (* 1 = 0.00167309 loss)
I0521 12:12:02.056165  3675 sgd_solver.cpp:138] Iteration 51500, lr = 3.125e-06
I0521 12:12:05.575212  3675 solver.cpp:243] Iteration 51520, loss = 0.00262206
I0521 12:12:05.575243  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00262195 (* 1 = 0.00262195 loss)
I0521 12:12:05.575249  3675 sgd_solver.cpp:138] Iteration 51520, lr = 3.125e-06
I0521 12:12:09.093742  3675 solver.cpp:243] Iteration 51540, loss = 0.00148918
I0521 12:12:09.093772  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00148907 (* 1 = 0.00148907 loss)
I0521 12:12:09.093778  3675 sgd_solver.cpp:138] Iteration 51540, lr = 3.125e-06
I0521 12:12:12.618054  3675 solver.cpp:243] Iteration 51560, loss = 0.00152538
I0521 12:12:12.618084  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00152527 (* 1 = 0.00152527 loss)
I0521 12:12:12.618090  3675 sgd_solver.cpp:138] Iteration 51560, lr = 3.125e-06
I0521 12:12:16.142876  3675 solver.cpp:243] Iteration 51580, loss = 0.00175621
I0521 12:12:16.142910  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00175611 (* 1 = 0.00175611 loss)
I0521 12:12:16.142916  3675 sgd_solver.cpp:138] Iteration 51580, lr = 3.125e-06
I0521 12:12:19.665078  3675 solver.cpp:243] Iteration 51600, loss = 0.00184264
I0521 12:12:19.665109  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00184253 (* 1 = 0.00184253 loss)
I0521 12:12:19.665115  3675 sgd_solver.cpp:138] Iteration 51600, lr = 3.125e-06
I0521 12:12:23.184707  3675 solver.cpp:243] Iteration 51620, loss = 0.00204156
I0521 12:12:23.184739  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00204145 (* 1 = 0.00204145 loss)
I0521 12:12:23.184746  3675 sgd_solver.cpp:138] Iteration 51620, lr = 3.125e-06
I0521 12:12:26.705458  3675 solver.cpp:243] Iteration 51640, loss = 0.00194581
I0521 12:12:26.705488  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0019457 (* 1 = 0.0019457 loss)
I0521 12:12:26.705495  3675 sgd_solver.cpp:138] Iteration 51640, lr = 3.125e-06
I0521 12:12:30.223212  3675 solver.cpp:243] Iteration 51660, loss = 0.00181523
I0521 12:12:30.223244  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00181513 (* 1 = 0.00181513 loss)
I0521 12:12:30.223250  3675 sgd_solver.cpp:138] Iteration 51660, lr = 3.125e-06
I0521 12:12:33.741044  3675 solver.cpp:243] Iteration 51680, loss = 0.00447269
I0521 12:12:33.741163  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00447258 (* 1 = 0.00447258 loss)
I0521 12:12:33.741170  3675 sgd_solver.cpp:138] Iteration 51680, lr = 3.125e-06
I0521 12:12:37.258343  3675 solver.cpp:243] Iteration 51700, loss = 0.00188663
I0521 12:12:37.258374  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00188652 (* 1 = 0.00188652 loss)
I0521 12:12:37.258381  3675 sgd_solver.cpp:138] Iteration 51700, lr = 3.125e-06
I0521 12:12:40.775573  3675 solver.cpp:243] Iteration 51720, loss = 0.00511131
I0521 12:12:40.775604  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00511121 (* 1 = 0.00511121 loss)
I0521 12:12:40.775621  3675 sgd_solver.cpp:138] Iteration 51720, lr = 3.125e-06
I0521 12:12:44.293267  3675 solver.cpp:243] Iteration 51740, loss = 0.00191527
I0521 12:12:44.293298  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00191517 (* 1 = 0.00191517 loss)
I0521 12:12:44.293304  3675 sgd_solver.cpp:138] Iteration 51740, lr = 3.125e-06
I0521 12:12:47.815757  3675 solver.cpp:243] Iteration 51760, loss = 0.00170695
I0521 12:12:47.815789  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00170685 (* 1 = 0.00170685 loss)
I0521 12:12:47.815795  3675 sgd_solver.cpp:138] Iteration 51760, lr = 3.125e-06
I0521 12:12:51.332870  3675 solver.cpp:243] Iteration 51780, loss = 0.00138251
I0521 12:12:51.332901  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0013824 (* 1 = 0.0013824 loss)
I0521 12:12:51.332907  3675 sgd_solver.cpp:138] Iteration 51780, lr = 3.125e-06
I0521 12:12:54.853758  3675 solver.cpp:243] Iteration 51800, loss = 0.00166231
I0521 12:12:54.853790  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00166221 (* 1 = 0.00166221 loss)
I0521 12:12:54.853796  3675 sgd_solver.cpp:138] Iteration 51800, lr = 3.125e-06
I0521 12:12:58.372931  3675 solver.cpp:243] Iteration 51820, loss = 0.00180844
I0521 12:12:58.372962  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00180833 (* 1 = 0.00180833 loss)
I0521 12:12:58.372969  3675 sgd_solver.cpp:138] Iteration 51820, lr = 3.125e-06
I0521 12:13:01.891846  3675 solver.cpp:243] Iteration 51840, loss = 0.00161421
I0521 12:13:01.891876  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0016141 (* 1 = 0.0016141 loss)
I0521 12:13:01.891882  3675 sgd_solver.cpp:138] Iteration 51840, lr = 3.125e-06
I0521 12:13:05.407619  3675 solver.cpp:243] Iteration 51860, loss = 0.00223023
I0521 12:13:05.407788  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00223012 (* 1 = 0.00223012 loss)
I0521 12:13:05.407796  3675 sgd_solver.cpp:138] Iteration 51860, lr = 3.125e-06
I0521 12:13:08.926816  3675 solver.cpp:243] Iteration 51880, loss = 0.00174664
I0521 12:13:08.926849  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00174654 (* 1 = 0.00174654 loss)
I0521 12:13:08.926856  3675 sgd_solver.cpp:138] Iteration 51880, lr = 3.125e-06
I0521 12:13:12.442044  3675 solver.cpp:243] Iteration 51900, loss = 0.00181702
I0521 12:13:12.442077  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00181691 (* 1 = 0.00181691 loss)
I0521 12:13:12.442083  3675 sgd_solver.cpp:138] Iteration 51900, lr = 3.125e-06
I0521 12:13:15.963057  3675 solver.cpp:243] Iteration 51920, loss = 0.00153363
I0521 12:13:15.963088  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00153353 (* 1 = 0.00153353 loss)
I0521 12:13:15.963093  3675 sgd_solver.cpp:138] Iteration 51920, lr = 3.125e-06
I0521 12:13:19.483924  3675 solver.cpp:243] Iteration 51940, loss = 0.00214032
I0521 12:13:19.483955  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00214022 (* 1 = 0.00214022 loss)
I0521 12:13:19.483963  3675 sgd_solver.cpp:138] Iteration 51940, lr = 3.125e-06
I0521 12:13:23.006172  3675 solver.cpp:243] Iteration 51960, loss = 0.00164801
I0521 12:13:23.006202  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0016479 (* 1 = 0.0016479 loss)
I0521 12:13:23.006208  3675 sgd_solver.cpp:138] Iteration 51960, lr = 3.125e-06
I0521 12:13:26.520752  3675 solver.cpp:243] Iteration 51980, loss = 0.00177493
I0521 12:13:26.520784  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00177482 (* 1 = 0.00177482 loss)
I0521 12:13:26.520792  3675 sgd_solver.cpp:138] Iteration 51980, lr = 3.125e-06
I0521 12:13:29.844168  3675 solver.cpp:596] Snapshotting to binary proto file models/LPR/lpr_resnet_lstm_iter_52000.caffemodel
I0521 12:13:29.871423  3675 sgd_solver.cpp:307] Snapshotting solver state to binary proto file models/LPR/lpr_resnet_lstm_iter_52000.solverstate
I0521 12:13:29.886189  3675 solver.cpp:358] Iteration 52000, Testing net (#0)
I0521 12:13:34.620486  3675 solver.cpp:425]     Test net output #0: acc = 1
I0521 12:13:34.620512  3675 solver.cpp:425]     Test net output #1: acc = 1
I0521 12:13:34.620518  3675 solver.cpp:425]     Test net output #2: ctcloss = 0.000634408 (* 1 = 0.000634408 loss)
I0521 12:13:34.818248  3675 solver.cpp:243] Iteration 52000, loss = 0.00228968
I0521 12:13:34.818279  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00228957 (* 1 = 0.00228957 loss)
I0521 12:13:34.818285  3675 sgd_solver.cpp:138] Iteration 52000, lr = 3.125e-06
I0521 12:13:38.328861  3675 solver.cpp:243] Iteration 52020, loss = 0.00174177
I0521 12:13:38.329030  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00174166 (* 1 = 0.00174166 loss)
I0521 12:13:38.329041  3675 sgd_solver.cpp:138] Iteration 52020, lr = 3.125e-06
I0521 12:13:41.836793  3675 solver.cpp:243] Iteration 52040, loss = 0.00301088
I0521 12:13:41.836825  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00301078 (* 1 = 0.00301078 loss)
I0521 12:13:41.836833  3675 sgd_solver.cpp:138] Iteration 52040, lr = 3.125e-06
I0521 12:13:45.345240  3675 solver.cpp:243] Iteration 52060, loss = 0.00234339
I0521 12:13:45.345271  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00234328 (* 1 = 0.00234328 loss)
I0521 12:13:45.345278  3675 sgd_solver.cpp:138] Iteration 52060, lr = 3.125e-06
I0521 12:13:48.789142  3675 solver.cpp:243] Iteration 52080, loss = 0.00192669
I0521 12:13:48.789172  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00192659 (* 1 = 0.00192659 loss)
I0521 12:13:48.789178  3675 sgd_solver.cpp:138] Iteration 52080, lr = 3.125e-06
I0521 12:13:52.298167  3675 solver.cpp:243] Iteration 52100, loss = 0.00252469
I0521 12:13:52.298198  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00252458 (* 1 = 0.00252458 loss)
I0521 12:13:52.298205  3675 sgd_solver.cpp:138] Iteration 52100, lr = 3.125e-06
I0521 12:13:55.808140  3675 solver.cpp:243] Iteration 52120, loss = 0.00208883
I0521 12:13:55.808171  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00208872 (* 1 = 0.00208872 loss)
I0521 12:13:55.808176  3675 sgd_solver.cpp:138] Iteration 52120, lr = 3.125e-06
I0521 12:13:59.319340  3675 solver.cpp:243] Iteration 52140, loss = 0.00187791
I0521 12:13:59.319371  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00187781 (* 1 = 0.00187781 loss)
I0521 12:13:59.319393  3675 sgd_solver.cpp:138] Iteration 52140, lr = 3.125e-06
I0521 12:14:02.827374  3675 solver.cpp:243] Iteration 52160, loss = 0.00150015
I0521 12:14:02.827405  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00150004 (* 1 = 0.00150004 loss)
I0521 12:14:02.827426  3675 sgd_solver.cpp:138] Iteration 52160, lr = 3.125e-06
I0521 12:14:06.341909  3675 solver.cpp:243] Iteration 52180, loss = 0.00171748
I0521 12:14:06.341941  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00171737 (* 1 = 0.00171737 loss)
I0521 12:14:06.341950  3675 sgd_solver.cpp:138] Iteration 52180, lr = 3.125e-06
I0521 12:14:09.856284  3675 solver.cpp:243] Iteration 52200, loss = 0.00262862
I0521 12:14:09.856405  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00262851 (* 1 = 0.00262851 loss)
I0521 12:14:09.856412  3675 sgd_solver.cpp:138] Iteration 52200, lr = 3.125e-06
I0521 12:14:13.368165  3675 solver.cpp:243] Iteration 52220, loss = 0.00254878
I0521 12:14:13.368194  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00254867 (* 1 = 0.00254867 loss)
I0521 12:14:13.368201  3675 sgd_solver.cpp:138] Iteration 52220, lr = 3.125e-06
I0521 12:14:16.877161  3675 solver.cpp:243] Iteration 52240, loss = 0.00196101
I0521 12:14:16.877189  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00196091 (* 1 = 0.00196091 loss)
I0521 12:14:16.877195  3675 sgd_solver.cpp:138] Iteration 52240, lr = 3.125e-06
I0521 12:14:20.384789  3675 solver.cpp:243] Iteration 52260, loss = 0.00125791
I0521 12:14:20.384819  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0012578 (* 1 = 0.0012578 loss)
I0521 12:14:20.384826  3675 sgd_solver.cpp:138] Iteration 52260, lr = 3.125e-06
I0521 12:14:23.895987  3675 solver.cpp:243] Iteration 52280, loss = 0.00260558
I0521 12:14:23.896018  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00260548 (* 1 = 0.00260548 loss)
I0521 12:14:23.896023  3675 sgd_solver.cpp:138] Iteration 52280, lr = 3.125e-06
I0521 12:14:27.404987  3675 solver.cpp:243] Iteration 52300, loss = 0.00219992
I0521 12:14:27.405019  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00219981 (* 1 = 0.00219981 loss)
I0521 12:14:27.405025  3675 sgd_solver.cpp:138] Iteration 52300, lr = 3.125e-06
I0521 12:14:30.913728  3675 solver.cpp:243] Iteration 52320, loss = 0.00136886
I0521 12:14:30.913758  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00136875 (* 1 = 0.00136875 loss)
I0521 12:14:30.913764  3675 sgd_solver.cpp:138] Iteration 52320, lr = 3.125e-06
I0521 12:14:34.423162  3675 solver.cpp:243] Iteration 52340, loss = 0.00518305
I0521 12:14:34.423193  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00518295 (* 1 = 0.00518295 loss)
I0521 12:14:34.423199  3675 sgd_solver.cpp:138] Iteration 52340, lr = 3.125e-06
I0521 12:14:37.932749  3675 solver.cpp:243] Iteration 52360, loss = 0.00168059
I0521 12:14:37.932780  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00168049 (* 1 = 0.00168049 loss)
I0521 12:14:37.932786  3675 sgd_solver.cpp:138] Iteration 52360, lr = 3.125e-06
I0521 12:14:41.445412  3675 solver.cpp:243] Iteration 52380, loss = 0.0016447
I0521 12:14:41.445569  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0016446 (* 1 = 0.0016446 loss)
I0521 12:14:41.445577  3675 sgd_solver.cpp:138] Iteration 52380, lr = 3.125e-06
I0521 12:14:44.952857  3675 solver.cpp:243] Iteration 52400, loss = 0.00184662
I0521 12:14:44.952888  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00184652 (* 1 = 0.00184652 loss)
I0521 12:14:44.952893  3675 sgd_solver.cpp:138] Iteration 52400, lr = 3.125e-06
I0521 12:14:48.467027  3675 solver.cpp:243] Iteration 52420, loss = 0.0018024
I0521 12:14:48.467056  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00180229 (* 1 = 0.00180229 loss)
I0521 12:14:48.467062  3675 sgd_solver.cpp:138] Iteration 52420, lr = 3.125e-06
I0521 12:14:51.978310  3675 solver.cpp:243] Iteration 52440, loss = 0.00232407
I0521 12:14:51.978350  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00232396 (* 1 = 0.00232396 loss)
I0521 12:14:51.978359  3675 sgd_solver.cpp:138] Iteration 52440, lr = 3.125e-06
I0521 12:14:55.488006  3675 solver.cpp:243] Iteration 52460, loss = 0.00187922
I0521 12:14:55.488037  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00187911 (* 1 = 0.00187911 loss)
I0521 12:14:55.488044  3675 sgd_solver.cpp:138] Iteration 52460, lr = 3.125e-06
I0521 12:14:58.997750  3675 solver.cpp:243] Iteration 52480, loss = 0.00198383
I0521 12:14:58.997781  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00198372 (* 1 = 0.00198372 loss)
I0521 12:14:58.997803  3675 sgd_solver.cpp:138] Iteration 52480, lr = 3.125e-06
I0521 12:15:02.510417  3675 solver.cpp:243] Iteration 52500, loss = 0.00171546
I0521 12:15:02.510449  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00171536 (* 1 = 0.00171536 loss)
I0521 12:15:02.510455  3675 sgd_solver.cpp:138] Iteration 52500, lr = 3.125e-06
I0521 12:15:06.019924  3675 solver.cpp:243] Iteration 52520, loss = 0.0015782
I0521 12:15:06.019956  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00157809 (* 1 = 0.00157809 loss)
I0521 12:15:06.019963  3675 sgd_solver.cpp:138] Iteration 52520, lr = 3.125e-06
I0521 12:15:09.528265  3675 solver.cpp:243] Iteration 52540, loss = 0.00168477
I0521 12:15:09.528295  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00168466 (* 1 = 0.00168466 loss)
I0521 12:15:09.528301  3675 sgd_solver.cpp:138] Iteration 52540, lr = 3.125e-06
I0521 12:15:13.039172  3675 solver.cpp:243] Iteration 52560, loss = 0.00233701
I0521 12:15:13.039309  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0023369 (* 1 = 0.0023369 loss)
I0521 12:15:13.039319  3675 sgd_solver.cpp:138] Iteration 52560, lr = 3.125e-06
I0521 12:15:16.545996  3675 solver.cpp:243] Iteration 52580, loss = 0.00186518
I0521 12:15:16.546027  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00186508 (* 1 = 0.00186508 loss)
I0521 12:15:16.546033  3675 sgd_solver.cpp:138] Iteration 52580, lr = 3.125e-06
I0521 12:15:20.059136  3675 solver.cpp:243] Iteration 52600, loss = 0.00212712
I0521 12:15:20.059167  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00212701 (* 1 = 0.00212701 loss)
I0521 12:15:20.059173  3675 sgd_solver.cpp:138] Iteration 52600, lr = 3.125e-06
I0521 12:15:23.573781  3675 solver.cpp:243] Iteration 52620, loss = 0.00240956
I0521 12:15:23.573812  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00240945 (* 1 = 0.00240945 loss)
I0521 12:15:23.573817  3675 sgd_solver.cpp:138] Iteration 52620, lr = 3.125e-06
I0521 12:15:27.085135  3675 solver.cpp:243] Iteration 52640, loss = 0.00173268
I0521 12:15:27.085165  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00173257 (* 1 = 0.00173257 loss)
I0521 12:15:27.085171  3675 sgd_solver.cpp:138] Iteration 52640, lr = 3.125e-06
I0521 12:15:30.597863  3675 solver.cpp:243] Iteration 52660, loss = 0.00195841
I0521 12:15:30.597894  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00195831 (* 1 = 0.00195831 loss)
I0521 12:15:30.597901  3675 sgd_solver.cpp:138] Iteration 52660, lr = 3.125e-06
I0521 12:15:34.112682  3675 solver.cpp:243] Iteration 52680, loss = 0.00211501
I0521 12:15:34.112713  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00211491 (* 1 = 0.00211491 loss)
I0521 12:15:34.112718  3675 sgd_solver.cpp:138] Iteration 52680, lr = 3.125e-06
I0521 12:15:37.619196  3675 solver.cpp:243] Iteration 52700, loss = 0.00139099
I0521 12:15:37.619227  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00139088 (* 1 = 0.00139088 loss)
I0521 12:15:37.619251  3675 sgd_solver.cpp:138] Iteration 52700, lr = 3.125e-06
I0521 12:15:41.132853  3675 solver.cpp:243] Iteration 52720, loss = 0.00211945
I0521 12:15:41.132882  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00211935 (* 1 = 0.00211935 loss)
I0521 12:15:41.132889  3675 sgd_solver.cpp:138] Iteration 52720, lr = 3.125e-06
I0521 12:15:44.642514  3675 solver.cpp:243] Iteration 52740, loss = 0.00149086
I0521 12:15:44.642673  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00149076 (* 1 = 0.00149076 loss)
I0521 12:15:44.642683  3675 sgd_solver.cpp:138] Iteration 52740, lr = 3.125e-06
I0521 12:15:48.153645  3675 solver.cpp:243] Iteration 52760, loss = 0.00160091
I0521 12:15:48.153674  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00160081 (* 1 = 0.00160081 loss)
I0521 12:15:48.153681  3675 sgd_solver.cpp:138] Iteration 52760, lr = 3.125e-06
I0521 12:15:51.664870  3675 solver.cpp:243] Iteration 52780, loss = 0.00202098
I0521 12:15:51.664901  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00202087 (* 1 = 0.00202087 loss)
I0521 12:15:51.664907  3675 sgd_solver.cpp:138] Iteration 52780, lr = 3.125e-06
I0521 12:15:55.173714  3675 solver.cpp:243] Iteration 52800, loss = 0.00270663
I0521 12:15:55.173743  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00270653 (* 1 = 0.00270653 loss)
I0521 12:15:55.173749  3675 sgd_solver.cpp:138] Iteration 52800, lr = 3.125e-06
I0521 12:15:58.690320  3675 solver.cpp:243] Iteration 52820, loss = 0.00343784
I0521 12:15:58.690352  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00343773 (* 1 = 0.00343773 loss)
I0521 12:15:58.690358  3675 sgd_solver.cpp:138] Iteration 52820, lr = 3.125e-06
I0521 12:16:02.202657  3675 solver.cpp:243] Iteration 52840, loss = 0.00321257
I0521 12:16:02.202688  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00321247 (* 1 = 0.00321247 loss)
I0521 12:16:02.202694  3675 sgd_solver.cpp:138] Iteration 52840, lr = 3.125e-06
I0521 12:16:05.712121  3675 solver.cpp:243] Iteration 52860, loss = 0.00135927
I0521 12:16:05.712152  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00135917 (* 1 = 0.00135917 loss)
I0521 12:16:05.712158  3675 sgd_solver.cpp:138] Iteration 52860, lr = 3.125e-06
I0521 12:16:09.227457  3675 solver.cpp:243] Iteration 52880, loss = 0.00179251
I0521 12:16:09.227486  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0017924 (* 1 = 0.0017924 loss)
I0521 12:16:09.227509  3675 sgd_solver.cpp:138] Iteration 52880, lr = 3.125e-06
I0521 12:16:12.738121  3675 solver.cpp:243] Iteration 52900, loss = 0.00138738
I0521 12:16:12.738150  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00138728 (* 1 = 0.00138728 loss)
I0521 12:16:12.738157  3675 sgd_solver.cpp:138] Iteration 52900, lr = 3.125e-06
I0521 12:16:16.247385  3675 solver.cpp:243] Iteration 52920, loss = 0.00223265
I0521 12:16:16.247568  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00223255 (* 1 = 0.00223255 loss)
I0521 12:16:16.247577  3675 sgd_solver.cpp:138] Iteration 52920, lr = 3.125e-06
I0521 12:16:19.752990  3675 solver.cpp:243] Iteration 52940, loss = 0.00188924
I0521 12:16:19.753021  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00188914 (* 1 = 0.00188914 loss)
I0521 12:16:19.753027  3675 sgd_solver.cpp:138] Iteration 52940, lr = 3.125e-06
I0521 12:16:23.265111  3675 solver.cpp:243] Iteration 52960, loss = 0.00256316
I0521 12:16:23.265141  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00256306 (* 1 = 0.00256306 loss)
I0521 12:16:23.265147  3675 sgd_solver.cpp:138] Iteration 52960, lr = 3.125e-06
I0521 12:16:26.772756  3675 solver.cpp:243] Iteration 52980, loss = 0.00202917
I0521 12:16:26.772790  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00202906 (* 1 = 0.00202906 loss)
I0521 12:16:26.772797  3675 sgd_solver.cpp:138] Iteration 52980, lr = 3.125e-06
I0521 12:16:30.155498  3675 solver.cpp:358] Iteration 53000, Testing net (#0)
I0521 12:16:34.887342  3675 solver.cpp:425]     Test net output #0: acc = 1
I0521 12:16:34.887369  3675 solver.cpp:425]     Test net output #1: acc = 1
I0521 12:16:34.887375  3675 solver.cpp:425]     Test net output #2: ctcloss = 0.000636015 (* 1 = 0.000636015 loss)
I0521 12:16:35.022305  3675 solver.cpp:243] Iteration 53000, loss = 0.00178752
I0521 12:16:35.022336  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00178741 (* 1 = 0.00178741 loss)
I0521 12:16:35.022342  3675 sgd_solver.cpp:138] Iteration 53000, lr = 3.125e-06
I0521 12:16:38.543160  3675 solver.cpp:243] Iteration 53020, loss = 0.00205571
I0521 12:16:38.543192  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0020556 (* 1 = 0.0020556 loss)
I0521 12:16:38.543215  3675 sgd_solver.cpp:138] Iteration 53020, lr = 3.125e-06
I0521 12:16:42.057667  3675 solver.cpp:243] Iteration 53040, loss = 0.00243111
I0521 12:16:42.057698  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.002431 (* 1 = 0.002431 loss)
I0521 12:16:42.057705  3675 sgd_solver.cpp:138] Iteration 53040, lr = 3.125e-06
I0521 12:16:45.575995  3675 solver.cpp:243] Iteration 53060, loss = 0.00142688
I0521 12:16:45.576027  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00142678 (* 1 = 0.00142678 loss)
I0521 12:16:45.576050  3675 sgd_solver.cpp:138] Iteration 53060, lr = 3.125e-06
I0521 12:16:49.093439  3675 solver.cpp:243] Iteration 53080, loss = 0.00149903
I0521 12:16:49.093571  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00149893 (* 1 = 0.00149893 loss)
I0521 12:16:49.093580  3675 sgd_solver.cpp:138] Iteration 53080, lr = 3.125e-06
I0521 12:16:52.621439  3675 solver.cpp:243] Iteration 53100, loss = 0.00190458
I0521 12:16:52.621471  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00190447 (* 1 = 0.00190447 loss)
I0521 12:16:52.621479  3675 sgd_solver.cpp:138] Iteration 53100, lr = 3.125e-06
I0521 12:16:56.136329  3675 solver.cpp:243] Iteration 53120, loss = 0.00187122
I0521 12:16:56.136360  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00187112 (* 1 = 0.00187112 loss)
I0521 12:16:56.136368  3675 sgd_solver.cpp:138] Iteration 53120, lr = 3.125e-06
I0521 12:16:59.659705  3675 solver.cpp:243] Iteration 53140, loss = 0.0022362
I0521 12:16:59.659737  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0022361 (* 1 = 0.0022361 loss)
I0521 12:16:59.659744  3675 sgd_solver.cpp:138] Iteration 53140, lr = 3.125e-06
I0521 12:17:03.179903  3675 solver.cpp:243] Iteration 53160, loss = 0.00194988
I0521 12:17:03.179934  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00194978 (* 1 = 0.00194978 loss)
I0521 12:17:03.179940  3675 sgd_solver.cpp:138] Iteration 53160, lr = 3.125e-06
I0521 12:17:06.693320  3675 solver.cpp:243] Iteration 53180, loss = 0.00222697
I0521 12:17:06.693351  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00222686 (* 1 = 0.00222686 loss)
I0521 12:17:06.693357  3675 sgd_solver.cpp:138] Iteration 53180, lr = 3.125e-06
I0521 12:17:10.207584  3675 solver.cpp:243] Iteration 53200, loss = 0.00146614
I0521 12:17:10.207615  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00146603 (* 1 = 0.00146603 loss)
I0521 12:17:10.207621  3675 sgd_solver.cpp:138] Iteration 53200, lr = 3.125e-06
I0521 12:17:13.720959  3675 solver.cpp:243] Iteration 53220, loss = 0.00238256
I0521 12:17:13.720991  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00238246 (* 1 = 0.00238246 loss)
I0521 12:17:13.720997  3675 sgd_solver.cpp:138] Iteration 53220, lr = 3.125e-06
I0521 12:17:17.241567  3675 solver.cpp:243] Iteration 53240, loss = 0.00145893
I0521 12:17:17.241596  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00145883 (* 1 = 0.00145883 loss)
I0521 12:17:17.241603  3675 sgd_solver.cpp:138] Iteration 53240, lr = 3.125e-06
I0521 12:17:20.759479  3675 solver.cpp:243] Iteration 53260, loss = 0.00140152
I0521 12:17:20.759673  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00140142 (* 1 = 0.00140142 loss)
I0521 12:17:20.759694  3675 sgd_solver.cpp:138] Iteration 53260, lr = 3.125e-06
I0521 12:17:24.282243  3675 solver.cpp:243] Iteration 53280, loss = 0.00203102
I0521 12:17:24.282274  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00203092 (* 1 = 0.00203092 loss)
I0521 12:17:24.282281  3675 sgd_solver.cpp:138] Iteration 53280, lr = 3.125e-06
I0521 12:17:27.802327  3675 solver.cpp:243] Iteration 53300, loss = 0.001818
I0521 12:17:27.802359  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00181789 (* 1 = 0.00181789 loss)
I0521 12:17:27.802366  3675 sgd_solver.cpp:138] Iteration 53300, lr = 3.125e-06
I0521 12:17:31.321463  3675 solver.cpp:243] Iteration 53320, loss = 0.00198048
I0521 12:17:31.321496  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00198038 (* 1 = 0.00198038 loss)
I0521 12:17:31.321502  3675 sgd_solver.cpp:138] Iteration 53320, lr = 3.125e-06
I0521 12:17:34.839208  3675 solver.cpp:243] Iteration 53340, loss = 0.00214942
I0521 12:17:34.839241  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00214932 (* 1 = 0.00214932 loss)
I0521 12:17:34.839247  3675 sgd_solver.cpp:138] Iteration 53340, lr = 3.125e-06
I0521 12:17:38.384459  3675 solver.cpp:243] Iteration 53360, loss = 0.00210575
I0521 12:17:38.384491  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00210564 (* 1 = 0.00210564 loss)
I0521 12:17:38.384515  3675 sgd_solver.cpp:138] Iteration 53360, lr = 3.125e-06
I0521 12:17:41.878425  3675 solver.cpp:243] Iteration 53380, loss = 0.00191093
I0521 12:17:41.878458  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00191083 (* 1 = 0.00191083 loss)
I0521 12:17:41.878464  3675 sgd_solver.cpp:138] Iteration 53380, lr = 3.125e-06
I0521 12:17:45.595522  3675 solver.cpp:243] Iteration 53400, loss = 0.00143781
I0521 12:17:45.595556  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00143771 (* 1 = 0.00143771 loss)
I0521 12:17:45.595578  3675 sgd_solver.cpp:138] Iteration 53400, lr = 3.125e-06
I0521 12:17:49.211103  3675 solver.cpp:243] Iteration 53420, loss = 0.0021451
I0521 12:17:49.211136  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00214499 (* 1 = 0.00214499 loss)
I0521 12:17:49.211143  3675 sgd_solver.cpp:138] Iteration 53420, lr = 3.125e-06
I0521 12:17:52.860646  3675 solver.cpp:243] Iteration 53440, loss = 0.0014556
I0521 12:17:52.860754  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00145549 (* 1 = 0.00145549 loss)
I0521 12:17:52.860764  3675 sgd_solver.cpp:138] Iteration 53440, lr = 3.125e-06
I0521 12:17:56.517707  3675 solver.cpp:243] Iteration 53460, loss = 0.00178395
I0521 12:17:56.517737  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00178385 (* 1 = 0.00178385 loss)
I0521 12:17:56.517760  3675 sgd_solver.cpp:138] Iteration 53460, lr = 3.125e-06
I0521 12:18:00.180831  3675 solver.cpp:243] Iteration 53480, loss = 0.00199045
I0521 12:18:00.180863  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00199035 (* 1 = 0.00199035 loss)
I0521 12:18:00.180871  3675 sgd_solver.cpp:138] Iteration 53480, lr = 3.125e-06
I0521 12:18:03.842921  3675 solver.cpp:243] Iteration 53500, loss = 0.0019622
I0521 12:18:03.842954  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0019621 (* 1 = 0.0019621 loss)
I0521 12:18:03.842962  3675 sgd_solver.cpp:138] Iteration 53500, lr = 3.125e-06
I0521 12:18:07.589354  3675 solver.cpp:243] Iteration 53520, loss = 0.00145752
I0521 12:18:07.589388  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00145742 (* 1 = 0.00145742 loss)
I0521 12:18:07.589396  3675 sgd_solver.cpp:138] Iteration 53520, lr = 3.125e-06
I0521 12:18:11.301167  3675 solver.cpp:243] Iteration 53540, loss = 0.00185024
I0521 12:18:11.301199  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00185013 (* 1 = 0.00185013 loss)
I0521 12:18:11.301208  3675 sgd_solver.cpp:138] Iteration 53540, lr = 3.125e-06
I0521 12:18:14.958739  3675 solver.cpp:243] Iteration 53560, loss = 0.00250148
I0521 12:18:14.958770  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00250137 (* 1 = 0.00250137 loss)
I0521 12:18:14.958775  3675 sgd_solver.cpp:138] Iteration 53560, lr = 3.125e-06
I0521 12:18:18.551720  3675 solver.cpp:243] Iteration 53580, loss = 0.0018172
I0521 12:18:18.551753  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0018171 (* 1 = 0.0018171 loss)
I0521 12:18:18.551775  3675 sgd_solver.cpp:138] Iteration 53580, lr = 3.125e-06
I0521 12:18:22.212500  3675 solver.cpp:243] Iteration 53600, loss = 0.00201278
I0521 12:18:22.212532  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00201268 (* 1 = 0.00201268 loss)
I0521 12:18:22.212538  3675 sgd_solver.cpp:138] Iteration 53600, lr = 3.125e-06
I0521 12:18:25.973783  3675 solver.cpp:243] Iteration 53620, loss = 0.00195627
I0521 12:18:25.973986  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00195617 (* 1 = 0.00195617 loss)
I0521 12:18:25.973997  3675 sgd_solver.cpp:138] Iteration 53620, lr = 3.125e-06
I0521 12:18:29.600343  3675 solver.cpp:243] Iteration 53640, loss = 0.00198582
I0521 12:18:29.600375  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00198571 (* 1 = 0.00198571 loss)
I0521 12:18:29.600383  3675 sgd_solver.cpp:138] Iteration 53640, lr = 3.125e-06
I0521 12:18:33.200408  3675 solver.cpp:243] Iteration 53660, loss = 0.00184323
I0521 12:18:33.200439  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00184312 (* 1 = 0.00184312 loss)
I0521 12:18:33.200462  3675 sgd_solver.cpp:138] Iteration 53660, lr = 3.125e-06
I0521 12:18:36.826942  3675 solver.cpp:243] Iteration 53680, loss = 0.00202686
I0521 12:18:36.826973  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00202676 (* 1 = 0.00202676 loss)
I0521 12:18:36.826995  3675 sgd_solver.cpp:138] Iteration 53680, lr = 3.125e-06
I0521 12:18:40.444375  3675 solver.cpp:243] Iteration 53700, loss = 0.00177767
I0521 12:18:40.444406  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00177757 (* 1 = 0.00177757 loss)
I0521 12:18:40.444428  3675 sgd_solver.cpp:138] Iteration 53700, lr = 3.125e-06
I0521 12:18:44.074388  3675 solver.cpp:243] Iteration 53720, loss = 0.00144385
I0521 12:18:44.074419  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00144375 (* 1 = 0.00144375 loss)
I0521 12:18:44.074425  3675 sgd_solver.cpp:138] Iteration 53720, lr = 3.125e-06
I0521 12:18:47.703506  3675 solver.cpp:243] Iteration 53740, loss = 0.00160141
I0521 12:18:47.703538  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00160131 (* 1 = 0.00160131 loss)
I0521 12:18:47.703560  3675 sgd_solver.cpp:138] Iteration 53740, lr = 3.125e-06
I0521 12:18:51.303772  3675 solver.cpp:243] Iteration 53760, loss = 0.00148033
I0521 12:18:51.303804  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00148022 (* 1 = 0.00148022 loss)
I0521 12:18:51.303827  3675 sgd_solver.cpp:138] Iteration 53760, lr = 3.125e-06
I0521 12:18:54.946153  3675 solver.cpp:243] Iteration 53780, loss = 0.002064
I0521 12:18:54.946185  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0020639 (* 1 = 0.0020639 loss)
I0521 12:18:54.946192  3675 sgd_solver.cpp:138] Iteration 53780, lr = 3.125e-06
I0521 12:18:58.567873  3675 solver.cpp:243] Iteration 53800, loss = 0.00200566
I0521 12:18:58.568028  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00200555 (* 1 = 0.00200555 loss)
I0521 12:18:58.568037  3675 sgd_solver.cpp:138] Iteration 53800, lr = 3.125e-06
I0521 12:19:02.189925  3675 solver.cpp:243] Iteration 53820, loss = 0.00271851
I0521 12:19:02.189956  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0027184 (* 1 = 0.0027184 loss)
I0521 12:19:02.189962  3675 sgd_solver.cpp:138] Iteration 53820, lr = 3.125e-06
I0521 12:19:05.810665  3675 solver.cpp:243] Iteration 53840, loss = 0.00185556
I0521 12:19:05.810698  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00185546 (* 1 = 0.00185546 loss)
I0521 12:19:05.810705  3675 sgd_solver.cpp:138] Iteration 53840, lr = 3.125e-06
I0521 12:19:09.431126  3675 solver.cpp:243] Iteration 53860, loss = 0.00469667
I0521 12:19:09.431156  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00469656 (* 1 = 0.00469656 loss)
I0521 12:19:09.431162  3675 sgd_solver.cpp:138] Iteration 53860, lr = 3.125e-06
I0521 12:19:13.048051  3675 solver.cpp:243] Iteration 53880, loss = 0.00210269
I0521 12:19:13.048084  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00210259 (* 1 = 0.00210259 loss)
I0521 12:19:13.048089  3675 sgd_solver.cpp:138] Iteration 53880, lr = 3.125e-06
I0521 12:19:16.666420  3675 solver.cpp:243] Iteration 53900, loss = 0.00176876
I0521 12:19:16.666452  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00176866 (* 1 = 0.00176866 loss)
I0521 12:19:16.666458  3675 sgd_solver.cpp:138] Iteration 53900, lr = 3.125e-06
I0521 12:19:20.266429  3675 solver.cpp:243] Iteration 53920, loss = 0.00150836
I0521 12:19:20.266460  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00150826 (* 1 = 0.00150826 loss)
I0521 12:19:20.266482  3675 sgd_solver.cpp:138] Iteration 53920, lr = 3.125e-06
I0521 12:19:23.893280  3675 solver.cpp:243] Iteration 53940, loss = 0.00185561
I0521 12:19:23.893309  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0018555 (* 1 = 0.0018555 loss)
I0521 12:19:23.893332  3675 sgd_solver.cpp:138] Iteration 53940, lr = 3.125e-06
I0521 12:19:27.517475  3675 solver.cpp:243] Iteration 53960, loss = 0.00128015
I0521 12:19:27.517506  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00128005 (* 1 = 0.00128005 loss)
I0521 12:19:27.517513  3675 sgd_solver.cpp:138] Iteration 53960, lr = 3.125e-06
I0521 12:19:31.137161  3675 solver.cpp:243] Iteration 53980, loss = 0.0015978
I0521 12:19:31.137282  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0015977 (* 1 = 0.0015977 loss)
I0521 12:19:31.137290  3675 sgd_solver.cpp:138] Iteration 53980, lr = 3.125e-06
I0521 12:19:34.599588  3675 solver.cpp:596] Snapshotting to binary proto file models/LPR/lpr_resnet_lstm_iter_54000.caffemodel
I0521 12:19:34.629302  3675 sgd_solver.cpp:307] Snapshotting solver state to binary proto file models/LPR/lpr_resnet_lstm_iter_54000.solverstate
I0521 12:19:34.644745  3675 solver.cpp:358] Iteration 54000, Testing net (#0)
I0521 12:19:39.497970  3675 solver.cpp:425]     Test net output #0: acc = 1
I0521 12:19:39.498056  3675 solver.cpp:425]     Test net output #1: acc = 1
I0521 12:19:39.498077  3675 solver.cpp:425]     Test net output #2: ctcloss = 0.000634034 (* 1 = 0.000634034 loss)
I0521 12:19:39.639967  3675 solver.cpp:243] Iteration 54000, loss = 0.00173062
I0521 12:19:39.639999  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00173051 (* 1 = 0.00173051 loss)
I0521 12:19:39.640022  3675 sgd_solver.cpp:138] Iteration 54000, lr = 3.125e-06
I0521 12:19:43.272106  3675 solver.cpp:243] Iteration 54020, loss = 0.001852
I0521 12:19:43.272137  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0018519 (* 1 = 0.0018519 loss)
I0521 12:19:43.272145  3675 sgd_solver.cpp:138] Iteration 54020, lr = 3.125e-06
I0521 12:19:46.891266  3675 solver.cpp:243] Iteration 54040, loss = 0.0043304
I0521 12:19:46.891297  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0043303 (* 1 = 0.0043303 loss)
I0521 12:19:46.891304  3675 sgd_solver.cpp:138] Iteration 54040, lr = 3.125e-06
I0521 12:19:50.525712  3675 solver.cpp:243] Iteration 54060, loss = 0.0020258
I0521 12:19:50.525745  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00202569 (* 1 = 0.00202569 loss)
I0521 12:19:50.525753  3675 sgd_solver.cpp:138] Iteration 54060, lr = 3.125e-06
I0521 12:19:54.132122  3675 solver.cpp:243] Iteration 54080, loss = 0.0026865
I0521 12:19:54.132153  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0026864 (* 1 = 0.0026864 loss)
I0521 12:19:54.132176  3675 sgd_solver.cpp:138] Iteration 54080, lr = 3.125e-06
I0521 12:19:57.754194  3675 solver.cpp:243] Iteration 54100, loss = 0.00196267
I0521 12:19:57.754226  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00196257 (* 1 = 0.00196257 loss)
I0521 12:19:57.754233  3675 sgd_solver.cpp:138] Iteration 54100, lr = 3.125e-06
I0521 12:20:01.379325  3675 solver.cpp:243] Iteration 54120, loss = 0.00152799
I0521 12:20:01.379492  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00152788 (* 1 = 0.00152788 loss)
I0521 12:20:01.379499  3675 sgd_solver.cpp:138] Iteration 54120, lr = 3.125e-06
I0521 12:20:04.999495  3675 solver.cpp:243] Iteration 54140, loss = 0.0021165
I0521 12:20:04.999526  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00211639 (* 1 = 0.00211639 loss)
I0521 12:20:04.999532  3675 sgd_solver.cpp:138] Iteration 54140, lr = 3.125e-06
I0521 12:20:08.598899  3675 solver.cpp:243] Iteration 54160, loss = 0.0019117
I0521 12:20:08.598932  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0019116 (* 1 = 0.0019116 loss)
I0521 12:20:08.598938  3675 sgd_solver.cpp:138] Iteration 54160, lr = 3.125e-06
I0521 12:20:12.229724  3675 solver.cpp:243] Iteration 54180, loss = 0.00157268
I0521 12:20:12.229758  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00157257 (* 1 = 0.00157257 loss)
I0521 12:20:12.229763  3675 sgd_solver.cpp:138] Iteration 54180, lr = 3.125e-06
I0521 12:20:15.877846  3675 solver.cpp:243] Iteration 54200, loss = 0.00221982
I0521 12:20:15.877887  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00221971 (* 1 = 0.00221971 loss)
I0521 12:20:15.877908  3675 sgd_solver.cpp:138] Iteration 54200, lr = 3.125e-06
I0521 12:20:19.498162  3675 solver.cpp:243] Iteration 54220, loss = 0.00183505
I0521 12:20:19.498193  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00183494 (* 1 = 0.00183494 loss)
I0521 12:20:19.498199  3675 sgd_solver.cpp:138] Iteration 54220, lr = 3.125e-06
I0521 12:20:23.118861  3675 solver.cpp:243] Iteration 54240, loss = 0.00181368
I0521 12:20:23.118896  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00181358 (* 1 = 0.00181358 loss)
I0521 12:20:23.118902  3675 sgd_solver.cpp:138] Iteration 54240, lr = 3.125e-06
I0521 12:20:26.736614  3675 solver.cpp:243] Iteration 54260, loss = 0.00229553
I0521 12:20:26.736647  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00229543 (* 1 = 0.00229543 loss)
I0521 12:20:26.736655  3675 sgd_solver.cpp:138] Iteration 54260, lr = 3.125e-06
I0521 12:20:30.387787  3675 solver.cpp:243] Iteration 54280, loss = 0.00265613
I0521 12:20:30.387820  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00265603 (* 1 = 0.00265603 loss)
I0521 12:20:30.387827  3675 sgd_solver.cpp:138] Iteration 54280, lr = 3.125e-06
I0521 12:20:34.012977  3675 solver.cpp:243] Iteration 54300, loss = 0.00201647
I0521 12:20:34.013116  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00201636 (* 1 = 0.00201636 loss)
I0521 12:20:34.013125  3675 sgd_solver.cpp:138] Iteration 54300, lr = 3.125e-06
I0521 12:20:37.631618  3675 solver.cpp:243] Iteration 54320, loss = 0.00216634
I0521 12:20:37.631650  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00216623 (* 1 = 0.00216623 loss)
I0521 12:20:37.631659  3675 sgd_solver.cpp:138] Iteration 54320, lr = 3.125e-06
I0521 12:20:41.239136  3675 solver.cpp:243] Iteration 54340, loss = 0.00237663
I0521 12:20:41.239169  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00237653 (* 1 = 0.00237653 loss)
I0521 12:20:41.239177  3675 sgd_solver.cpp:138] Iteration 54340, lr = 3.125e-06
I0521 12:20:44.878660  3675 solver.cpp:243] Iteration 54360, loss = 0.00169387
I0521 12:20:44.878693  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00169377 (* 1 = 0.00169377 loss)
I0521 12:20:44.878702  3675 sgd_solver.cpp:138] Iteration 54360, lr = 3.125e-06
I0521 12:20:48.498100  3675 solver.cpp:243] Iteration 54380, loss = 0.00225213
I0521 12:20:48.498134  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00225202 (* 1 = 0.00225202 loss)
I0521 12:20:48.498142  3675 sgd_solver.cpp:138] Iteration 54380, lr = 3.125e-06
I0521 12:20:52.123878  3675 solver.cpp:243] Iteration 54400, loss = 0.0021703
I0521 12:20:52.123909  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00217019 (* 1 = 0.00217019 loss)
I0521 12:20:52.123917  3675 sgd_solver.cpp:138] Iteration 54400, lr = 3.125e-06
I0521 12:20:55.746613  3675 solver.cpp:243] Iteration 54420, loss = 0.00202891
I0521 12:20:55.746702  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00202881 (* 1 = 0.00202881 loss)
I0521 12:20:55.746722  3675 sgd_solver.cpp:138] Iteration 54420, lr = 3.125e-06
I0521 12:20:59.358880  3675 solver.cpp:243] Iteration 54440, loss = 0.00159111
I0521 12:20:59.358911  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00159101 (* 1 = 0.00159101 loss)
I0521 12:20:59.358934  3675 sgd_solver.cpp:138] Iteration 54440, lr = 3.125e-06
I0521 12:21:02.989138  3675 solver.cpp:243] Iteration 54460, loss = 0.00198747
I0521 12:21:02.989171  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00198737 (* 1 = 0.00198737 loss)
I0521 12:21:02.989177  3675 sgd_solver.cpp:138] Iteration 54460, lr = 3.125e-06
I0521 12:21:06.609462  3675 solver.cpp:243] Iteration 54480, loss = 0.0016466
I0521 12:21:06.609649  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0016465 (* 1 = 0.0016465 loss)
I0521 12:21:06.609659  3675 sgd_solver.cpp:138] Iteration 54480, lr = 3.125e-06
I0521 12:21:10.233001  3675 solver.cpp:243] Iteration 54500, loss = 0.00192187
I0521 12:21:10.233031  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00192176 (* 1 = 0.00192176 loss)
I0521 12:21:10.233053  3675 sgd_solver.cpp:138] Iteration 54500, lr = 3.125e-06
I0521 12:21:13.852219  3675 solver.cpp:243] Iteration 54520, loss = 0.00223986
I0521 12:21:13.852252  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00223975 (* 1 = 0.00223975 loss)
I0521 12:21:13.852258  3675 sgd_solver.cpp:138] Iteration 54520, lr = 3.125e-06
I0521 12:21:17.444097  3675 solver.cpp:243] Iteration 54540, loss = 0.00211367
I0521 12:21:17.444131  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00211356 (* 1 = 0.00211356 loss)
I0521 12:21:17.444154  3675 sgd_solver.cpp:138] Iteration 54540, lr = 3.125e-06
I0521 12:21:21.064155  3675 solver.cpp:243] Iteration 54560, loss = 0.00176654
I0521 12:21:21.064186  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00176644 (* 1 = 0.00176644 loss)
I0521 12:21:21.064209  3675 sgd_solver.cpp:138] Iteration 54560, lr = 3.125e-06
I0521 12:21:24.701488  3675 solver.cpp:243] Iteration 54580, loss = 0.00172324
I0521 12:21:24.701522  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00172314 (* 1 = 0.00172314 loss)
I0521 12:21:24.701529  3675 sgd_solver.cpp:138] Iteration 54580, lr = 3.125e-06
I0521 12:21:28.321290  3675 solver.cpp:243] Iteration 54600, loss = 0.00219914
I0521 12:21:28.321321  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00219903 (* 1 = 0.00219903 loss)
I0521 12:21:28.321346  3675 sgd_solver.cpp:138] Iteration 54600, lr = 3.125e-06
I0521 12:21:31.945803  3675 solver.cpp:243] Iteration 54620, loss = 0.00177698
I0521 12:21:31.945837  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00177688 (* 1 = 0.00177688 loss)
I0521 12:21:31.945845  3675 sgd_solver.cpp:138] Iteration 54620, lr = 3.125e-06
I0521 12:21:35.553478  3675 solver.cpp:243] Iteration 54640, loss = 0.00333945
I0521 12:21:35.553511  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00333935 (* 1 = 0.00333935 loss)
I0521 12:21:35.553519  3675 sgd_solver.cpp:138] Iteration 54640, lr = 3.125e-06
I0521 12:21:39.174132  3675 solver.cpp:243] Iteration 54660, loss = 0.00142673
I0521 12:21:39.174312  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00142663 (* 1 = 0.00142663 loss)
I0521 12:21:39.174322  3675 sgd_solver.cpp:138] Iteration 54660, lr = 3.125e-06
I0521 12:21:42.718493  3675 solver.cpp:243] Iteration 54680, loss = 0.00286701
I0521 12:21:42.718526  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00286691 (* 1 = 0.00286691 loss)
I0521 12:21:42.718533  3675 sgd_solver.cpp:138] Iteration 54680, lr = 3.125e-06
I0521 12:21:46.333634  3675 solver.cpp:243] Iteration 54700, loss = 0.00228457
I0521 12:21:46.333667  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00228447 (* 1 = 0.00228447 loss)
I0521 12:21:46.333674  3675 sgd_solver.cpp:138] Iteration 54700, lr = 3.125e-06
I0521 12:21:49.950263  3675 solver.cpp:243] Iteration 54720, loss = 0.002196
I0521 12:21:49.950296  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00219589 (* 1 = 0.00219589 loss)
I0521 12:21:49.950302  3675 sgd_solver.cpp:138] Iteration 54720, lr = 3.125e-06
I0521 12:21:53.550628  3675 solver.cpp:243] Iteration 54740, loss = 0.00197325
I0521 12:21:53.550658  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00197314 (* 1 = 0.00197314 loss)
I0521 12:21:53.550664  3675 sgd_solver.cpp:138] Iteration 54740, lr = 3.125e-06
I0521 12:21:57.165906  3675 solver.cpp:243] Iteration 54760, loss = 0.00201525
I0521 12:21:57.165940  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00201514 (* 1 = 0.00201514 loss)
I0521 12:21:57.165947  3675 sgd_solver.cpp:138] Iteration 54760, lr = 3.125e-06
I0521 12:22:00.791251  3675 solver.cpp:243] Iteration 54780, loss = 0.00224854
I0521 12:22:00.791283  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00224843 (* 1 = 0.00224843 loss)
I0521 12:22:00.791290  3675 sgd_solver.cpp:138] Iteration 54780, lr = 3.125e-06
I0521 12:22:04.407941  3675 solver.cpp:243] Iteration 54800, loss = 0.00124964
I0521 12:22:04.407974  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00124954 (* 1 = 0.00124954 loss)
I0521 12:22:04.407980  3675 sgd_solver.cpp:138] Iteration 54800, lr = 3.125e-06
I0521 12:22:08.017737  3675 solver.cpp:243] Iteration 54820, loss = 0.00219737
I0521 12:22:08.017769  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00219727 (* 1 = 0.00219727 loss)
I0521 12:22:08.017777  3675 sgd_solver.cpp:138] Iteration 54820, lr = 3.125e-06
I0521 12:22:11.638772  3675 solver.cpp:243] Iteration 54840, loss = 0.00284591
I0521 12:22:11.638932  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00284581 (* 1 = 0.00284581 loss)
I0521 12:22:11.638940  3675 sgd_solver.cpp:138] Iteration 54840, lr = 3.125e-06
I0521 12:22:15.256088  3675 solver.cpp:243] Iteration 54860, loss = 0.00190571
I0521 12:22:15.256119  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0019056 (* 1 = 0.0019056 loss)
I0521 12:22:15.256125  3675 sgd_solver.cpp:138] Iteration 54860, lr = 3.125e-06
I0521 12:22:18.879379  3675 solver.cpp:243] Iteration 54880, loss = 0.00149024
I0521 12:22:18.879410  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00149014 (* 1 = 0.00149014 loss)
I0521 12:22:18.879416  3675 sgd_solver.cpp:138] Iteration 54880, lr = 3.125e-06
I0521 12:22:22.495714  3675 solver.cpp:243] Iteration 54900, loss = 0.00147641
I0521 12:22:22.495745  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00147631 (* 1 = 0.00147631 loss)
I0521 12:22:22.495752  3675 sgd_solver.cpp:138] Iteration 54900, lr = 3.125e-06
I0521 12:22:26.119349  3675 solver.cpp:243] Iteration 54920, loss = 0.00276792
I0521 12:22:26.119379  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00276781 (* 1 = 0.00276781 loss)
I0521 12:22:26.119385  3675 sgd_solver.cpp:138] Iteration 54920, lr = 3.125e-06
I0521 12:22:29.743424  3675 solver.cpp:243] Iteration 54940, loss = 0.00232446
I0521 12:22:29.743525  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00232435 (* 1 = 0.00232435 loss)
I0521 12:22:29.743556  3675 sgd_solver.cpp:138] Iteration 54940, lr = 3.125e-06
I0521 12:22:33.336015  3675 solver.cpp:243] Iteration 54960, loss = 0.00138044
I0521 12:22:33.336047  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00138033 (* 1 = 0.00138033 loss)
I0521 12:22:33.336069  3675 sgd_solver.cpp:138] Iteration 54960, lr = 3.125e-06
I0521 12:22:36.959637  3675 solver.cpp:243] Iteration 54980, loss = 0.00186422
I0521 12:22:36.959671  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00186411 (* 1 = 0.00186411 loss)
I0521 12:22:36.959692  3675 sgd_solver.cpp:138] Iteration 54980, lr = 3.125e-06
I0521 12:22:40.444317  3675 solver.cpp:358] Iteration 55000, Testing net (#0)
I0521 12:22:45.275277  3675 solver.cpp:425]     Test net output #0: acc = 1
I0521 12:22:45.277567  3675 solver.cpp:425]     Test net output #1: acc = 1
I0521 12:22:45.277588  3675 solver.cpp:425]     Test net output #2: ctcloss = 0.000630792 (* 1 = 0.000630792 loss)
I0521 12:22:45.420677  3675 solver.cpp:243] Iteration 55000, loss = 0.00176988
I0521 12:22:45.420704  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00176977 (* 1 = 0.00176977 loss)
I0521 12:22:45.420711  3675 sgd_solver.cpp:138] Iteration 55000, lr = 3.125e-06
I0521 12:22:49.040189  3675 solver.cpp:243] Iteration 55020, loss = 0.00251764
I0521 12:22:49.040220  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00251754 (* 1 = 0.00251754 loss)
I0521 12:22:49.040225  3675 sgd_solver.cpp:138] Iteration 55020, lr = 3.125e-06
I0521 12:22:52.669939  3675 solver.cpp:243] Iteration 55040, loss = 0.0017226
I0521 12:22:52.669972  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0017225 (* 1 = 0.0017225 loss)
I0521 12:22:52.669979  3675 sgd_solver.cpp:138] Iteration 55040, lr = 3.125e-06
I0521 12:22:56.295861  3675 solver.cpp:243] Iteration 55060, loss = 0.00169324
I0521 12:22:56.295892  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00169314 (* 1 = 0.00169314 loss)
I0521 12:22:56.295898  3675 sgd_solver.cpp:138] Iteration 55060, lr = 3.125e-06
I0521 12:22:59.915242  3675 solver.cpp:243] Iteration 55080, loss = 0.00224163
I0521 12:22:59.915273  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00224152 (* 1 = 0.00224152 loss)
I0521 12:22:59.915279  3675 sgd_solver.cpp:138] Iteration 55080, lr = 3.125e-06
I0521 12:23:03.526139  3675 solver.cpp:243] Iteration 55100, loss = 0.0021517
I0521 12:23:03.526171  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0021516 (* 1 = 0.0021516 loss)
I0521 12:23:03.526194  3675 sgd_solver.cpp:138] Iteration 55100, lr = 3.125e-06
I0521 12:23:07.128747  3675 solver.cpp:243] Iteration 55120, loss = 0.00156582
I0521 12:23:07.128779  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00156571 (* 1 = 0.00156571 loss)
I0521 12:23:07.128804  3675 sgd_solver.cpp:138] Iteration 55120, lr = 3.125e-06
I0521 12:23:10.763738  3675 solver.cpp:243] Iteration 55140, loss = 0.00191047
I0521 12:23:10.763769  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00191036 (* 1 = 0.00191036 loss)
I0521 12:23:10.763775  3675 sgd_solver.cpp:138] Iteration 55140, lr = 3.125e-06
I0521 12:23:14.380229  3675 solver.cpp:243] Iteration 55160, loss = 0.00176778
I0521 12:23:14.380261  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00176768 (* 1 = 0.00176768 loss)
I0521 12:23:14.380268  3675 sgd_solver.cpp:138] Iteration 55160, lr = 3.125e-06
I0521 12:23:18.012472  3675 solver.cpp:243] Iteration 55180, loss = 0.00210057
I0521 12:23:18.012624  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00210047 (* 1 = 0.00210047 loss)
I0521 12:23:18.012631  3675 sgd_solver.cpp:138] Iteration 55180, lr = 3.125e-06
I0521 12:23:21.596361  3675 solver.cpp:243] Iteration 55200, loss = 0.00160247
I0521 12:23:21.596395  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00160236 (* 1 = 0.00160236 loss)
I0521 12:23:21.596416  3675 sgd_solver.cpp:138] Iteration 55200, lr = 3.125e-06
I0521 12:23:25.234797  3675 solver.cpp:243] Iteration 55220, loss = 0.00252624
I0521 12:23:25.234829  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00252614 (* 1 = 0.00252614 loss)
I0521 12:23:25.234836  3675 sgd_solver.cpp:138] Iteration 55220, lr = 3.125e-06
I0521 12:23:28.845715  3675 solver.cpp:243] Iteration 55240, loss = 0.0023311
I0521 12:23:28.845747  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00233099 (* 1 = 0.00233099 loss)
I0521 12:23:28.845753  3675 sgd_solver.cpp:138] Iteration 55240, lr = 3.125e-06
I0521 12:23:32.377909  3675 solver.cpp:243] Iteration 55260, loss = 0.00139437
I0521 12:23:32.377941  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00139427 (* 1 = 0.00139427 loss)
I0521 12:23:32.377964  3675 sgd_solver.cpp:138] Iteration 55260, lr = 3.125e-06
I0521 12:23:35.911518  3675 solver.cpp:243] Iteration 55280, loss = 0.00144701
I0521 12:23:35.911551  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00144691 (* 1 = 0.00144691 loss)
I0521 12:23:35.911557  3675 sgd_solver.cpp:138] Iteration 55280, lr = 3.125e-06
I0521 12:23:39.447297  3675 solver.cpp:243] Iteration 55300, loss = 0.00180208
I0521 12:23:39.447329  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00180198 (* 1 = 0.00180198 loss)
I0521 12:23:39.447335  3675 sgd_solver.cpp:138] Iteration 55300, lr = 3.125e-06
I0521 12:23:42.980877  3675 solver.cpp:243] Iteration 55320, loss = 0.0015065
I0521 12:23:42.980911  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0015064 (* 1 = 0.0015064 loss)
I0521 12:23:42.980916  3675 sgd_solver.cpp:138] Iteration 55320, lr = 3.125e-06
I0521 12:23:46.524220  3675 solver.cpp:243] Iteration 55340, loss = 0.00140018
I0521 12:23:46.524252  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00140007 (* 1 = 0.00140007 loss)
I0521 12:23:46.524257  3675 sgd_solver.cpp:138] Iteration 55340, lr = 3.125e-06
I0521 12:23:50.061523  3675 solver.cpp:243] Iteration 55360, loss = 0.00182448
I0521 12:23:50.061679  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00182437 (* 1 = 0.00182437 loss)
I0521 12:23:50.061687  3675 sgd_solver.cpp:138] Iteration 55360, lr = 3.125e-06
I0521 12:23:53.595356  3675 solver.cpp:243] Iteration 55380, loss = 0.00150725
I0521 12:23:53.595386  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00150715 (* 1 = 0.00150715 loss)
I0521 12:23:53.595408  3675 sgd_solver.cpp:138] Iteration 55380, lr = 3.125e-06
I0521 12:23:57.135390  3675 solver.cpp:243] Iteration 55400, loss = 0.00279514
I0521 12:23:57.135421  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00279503 (* 1 = 0.00279503 loss)
I0521 12:23:57.135444  3675 sgd_solver.cpp:138] Iteration 55400, lr = 3.125e-06
I0521 12:24:00.679445  3675 solver.cpp:243] Iteration 55420, loss = 0.00221231
I0521 12:24:00.679478  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0022122 (* 1 = 0.0022122 loss)
I0521 12:24:00.679484  3675 sgd_solver.cpp:138] Iteration 55420, lr = 3.125e-06
I0521 12:24:04.214947  3675 solver.cpp:243] Iteration 55440, loss = 0.00255704
I0521 12:24:04.214979  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00255693 (* 1 = 0.00255693 loss)
I0521 12:24:04.214985  3675 sgd_solver.cpp:138] Iteration 55440, lr = 3.125e-06
I0521 12:24:07.749644  3675 solver.cpp:243] Iteration 55460, loss = 0.00195994
I0521 12:24:07.749676  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00195984 (* 1 = 0.00195984 loss)
I0521 12:24:07.749682  3675 sgd_solver.cpp:138] Iteration 55460, lr = 3.125e-06
I0521 12:24:11.285440  3675 solver.cpp:243] Iteration 55480, loss = 0.00247513
I0521 12:24:11.285472  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00247503 (* 1 = 0.00247503 loss)
I0521 12:24:11.285480  3675 sgd_solver.cpp:138] Iteration 55480, lr = 3.125e-06
I0521 12:24:14.824339  3675 solver.cpp:243] Iteration 55500, loss = 0.00225155
I0521 12:24:14.824370  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00225145 (* 1 = 0.00225145 loss)
I0521 12:24:14.824376  3675 sgd_solver.cpp:138] Iteration 55500, lr = 3.125e-06
I0521 12:24:18.355367  3675 solver.cpp:243] Iteration 55520, loss = 0.00154369
I0521 12:24:18.355401  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00154358 (* 1 = 0.00154358 loss)
I0521 12:24:18.355407  3675 sgd_solver.cpp:138] Iteration 55520, lr = 3.125e-06
I0521 12:24:21.894819  3675 solver.cpp:243] Iteration 55540, loss = 0.00531734
I0521 12:24:21.895004  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00531724 (* 1 = 0.00531724 loss)
I0521 12:24:21.895015  3675 sgd_solver.cpp:138] Iteration 55540, lr = 3.125e-06
I0521 12:24:25.433281  3675 solver.cpp:243] Iteration 55560, loss = 0.00218014
I0521 12:24:25.433315  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00218004 (* 1 = 0.00218004 loss)
I0521 12:24:25.433323  3675 sgd_solver.cpp:138] Iteration 55560, lr = 3.125e-06
I0521 12:24:28.963547  3675 solver.cpp:243] Iteration 55580, loss = 0.00185001
I0521 12:24:28.963579  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0018499 (* 1 = 0.0018499 loss)
I0521 12:24:28.963585  3675 sgd_solver.cpp:138] Iteration 55580, lr = 3.125e-06
I0521 12:24:32.498173  3675 solver.cpp:243] Iteration 55600, loss = 0.00312128
I0521 12:24:32.498204  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00312118 (* 1 = 0.00312118 loss)
I0521 12:24:32.498210  3675 sgd_solver.cpp:138] Iteration 55600, lr = 3.125e-06
I0521 12:24:36.022110  3675 solver.cpp:243] Iteration 55620, loss = 0.00139186
I0521 12:24:36.022142  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00139176 (* 1 = 0.00139176 loss)
I0521 12:24:36.022148  3675 sgd_solver.cpp:138] Iteration 55620, lr = 3.125e-06
I0521 12:24:39.553212  3675 solver.cpp:243] Iteration 55640, loss = 0.00181824
I0521 12:24:39.553246  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00181814 (* 1 = 0.00181814 loss)
I0521 12:24:39.553252  3675 sgd_solver.cpp:138] Iteration 55640, lr = 3.125e-06
I0521 12:24:43.088688  3675 solver.cpp:243] Iteration 55660, loss = 0.00167226
I0521 12:24:43.088721  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00167216 (* 1 = 0.00167216 loss)
I0521 12:24:43.088727  3675 sgd_solver.cpp:138] Iteration 55660, lr = 3.125e-06
I0521 12:24:46.626504  3675 solver.cpp:243] Iteration 55680, loss = 0.00147738
I0521 12:24:46.626536  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00147728 (* 1 = 0.00147728 loss)
I0521 12:24:46.626543  3675 sgd_solver.cpp:138] Iteration 55680, lr = 3.125e-06
I0521 12:24:50.162978  3675 solver.cpp:243] Iteration 55700, loss = 0.00235657
I0521 12:24:50.163010  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00235646 (* 1 = 0.00235646 loss)
I0521 12:24:50.163017  3675 sgd_solver.cpp:138] Iteration 55700, lr = 3.125e-06
I0521 12:24:53.698861  3675 solver.cpp:243] Iteration 55720, loss = 0.00205468
I0521 12:24:53.699024  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00205458 (* 1 = 0.00205458 loss)
I0521 12:24:53.699031  3675 sgd_solver.cpp:138] Iteration 55720, lr = 3.125e-06
I0521 12:24:57.232291  3675 solver.cpp:243] Iteration 55740, loss = 0.00280068
I0521 12:24:57.232322  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00280058 (* 1 = 0.00280058 loss)
I0521 12:24:57.232329  3675 sgd_solver.cpp:138] Iteration 55740, lr = 3.125e-06
I0521 12:25:00.765496  3675 solver.cpp:243] Iteration 55760, loss = 0.00201199
I0521 12:25:00.765530  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00201189 (* 1 = 0.00201189 loss)
I0521 12:25:00.765537  3675 sgd_solver.cpp:138] Iteration 55760, lr = 3.125e-06
I0521 12:25:04.293241  3675 solver.cpp:243] Iteration 55780, loss = 0.00184287
I0521 12:25:04.293275  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00184276 (* 1 = 0.00184276 loss)
I0521 12:25:04.293282  3675 sgd_solver.cpp:138] Iteration 55780, lr = 3.125e-06
I0521 12:25:07.824890  3675 solver.cpp:243] Iteration 55800, loss = 0.00173397
I0521 12:25:07.824923  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00173387 (* 1 = 0.00173387 loss)
I0521 12:25:07.824929  3675 sgd_solver.cpp:138] Iteration 55800, lr = 3.125e-06
I0521 12:25:11.350381  3675 solver.cpp:243] Iteration 55820, loss = 0.00157586
I0521 12:25:11.350412  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00157576 (* 1 = 0.00157576 loss)
I0521 12:25:11.350419  3675 sgd_solver.cpp:138] Iteration 55820, lr = 3.125e-06
I0521 12:25:14.882575  3675 solver.cpp:243] Iteration 55840, loss = 0.00157717
I0521 12:25:14.882606  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00157707 (* 1 = 0.00157707 loss)
I0521 12:25:14.882612  3675 sgd_solver.cpp:138] Iteration 55840, lr = 3.125e-06
I0521 12:25:18.415092  3675 solver.cpp:243] Iteration 55860, loss = 0.00171682
I0521 12:25:18.415123  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00171672 (* 1 = 0.00171672 loss)
I0521 12:25:18.415145  3675 sgd_solver.cpp:138] Iteration 55860, lr = 3.125e-06
I0521 12:25:21.943925  3675 solver.cpp:243] Iteration 55880, loss = 0.00164583
I0521 12:25:21.943955  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00164573 (* 1 = 0.00164573 loss)
I0521 12:25:21.943961  3675 sgd_solver.cpp:138] Iteration 55880, lr = 3.125e-06
I0521 12:25:25.475754  3675 solver.cpp:243] Iteration 55900, loss = 0.00134832
I0521 12:25:25.475905  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00134821 (* 1 = 0.00134821 loss)
I0521 12:25:25.475914  3675 sgd_solver.cpp:138] Iteration 55900, lr = 3.125e-06
I0521 12:25:29.008442  3675 solver.cpp:243] Iteration 55920, loss = 0.00216015
I0521 12:25:29.008473  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00216005 (* 1 = 0.00216005 loss)
I0521 12:25:29.008479  3675 sgd_solver.cpp:138] Iteration 55920, lr = 3.125e-06
I0521 12:25:32.538208  3675 solver.cpp:243] Iteration 55940, loss = 0.00177201
I0521 12:25:32.538239  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0017719 (* 1 = 0.0017719 loss)
I0521 12:25:32.538246  3675 sgd_solver.cpp:138] Iteration 55940, lr = 3.125e-06
I0521 12:25:36.072261  3675 solver.cpp:243] Iteration 55960, loss = 0.00226752
I0521 12:25:36.072294  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00226742 (* 1 = 0.00226742 loss)
I0521 12:25:36.072301  3675 sgd_solver.cpp:138] Iteration 55960, lr = 3.125e-06
I0521 12:25:39.540913  3675 solver.cpp:243] Iteration 55980, loss = 0.00173089
I0521 12:25:39.540944  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00173079 (* 1 = 0.00173079 loss)
I0521 12:25:39.540951  3675 sgd_solver.cpp:138] Iteration 55980, lr = 3.125e-06
I0521 12:25:42.939342  3675 solver.cpp:596] Snapshotting to binary proto file models/LPR/lpr_resnet_lstm_iter_56000.caffemodel
I0521 12:25:42.969231  3675 sgd_solver.cpp:307] Snapshotting solver state to binary proto file models/LPR/lpr_resnet_lstm_iter_56000.solverstate
I0521 12:25:42.985775  3675 solver.cpp:358] Iteration 56000, Testing net (#0)
I0521 12:25:47.745615  3675 solver.cpp:425]     Test net output #0: acc = 1
I0521 12:25:47.745643  3675 solver.cpp:425]     Test net output #1: acc = 1
I0521 12:25:47.745651  3675 solver.cpp:425]     Test net output #2: ctcloss = 0.000631203 (* 1 = 0.000631203 loss)
I0521 12:25:47.884115  3675 solver.cpp:243] Iteration 56000, loss = 0.00228945
I0521 12:25:47.884147  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00228935 (* 1 = 0.00228935 loss)
I0521 12:25:47.884153  3675 sgd_solver.cpp:138] Iteration 56000, lr = 3.125e-06
I0521 12:25:51.416049  3675 solver.cpp:243] Iteration 56020, loss = 0.00167157
I0521 12:25:51.416081  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00167147 (* 1 = 0.00167147 loss)
I0521 12:25:51.416087  3675 sgd_solver.cpp:138] Iteration 56020, lr = 3.125e-06
I0521 12:25:54.957686  3675 solver.cpp:243] Iteration 56040, loss = 0.00136847
I0521 12:25:54.957716  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00136836 (* 1 = 0.00136836 loss)
I0521 12:25:54.957738  3675 sgd_solver.cpp:138] Iteration 56040, lr = 3.125e-06
I0521 12:25:58.491438  3675 solver.cpp:243] Iteration 56060, loss = 0.00158125
I0521 12:25:58.491605  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00158115 (* 1 = 0.00158115 loss)
I0521 12:25:58.491613  3675 sgd_solver.cpp:138] Iteration 56060, lr = 3.125e-06
I0521 12:26:02.032198  3675 solver.cpp:243] Iteration 56080, loss = 0.00155819
I0521 12:26:02.032230  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00155809 (* 1 = 0.00155809 loss)
I0521 12:26:02.032236  3675 sgd_solver.cpp:138] Iteration 56080, lr = 3.125e-06
I0521 12:26:05.576788  3675 solver.cpp:243] Iteration 56100, loss = 0.00181543
I0521 12:26:05.576836  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00181533 (* 1 = 0.00181533 loss)
I0521 12:26:05.576843  3675 sgd_solver.cpp:138] Iteration 56100, lr = 3.125e-06
I0521 12:26:09.111038  3675 solver.cpp:243] Iteration 56120, loss = 0.00101094
I0521 12:26:09.111073  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00101084 (* 1 = 0.00101084 loss)
I0521 12:26:09.111078  3675 sgd_solver.cpp:138] Iteration 56120, lr = 3.125e-06
I0521 12:26:12.651286  3675 solver.cpp:243] Iteration 56140, loss = 0.00171787
I0521 12:26:12.651316  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00171777 (* 1 = 0.00171777 loss)
I0521 12:26:12.651322  3675 sgd_solver.cpp:138] Iteration 56140, lr = 3.125e-06
I0521 12:26:16.188580  3675 solver.cpp:243] Iteration 56160, loss = 0.00174021
I0521 12:26:16.188613  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00174011 (* 1 = 0.00174011 loss)
I0521 12:26:16.188619  3675 sgd_solver.cpp:138] Iteration 56160, lr = 3.125e-06
I0521 12:26:19.723701  3675 solver.cpp:243] Iteration 56180, loss = 0.00205639
I0521 12:26:19.723732  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00205628 (* 1 = 0.00205628 loss)
I0521 12:26:19.723737  3675 sgd_solver.cpp:138] Iteration 56180, lr = 3.125e-06
I0521 12:26:23.255980  3675 solver.cpp:243] Iteration 56200, loss = 0.00159853
I0521 12:26:23.256011  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00159842 (* 1 = 0.00159842 loss)
I0521 12:26:23.256016  3675 sgd_solver.cpp:138] Iteration 56200, lr = 3.125e-06
I0521 12:26:26.796216  3675 solver.cpp:243] Iteration 56220, loss = 0.00158497
I0521 12:26:26.796245  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00158487 (* 1 = 0.00158487 loss)
I0521 12:26:26.796268  3675 sgd_solver.cpp:138] Iteration 56220, lr = 3.125e-06
I0521 12:26:30.330219  3675 solver.cpp:243] Iteration 56240, loss = 0.00178519
I0521 12:26:30.330384  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00178509 (* 1 = 0.00178509 loss)
I0521 12:26:30.330390  3675 sgd_solver.cpp:138] Iteration 56240, lr = 3.125e-06
I0521 12:26:33.874186  3675 solver.cpp:243] Iteration 56260, loss = 0.00152846
I0521 12:26:33.874217  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00152835 (* 1 = 0.00152835 loss)
I0521 12:26:33.874238  3675 sgd_solver.cpp:138] Iteration 56260, lr = 3.125e-06
I0521 12:26:37.408578  3675 solver.cpp:243] Iteration 56280, loss = 0.00228272
I0521 12:26:37.408609  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00228262 (* 1 = 0.00228262 loss)
I0521 12:26:37.408615  3675 sgd_solver.cpp:138] Iteration 56280, lr = 3.125e-06
I0521 12:26:40.944422  3675 solver.cpp:243] Iteration 56300, loss = 0.00240433
I0521 12:26:40.944453  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00240423 (* 1 = 0.00240423 loss)
I0521 12:26:40.944458  3675 sgd_solver.cpp:138] Iteration 56300, lr = 3.125e-06
I0521 12:26:44.482038  3675 solver.cpp:243] Iteration 56320, loss = 0.00145485
I0521 12:26:44.482070  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00145475 (* 1 = 0.00145475 loss)
I0521 12:26:44.482076  3675 sgd_solver.cpp:138] Iteration 56320, lr = 3.125e-06
I0521 12:26:48.022171  3675 solver.cpp:243] Iteration 56340, loss = 0.00226816
I0521 12:26:48.022203  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00226806 (* 1 = 0.00226806 loss)
I0521 12:26:48.022210  3675 sgd_solver.cpp:138] Iteration 56340, lr = 3.125e-06
I0521 12:26:51.554162  3675 solver.cpp:243] Iteration 56360, loss = 0.00118673
I0521 12:26:51.554194  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00118663 (* 1 = 0.00118663 loss)
I0521 12:26:51.554215  3675 sgd_solver.cpp:138] Iteration 56360, lr = 3.125e-06
I0521 12:26:55.097231  3675 solver.cpp:243] Iteration 56380, loss = 0.00173245
I0521 12:26:55.097262  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00173235 (* 1 = 0.00173235 loss)
I0521 12:26:55.097268  3675 sgd_solver.cpp:138] Iteration 56380, lr = 3.125e-06
I0521 12:26:58.630470  3675 solver.cpp:243] Iteration 56400, loss = 0.00158862
I0521 12:26:58.630501  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00158852 (* 1 = 0.00158852 loss)
I0521 12:26:58.630509  3675 sgd_solver.cpp:138] Iteration 56400, lr = 3.125e-06
I0521 12:27:02.171727  3675 solver.cpp:243] Iteration 56420, loss = 0.00289945
I0521 12:27:02.171882  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00289935 (* 1 = 0.00289935 loss)
I0521 12:27:02.171890  3675 sgd_solver.cpp:138] Iteration 56420, lr = 3.125e-06
I0521 12:27:05.708750  3675 solver.cpp:243] Iteration 56440, loss = 0.00173013
I0521 12:27:05.708783  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00173003 (* 1 = 0.00173003 loss)
I0521 12:27:05.708789  3675 sgd_solver.cpp:138] Iteration 56440, lr = 3.125e-06
I0521 12:27:09.247520  3675 solver.cpp:243] Iteration 56460, loss = 0.00249139
I0521 12:27:09.247551  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00249129 (* 1 = 0.00249129 loss)
I0521 12:27:09.247557  3675 sgd_solver.cpp:138] Iteration 56460, lr = 3.125e-06
I0521 12:27:12.779006  3675 solver.cpp:243] Iteration 56480, loss = 0.00206374
I0521 12:27:12.779037  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00206364 (* 1 = 0.00206364 loss)
I0521 12:27:12.779043  3675 sgd_solver.cpp:138] Iteration 56480, lr = 3.125e-06
I0521 12:27:16.325301  3675 solver.cpp:243] Iteration 56500, loss = 0.0020642
I0521 12:27:16.325333  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0020641 (* 1 = 0.0020641 loss)
I0521 12:27:16.325340  3675 sgd_solver.cpp:138] Iteration 56500, lr = 3.125e-06
I0521 12:27:19.863572  3675 solver.cpp:243] Iteration 56520, loss = 0.00200139
I0521 12:27:19.863605  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00200129 (* 1 = 0.00200129 loss)
I0521 12:27:19.863626  3675 sgd_solver.cpp:138] Iteration 56520, lr = 3.125e-06
I0521 12:27:23.401458  3675 solver.cpp:243] Iteration 56540, loss = 0.00177653
I0521 12:27:23.401489  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00177643 (* 1 = 0.00177643 loss)
I0521 12:27:23.401512  3675 sgd_solver.cpp:138] Iteration 56540, lr = 3.125e-06
I0521 12:27:26.940582  3675 solver.cpp:243] Iteration 56560, loss = 0.00170593
I0521 12:27:26.940613  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00170583 (* 1 = 0.00170583 loss)
I0521 12:27:26.940635  3675 sgd_solver.cpp:138] Iteration 56560, lr = 3.125e-06
I0521 12:27:30.478163  3675 solver.cpp:243] Iteration 56580, loss = 0.00235713
I0521 12:27:30.478193  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00235703 (* 1 = 0.00235703 loss)
I0521 12:27:30.478199  3675 sgd_solver.cpp:138] Iteration 56580, lr = 3.125e-06
I0521 12:27:34.022544  3675 solver.cpp:243] Iteration 56600, loss = 0.00148692
I0521 12:27:34.022701  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00148681 (* 1 = 0.00148681 loss)
I0521 12:27:34.022708  3675 sgd_solver.cpp:138] Iteration 56600, lr = 3.125e-06
I0521 12:27:37.558154  3675 solver.cpp:243] Iteration 56620, loss = 0.00179935
I0521 12:27:37.558187  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00179925 (* 1 = 0.00179925 loss)
I0521 12:27:37.558192  3675 sgd_solver.cpp:138] Iteration 56620, lr = 3.125e-06
I0521 12:27:41.092730  3675 solver.cpp:243] Iteration 56640, loss = 0.00132848
I0521 12:27:41.092761  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00132838 (* 1 = 0.00132838 loss)
I0521 12:27:41.092767  3675 sgd_solver.cpp:138] Iteration 56640, lr = 3.125e-06
I0521 12:27:44.628262  3675 solver.cpp:243] Iteration 56660, loss = 0.0019135
I0521 12:27:44.628293  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0019134 (* 1 = 0.0019134 loss)
I0521 12:27:44.628315  3675 sgd_solver.cpp:138] Iteration 56660, lr = 3.125e-06
I0521 12:27:48.168048  3675 solver.cpp:243] Iteration 56680, loss = 0.00505911
I0521 12:27:48.168079  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00505901 (* 1 = 0.00505901 loss)
I0521 12:27:48.168085  3675 sgd_solver.cpp:138] Iteration 56680, lr = 3.125e-06
I0521 12:27:51.708019  3675 solver.cpp:243] Iteration 56700, loss = 0.00240139
I0521 12:27:51.708050  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00240129 (* 1 = 0.00240129 loss)
I0521 12:27:51.708056  3675 sgd_solver.cpp:138] Iteration 56700, lr = 3.125e-06
I0521 12:27:55.247515  3675 solver.cpp:243] Iteration 56720, loss = 0.00218541
I0521 12:27:55.247546  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00218531 (* 1 = 0.00218531 loss)
I0521 12:27:55.247552  3675 sgd_solver.cpp:138] Iteration 56720, lr = 3.125e-06
I0521 12:27:58.779677  3675 solver.cpp:243] Iteration 56740, loss = 0.00226291
I0521 12:27:58.779709  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0022628 (* 1 = 0.0022628 loss)
I0521 12:27:58.779716  3675 sgd_solver.cpp:138] Iteration 56740, lr = 3.125e-06
I0521 12:28:02.321385  3675 solver.cpp:243] Iteration 56760, loss = 0.00232779
I0521 12:28:02.321418  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00232769 (* 1 = 0.00232769 loss)
I0521 12:28:02.321424  3675 sgd_solver.cpp:138] Iteration 56760, lr = 3.125e-06
I0521 12:28:05.857095  3675 solver.cpp:243] Iteration 56780, loss = 0.00177276
I0521 12:28:05.857261  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00177266 (* 1 = 0.00177266 loss)
I0521 12:28:05.857271  3675 sgd_solver.cpp:138] Iteration 56780, lr = 3.125e-06
I0521 12:28:09.395419  3675 solver.cpp:243] Iteration 56800, loss = 0.00212457
I0521 12:28:09.395449  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00212447 (* 1 = 0.00212447 loss)
I0521 12:28:09.395457  3675 sgd_solver.cpp:138] Iteration 56800, lr = 3.125e-06
I0521 12:28:12.931310  3675 solver.cpp:243] Iteration 56820, loss = 0.00234763
I0521 12:28:12.931341  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00234752 (* 1 = 0.00234752 loss)
I0521 12:28:12.931347  3675 sgd_solver.cpp:138] Iteration 56820, lr = 3.125e-06
I0521 12:28:16.472504  3675 solver.cpp:243] Iteration 56840, loss = 0.00195147
I0521 12:28:16.472537  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00195136 (* 1 = 0.00195136 loss)
I0521 12:28:16.472558  3675 sgd_solver.cpp:138] Iteration 56840, lr = 3.125e-06
I0521 12:28:20.004478  3675 solver.cpp:243] Iteration 56860, loss = 0.00194763
I0521 12:28:20.004509  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00194753 (* 1 = 0.00194753 loss)
I0521 12:28:20.004515  3675 sgd_solver.cpp:138] Iteration 56860, lr = 3.125e-06
I0521 12:28:23.537959  3675 solver.cpp:243] Iteration 56880, loss = 0.00179743
I0521 12:28:23.537992  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00179733 (* 1 = 0.00179733 loss)
I0521 12:28:23.537999  3675 sgd_solver.cpp:138] Iteration 56880, lr = 3.125e-06
I0521 12:28:27.068349  3675 solver.cpp:243] Iteration 56900, loss = 0.00203534
I0521 12:28:27.068380  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00203523 (* 1 = 0.00203523 loss)
I0521 12:28:27.068403  3675 sgd_solver.cpp:138] Iteration 56900, lr = 3.125e-06
I0521 12:28:30.596014  3675 solver.cpp:243] Iteration 56920, loss = 0.00243815
I0521 12:28:30.596045  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00243804 (* 1 = 0.00243804 loss)
I0521 12:28:30.596050  3675 sgd_solver.cpp:138] Iteration 56920, lr = 3.125e-06
I0521 12:28:34.126781  3675 solver.cpp:243] Iteration 56940, loss = 0.00151241
I0521 12:28:34.126813  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00151231 (* 1 = 0.00151231 loss)
I0521 12:28:34.126821  3675 sgd_solver.cpp:138] Iteration 56940, lr = 3.125e-06
I0521 12:28:37.658447  3675 solver.cpp:243] Iteration 56960, loss = 0.00234871
I0521 12:28:37.658612  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00234861 (* 1 = 0.00234861 loss)
I0521 12:28:37.658622  3675 sgd_solver.cpp:138] Iteration 56960, lr = 3.125e-06
I0521 12:28:41.198307  3675 solver.cpp:243] Iteration 56980, loss = 0.00187163
I0521 12:28:41.198339  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00187153 (* 1 = 0.00187153 loss)
I0521 12:28:41.198361  3675 sgd_solver.cpp:138] Iteration 56980, lr = 3.125e-06
I0521 12:28:44.600605  3675 solver.cpp:358] Iteration 57000, Testing net (#0)
I0521 12:28:49.356828  3675 solver.cpp:425]     Test net output #0: acc = 1
I0521 12:28:49.356858  3675 solver.cpp:425]     Test net output #1: acc = 1
I0521 12:28:49.356880  3675 solver.cpp:425]     Test net output #2: ctcloss = 0.00062804 (* 1 = 0.00062804 loss)
I0521 12:28:49.492794  3675 solver.cpp:243] Iteration 57000, loss = 0.00214727
I0521 12:28:49.492825  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00214716 (* 1 = 0.00214716 loss)
I0521 12:28:49.492831  3675 sgd_solver.cpp:138] Iteration 57000, lr = 3.125e-06
I0521 12:28:53.035117  3675 solver.cpp:243] Iteration 57020, loss = 0.00269186
I0521 12:28:53.035149  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00269176 (* 1 = 0.00269176 loss)
I0521 12:28:53.035156  3675 sgd_solver.cpp:138] Iteration 57020, lr = 3.125e-06
I0521 12:28:56.568336  3675 solver.cpp:243] Iteration 57040, loss = 0.00779919
I0521 12:28:56.568367  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00779909 (* 1 = 0.00779909 loss)
I0521 12:28:56.568373  3675 sgd_solver.cpp:138] Iteration 57040, lr = 3.125e-06
I0521 12:29:00.101122  3675 solver.cpp:243] Iteration 57060, loss = 0.00162688
I0521 12:29:00.101155  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00162678 (* 1 = 0.00162678 loss)
I0521 12:29:00.101161  3675 sgd_solver.cpp:138] Iteration 57060, lr = 3.125e-06
I0521 12:29:03.633208  3675 solver.cpp:243] Iteration 57080, loss = 0.0018484
I0521 12:29:03.633240  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0018483 (* 1 = 0.0018483 loss)
I0521 12:29:03.633247  3675 sgd_solver.cpp:138] Iteration 57080, lr = 3.125e-06
I0521 12:29:07.161192  3675 solver.cpp:243] Iteration 57100, loss = 0.00200894
I0521 12:29:07.161222  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00200884 (* 1 = 0.00200884 loss)
I0521 12:29:07.161228  3675 sgd_solver.cpp:138] Iteration 57100, lr = 3.125e-06
I0521 12:29:10.689673  3675 solver.cpp:243] Iteration 57120, loss = 0.00127793
I0521 12:29:10.689841  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00127783 (* 1 = 0.00127783 loss)
I0521 12:29:10.689847  3675 sgd_solver.cpp:138] Iteration 57120, lr = 3.125e-06
I0521 12:29:14.216214  3675 solver.cpp:243] Iteration 57140, loss = 0.00209244
I0521 12:29:14.216246  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00209234 (* 1 = 0.00209234 loss)
I0521 12:29:14.216253  3675 sgd_solver.cpp:138] Iteration 57140, lr = 3.125e-06
I0521 12:29:17.755726  3675 solver.cpp:243] Iteration 57160, loss = 0.00206716
I0521 12:29:17.755759  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00206705 (* 1 = 0.00206705 loss)
I0521 12:29:17.755764  3675 sgd_solver.cpp:138] Iteration 57160, lr = 3.125e-06
I0521 12:29:21.288417  3675 solver.cpp:243] Iteration 57180, loss = 0.00206126
I0521 12:29:21.288448  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00206116 (* 1 = 0.00206116 loss)
I0521 12:29:21.288470  3675 sgd_solver.cpp:138] Iteration 57180, lr = 3.125e-06
I0521 12:29:24.820475  3675 solver.cpp:243] Iteration 57200, loss = 0.00132983
I0521 12:29:24.820506  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00132972 (* 1 = 0.00132972 loss)
I0521 12:29:24.820513  3675 sgd_solver.cpp:138] Iteration 57200, lr = 3.125e-06
I0521 12:29:28.356317  3675 solver.cpp:243] Iteration 57220, loss = 0.00193608
I0521 12:29:28.356348  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00193598 (* 1 = 0.00193598 loss)
I0521 12:29:28.356354  3675 sgd_solver.cpp:138] Iteration 57220, lr = 3.125e-06
I0521 12:29:31.882987  3675 solver.cpp:243] Iteration 57240, loss = 0.00207969
I0521 12:29:31.883018  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00207959 (* 1 = 0.00207959 loss)
I0521 12:29:31.883024  3675 sgd_solver.cpp:138] Iteration 57240, lr = 3.125e-06
I0521 12:29:35.416955  3675 solver.cpp:243] Iteration 57260, loss = 0.00173009
I0521 12:29:35.416988  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00172999 (* 1 = 0.00172999 loss)
I0521 12:29:35.416995  3675 sgd_solver.cpp:138] Iteration 57260, lr = 3.125e-06
I0521 12:29:38.885588  3675 solver.cpp:243] Iteration 57280, loss = 0.00157314
I0521 12:29:38.885618  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00157303 (* 1 = 0.00157303 loss)
I0521 12:29:38.885624  3675 sgd_solver.cpp:138] Iteration 57280, lr = 3.125e-06
I0521 12:29:42.418391  3675 solver.cpp:243] Iteration 57300, loss = 0.00193111
I0521 12:29:42.418550  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.001931 (* 1 = 0.001931 loss)
I0521 12:29:42.418557  3675 sgd_solver.cpp:138] Iteration 57300, lr = 3.125e-06
I0521 12:29:45.949692  3675 solver.cpp:243] Iteration 57320, loss = 0.00208232
I0521 12:29:45.949723  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00208222 (* 1 = 0.00208222 loss)
I0521 12:29:45.949729  3675 sgd_solver.cpp:138] Iteration 57320, lr = 3.125e-06
I0521 12:29:49.481858  3675 solver.cpp:243] Iteration 57340, loss = 0.00217487
I0521 12:29:49.481887  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00217477 (* 1 = 0.00217477 loss)
I0521 12:29:49.481894  3675 sgd_solver.cpp:138] Iteration 57340, lr = 3.125e-06
I0521 12:29:53.015099  3675 solver.cpp:243] Iteration 57360, loss = 0.00195382
I0521 12:29:53.015130  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00195372 (* 1 = 0.00195372 loss)
I0521 12:29:53.015136  3675 sgd_solver.cpp:138] Iteration 57360, lr = 3.125e-06
I0521 12:29:56.551026  3675 solver.cpp:243] Iteration 57380, loss = 0.00159733
I0521 12:29:56.551056  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00159723 (* 1 = 0.00159723 loss)
I0521 12:29:56.551079  3675 sgd_solver.cpp:138] Iteration 57380, lr = 3.125e-06
I0521 12:30:00.078652  3675 solver.cpp:243] Iteration 57400, loss = 0.00157855
I0521 12:30:00.078682  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00157845 (* 1 = 0.00157845 loss)
I0521 12:30:00.078689  3675 sgd_solver.cpp:138] Iteration 57400, lr = 3.125e-06
I0521 12:30:03.608803  3675 solver.cpp:243] Iteration 57420, loss = 0.00190707
I0521 12:30:03.608835  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00190697 (* 1 = 0.00190697 loss)
I0521 12:30:03.608841  3675 sgd_solver.cpp:138] Iteration 57420, lr = 3.125e-06
I0521 12:30:07.141047  3675 solver.cpp:243] Iteration 57440, loss = 0.00146132
I0521 12:30:07.141077  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00146121 (* 1 = 0.00146121 loss)
I0521 12:30:07.141082  3675 sgd_solver.cpp:138] Iteration 57440, lr = 3.125e-06
I0521 12:30:10.680743  3675 solver.cpp:243] Iteration 57460, loss = 0.00134185
I0521 12:30:10.680773  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00134175 (* 1 = 0.00134175 loss)
I0521 12:30:10.680797  3675 sgd_solver.cpp:138] Iteration 57460, lr = 3.125e-06
I0521 12:30:14.219681  3675 solver.cpp:243] Iteration 57480, loss = 0.00198842
I0521 12:30:14.219820  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00198832 (* 1 = 0.00198832 loss)
I0521 12:30:14.219828  3675 sgd_solver.cpp:138] Iteration 57480, lr = 3.125e-06
I0521 12:30:17.768201  3675 solver.cpp:243] Iteration 57500, loss = 0.00208701
I0521 12:30:17.768232  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00208691 (* 1 = 0.00208691 loss)
I0521 12:30:17.768239  3675 sgd_solver.cpp:138] Iteration 57500, lr = 3.125e-06
I0521 12:30:21.304785  3675 solver.cpp:243] Iteration 57520, loss = 0.00226293
I0521 12:30:21.304833  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00226283 (* 1 = 0.00226283 loss)
I0521 12:30:21.304839  3675 sgd_solver.cpp:138] Iteration 57520, lr = 3.125e-06
I0521 12:30:24.837589  3675 solver.cpp:243] Iteration 57540, loss = 0.00136653
I0521 12:30:24.837620  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00136643 (* 1 = 0.00136643 loss)
I0521 12:30:24.837626  3675 sgd_solver.cpp:138] Iteration 57540, lr = 3.125e-06
I0521 12:30:28.370898  3675 solver.cpp:243] Iteration 57560, loss = 0.00208616
I0521 12:30:28.370930  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00208606 (* 1 = 0.00208606 loss)
I0521 12:30:28.370936  3675 sgd_solver.cpp:138] Iteration 57560, lr = 3.125e-06
I0521 12:30:31.906308  3675 solver.cpp:243] Iteration 57580, loss = 0.00212487
I0521 12:30:31.906339  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00212477 (* 1 = 0.00212477 loss)
I0521 12:30:31.906345  3675 sgd_solver.cpp:138] Iteration 57580, lr = 3.125e-06
I0521 12:30:35.439275  3675 solver.cpp:243] Iteration 57600, loss = 0.00167468
I0521 12:30:35.439306  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00167458 (* 1 = 0.00167458 loss)
I0521 12:30:35.439311  3675 sgd_solver.cpp:138] Iteration 57600, lr = 3.125e-06
I0521 12:30:38.971457  3675 solver.cpp:243] Iteration 57620, loss = 0.00166679
I0521 12:30:38.971488  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00166669 (* 1 = 0.00166669 loss)
I0521 12:30:38.971494  3675 sgd_solver.cpp:138] Iteration 57620, lr = 3.125e-06
I0521 12:30:42.504272  3675 solver.cpp:243] Iteration 57640, loss = 0.00154967
I0521 12:30:42.504307  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00154957 (* 1 = 0.00154957 loss)
I0521 12:30:42.504314  3675 sgd_solver.cpp:138] Iteration 57640, lr = 3.125e-06
I0521 12:30:46.040801  3675 solver.cpp:243] Iteration 57660, loss = 0.00253795
I0521 12:30:46.040973  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00253785 (* 1 = 0.00253785 loss)
I0521 12:30:46.040982  3675 sgd_solver.cpp:138] Iteration 57660, lr = 3.125e-06
I0521 12:30:49.573210  3675 solver.cpp:243] Iteration 57680, loss = 0.00398366
I0521 12:30:49.573241  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00398356 (* 1 = 0.00398356 loss)
I0521 12:30:49.573247  3675 sgd_solver.cpp:138] Iteration 57680, lr = 3.125e-06
I0521 12:30:53.117811  3675 solver.cpp:243] Iteration 57700, loss = 0.00222828
I0521 12:30:53.117844  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00222818 (* 1 = 0.00222818 loss)
I0521 12:30:53.117851  3675 sgd_solver.cpp:138] Iteration 57700, lr = 3.125e-06
I0521 12:30:56.652737  3675 solver.cpp:243] Iteration 57720, loss = 0.00179777
I0521 12:30:56.652770  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00179767 (* 1 = 0.00179767 loss)
I0521 12:30:56.652776  3675 sgd_solver.cpp:138] Iteration 57720, lr = 3.125e-06
I0521 12:31:00.192045  3675 solver.cpp:243] Iteration 57740, loss = 0.00204393
I0521 12:31:00.192076  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00204383 (* 1 = 0.00204383 loss)
I0521 12:31:00.192082  3675 sgd_solver.cpp:138] Iteration 57740, lr = 3.125e-06
I0521 12:31:03.726405  3675 solver.cpp:243] Iteration 57760, loss = 0.00194659
I0521 12:31:03.726436  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00194649 (* 1 = 0.00194649 loss)
I0521 12:31:03.726459  3675 sgd_solver.cpp:138] Iteration 57760, lr = 3.125e-06
I0521 12:31:07.267097  3675 solver.cpp:243] Iteration 57780, loss = 0.00134533
I0521 12:31:07.267128  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00134523 (* 1 = 0.00134523 loss)
I0521 12:31:07.267134  3675 sgd_solver.cpp:138] Iteration 57780, lr = 3.125e-06
I0521 12:31:10.802664  3675 solver.cpp:243] Iteration 57800, loss = 0.00177668
I0521 12:31:10.802695  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00177658 (* 1 = 0.00177658 loss)
I0521 12:31:10.802701  3675 sgd_solver.cpp:138] Iteration 57800, lr = 3.125e-06
I0521 12:31:14.341812  3675 solver.cpp:243] Iteration 57820, loss = 0.00117368
I0521 12:31:14.341859  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00117358 (* 1 = 0.00117358 loss)
I0521 12:31:14.341869  3675 sgd_solver.cpp:138] Iteration 57820, lr = 3.125e-06
I0521 12:31:17.883021  3675 solver.cpp:243] Iteration 57840, loss = 0.00147587
I0521 12:31:17.883173  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00147577 (* 1 = 0.00147577 loss)
I0521 12:31:17.883181  3675 sgd_solver.cpp:138] Iteration 57840, lr = 3.125e-06
I0521 12:31:21.415702  3675 solver.cpp:243] Iteration 57860, loss = 0.00146292
I0521 12:31:21.415735  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00146282 (* 1 = 0.00146282 loss)
I0521 12:31:21.415740  3675 sgd_solver.cpp:138] Iteration 57860, lr = 3.125e-06
I0521 12:31:24.953486  3675 solver.cpp:243] Iteration 57880, loss = 0.00229013
I0521 12:31:24.953518  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00229003 (* 1 = 0.00229003 loss)
I0521 12:31:24.953526  3675 sgd_solver.cpp:138] Iteration 57880, lr = 3.125e-06
I0521 12:31:28.484630  3675 solver.cpp:243] Iteration 57900, loss = 0.00165398
I0521 12:31:28.484661  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00165388 (* 1 = 0.00165388 loss)
I0521 12:31:28.484668  3675 sgd_solver.cpp:138] Iteration 57900, lr = 3.125e-06
I0521 12:31:32.018420  3675 solver.cpp:243] Iteration 57920, loss = 0.00166773
I0521 12:31:32.018453  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00166763 (* 1 = 0.00166763 loss)
I0521 12:31:32.018460  3675 sgd_solver.cpp:138] Iteration 57920, lr = 3.125e-06
I0521 12:31:35.555259  3675 solver.cpp:243] Iteration 57940, loss = 0.00155971
I0521 12:31:35.555291  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00155961 (* 1 = 0.00155961 loss)
I0521 12:31:35.555297  3675 sgd_solver.cpp:138] Iteration 57940, lr = 3.125e-06
I0521 12:31:39.094262  3675 solver.cpp:243] Iteration 57960, loss = 0.00185923
I0521 12:31:39.094295  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00185913 (* 1 = 0.00185913 loss)
I0521 12:31:39.094316  3675 sgd_solver.cpp:138] Iteration 57960, lr = 3.125e-06
I0521 12:31:42.631563  3675 solver.cpp:243] Iteration 57980, loss = 0.00141867
I0521 12:31:42.631593  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00141856 (* 1 = 0.00141856 loss)
I0521 12:31:42.631599  3675 sgd_solver.cpp:138] Iteration 57980, lr = 3.125e-06
I0521 12:31:46.033548  3675 solver.cpp:596] Snapshotting to binary proto file models/LPR/lpr_resnet_lstm_iter_58000.caffemodel
I0521 12:31:46.062961  3675 sgd_solver.cpp:307] Snapshotting solver state to binary proto file models/LPR/lpr_resnet_lstm_iter_58000.solverstate
I0521 12:31:46.079411  3675 solver.cpp:358] Iteration 58000, Testing net (#0)
I0521 12:31:50.845432  3675 solver.cpp:425]     Test net output #0: acc = 1
I0521 12:31:50.845556  3675 solver.cpp:425]     Test net output #1: acc = 1
I0521 12:31:50.845566  3675 solver.cpp:425]     Test net output #2: ctcloss = 0.000629848 (* 1 = 0.000629848 loss)
I0521 12:31:50.983219  3675 solver.cpp:243] Iteration 58000, loss = 0.00149209
I0521 12:31:50.983250  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00149199 (* 1 = 0.00149199 loss)
I0521 12:31:50.983258  3675 sgd_solver.cpp:138] Iteration 58000, lr = 3.125e-06
I0521 12:31:54.522718  3675 solver.cpp:243] Iteration 58020, loss = 0.00164014
I0521 12:31:54.522750  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00164004 (* 1 = 0.00164004 loss)
I0521 12:31:54.522755  3675 sgd_solver.cpp:138] Iteration 58020, lr = 3.125e-06
I0521 12:31:58.061990  3675 solver.cpp:243] Iteration 58040, loss = 0.00162164
I0521 12:31:58.062021  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00162154 (* 1 = 0.00162154 loss)
I0521 12:31:58.062043  3675 sgd_solver.cpp:138] Iteration 58040, lr = 3.125e-06
I0521 12:32:01.602643  3675 solver.cpp:243] Iteration 58060, loss = 0.00174332
I0521 12:32:01.602674  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00174322 (* 1 = 0.00174322 loss)
I0521 12:32:01.602680  3675 sgd_solver.cpp:138] Iteration 58060, lr = 3.125e-06
I0521 12:32:05.133522  3675 solver.cpp:243] Iteration 58080, loss = 0.00170294
I0521 12:32:05.133554  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00170284 (* 1 = 0.00170284 loss)
I0521 12:32:05.133560  3675 sgd_solver.cpp:138] Iteration 58080, lr = 3.125e-06
I0521 12:32:08.674038  3675 solver.cpp:243] Iteration 58100, loss = 0.00206527
I0521 12:32:08.674072  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00206516 (* 1 = 0.00206516 loss)
I0521 12:32:08.674094  3675 sgd_solver.cpp:138] Iteration 58100, lr = 3.125e-06
I0521 12:32:12.210141  3675 solver.cpp:243] Iteration 58120, loss = 0.00272675
I0521 12:32:12.210175  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00272665 (* 1 = 0.00272665 loss)
I0521 12:32:12.210181  3675 sgd_solver.cpp:138] Iteration 58120, lr = 3.125e-06
I0521 12:32:15.747069  3675 solver.cpp:243] Iteration 58140, loss = 0.00257902
I0521 12:32:15.747102  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00257892 (* 1 = 0.00257892 loss)
I0521 12:32:15.747107  3675 sgd_solver.cpp:138] Iteration 58140, lr = 3.125e-06
I0521 12:32:19.278556  3675 solver.cpp:243] Iteration 58160, loss = 0.00180037
I0521 12:32:19.278587  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00180027 (* 1 = 0.00180027 loss)
I0521 12:32:19.278594  3675 sgd_solver.cpp:138] Iteration 58160, lr = 3.125e-06
I0521 12:32:22.808849  3675 solver.cpp:243] Iteration 58180, loss = 0.00434281
I0521 12:32:22.809063  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00434271 (* 1 = 0.00434271 loss)
I0521 12:32:22.809072  3675 sgd_solver.cpp:138] Iteration 58180, lr = 3.125e-06
I0521 12:32:26.345177  3675 solver.cpp:243] Iteration 58200, loss = 0.00195837
I0521 12:32:26.345207  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00195827 (* 1 = 0.00195827 loss)
I0521 12:32:26.345213  3675 sgd_solver.cpp:138] Iteration 58200, lr = 3.125e-06
I0521 12:32:29.881969  3675 solver.cpp:243] Iteration 58220, loss = 0.00565673
I0521 12:32:29.882011  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00565662 (* 1 = 0.00565662 loss)
I0521 12:32:29.882017  3675 sgd_solver.cpp:138] Iteration 58220, lr = 3.125e-06
I0521 12:32:33.417953  3675 solver.cpp:243] Iteration 58240, loss = 0.00263272
I0521 12:32:33.417986  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00263262 (* 1 = 0.00263262 loss)
I0521 12:32:33.417992  3675 sgd_solver.cpp:138] Iteration 58240, lr = 3.125e-06
I0521 12:32:36.958350  3675 solver.cpp:243] Iteration 58260, loss = 0.00211193
I0521 12:32:36.958380  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00211183 (* 1 = 0.00211183 loss)
I0521 12:32:36.958385  3675 sgd_solver.cpp:138] Iteration 58260, lr = 3.125e-06
I0521 12:32:40.496897  3675 solver.cpp:243] Iteration 58280, loss = 0.00181372
I0521 12:32:40.496930  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00181362 (* 1 = 0.00181362 loss)
I0521 12:32:40.496937  3675 sgd_solver.cpp:138] Iteration 58280, lr = 3.125e-06
I0521 12:32:44.036411  3675 solver.cpp:243] Iteration 58300, loss = 0.00145936
I0521 12:32:44.036442  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00145926 (* 1 = 0.00145926 loss)
I0521 12:32:44.036449  3675 sgd_solver.cpp:138] Iteration 58300, lr = 3.125e-06
I0521 12:32:47.571058  3675 solver.cpp:243] Iteration 58320, loss = 0.00196888
I0521 12:32:47.571087  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00196878 (* 1 = 0.00196878 loss)
I0521 12:32:47.571092  3675 sgd_solver.cpp:138] Iteration 58320, lr = 3.125e-06
I0521 12:32:51.103224  3675 solver.cpp:243] Iteration 58340, loss = 0.00179671
I0521 12:32:51.103255  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00179661 (* 1 = 0.00179661 loss)
I0521 12:32:51.103261  3675 sgd_solver.cpp:138] Iteration 58340, lr = 3.125e-06
I0521 12:32:54.639533  3675 solver.cpp:243] Iteration 58360, loss = 0.00203874
I0521 12:32:54.639629  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00203864 (* 1 = 0.00203864 loss)
I0521 12:32:54.639637  3675 sgd_solver.cpp:138] Iteration 58360, lr = 3.125e-06
I0521 12:32:58.175804  3675 solver.cpp:243] Iteration 58380, loss = 0.00191026
I0521 12:32:58.175835  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00191016 (* 1 = 0.00191016 loss)
I0521 12:32:58.175858  3675 sgd_solver.cpp:138] Iteration 58380, lr = 3.125e-06
I0521 12:33:01.702498  3675 solver.cpp:243] Iteration 58400, loss = 0.00194133
I0521 12:33:01.702530  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00194123 (* 1 = 0.00194123 loss)
I0521 12:33:01.702536  3675 sgd_solver.cpp:138] Iteration 58400, lr = 3.125e-06
I0521 12:33:05.233896  3675 solver.cpp:243] Iteration 58420, loss = 0.00136621
I0521 12:33:05.233927  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00136611 (* 1 = 0.00136611 loss)
I0521 12:33:05.233933  3675 sgd_solver.cpp:138] Iteration 58420, lr = 3.125e-06
I0521 12:33:08.769680  3675 solver.cpp:243] Iteration 58440, loss = 0.00192226
I0521 12:33:08.769711  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00192216 (* 1 = 0.00192216 loss)
I0521 12:33:08.769717  3675 sgd_solver.cpp:138] Iteration 58440, lr = 3.125e-06
I0521 12:33:12.305572  3675 solver.cpp:243] Iteration 58460, loss = 0.00197194
I0521 12:33:12.305604  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00197184 (* 1 = 0.00197184 loss)
I0521 12:33:12.305610  3675 sgd_solver.cpp:138] Iteration 58460, lr = 3.125e-06
I0521 12:33:15.846359  3675 solver.cpp:243] Iteration 58480, loss = 0.00152908
I0521 12:33:15.846392  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00152898 (* 1 = 0.00152898 loss)
I0521 12:33:15.846415  3675 sgd_solver.cpp:138] Iteration 58480, lr = 3.125e-06
I0521 12:33:19.395965  3675 solver.cpp:243] Iteration 58500, loss = 0.00197637
I0521 12:33:19.395997  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00197627 (* 1 = 0.00197627 loss)
I0521 12:33:19.396019  3675 sgd_solver.cpp:138] Iteration 58500, lr = 3.125e-06
I0521 12:33:22.930145  3675 solver.cpp:243] Iteration 58520, loss = 0.00151578
I0521 12:33:22.930177  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00151568 (* 1 = 0.00151568 loss)
I0521 12:33:22.930183  3675 sgd_solver.cpp:138] Iteration 58520, lr = 3.125e-06
I0521 12:33:26.455097  3675 solver.cpp:243] Iteration 58540, loss = 0.00372641
I0521 12:33:26.455267  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00372631 (* 1 = 0.00372631 loss)
I0521 12:33:26.455276  3675 sgd_solver.cpp:138] Iteration 58540, lr = 3.125e-06
I0521 12:33:29.986359  3675 solver.cpp:243] Iteration 58560, loss = 0.00192693
I0521 12:33:29.986392  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00192683 (* 1 = 0.00192683 loss)
I0521 12:33:29.986397  3675 sgd_solver.cpp:138] Iteration 58560, lr = 3.125e-06
I0521 12:33:33.456043  3675 solver.cpp:243] Iteration 58580, loss = 0.00202285
I0521 12:33:33.456071  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00202275 (* 1 = 0.00202275 loss)
I0521 12:33:33.456077  3675 sgd_solver.cpp:138] Iteration 58580, lr = 3.125e-06
I0521 12:33:36.998096  3675 solver.cpp:243] Iteration 58600, loss = 0.00231292
I0521 12:33:36.998127  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00231282 (* 1 = 0.00231282 loss)
I0521 12:33:36.998149  3675 sgd_solver.cpp:138] Iteration 58600, lr = 3.125e-06
I0521 12:33:40.528859  3675 solver.cpp:243] Iteration 58620, loss = 0.00225708
I0521 12:33:40.528892  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00225699 (* 1 = 0.00225699 loss)
I0521 12:33:40.528898  3675 sgd_solver.cpp:138] Iteration 58620, lr = 3.125e-06
I0521 12:33:44.069017  3675 solver.cpp:243] Iteration 58640, loss = 0.00182088
I0521 12:33:44.069048  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00182078 (* 1 = 0.00182078 loss)
I0521 12:33:44.069054  3675 sgd_solver.cpp:138] Iteration 58640, lr = 3.125e-06
I0521 12:33:47.607488  3675 solver.cpp:243] Iteration 58660, loss = 0.00150273
I0521 12:33:47.607519  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00150263 (* 1 = 0.00150263 loss)
I0521 12:33:47.607540  3675 sgd_solver.cpp:138] Iteration 58660, lr = 3.125e-06
I0521 12:33:51.144047  3675 solver.cpp:243] Iteration 58680, loss = 0.0019076
I0521 12:33:51.144078  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0019075 (* 1 = 0.0019075 loss)
I0521 12:33:51.144100  3675 sgd_solver.cpp:138] Iteration 58680, lr = 3.125e-06
I0521 12:33:54.677987  3675 solver.cpp:243] Iteration 58700, loss = 0.00262771
I0521 12:33:54.678020  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00262761 (* 1 = 0.00262761 loss)
I0521 12:33:54.678026  3675 sgd_solver.cpp:138] Iteration 58700, lr = 3.125e-06
I0521 12:33:58.222400  3675 solver.cpp:243] Iteration 58720, loss = 0.00274721
I0521 12:33:58.222579  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00274711 (* 1 = 0.00274711 loss)
I0521 12:33:58.222587  3675 sgd_solver.cpp:138] Iteration 58720, lr = 3.125e-06
I0521 12:34:01.762461  3675 solver.cpp:243] Iteration 58740, loss = 0.00133512
I0521 12:34:01.762495  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00133502 (* 1 = 0.00133502 loss)
I0521 12:34:01.762517  3675 sgd_solver.cpp:138] Iteration 58740, lr = 3.125e-06
I0521 12:34:05.298594  3675 solver.cpp:243] Iteration 58760, loss = 0.00146561
I0521 12:34:05.298627  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00146551 (* 1 = 0.00146551 loss)
I0521 12:34:05.298633  3675 sgd_solver.cpp:138] Iteration 58760, lr = 3.125e-06
I0521 12:34:08.845899  3675 solver.cpp:243] Iteration 58780, loss = 0.00244168
I0521 12:34:08.845932  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00244158 (* 1 = 0.00244158 loss)
I0521 12:34:08.845954  3675 sgd_solver.cpp:138] Iteration 58780, lr = 3.125e-06
I0521 12:34:12.384387  3675 solver.cpp:243] Iteration 58800, loss = 0.00195508
I0521 12:34:12.384418  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00195498 (* 1 = 0.00195498 loss)
I0521 12:34:12.384424  3675 sgd_solver.cpp:138] Iteration 58800, lr = 3.125e-06
I0521 12:34:15.916231  3675 solver.cpp:243] Iteration 58820, loss = 0.0014338
I0521 12:34:15.916262  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0014337 (* 1 = 0.0014337 loss)
I0521 12:34:15.916268  3675 sgd_solver.cpp:138] Iteration 58820, lr = 3.125e-06
I0521 12:34:19.454314  3675 solver.cpp:243] Iteration 58840, loss = 0.00225019
I0521 12:34:19.454345  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00225009 (* 1 = 0.00225009 loss)
I0521 12:34:19.454351  3675 sgd_solver.cpp:138] Iteration 58840, lr = 3.125e-06
I0521 12:34:22.993299  3675 solver.cpp:243] Iteration 58860, loss = 0.00168167
I0521 12:34:22.993332  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00168157 (* 1 = 0.00168157 loss)
I0521 12:34:22.993338  3675 sgd_solver.cpp:138] Iteration 58860, lr = 3.125e-06
I0521 12:34:26.536603  3675 solver.cpp:243] Iteration 58880, loss = 0.00141188
I0521 12:34:26.536634  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00141178 (* 1 = 0.00141178 loss)
I0521 12:34:26.536640  3675 sgd_solver.cpp:138] Iteration 58880, lr = 3.125e-06
I0521 12:34:30.083075  3675 solver.cpp:243] Iteration 58900, loss = 0.00138121
I0521 12:34:30.083240  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00138111 (* 1 = 0.00138111 loss)
I0521 12:34:30.083245  3675 sgd_solver.cpp:138] Iteration 58900, lr = 3.125e-06
I0521 12:34:33.625165  3675 solver.cpp:243] Iteration 58920, loss = 0.00206211
I0521 12:34:33.625200  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00206201 (* 1 = 0.00206201 loss)
I0521 12:34:33.625205  3675 sgd_solver.cpp:138] Iteration 58920, lr = 3.125e-06
I0521 12:34:37.165237  3675 solver.cpp:243] Iteration 58940, loss = 0.00212798
I0521 12:34:37.165268  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00212788 (* 1 = 0.00212788 loss)
I0521 12:34:37.165274  3675 sgd_solver.cpp:138] Iteration 58940, lr = 3.125e-06
I0521 12:34:40.701627  3675 solver.cpp:243] Iteration 58960, loss = 0.00150938
I0521 12:34:40.701655  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00150928 (* 1 = 0.00150928 loss)
I0521 12:34:40.701676  3675 sgd_solver.cpp:138] Iteration 58960, lr = 3.125e-06
I0521 12:34:44.239890  3675 solver.cpp:243] Iteration 58980, loss = 0.00148645
I0521 12:34:44.239923  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00148635 (* 1 = 0.00148635 loss)
I0521 12:34:44.239930  3675 sgd_solver.cpp:138] Iteration 58980, lr = 3.125e-06
I0521 12:34:47.648790  3675 solver.cpp:358] Iteration 59000, Testing net (#0)
I0521 12:34:52.402801  3675 solver.cpp:425]     Test net output #0: acc = 1
I0521 12:34:52.402829  3675 solver.cpp:425]     Test net output #1: acc = 1
I0521 12:34:52.402835  3675 solver.cpp:425]     Test net output #2: ctcloss = 0.000626022 (* 1 = 0.000626022 loss)
I0521 12:34:52.540010  3675 solver.cpp:243] Iteration 59000, loss = 0.00132842
I0521 12:34:52.540038  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00132832 (* 1 = 0.00132832 loss)
I0521 12:34:52.540045  3675 sgd_solver.cpp:138] Iteration 59000, lr = 3.125e-06
I0521 12:34:56.072850  3675 solver.cpp:243] Iteration 59020, loss = 0.00155596
I0521 12:34:56.072881  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00155586 (* 1 = 0.00155586 loss)
I0521 12:34:56.072903  3675 sgd_solver.cpp:138] Iteration 59020, lr = 3.125e-06
I0521 12:34:59.607050  3675 solver.cpp:243] Iteration 59040, loss = 0.00156115
I0521 12:34:59.607082  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00156105 (* 1 = 0.00156105 loss)
I0521 12:34:59.607089  3675 sgd_solver.cpp:138] Iteration 59040, lr = 3.125e-06
I0521 12:35:03.149974  3675 solver.cpp:243] Iteration 59060, loss = 0.00182001
I0521 12:35:03.150120  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00181991 (* 1 = 0.00181991 loss)
I0521 12:35:03.150128  3675 sgd_solver.cpp:138] Iteration 59060, lr = 3.125e-06
I0521 12:35:06.684798  3675 solver.cpp:243] Iteration 59080, loss = 0.00195432
I0521 12:35:06.684829  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00195422 (* 1 = 0.00195422 loss)
I0521 12:35:06.684835  3675 sgd_solver.cpp:138] Iteration 59080, lr = 3.125e-06
I0521 12:35:10.217849  3675 solver.cpp:243] Iteration 59100, loss = 0.00182882
I0521 12:35:10.217882  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00182872 (* 1 = 0.00182872 loss)
I0521 12:35:10.217890  3675 sgd_solver.cpp:138] Iteration 59100, lr = 3.125e-06
I0521 12:35:13.749861  3675 solver.cpp:243] Iteration 59120, loss = 0.00190436
I0521 12:35:13.749891  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00190426 (* 1 = 0.00190426 loss)
I0521 12:35:13.749913  3675 sgd_solver.cpp:138] Iteration 59120, lr = 3.125e-06
I0521 12:35:17.287310  3675 solver.cpp:243] Iteration 59140, loss = 0.00182627
I0521 12:35:17.287353  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00182617 (* 1 = 0.00182617 loss)
I0521 12:35:17.287375  3675 sgd_solver.cpp:138] Iteration 59140, lr = 3.125e-06
I0521 12:35:20.822957  3675 solver.cpp:243] Iteration 59160, loss = 0.00189584
I0521 12:35:20.822988  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00189574 (* 1 = 0.00189574 loss)
I0521 12:35:20.822993  3675 sgd_solver.cpp:138] Iteration 59160, lr = 3.125e-06
I0521 12:35:24.358907  3675 solver.cpp:243] Iteration 59180, loss = 0.00179983
I0521 12:35:24.358939  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00179973 (* 1 = 0.00179973 loss)
I0521 12:35:24.358947  3675 sgd_solver.cpp:138] Iteration 59180, lr = 3.125e-06
I0521 12:35:27.902176  3675 solver.cpp:243] Iteration 59200, loss = 0.00159848
I0521 12:35:27.902209  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00159838 (* 1 = 0.00159838 loss)
I0521 12:35:27.902215  3675 sgd_solver.cpp:138] Iteration 59200, lr = 3.125e-06
I0521 12:35:31.443483  3675 solver.cpp:243] Iteration 59220, loss = 0.00224922
I0521 12:35:31.443512  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00224912 (* 1 = 0.00224912 loss)
I0521 12:35:31.443518  3675 sgd_solver.cpp:138] Iteration 59220, lr = 3.125e-06
I0521 12:35:34.984392  3675 solver.cpp:243] Iteration 59240, loss = 0.00142983
I0521 12:35:34.984509  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00142973 (* 1 = 0.00142973 loss)
I0521 12:35:34.984516  3675 sgd_solver.cpp:138] Iteration 59240, lr = 3.125e-06
I0521 12:35:38.522871  3675 solver.cpp:243] Iteration 59260, loss = 0.00157079
I0521 12:35:38.522902  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00157069 (* 1 = 0.00157069 loss)
I0521 12:35:38.522908  3675 sgd_solver.cpp:138] Iteration 59260, lr = 3.125e-06
I0521 12:35:42.060155  3675 solver.cpp:243] Iteration 59280, loss = 0.00190848
I0521 12:35:42.060189  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00190838 (* 1 = 0.00190838 loss)
I0521 12:35:42.060195  3675 sgd_solver.cpp:138] Iteration 59280, lr = 3.125e-06
I0521 12:35:45.599601  3675 solver.cpp:243] Iteration 59300, loss = 0.00238627
I0521 12:35:45.599632  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00238617 (* 1 = 0.00238617 loss)
I0521 12:35:45.599637  3675 sgd_solver.cpp:138] Iteration 59300, lr = 3.125e-06
I0521 12:35:49.142405  3675 solver.cpp:243] Iteration 59320, loss = 0.00269059
I0521 12:35:49.142436  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00269049 (* 1 = 0.00269049 loss)
I0521 12:35:49.142458  3675 sgd_solver.cpp:138] Iteration 59320, lr = 3.125e-06
I0521 12:35:52.677148  3675 solver.cpp:243] Iteration 59340, loss = 0.00267513
I0521 12:35:52.677179  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00267503 (* 1 = 0.00267503 loss)
I0521 12:35:52.677186  3675 sgd_solver.cpp:138] Iteration 59340, lr = 3.125e-06
I0521 12:35:56.210793  3675 solver.cpp:243] Iteration 59360, loss = 0.00162885
I0521 12:35:56.210824  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00162875 (* 1 = 0.00162875 loss)
I0521 12:35:56.210830  3675 sgd_solver.cpp:138] Iteration 59360, lr = 3.125e-06
I0521 12:35:59.751374  3675 solver.cpp:243] Iteration 59380, loss = 0.00146346
I0521 12:35:59.751405  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00146336 (* 1 = 0.00146336 loss)
I0521 12:35:59.751411  3675 sgd_solver.cpp:138] Iteration 59380, lr = 3.125e-06
I0521 12:36:03.280340  3675 solver.cpp:243] Iteration 59400, loss = 0.00154642
I0521 12:36:03.280371  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00154632 (* 1 = 0.00154632 loss)
I0521 12:36:03.280376  3675 sgd_solver.cpp:138] Iteration 59400, lr = 3.125e-06
I0521 12:36:06.817143  3675 solver.cpp:243] Iteration 59420, loss = 0.00238487
I0521 12:36:06.817339  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00238477 (* 1 = 0.00238477 loss)
I0521 12:36:06.817348  3675 sgd_solver.cpp:138] Iteration 59420, lr = 3.125e-06
I0521 12:36:10.350519  3675 solver.cpp:243] Iteration 59440, loss = 0.00180571
I0521 12:36:10.350551  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00180561 (* 1 = 0.00180561 loss)
I0521 12:36:10.350558  3675 sgd_solver.cpp:138] Iteration 59440, lr = 3.125e-06
I0521 12:36:13.888828  3675 solver.cpp:243] Iteration 59460, loss = 0.00349282
I0521 12:36:13.888860  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00349272 (* 1 = 0.00349272 loss)
I0521 12:36:13.888867  3675 sgd_solver.cpp:138] Iteration 59460, lr = 3.125e-06
I0521 12:36:17.423161  3675 solver.cpp:243] Iteration 59480, loss = 0.00218745
I0521 12:36:17.423192  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00218735 (* 1 = 0.00218735 loss)
I0521 12:36:17.423197  3675 sgd_solver.cpp:138] Iteration 59480, lr = 3.125e-06
I0521 12:36:20.952325  3675 solver.cpp:243] Iteration 59500, loss = 0.00151219
I0521 12:36:20.952358  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00151209 (* 1 = 0.00151209 loss)
I0521 12:36:20.952363  3675 sgd_solver.cpp:138] Iteration 59500, lr = 3.125e-06
I0521 12:36:24.482890  3675 solver.cpp:243] Iteration 59520, loss = 0.00215407
I0521 12:36:24.482921  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00215397 (* 1 = 0.00215397 loss)
I0521 12:36:24.482926  3675 sgd_solver.cpp:138] Iteration 59520, lr = 3.125e-06
I0521 12:36:28.016746  3675 solver.cpp:243] Iteration 59540, loss = 0.00218781
I0521 12:36:28.016777  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00218771 (* 1 = 0.00218771 loss)
I0521 12:36:28.016801  3675 sgd_solver.cpp:138] Iteration 59540, lr = 3.125e-06
I0521 12:36:31.554298  3675 solver.cpp:243] Iteration 59560, loss = 0.00158947
I0521 12:36:31.554332  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00158937 (* 1 = 0.00158937 loss)
I0521 12:36:31.554352  3675 sgd_solver.cpp:138] Iteration 59560, lr = 3.125e-06
I0521 12:36:35.091892  3675 solver.cpp:243] Iteration 59580, loss = 0.00139437
I0521 12:36:35.091923  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00139427 (* 1 = 0.00139427 loss)
I0521 12:36:35.091929  3675 sgd_solver.cpp:138] Iteration 59580, lr = 3.125e-06
I0521 12:36:38.625659  3675 solver.cpp:243] Iteration 59600, loss = 0.0017651
I0521 12:36:38.625818  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00176501 (* 1 = 0.00176501 loss)
I0521 12:36:38.625826  3675 sgd_solver.cpp:138] Iteration 59600, lr = 3.125e-06
I0521 12:36:42.158002  3675 solver.cpp:243] Iteration 59620, loss = 0.00153414
I0521 12:36:42.158035  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00153404 (* 1 = 0.00153404 loss)
I0521 12:36:42.158041  3675 sgd_solver.cpp:138] Iteration 59620, lr = 3.125e-06
I0521 12:36:45.690837  3675 solver.cpp:243] Iteration 59640, loss = 0.00192439
I0521 12:36:45.690870  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00192429 (* 1 = 0.00192429 loss)
I0521 12:36:45.690891  3675 sgd_solver.cpp:138] Iteration 59640, lr = 3.125e-06
I0521 12:36:49.225838  3675 solver.cpp:243] Iteration 59660, loss = 0.00183024
I0521 12:36:49.225870  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00183014 (* 1 = 0.00183014 loss)
I0521 12:36:49.225878  3675 sgd_solver.cpp:138] Iteration 59660, lr = 3.125e-06
I0521 12:36:52.752491  3675 solver.cpp:243] Iteration 59680, loss = 0.00188334
I0521 12:36:52.752521  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00188324 (* 1 = 0.00188324 loss)
I0521 12:36:52.752527  3675 sgd_solver.cpp:138] Iteration 59680, lr = 3.125e-06
I0521 12:36:56.276512  3675 solver.cpp:243] Iteration 59700, loss = 0.001796
I0521 12:36:56.276543  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0017959 (* 1 = 0.0017959 loss)
I0521 12:36:56.276549  3675 sgd_solver.cpp:138] Iteration 59700, lr = 3.125e-06
I0521 12:36:59.807051  3675 solver.cpp:243] Iteration 59720, loss = 0.00206985
I0521 12:36:59.807082  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00206975 (* 1 = 0.00206975 loss)
I0521 12:36:59.807090  3675 sgd_solver.cpp:138] Iteration 59720, lr = 3.125e-06
I0521 12:37:03.340337  3675 solver.cpp:243] Iteration 59740, loss = 0.00196505
I0521 12:37:03.340368  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00196495 (* 1 = 0.00196495 loss)
I0521 12:37:03.340376  3675 sgd_solver.cpp:138] Iteration 59740, lr = 3.125e-06
I0521 12:37:06.867976  3675 solver.cpp:243] Iteration 59760, loss = 0.00146361
I0521 12:37:06.868007  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00146351 (* 1 = 0.00146351 loss)
I0521 12:37:06.868014  3675 sgd_solver.cpp:138] Iteration 59760, lr = 3.125e-06
I0521 12:37:10.405709  3675 solver.cpp:243] Iteration 59780, loss = 0.00239437
I0521 12:37:10.405809  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00239427 (* 1 = 0.00239427 loss)
I0521 12:37:10.405817  3675 sgd_solver.cpp:138] Iteration 59780, lr = 3.125e-06
I0521 12:37:13.945252  3675 solver.cpp:243] Iteration 59800, loss = 0.00194654
I0521 12:37:13.945283  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00194644 (* 1 = 0.00194644 loss)
I0521 12:37:13.945291  3675 sgd_solver.cpp:138] Iteration 59800, lr = 3.125e-06
I0521 12:37:17.485198  3675 solver.cpp:243] Iteration 59820, loss = 0.0031675
I0521 12:37:17.485229  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0031674 (* 1 = 0.0031674 loss)
I0521 12:37:17.485235  3675 sgd_solver.cpp:138] Iteration 59820, lr = 3.125e-06
I0521 12:37:21.017592  3675 solver.cpp:243] Iteration 59840, loss = 0.00319309
I0521 12:37:21.017626  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00319299 (* 1 = 0.00319299 loss)
I0521 12:37:21.017648  3675 sgd_solver.cpp:138] Iteration 59840, lr = 3.125e-06
I0521 12:37:24.559641  3675 solver.cpp:243] Iteration 59860, loss = 0.00200001
I0521 12:37:24.559672  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00199991 (* 1 = 0.00199991 loss)
I0521 12:37:24.559695  3675 sgd_solver.cpp:138] Iteration 59860, lr = 3.125e-06
I0521 12:37:28.027496  3675 solver.cpp:243] Iteration 59880, loss = 0.00168853
I0521 12:37:28.027528  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00168843 (* 1 = 0.00168843 loss)
I0521 12:37:28.027550  3675 sgd_solver.cpp:138] Iteration 59880, lr = 3.125e-06
I0521 12:37:31.559247  3675 solver.cpp:243] Iteration 59900, loss = 0.00150818
I0521 12:37:31.559278  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00150808 (* 1 = 0.00150808 loss)
I0521 12:37:31.559283  3675 sgd_solver.cpp:138] Iteration 59900, lr = 3.125e-06
I0521 12:37:35.100210  3675 solver.cpp:243] Iteration 59920, loss = 0.00153385
I0521 12:37:35.100240  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00153375 (* 1 = 0.00153375 loss)
I0521 12:37:35.100246  3675 sgd_solver.cpp:138] Iteration 59920, lr = 3.125e-06
I0521 12:37:38.631311  3675 solver.cpp:243] Iteration 59940, loss = 0.00175323
I0521 12:37:38.631342  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00175313 (* 1 = 0.00175313 loss)
I0521 12:37:38.631348  3675 sgd_solver.cpp:138] Iteration 59940, lr = 3.125e-06
I0521 12:37:42.158376  3675 solver.cpp:243] Iteration 59960, loss = 0.00169597
I0521 12:37:42.158551  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00169587 (* 1 = 0.00169587 loss)
I0521 12:37:42.158560  3675 sgd_solver.cpp:138] Iteration 59960, lr = 3.125e-06
I0521 12:37:45.693723  3675 solver.cpp:243] Iteration 59980, loss = 0.00196201
I0521 12:37:45.693753  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00196191 (* 1 = 0.00196191 loss)
I0521 12:37:45.693761  3675 sgd_solver.cpp:138] Iteration 59980, lr = 3.125e-06
I0521 12:37:49.102036  3675 solver.cpp:596] Snapshotting to binary proto file models/LPR/lpr_resnet_lstm_iter_60000.caffemodel
I0521 12:37:49.129475  3675 sgd_solver.cpp:307] Snapshotting solver state to binary proto file models/LPR/lpr_resnet_lstm_iter_60000.solverstate
I0521 12:37:49.144263  3675 solver.cpp:358] Iteration 60000, Testing net (#0)
I0521 12:37:53.902812  3675 solver.cpp:425]     Test net output #0: acc = 1
I0521 12:37:53.902838  3675 solver.cpp:425]     Test net output #1: acc = 1
I0521 12:37:53.902845  3675 solver.cpp:425]     Test net output #2: ctcloss = 0.000626441 (* 1 = 0.000626441 loss)
I0521 12:37:54.040606  3675 solver.cpp:243] Iteration 60000, loss = 0.00136662
I0521 12:37:54.040634  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00136652 (* 1 = 0.00136652 loss)
I0521 12:37:54.040640  3675 sgd_solver.cpp:138] Iteration 60000, lr = 1.5625e-06
I0521 12:37:57.581542  3675 solver.cpp:243] Iteration 60020, loss = 0.00169949
I0521 12:37:57.581571  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00169939 (* 1 = 0.00169939 loss)
I0521 12:37:57.581578  3675 sgd_solver.cpp:138] Iteration 60020, lr = 1.5625e-06
I0521 12:38:01.124958  3675 solver.cpp:243] Iteration 60040, loss = 0.00173763
I0521 12:38:01.124990  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00173753 (* 1 = 0.00173753 loss)
I0521 12:38:01.124997  3675 sgd_solver.cpp:138] Iteration 60040, lr = 1.5625e-06
I0521 12:38:04.662142  3675 solver.cpp:243] Iteration 60060, loss = 0.00258186
I0521 12:38:04.662173  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00258176 (* 1 = 0.00258176 loss)
I0521 12:38:04.662179  3675 sgd_solver.cpp:138] Iteration 60060, lr = 1.5625e-06
I0521 12:38:08.202154  3675 solver.cpp:243] Iteration 60080, loss = 0.00147456
I0521 12:38:08.202185  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00147446 (* 1 = 0.00147446 loss)
I0521 12:38:08.202191  3675 sgd_solver.cpp:138] Iteration 60080, lr = 1.5625e-06
I0521 12:38:11.744292  3675 solver.cpp:243] Iteration 60100, loss = 0.0023307
I0521 12:38:11.744324  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00233059 (* 1 = 0.00233059 loss)
I0521 12:38:11.744330  3675 sgd_solver.cpp:138] Iteration 60100, lr = 1.5625e-06
I0521 12:38:15.278746  3675 solver.cpp:243] Iteration 60120, loss = 0.00191366
I0521 12:38:15.278867  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00191356 (* 1 = 0.00191356 loss)
I0521 12:38:15.278877  3675 sgd_solver.cpp:138] Iteration 60120, lr = 1.5625e-06
I0521 12:38:18.824129  3675 solver.cpp:243] Iteration 60140, loss = 0.0022206
I0521 12:38:18.824159  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0022205 (* 1 = 0.0022205 loss)
I0521 12:38:18.824165  3675 sgd_solver.cpp:138] Iteration 60140, lr = 1.5625e-06
I0521 12:38:22.372484  3675 solver.cpp:243] Iteration 60160, loss = 0.0016389
I0521 12:38:22.372515  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0016388 (* 1 = 0.0016388 loss)
I0521 12:38:22.372522  3675 sgd_solver.cpp:138] Iteration 60160, lr = 1.5625e-06
I0521 12:38:25.907598  3675 solver.cpp:243] Iteration 60180, loss = 0.00151525
I0521 12:38:25.907629  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00151515 (* 1 = 0.00151515 loss)
I0521 12:38:25.907634  3675 sgd_solver.cpp:138] Iteration 60180, lr = 1.5625e-06
I0521 12:38:29.442111  3675 solver.cpp:243] Iteration 60200, loss = 0.00162639
I0521 12:38:29.442142  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00162629 (* 1 = 0.00162629 loss)
I0521 12:38:29.442147  3675 sgd_solver.cpp:138] Iteration 60200, lr = 1.5625e-06
I0521 12:38:32.979692  3675 solver.cpp:243] Iteration 60220, loss = 0.00130593
I0521 12:38:32.979723  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00130583 (* 1 = 0.00130583 loss)
I0521 12:38:32.979729  3675 sgd_solver.cpp:138] Iteration 60220, lr = 1.5625e-06
I0521 12:38:36.522112  3675 solver.cpp:243] Iteration 60240, loss = 0.00146804
I0521 12:38:36.522145  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00146794 (* 1 = 0.00146794 loss)
I0521 12:38:36.522150  3675 sgd_solver.cpp:138] Iteration 60240, lr = 1.5625e-06
I0521 12:38:40.057301  3675 solver.cpp:243] Iteration 60260, loss = 0.00219031
I0521 12:38:40.057330  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00219021 (* 1 = 0.00219021 loss)
I0521 12:38:40.057337  3675 sgd_solver.cpp:138] Iteration 60260, lr = 1.5625e-06
I0521 12:38:43.591048  3675 solver.cpp:243] Iteration 60280, loss = 0.00204007
I0521 12:38:43.591078  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00203997 (* 1 = 0.00203997 loss)
I0521 12:38:43.591084  3675 sgd_solver.cpp:138] Iteration 60280, lr = 1.5625e-06
I0521 12:38:47.129338  3675 solver.cpp:243] Iteration 60300, loss = 0.00238403
I0521 12:38:47.129514  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00238393 (* 1 = 0.00238393 loss)
I0521 12:38:47.129523  3675 sgd_solver.cpp:138] Iteration 60300, lr = 1.5625e-06
I0521 12:38:50.669150  3675 solver.cpp:243] Iteration 60320, loss = 0.00219012
I0521 12:38:50.669181  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00219002 (* 1 = 0.00219002 loss)
I0521 12:38:50.669188  3675 sgd_solver.cpp:138] Iteration 60320, lr = 1.5625e-06
I0521 12:38:54.207648  3675 solver.cpp:243] Iteration 60340, loss = 0.00192805
I0521 12:38:54.207679  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00192795 (* 1 = 0.00192795 loss)
I0521 12:38:54.207685  3675 sgd_solver.cpp:138] Iteration 60340, lr = 1.5625e-06
I0521 12:38:57.746265  3675 solver.cpp:243] Iteration 60360, loss = 0.00192563
I0521 12:38:57.746296  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00192553 (* 1 = 0.00192553 loss)
I0521 12:38:57.746302  3675 sgd_solver.cpp:138] Iteration 60360, lr = 1.5625e-06
I0521 12:39:01.289644  3675 solver.cpp:243] Iteration 60380, loss = 0.00175227
I0521 12:39:01.289676  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00175217 (* 1 = 0.00175217 loss)
I0521 12:39:01.289683  3675 sgd_solver.cpp:138] Iteration 60380, lr = 1.5625e-06
I0521 12:39:04.829434  3675 solver.cpp:243] Iteration 60400, loss = 0.00182435
I0521 12:39:04.829463  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00182425 (* 1 = 0.00182425 loss)
I0521 12:39:04.829470  3675 sgd_solver.cpp:138] Iteration 60400, lr = 1.5625e-06
I0521 12:39:08.363905  3675 solver.cpp:243] Iteration 60420, loss = 0.00181757
I0521 12:39:08.363937  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00181747 (* 1 = 0.00181747 loss)
I0521 12:39:08.363943  3675 sgd_solver.cpp:138] Iteration 60420, lr = 1.5625e-06
I0521 12:39:11.904130  3675 solver.cpp:243] Iteration 60440, loss = 0.00226998
I0521 12:39:11.904161  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00226988 (* 1 = 0.00226988 loss)
I0521 12:39:11.904167  3675 sgd_solver.cpp:138] Iteration 60440, lr = 1.5625e-06
I0521 12:39:15.445567  3675 solver.cpp:243] Iteration 60460, loss = 0.00123732
I0521 12:39:15.445600  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00123722 (* 1 = 0.00123722 loss)
I0521 12:39:15.445605  3675 sgd_solver.cpp:138] Iteration 60460, lr = 1.5625e-06
I0521 12:39:18.980769  3675 solver.cpp:243] Iteration 60480, loss = 0.00163885
I0521 12:39:18.980937  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00163875 (* 1 = 0.00163875 loss)
I0521 12:39:18.980947  3675 sgd_solver.cpp:138] Iteration 60480, lr = 1.5625e-06
I0521 12:39:22.523670  3675 solver.cpp:243] Iteration 60500, loss = 0.00196437
I0521 12:39:22.523700  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00196427 (* 1 = 0.00196427 loss)
I0521 12:39:22.523706  3675 sgd_solver.cpp:138] Iteration 60500, lr = 1.5625e-06
I0521 12:39:26.060791  3675 solver.cpp:243] Iteration 60520, loss = 0.00208743
I0521 12:39:26.060822  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00208733 (* 1 = 0.00208733 loss)
I0521 12:39:26.060828  3675 sgd_solver.cpp:138] Iteration 60520, lr = 1.5625e-06
I0521 12:39:29.597271  3675 solver.cpp:243] Iteration 60540, loss = 0.0037186
I0521 12:39:29.597301  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0037185 (* 1 = 0.0037185 loss)
I0521 12:39:29.597324  3675 sgd_solver.cpp:138] Iteration 60540, lr = 1.5625e-06
I0521 12:39:33.128551  3675 solver.cpp:243] Iteration 60560, loss = 0.00190711
I0521 12:39:33.128581  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00190701 (* 1 = 0.00190701 loss)
I0521 12:39:33.128587  3675 sgd_solver.cpp:138] Iteration 60560, lr = 1.5625e-06
I0521 12:39:36.660396  3675 solver.cpp:243] Iteration 60580, loss = 0.00295986
I0521 12:39:36.660426  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00295976 (* 1 = 0.00295976 loss)
I0521 12:39:36.660432  3675 sgd_solver.cpp:138] Iteration 60580, lr = 1.5625e-06
I0521 12:39:40.195900  3675 solver.cpp:243] Iteration 60600, loss = 0.00177537
I0521 12:39:40.195930  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00177526 (* 1 = 0.00177526 loss)
I0521 12:39:40.195952  3675 sgd_solver.cpp:138] Iteration 60600, lr = 1.5625e-06
I0521 12:39:43.733711  3675 solver.cpp:243] Iteration 60620, loss = 0.00155224
I0521 12:39:43.733742  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00155214 (* 1 = 0.00155214 loss)
I0521 12:39:43.733748  3675 sgd_solver.cpp:138] Iteration 60620, lr = 1.5625e-06
I0521 12:39:47.275466  3675 solver.cpp:243] Iteration 60640, loss = 0.0020225
I0521 12:39:47.275497  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0020224 (* 1 = 0.0020224 loss)
I0521 12:39:47.275521  3675 sgd_solver.cpp:138] Iteration 60640, lr = 1.5625e-06
I0521 12:39:50.810696  3675 solver.cpp:243] Iteration 60660, loss = 0.00185697
I0521 12:39:50.810863  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00185687 (* 1 = 0.00185687 loss)
I0521 12:39:50.810869  3675 sgd_solver.cpp:138] Iteration 60660, lr = 1.5625e-06
I0521 12:39:54.347647  3675 solver.cpp:243] Iteration 60680, loss = 0.00142688
I0521 12:39:54.347678  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00142678 (* 1 = 0.00142678 loss)
I0521 12:39:54.347684  3675 sgd_solver.cpp:138] Iteration 60680, lr = 1.5625e-06
I0521 12:39:57.884109  3675 solver.cpp:243] Iteration 60700, loss = 0.00218935
I0521 12:39:57.884140  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00218924 (* 1 = 0.00218924 loss)
I0521 12:39:57.884145  3675 sgd_solver.cpp:138] Iteration 60700, lr = 1.5625e-06
I0521 12:40:01.420969  3675 solver.cpp:243] Iteration 60720, loss = 0.00185112
I0521 12:40:01.420998  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00185101 (* 1 = 0.00185101 loss)
I0521 12:40:01.421006  3675 sgd_solver.cpp:138] Iteration 60720, lr = 1.5625e-06
I0521 12:40:04.957156  3675 solver.cpp:243] Iteration 60740, loss = 0.00221848
I0521 12:40:04.957186  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00221838 (* 1 = 0.00221838 loss)
I0521 12:40:04.957192  3675 sgd_solver.cpp:138] Iteration 60740, lr = 1.5625e-06
I0521 12:40:08.494038  3675 solver.cpp:243] Iteration 60760, loss = 0.0023754
I0521 12:40:08.494071  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0023753 (* 1 = 0.0023753 loss)
I0521 12:40:08.494077  3675 sgd_solver.cpp:138] Iteration 60760, lr = 1.5625e-06
I0521 12:40:12.033042  3675 solver.cpp:243] Iteration 60780, loss = 0.00230422
I0521 12:40:12.033074  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00230412 (* 1 = 0.00230412 loss)
I0521 12:40:12.033080  3675 sgd_solver.cpp:138] Iteration 60780, lr = 1.5625e-06
I0521 12:40:15.562885  3675 solver.cpp:243] Iteration 60800, loss = 0.00339874
I0521 12:40:15.562917  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00339864 (* 1 = 0.00339864 loss)
I0521 12:40:15.562923  3675 sgd_solver.cpp:138] Iteration 60800, lr = 1.5625e-06
I0521 12:40:19.100685  3675 solver.cpp:243] Iteration 60820, loss = 0.0017101
I0521 12:40:19.100716  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00171 (* 1 = 0.00171 loss)
I0521 12:40:19.100723  3675 sgd_solver.cpp:138] Iteration 60820, lr = 1.5625e-06
I0521 12:40:22.632436  3675 solver.cpp:243] Iteration 60840, loss = 0.00190844
I0521 12:40:22.632598  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00190833 (* 1 = 0.00190833 loss)
I0521 12:40:22.632607  3675 sgd_solver.cpp:138] Iteration 60840, lr = 1.5625e-06
I0521 12:40:26.179253  3675 solver.cpp:243] Iteration 60860, loss = 0.00181422
I0521 12:40:26.179284  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00181412 (* 1 = 0.00181412 loss)
I0521 12:40:26.179306  3675 sgd_solver.cpp:138] Iteration 60860, lr = 1.5625e-06
I0521 12:40:29.722669  3675 solver.cpp:243] Iteration 60880, loss = 0.00145184
I0521 12:40:29.722700  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00145174 (* 1 = 0.00145174 loss)
I0521 12:40:29.722723  3675 sgd_solver.cpp:138] Iteration 60880, lr = 1.5625e-06
I0521 12:40:33.259217  3675 solver.cpp:243] Iteration 60900, loss = 0.00198646
I0521 12:40:33.259253  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00198636 (* 1 = 0.00198636 loss)
I0521 12:40:33.259259  3675 sgd_solver.cpp:138] Iteration 60900, lr = 1.5625e-06
I0521 12:40:36.798945  3675 solver.cpp:243] Iteration 60920, loss = 0.00178428
I0521 12:40:36.798975  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00178418 (* 1 = 0.00178418 loss)
I0521 12:40:36.798981  3675 sgd_solver.cpp:138] Iteration 60920, lr = 1.5625e-06
I0521 12:40:40.339706  3675 solver.cpp:243] Iteration 60940, loss = 0.00146605
I0521 12:40:40.339738  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00146595 (* 1 = 0.00146595 loss)
I0521 12:40:40.339745  3675 sgd_solver.cpp:138] Iteration 60940, lr = 1.5625e-06
I0521 12:40:43.875634  3675 solver.cpp:243] Iteration 60960, loss = 0.00194989
I0521 12:40:43.875666  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00194979 (* 1 = 0.00194979 loss)
I0521 12:40:43.875674  3675 sgd_solver.cpp:138] Iteration 60960, lr = 1.5625e-06
I0521 12:40:47.412011  3675 solver.cpp:243] Iteration 60980, loss = 0.00153644
I0521 12:40:47.412044  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00153634 (* 1 = 0.00153634 loss)
I0521 12:40:47.412050  3675 sgd_solver.cpp:138] Iteration 60980, lr = 1.5625e-06
I0521 12:40:50.814390  3675 solver.cpp:358] Iteration 61000, Testing net (#0)
I0521 12:40:55.569689  3675 solver.cpp:425]     Test net output #0: acc = 1
I0521 12:40:55.569847  3675 solver.cpp:425]     Test net output #1: acc = 1
I0521 12:40:55.569856  3675 solver.cpp:425]     Test net output #2: ctcloss = 0.000623554 (* 1 = 0.000623554 loss)
I0521 12:40:55.706049  3675 solver.cpp:243] Iteration 61000, loss = 0.00162254
I0521 12:40:55.706080  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00162244 (* 1 = 0.00162244 loss)
I0521 12:40:55.706087  3675 sgd_solver.cpp:138] Iteration 61000, lr = 1.5625e-06
I0521 12:40:59.232872  3675 solver.cpp:243] Iteration 61020, loss = 0.00209059
I0521 12:40:59.232901  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00209049 (* 1 = 0.00209049 loss)
I0521 12:40:59.232908  3675 sgd_solver.cpp:138] Iteration 61020, lr = 1.5625e-06
I0521 12:41:02.769362  3675 solver.cpp:243] Iteration 61040, loss = 0.00239124
I0521 12:41:02.769394  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00239114 (* 1 = 0.00239114 loss)
I0521 12:41:02.769402  3675 sgd_solver.cpp:138] Iteration 61040, lr = 1.5625e-06
I0521 12:41:06.309626  3675 solver.cpp:243] Iteration 61060, loss = 0.00179802
I0521 12:41:06.309657  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00179792 (* 1 = 0.00179792 loss)
I0521 12:41:06.309664  3675 sgd_solver.cpp:138] Iteration 61060, lr = 1.5625e-06
I0521 12:41:09.849331  3675 solver.cpp:243] Iteration 61080, loss = 0.00166169
I0521 12:41:09.849362  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00166159 (* 1 = 0.00166159 loss)
I0521 12:41:09.849385  3675 sgd_solver.cpp:138] Iteration 61080, lr = 1.5625e-06
I0521 12:41:13.380182  3675 solver.cpp:243] Iteration 61100, loss = 0.00213214
I0521 12:41:13.380213  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00213204 (* 1 = 0.00213204 loss)
I0521 12:41:13.380220  3675 sgd_solver.cpp:138] Iteration 61100, lr = 1.5625e-06
I0521 12:41:16.909620  3675 solver.cpp:243] Iteration 61120, loss = 0.00184734
I0521 12:41:16.909651  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00184724 (* 1 = 0.00184724 loss)
I0521 12:41:16.909657  3675 sgd_solver.cpp:138] Iteration 61120, lr = 1.5625e-06
I0521 12:41:20.447238  3675 solver.cpp:243] Iteration 61140, loss = 0.00250764
I0521 12:41:20.447269  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00250753 (* 1 = 0.00250753 loss)
I0521 12:41:20.447276  3675 sgd_solver.cpp:138] Iteration 61140, lr = 1.5625e-06
I0521 12:41:23.986486  3675 solver.cpp:243] Iteration 61160, loss = 0.00132972
I0521 12:41:23.986519  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00132962 (* 1 = 0.00132962 loss)
I0521 12:41:23.986526  3675 sgd_solver.cpp:138] Iteration 61160, lr = 1.5625e-06
I0521 12:41:27.453994  3675 solver.cpp:243] Iteration 61180, loss = 0.00564863
I0521 12:41:27.454165  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00564853 (* 1 = 0.00564853 loss)
I0521 12:41:27.454174  3675 sgd_solver.cpp:138] Iteration 61180, lr = 1.5625e-06
I0521 12:41:30.990679  3675 solver.cpp:243] Iteration 61200, loss = 0.00231686
I0521 12:41:30.990711  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00231676 (* 1 = 0.00231676 loss)
I0521 12:41:30.990733  3675 sgd_solver.cpp:138] Iteration 61200, lr = 1.5625e-06
I0521 12:41:34.526970  3675 solver.cpp:243] Iteration 61220, loss = 0.00186563
I0521 12:41:34.527002  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00186553 (* 1 = 0.00186553 loss)
I0521 12:41:34.527009  3675 sgd_solver.cpp:138] Iteration 61220, lr = 1.5625e-06
I0521 12:41:38.068792  3675 solver.cpp:243] Iteration 61240, loss = 0.00227375
I0521 12:41:38.068822  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00227365 (* 1 = 0.00227365 loss)
I0521 12:41:38.068828  3675 sgd_solver.cpp:138] Iteration 61240, lr = 1.5625e-06
I0521 12:41:41.603111  3675 solver.cpp:243] Iteration 61260, loss = 0.00209637
I0521 12:41:41.603142  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00209626 (* 1 = 0.00209626 loss)
I0521 12:41:41.603149  3675 sgd_solver.cpp:138] Iteration 61260, lr = 1.5625e-06
I0521 12:41:45.139621  3675 solver.cpp:243] Iteration 61280, loss = 0.0019018
I0521 12:41:45.139652  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0019017 (* 1 = 0.0019017 loss)
I0521 12:41:45.139657  3675 sgd_solver.cpp:138] Iteration 61280, lr = 1.5625e-06
I0521 12:41:48.671607  3675 solver.cpp:243] Iteration 61300, loss = 0.0012313
I0521 12:41:48.671638  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0012312 (* 1 = 0.0012312 loss)
I0521 12:41:48.671643  3675 sgd_solver.cpp:138] Iteration 61300, lr = 1.5625e-06
I0521 12:41:52.200567  3675 solver.cpp:243] Iteration 61320, loss = 0.00186596
I0521 12:41:52.200598  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00186585 (* 1 = 0.00186585 loss)
I0521 12:41:52.200603  3675 sgd_solver.cpp:138] Iteration 61320, lr = 1.5625e-06
I0521 12:41:55.734001  3675 solver.cpp:243] Iteration 61340, loss = 0.00289907
I0521 12:41:55.734033  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00289897 (* 1 = 0.00289897 loss)
I0521 12:41:55.734038  3675 sgd_solver.cpp:138] Iteration 61340, lr = 1.5625e-06
I0521 12:41:59.268848  3675 solver.cpp:243] Iteration 61360, loss = 0.00182773
I0521 12:41:59.269023  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00182763 (* 1 = 0.00182763 loss)
I0521 12:41:59.269032  3675 sgd_solver.cpp:138] Iteration 61360, lr = 1.5625e-06
I0521 12:42:02.803974  3675 solver.cpp:243] Iteration 61380, loss = 0.00152671
I0521 12:42:02.804008  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0015266 (* 1 = 0.0015266 loss)
I0521 12:42:02.804014  3675 sgd_solver.cpp:138] Iteration 61380, lr = 1.5625e-06
I0521 12:42:06.343236  3675 solver.cpp:243] Iteration 61400, loss = 0.0018195
I0521 12:42:06.343267  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0018194 (* 1 = 0.0018194 loss)
I0521 12:42:06.343274  3675 sgd_solver.cpp:138] Iteration 61400, lr = 1.5625e-06
I0521 12:42:09.878796  3675 solver.cpp:243] Iteration 61420, loss = 0.00220901
I0521 12:42:09.878829  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00220891 (* 1 = 0.00220891 loss)
I0521 12:42:09.878836  3675 sgd_solver.cpp:138] Iteration 61420, lr = 1.5625e-06
I0521 12:42:13.419001  3675 solver.cpp:243] Iteration 61440, loss = 0.00218045
I0521 12:42:13.419035  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00218035 (* 1 = 0.00218035 loss)
I0521 12:42:13.419042  3675 sgd_solver.cpp:138] Iteration 61440, lr = 1.5625e-06
I0521 12:42:16.962183  3675 solver.cpp:243] Iteration 61460, loss = 0.00156154
I0521 12:42:16.962214  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00156144 (* 1 = 0.00156144 loss)
I0521 12:42:16.962221  3675 sgd_solver.cpp:138] Iteration 61460, lr = 1.5625e-06
I0521 12:42:20.498109  3675 solver.cpp:243] Iteration 61480, loss = 0.00186931
I0521 12:42:20.498142  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00186921 (* 1 = 0.00186921 loss)
I0521 12:42:20.498148  3675 sgd_solver.cpp:138] Iteration 61480, lr = 1.5625e-06
I0521 12:42:24.029105  3675 solver.cpp:243] Iteration 61500, loss = 0.00171257
I0521 12:42:24.029137  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00171247 (* 1 = 0.00171247 loss)
I0521 12:42:24.029143  3675 sgd_solver.cpp:138] Iteration 61500, lr = 1.5625e-06
I0521 12:42:27.568361  3675 solver.cpp:243] Iteration 61520, loss = 0.00238848
I0521 12:42:27.568392  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00238838 (* 1 = 0.00238838 loss)
I0521 12:42:27.568399  3675 sgd_solver.cpp:138] Iteration 61520, lr = 1.5625e-06
I0521 12:42:31.099027  3675 solver.cpp:243] Iteration 61540, loss = 0.00157523
I0521 12:42:31.100458  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00157513 (* 1 = 0.00157513 loss)
I0521 12:42:31.100466  3675 sgd_solver.cpp:138] Iteration 61540, lr = 1.5625e-06
I0521 12:42:34.638013  3675 solver.cpp:243] Iteration 61560, loss = 0.0018238
I0521 12:42:34.638044  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0018237 (* 1 = 0.0018237 loss)
I0521 12:42:34.638051  3675 sgd_solver.cpp:138] Iteration 61560, lr = 1.5625e-06
I0521 12:42:38.173231  3675 solver.cpp:243] Iteration 61580, loss = 0.0017406
I0521 12:42:38.173261  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0017405 (* 1 = 0.0017405 loss)
I0521 12:42:38.173267  3675 sgd_solver.cpp:138] Iteration 61580, lr = 1.5625e-06
I0521 12:42:41.709045  3675 solver.cpp:243] Iteration 61600, loss = 0.00230502
I0521 12:42:41.709075  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00230492 (* 1 = 0.00230492 loss)
I0521 12:42:41.709081  3675 sgd_solver.cpp:138] Iteration 61600, lr = 1.5625e-06
I0521 12:42:45.244557  3675 solver.cpp:243] Iteration 61620, loss = 0.00175719
I0521 12:42:45.244588  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00175709 (* 1 = 0.00175709 loss)
I0521 12:42:45.244594  3675 sgd_solver.cpp:138] Iteration 61620, lr = 1.5625e-06
I0521 12:42:48.775701  3675 solver.cpp:243] Iteration 61640, loss = 0.00152934
I0521 12:42:48.775732  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00152924 (* 1 = 0.00152924 loss)
I0521 12:42:48.775738  3675 sgd_solver.cpp:138] Iteration 61640, lr = 1.5625e-06
I0521 12:42:52.315909  3675 solver.cpp:243] Iteration 61660, loss = 0.0013938
I0521 12:42:52.315940  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0013937 (* 1 = 0.0013937 loss)
I0521 12:42:52.315946  3675 sgd_solver.cpp:138] Iteration 61660, lr = 1.5625e-06
I0521 12:42:55.847962  3675 solver.cpp:243] Iteration 61680, loss = 0.00156551
I0521 12:42:55.847993  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00156541 (* 1 = 0.00156541 loss)
I0521 12:42:55.847999  3675 sgd_solver.cpp:138] Iteration 61680, lr = 1.5625e-06
I0521 12:42:59.376891  3675 solver.cpp:243] Iteration 61700, loss = 0.00144612
I0521 12:42:59.376922  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00144602 (* 1 = 0.00144602 loss)
I0521 12:42:59.376929  3675 sgd_solver.cpp:138] Iteration 61700, lr = 1.5625e-06
I0521 12:43:02.910001  3675 solver.cpp:243] Iteration 61720, loss = 0.00260217
I0521 12:43:02.910157  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00260207 (* 1 = 0.00260207 loss)
I0521 12:43:02.910166  3675 sgd_solver.cpp:138] Iteration 61720, lr = 1.5625e-06
I0521 12:43:06.449926  3675 solver.cpp:243] Iteration 61740, loss = 0.00240651
I0521 12:43:06.449957  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00240641 (* 1 = 0.00240641 loss)
I0521 12:43:06.449962  3675 sgd_solver.cpp:138] Iteration 61740, lr = 1.5625e-06
I0521 12:43:09.981117  3675 solver.cpp:243] Iteration 61760, loss = 0.00141445
I0521 12:43:09.981146  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00141435 (* 1 = 0.00141435 loss)
I0521 12:43:09.981168  3675 sgd_solver.cpp:138] Iteration 61760, lr = 1.5625e-06
I0521 12:43:13.521345  3675 solver.cpp:243] Iteration 61780, loss = 0.00170803
I0521 12:43:13.521378  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00170793 (* 1 = 0.00170793 loss)
I0521 12:43:13.521384  3675 sgd_solver.cpp:138] Iteration 61780, lr = 1.5625e-06
I0521 12:43:17.060637  3675 solver.cpp:243] Iteration 61800, loss = 0.00160912
I0521 12:43:17.060668  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00160902 (* 1 = 0.00160902 loss)
I0521 12:43:17.060690  3675 sgd_solver.cpp:138] Iteration 61800, lr = 1.5625e-06
I0521 12:43:20.596611  3675 solver.cpp:243] Iteration 61820, loss = 0.00172698
I0521 12:43:20.596640  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00172688 (* 1 = 0.00172688 loss)
I0521 12:43:20.596647  3675 sgd_solver.cpp:138] Iteration 61820, lr = 1.5625e-06
I0521 12:43:24.129732  3675 solver.cpp:243] Iteration 61840, loss = 0.00144809
I0521 12:43:24.129763  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00144799 (* 1 = 0.00144799 loss)
I0521 12:43:24.129770  3675 sgd_solver.cpp:138] Iteration 61840, lr = 1.5625e-06
I0521 12:43:27.668272  3675 solver.cpp:243] Iteration 61860, loss = 0.00159151
I0521 12:43:27.668303  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00159141 (* 1 = 0.00159141 loss)
I0521 12:43:27.668325  3675 sgd_solver.cpp:138] Iteration 61860, lr = 1.5625e-06
I0521 12:43:31.200999  3675 solver.cpp:243] Iteration 61880, loss = 0.00178248
I0521 12:43:31.201030  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00178238 (* 1 = 0.00178238 loss)
I0521 12:43:31.201051  3675 sgd_solver.cpp:138] Iteration 61880, lr = 1.5625e-06
I0521 12:43:34.737303  3675 solver.cpp:243] Iteration 61900, loss = 0.00173669
I0521 12:43:34.737428  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00173659 (* 1 = 0.00173659 loss)
I0521 12:43:34.737437  3675 sgd_solver.cpp:138] Iteration 61900, lr = 1.5625e-06
I0521 12:43:38.278389  3675 solver.cpp:243] Iteration 61920, loss = 0.00239822
I0521 12:43:38.278421  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00239812 (* 1 = 0.00239812 loss)
I0521 12:43:38.278427  3675 sgd_solver.cpp:138] Iteration 61920, lr = 1.5625e-06
I0521 12:43:41.816483  3675 solver.cpp:243] Iteration 61940, loss = 0.00202938
I0521 12:43:41.816516  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00202928 (* 1 = 0.00202928 loss)
I0521 12:43:41.816522  3675 sgd_solver.cpp:138] Iteration 61940, lr = 1.5625e-06
I0521 12:43:45.372179  3675 solver.cpp:243] Iteration 61960, loss = 0.00186923
I0521 12:43:45.372211  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00186913 (* 1 = 0.00186913 loss)
I0521 12:43:45.372217  3675 sgd_solver.cpp:138] Iteration 61960, lr = 1.5625e-06
I0521 12:43:48.901993  3675 solver.cpp:243] Iteration 61980, loss = 0.00229839
I0521 12:43:48.902026  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00229829 (* 1 = 0.00229829 loss)
I0521 12:43:48.902031  3675 sgd_solver.cpp:138] Iteration 61980, lr = 1.5625e-06
I0521 12:43:52.314363  3675 solver.cpp:596] Snapshotting to binary proto file models/LPR/lpr_resnet_lstm_iter_62000.caffemodel
I0521 12:43:52.343528  3675 sgd_solver.cpp:307] Snapshotting solver state to binary proto file models/LPR/lpr_resnet_lstm_iter_62000.solverstate
I0521 12:43:52.359757  3675 solver.cpp:358] Iteration 62000, Testing net (#0)
I0521 12:43:57.119499  3675 solver.cpp:425]     Test net output #0: acc = 1
I0521 12:43:57.119527  3675 solver.cpp:425]     Test net output #1: acc = 1
I0521 12:43:57.119534  3675 solver.cpp:425]     Test net output #2: ctcloss = 0.000624105 (* 1 = 0.000624105 loss)
I0521 12:43:57.256983  3675 solver.cpp:243] Iteration 62000, loss = 0.00233513
I0521 12:43:57.257014  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00233503 (* 1 = 0.00233503 loss)
I0521 12:43:57.257020  3675 sgd_solver.cpp:138] Iteration 62000, lr = 1.5625e-06
I0521 12:44:00.791784  3675 solver.cpp:243] Iteration 62020, loss = 0.00131897
I0521 12:44:00.791815  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00131887 (* 1 = 0.00131887 loss)
I0521 12:44:00.791821  3675 sgd_solver.cpp:138] Iteration 62020, lr = 1.5625e-06
I0521 12:44:04.336371  3675 solver.cpp:243] Iteration 62040, loss = 0.00386967
I0521 12:44:04.336400  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00386957 (* 1 = 0.00386957 loss)
I0521 12:44:04.336422  3675 sgd_solver.cpp:138] Iteration 62040, lr = 1.5625e-06
I0521 12:44:07.866617  3675 solver.cpp:243] Iteration 62060, loss = 0.00293022
I0521 12:44:07.866741  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00293011 (* 1 = 0.00293011 loss)
I0521 12:44:07.866750  3675 sgd_solver.cpp:138] Iteration 62060, lr = 1.5625e-06
I0521 12:44:11.396322  3675 solver.cpp:243] Iteration 62080, loss = 0.00183664
I0521 12:44:11.396353  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00183654 (* 1 = 0.00183654 loss)
I0521 12:44:11.396363  3675 sgd_solver.cpp:138] Iteration 62080, lr = 1.5625e-06
I0521 12:44:14.928990  3675 solver.cpp:243] Iteration 62100, loss = 0.00175925
I0521 12:44:14.929021  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00175915 (* 1 = 0.00175915 loss)
I0521 12:44:14.929028  3675 sgd_solver.cpp:138] Iteration 62100, lr = 1.5625e-06
I0521 12:44:18.458498  3675 solver.cpp:243] Iteration 62120, loss = 0.00190584
I0521 12:44:18.458528  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00190574 (* 1 = 0.00190574 loss)
I0521 12:44:18.458534  3675 sgd_solver.cpp:138] Iteration 62120, lr = 1.5625e-06
I0521 12:44:21.991189  3675 solver.cpp:243] Iteration 62140, loss = 0.00233853
I0521 12:44:21.991219  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00233843 (* 1 = 0.00233843 loss)
I0521 12:44:21.991226  3675 sgd_solver.cpp:138] Iteration 62140, lr = 1.5625e-06
I0521 12:44:25.526834  3675 solver.cpp:243] Iteration 62160, loss = 0.00170304
I0521 12:44:25.526865  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00170293 (* 1 = 0.00170293 loss)
I0521 12:44:25.526870  3675 sgd_solver.cpp:138] Iteration 62160, lr = 1.5625e-06
I0521 12:44:29.059988  3675 solver.cpp:243] Iteration 62180, loss = 0.00145504
I0521 12:44:29.060019  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00145494 (* 1 = 0.00145494 loss)
I0521 12:44:29.060024  3675 sgd_solver.cpp:138] Iteration 62180, lr = 1.5625e-06
I0521 12:44:32.593403  3675 solver.cpp:243] Iteration 62200, loss = 0.0024603
I0521 12:44:32.593436  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0024602 (* 1 = 0.0024602 loss)
I0521 12:44:32.593459  3675 sgd_solver.cpp:138] Iteration 62200, lr = 1.5625e-06
I0521 12:44:36.128669  3675 solver.cpp:243] Iteration 62220, loss = 0.00136347
I0521 12:44:36.128700  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00136337 (* 1 = 0.00136337 loss)
I0521 12:44:36.128705  3675 sgd_solver.cpp:138] Iteration 62220, lr = 1.5625e-06
I0521 12:44:39.662302  3675 solver.cpp:243] Iteration 62240, loss = 0.00224577
I0521 12:44:39.662465  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00224567 (* 1 = 0.00224567 loss)
I0521 12:44:39.662474  3675 sgd_solver.cpp:138] Iteration 62240, lr = 1.5625e-06
I0521 12:44:43.192589  3675 solver.cpp:243] Iteration 62260, loss = 0.0018855
I0521 12:44:43.192618  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0018854 (* 1 = 0.0018854 loss)
I0521 12:44:43.192625  3675 sgd_solver.cpp:138] Iteration 62260, lr = 1.5625e-06
I0521 12:44:46.722421  3675 solver.cpp:243] Iteration 62280, loss = 0.0017221
I0521 12:44:46.722452  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.001722 (* 1 = 0.001722 loss)
I0521 12:44:46.722458  3675 sgd_solver.cpp:138] Iteration 62280, lr = 1.5625e-06
I0521 12:44:50.248036  3675 solver.cpp:243] Iteration 62300, loss = 0.00168299
I0521 12:44:50.248067  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00168289 (* 1 = 0.00168289 loss)
I0521 12:44:50.248073  3675 sgd_solver.cpp:138] Iteration 62300, lr = 1.5625e-06
I0521 12:44:53.773257  3675 solver.cpp:243] Iteration 62320, loss = 0.00215367
I0521 12:44:53.773288  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00215357 (* 1 = 0.00215357 loss)
I0521 12:44:53.773293  3675 sgd_solver.cpp:138] Iteration 62320, lr = 1.5625e-06
I0521 12:44:57.302423  3675 solver.cpp:243] Iteration 62340, loss = 0.00178954
I0521 12:44:57.302465  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00178944 (* 1 = 0.00178944 loss)
I0521 12:44:57.302475  3675 sgd_solver.cpp:138] Iteration 62340, lr = 1.5625e-06
I0521 12:45:00.837496  3675 solver.cpp:243] Iteration 62360, loss = 0.00224559
I0521 12:45:00.837527  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00224549 (* 1 = 0.00224549 loss)
I0521 12:45:00.837533  3675 sgd_solver.cpp:138] Iteration 62360, lr = 1.5625e-06
I0521 12:45:04.376694  3675 solver.cpp:243] Iteration 62380, loss = 0.0017521
I0521 12:45:04.376725  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.001752 (* 1 = 0.001752 loss)
I0521 12:45:04.376731  3675 sgd_solver.cpp:138] Iteration 62380, lr = 1.5625e-06
I0521 12:45:07.912276  3675 solver.cpp:243] Iteration 62400, loss = 0.001539
I0521 12:45:07.912308  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0015389 (* 1 = 0.0015389 loss)
I0521 12:45:07.912330  3675 sgd_solver.cpp:138] Iteration 62400, lr = 1.5625e-06
I0521 12:45:11.444036  3675 solver.cpp:243] Iteration 62420, loss = 0.00216112
I0521 12:45:11.444165  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00216102 (* 1 = 0.00216102 loss)
I0521 12:45:11.444173  3675 sgd_solver.cpp:138] Iteration 62420, lr = 1.5625e-06
I0521 12:45:14.972908  3675 solver.cpp:243] Iteration 62440, loss = 0.00182393
I0521 12:45:14.972939  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00182383 (* 1 = 0.00182383 loss)
I0521 12:45:14.972949  3675 sgd_solver.cpp:138] Iteration 62440, lr = 1.5625e-06
I0521 12:45:18.504034  3675 solver.cpp:243] Iteration 62460, loss = 0.00195081
I0521 12:45:18.504065  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00195071 (* 1 = 0.00195071 loss)
I0521 12:45:18.504070  3675 sgd_solver.cpp:138] Iteration 62460, lr = 1.5625e-06
I0521 12:45:21.967294  3675 solver.cpp:243] Iteration 62480, loss = 0.00208043
I0521 12:45:21.967325  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00208033 (* 1 = 0.00208033 loss)
I0521 12:45:21.967331  3675 sgd_solver.cpp:138] Iteration 62480, lr = 1.5625e-06
I0521 12:45:25.495342  3675 solver.cpp:243] Iteration 62500, loss = 0.00165926
I0521 12:45:25.495373  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00165916 (* 1 = 0.00165916 loss)
I0521 12:45:25.495379  3675 sgd_solver.cpp:138] Iteration 62500, lr = 1.5625e-06
I0521 12:45:29.023391  3675 solver.cpp:243] Iteration 62520, loss = 0.0018547
I0521 12:45:29.023420  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0018546 (* 1 = 0.0018546 loss)
I0521 12:45:29.023427  3675 sgd_solver.cpp:138] Iteration 62520, lr = 1.5625e-06
I0521 12:45:32.553872  3675 solver.cpp:243] Iteration 62540, loss = 0.00162719
I0521 12:45:32.553905  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00162709 (* 1 = 0.00162709 loss)
I0521 12:45:32.553911  3675 sgd_solver.cpp:138] Iteration 62540, lr = 1.5625e-06
I0521 12:45:36.082551  3675 solver.cpp:243] Iteration 62560, loss = 0.00163326
I0521 12:45:36.082581  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00163316 (* 1 = 0.00163316 loss)
I0521 12:45:36.082587  3675 sgd_solver.cpp:138] Iteration 62560, lr = 1.5625e-06
I0521 12:45:39.611596  3675 solver.cpp:243] Iteration 62580, loss = 0.00180601
I0521 12:45:39.611629  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00180591 (* 1 = 0.00180591 loss)
I0521 12:45:39.611634  3675 sgd_solver.cpp:138] Iteration 62580, lr = 1.5625e-06
I0521 12:45:43.141877  3675 solver.cpp:243] Iteration 62600, loss = 0.0020799
I0521 12:45:43.142036  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0020798 (* 1 = 0.0020798 loss)
I0521 12:45:43.142047  3675 sgd_solver.cpp:138] Iteration 62600, lr = 1.5625e-06
I0521 12:45:46.667760  3675 solver.cpp:243] Iteration 62620, loss = 0.0014734
I0521 12:45:46.667793  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0014733 (* 1 = 0.0014733 loss)
I0521 12:45:46.667798  3675 sgd_solver.cpp:138] Iteration 62620, lr = 1.5625e-06
I0521 12:45:50.209331  3675 solver.cpp:243] Iteration 62640, loss = 0.00174259
I0521 12:45:50.209362  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00174249 (* 1 = 0.00174249 loss)
I0521 12:45:50.209368  3675 sgd_solver.cpp:138] Iteration 62640, lr = 1.5625e-06
I0521 12:45:53.737639  3675 solver.cpp:243] Iteration 62660, loss = 0.00264603
I0521 12:45:53.737671  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00264592 (* 1 = 0.00264592 loss)
I0521 12:45:53.737679  3675 sgd_solver.cpp:138] Iteration 62660, lr = 1.5625e-06
I0521 12:45:57.263425  3675 solver.cpp:243] Iteration 62680, loss = 0.00172298
I0521 12:45:57.263455  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00172288 (* 1 = 0.00172288 loss)
I0521 12:45:57.263461  3675 sgd_solver.cpp:138] Iteration 62680, lr = 1.5625e-06
I0521 12:46:00.793655  3675 solver.cpp:243] Iteration 62700, loss = 0.00151576
I0521 12:46:00.793686  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00151566 (* 1 = 0.00151566 loss)
I0521 12:46:00.793709  3675 sgd_solver.cpp:138] Iteration 62700, lr = 1.5625e-06
I0521 12:46:04.322330  3675 solver.cpp:243] Iteration 62720, loss = 0.00162172
I0521 12:46:04.322361  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00162162 (* 1 = 0.00162162 loss)
I0521 12:46:04.322367  3675 sgd_solver.cpp:138] Iteration 62720, lr = 1.5625e-06
I0521 12:46:07.854111  3675 solver.cpp:243] Iteration 62740, loss = 0.00241651
I0521 12:46:07.854142  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00241641 (* 1 = 0.00241641 loss)
I0521 12:46:07.854148  3675 sgd_solver.cpp:138] Iteration 62740, lr = 1.5625e-06
I0521 12:46:11.385071  3675 solver.cpp:243] Iteration 62760, loss = 0.00121049
I0521 12:46:11.385102  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00121039 (* 1 = 0.00121039 loss)
I0521 12:46:11.385107  3675 sgd_solver.cpp:138] Iteration 62760, lr = 1.5625e-06
I0521 12:46:14.912326  3675 solver.cpp:243] Iteration 62780, loss = 0.00204672
I0521 12:46:14.912499  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00204662 (* 1 = 0.00204662 loss)
I0521 12:46:14.912509  3675 sgd_solver.cpp:138] Iteration 62780, lr = 1.5625e-06
I0521 12:46:18.444411  3675 solver.cpp:243] Iteration 62800, loss = 0.00220857
I0521 12:46:18.444442  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00220847 (* 1 = 0.00220847 loss)
I0521 12:46:18.444463  3675 sgd_solver.cpp:138] Iteration 62800, lr = 1.5625e-06
I0521 12:46:21.976882  3675 solver.cpp:243] Iteration 62820, loss = 0.00157366
I0521 12:46:21.976914  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00157355 (* 1 = 0.00157355 loss)
I0521 12:46:21.976922  3675 sgd_solver.cpp:138] Iteration 62820, lr = 1.5625e-06
I0521 12:46:25.507936  3675 solver.cpp:243] Iteration 62840, loss = 0.00206574
I0521 12:46:25.507966  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00206564 (* 1 = 0.00206564 loss)
I0521 12:46:25.507972  3675 sgd_solver.cpp:138] Iteration 62840, lr = 1.5625e-06
I0521 12:46:29.036276  3675 solver.cpp:243] Iteration 62860, loss = 0.00125003
I0521 12:46:29.036307  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00124993 (* 1 = 0.00124993 loss)
I0521 12:46:29.036314  3675 sgd_solver.cpp:138] Iteration 62860, lr = 1.5625e-06
I0521 12:46:32.568490  3675 solver.cpp:243] Iteration 62880, loss = 0.00155091
I0521 12:46:32.568522  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00155081 (* 1 = 0.00155081 loss)
I0521 12:46:32.568529  3675 sgd_solver.cpp:138] Iteration 62880, lr = 1.5625e-06
I0521 12:46:36.112779  3675 solver.cpp:243] Iteration 62900, loss = 0.00139951
I0521 12:46:36.112813  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00139941 (* 1 = 0.00139941 loss)
I0521 12:46:36.112835  3675 sgd_solver.cpp:138] Iteration 62900, lr = 1.5625e-06
I0521 12:46:39.639215  3675 solver.cpp:243] Iteration 62920, loss = 0.0028908
I0521 12:46:39.639245  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0028907 (* 1 = 0.0028907 loss)
I0521 12:46:39.639267  3675 sgd_solver.cpp:138] Iteration 62920, lr = 1.5625e-06
I0521 12:46:43.171711  3675 solver.cpp:243] Iteration 62940, loss = 0.00149566
I0521 12:46:43.171743  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00149556 (* 1 = 0.00149556 loss)
I0521 12:46:43.171749  3675 sgd_solver.cpp:138] Iteration 62940, lr = 1.5625e-06
I0521 12:46:46.711091  3675 solver.cpp:243] Iteration 62960, loss = 0.00191725
I0521 12:46:46.711197  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00191714 (* 1 = 0.00191714 loss)
I0521 12:46:46.711205  3675 sgd_solver.cpp:138] Iteration 62960, lr = 1.5625e-06
I0521 12:46:50.238955  3675 solver.cpp:243] Iteration 62980, loss = 0.00177935
I0521 12:46:50.238984  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00177925 (* 1 = 0.00177925 loss)
I0521 12:46:50.238991  3675 sgd_solver.cpp:138] Iteration 62980, lr = 1.5625e-06
I0521 12:46:53.640960  3675 solver.cpp:358] Iteration 63000, Testing net (#0)
I0521 12:46:58.395732  3675 solver.cpp:425]     Test net output #0: acc = 1
I0521 12:46:58.395761  3675 solver.cpp:425]     Test net output #1: acc = 1
I0521 12:46:58.395768  3675 solver.cpp:425]     Test net output #2: ctcloss = 0.000622798 (* 1 = 0.000622798 loss)
I0521 12:46:58.533098  3675 solver.cpp:243] Iteration 63000, loss = 0.00163907
I0521 12:46:58.533129  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00163897 (* 1 = 0.00163897 loss)
I0521 12:46:58.533135  3675 sgd_solver.cpp:138] Iteration 63000, lr = 1.5625e-06
I0521 12:47:02.071465  3675 solver.cpp:243] Iteration 63020, loss = 0.00128026
I0521 12:47:02.071496  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00128016 (* 1 = 0.00128016 loss)
I0521 12:47:02.071502  3675 sgd_solver.cpp:138] Iteration 63020, lr = 1.5625e-06
I0521 12:47:05.603804  3675 solver.cpp:243] Iteration 63040, loss = 0.00172566
I0521 12:47:05.603837  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00172556 (* 1 = 0.00172556 loss)
I0521 12:47:05.603842  3675 sgd_solver.cpp:138] Iteration 63040, lr = 1.5625e-06
I0521 12:47:09.139281  3675 solver.cpp:243] Iteration 63060, loss = 0.00170989
I0521 12:47:09.139312  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00170978 (* 1 = 0.00170978 loss)
I0521 12:47:09.139317  3675 sgd_solver.cpp:138] Iteration 63060, lr = 1.5625e-06
I0521 12:47:12.671859  3675 solver.cpp:243] Iteration 63080, loss = 0.00212385
I0521 12:47:12.671887  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00212375 (* 1 = 0.00212375 loss)
I0521 12:47:12.671895  3675 sgd_solver.cpp:138] Iteration 63080, lr = 1.5625e-06
I0521 12:47:16.205083  3675 solver.cpp:243] Iteration 63100, loss = 0.00119011
I0521 12:47:16.205114  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00119001 (* 1 = 0.00119001 loss)
I0521 12:47:16.205119  3675 sgd_solver.cpp:138] Iteration 63100, lr = 1.5625e-06
I0521 12:47:19.748586  3675 solver.cpp:243] Iteration 63120, loss = 0.00148116
I0521 12:47:19.748739  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00148106 (* 1 = 0.00148106 loss)
I0521 12:47:19.748767  3675 sgd_solver.cpp:138] Iteration 63120, lr = 1.5625e-06
I0521 12:47:23.283686  3675 solver.cpp:243] Iteration 63140, loss = 0.00161281
I0521 12:47:23.283716  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00161271 (* 1 = 0.00161271 loss)
I0521 12:47:23.283738  3675 sgd_solver.cpp:138] Iteration 63140, lr = 1.5625e-06
I0521 12:47:26.823091  3675 solver.cpp:243] Iteration 63160, loss = 0.00225428
I0521 12:47:26.823122  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00225418 (* 1 = 0.00225418 loss)
I0521 12:47:26.823127  3675 sgd_solver.cpp:138] Iteration 63160, lr = 1.5625e-06
I0521 12:47:30.365664  3675 solver.cpp:243] Iteration 63180, loss = 0.00473338
I0521 12:47:30.365695  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00473328 (* 1 = 0.00473328 loss)
I0521 12:47:30.365701  3675 sgd_solver.cpp:138] Iteration 63180, lr = 1.5625e-06
I0521 12:47:33.904289  3675 solver.cpp:243] Iteration 63200, loss = 0.00175498
I0521 12:47:33.904322  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00175488 (* 1 = 0.00175488 loss)
I0521 12:47:33.904330  3675 sgd_solver.cpp:138] Iteration 63200, lr = 1.5625e-06
I0521 12:47:37.444684  3675 solver.cpp:243] Iteration 63220, loss = 0.00231417
I0521 12:47:37.444713  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00231407 (* 1 = 0.00231407 loss)
I0521 12:47:37.444720  3675 sgd_solver.cpp:138] Iteration 63220, lr = 1.5625e-06
I0521 12:47:40.982151  3675 solver.cpp:243] Iteration 63240, loss = 0.00228527
I0521 12:47:40.982184  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00228517 (* 1 = 0.00228517 loss)
I0521 12:47:40.982192  3675 sgd_solver.cpp:138] Iteration 63240, lr = 1.5625e-06
I0521 12:47:44.520218  3675 solver.cpp:243] Iteration 63260, loss = 0.00170545
I0521 12:47:44.520247  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00170535 (* 1 = 0.00170535 loss)
I0521 12:47:44.520253  3675 sgd_solver.cpp:138] Iteration 63260, lr = 1.5625e-06
I0521 12:47:48.052841  3675 solver.cpp:243] Iteration 63280, loss = 0.00157673
I0521 12:47:48.052873  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00157663 (* 1 = 0.00157663 loss)
I0521 12:47:48.052879  3675 sgd_solver.cpp:138] Iteration 63280, lr = 1.5625e-06
I0521 12:47:51.591564  3675 solver.cpp:243] Iteration 63300, loss = 0.00215924
I0521 12:47:51.591732  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00215914 (* 1 = 0.00215914 loss)
I0521 12:47:51.591739  3675 sgd_solver.cpp:138] Iteration 63300, lr = 1.5625e-06
I0521 12:47:55.126897  3675 solver.cpp:243] Iteration 63320, loss = 0.00191802
I0521 12:47:55.126930  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00191792 (* 1 = 0.00191792 loss)
I0521 12:47:55.126937  3675 sgd_solver.cpp:138] Iteration 63320, lr = 1.5625e-06
I0521 12:47:58.668094  3675 solver.cpp:243] Iteration 63340, loss = 0.00196894
I0521 12:47:58.668124  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00196884 (* 1 = 0.00196884 loss)
I0521 12:47:58.668130  3675 sgd_solver.cpp:138] Iteration 63340, lr = 1.5625e-06
I0521 12:48:02.199832  3675 solver.cpp:243] Iteration 63360, loss = 0.00208237
I0521 12:48:02.199872  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00208227 (* 1 = 0.00208227 loss)
I0521 12:48:02.199880  3675 sgd_solver.cpp:138] Iteration 63360, lr = 1.5625e-06
I0521 12:48:05.742043  3675 solver.cpp:243] Iteration 63380, loss = 0.00182834
I0521 12:48:05.742074  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00182824 (* 1 = 0.00182824 loss)
I0521 12:48:05.742079  3675 sgd_solver.cpp:138] Iteration 63380, lr = 1.5625e-06
I0521 12:48:09.274510  3675 solver.cpp:243] Iteration 63400, loss = 0.00206111
I0521 12:48:09.274543  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.002061 (* 1 = 0.002061 loss)
I0521 12:48:09.274564  3675 sgd_solver.cpp:138] Iteration 63400, lr = 1.5625e-06
I0521 12:48:12.804000  3675 solver.cpp:243] Iteration 63420, loss = 0.00252309
I0521 12:48:12.804029  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00252299 (* 1 = 0.00252299 loss)
I0521 12:48:12.804051  3675 sgd_solver.cpp:138] Iteration 63420, lr = 1.5625e-06
I0521 12:48:16.341471  3675 solver.cpp:243] Iteration 63440, loss = 0.00145483
I0521 12:48:16.341503  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00145473 (* 1 = 0.00145473 loss)
I0521 12:48:16.341511  3675 sgd_solver.cpp:138] Iteration 63440, lr = 1.5625e-06
I0521 12:48:19.876952  3675 solver.cpp:243] Iteration 63460, loss = 0.0016568
I0521 12:48:19.876982  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0016567 (* 1 = 0.0016567 loss)
I0521 12:48:19.876989  3675 sgd_solver.cpp:138] Iteration 63460, lr = 1.5625e-06
I0521 12:48:23.413437  3675 solver.cpp:243] Iteration 63480, loss = 0.001854
I0521 12:48:23.413565  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0018539 (* 1 = 0.0018539 loss)
I0521 12:48:23.413574  3675 sgd_solver.cpp:138] Iteration 63480, lr = 1.5625e-06
I0521 12:48:26.948132  3675 solver.cpp:243] Iteration 63500, loss = 0.00193934
I0521 12:48:26.948163  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00193924 (* 1 = 0.00193924 loss)
I0521 12:48:26.948170  3675 sgd_solver.cpp:138] Iteration 63500, lr = 1.5625e-06
I0521 12:48:30.475270  3675 solver.cpp:243] Iteration 63520, loss = 0.00192075
I0521 12:48:30.475317  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00192065 (* 1 = 0.00192065 loss)
I0521 12:48:30.475322  3675 sgd_solver.cpp:138] Iteration 63520, lr = 1.5625e-06
I0521 12:48:34.011338  3675 solver.cpp:243] Iteration 63540, loss = 0.00731912
I0521 12:48:34.011370  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00731902 (* 1 = 0.00731902 loss)
I0521 12:48:34.011394  3675 sgd_solver.cpp:138] Iteration 63540, lr = 1.5625e-06
I0521 12:48:37.542006  3675 solver.cpp:243] Iteration 63560, loss = 0.0017905
I0521 12:48:37.542037  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0017904 (* 1 = 0.0017904 loss)
I0521 12:48:37.542059  3675 sgd_solver.cpp:138] Iteration 63560, lr = 1.5625e-06
I0521 12:48:41.076172  3675 solver.cpp:243] Iteration 63580, loss = 0.00173458
I0521 12:48:41.076203  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00173448 (* 1 = 0.00173448 loss)
I0521 12:48:41.076225  3675 sgd_solver.cpp:138] Iteration 63580, lr = 1.5625e-06
I0521 12:48:44.614579  3675 solver.cpp:243] Iteration 63600, loss = 0.00221548
I0521 12:48:44.614610  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00221538 (* 1 = 0.00221538 loss)
I0521 12:48:44.614617  3675 sgd_solver.cpp:138] Iteration 63600, lr = 1.5625e-06
I0521 12:48:48.141604  3675 solver.cpp:243] Iteration 63620, loss = 0.00132692
I0521 12:48:48.141634  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00132682 (* 1 = 0.00132682 loss)
I0521 12:48:48.141656  3675 sgd_solver.cpp:138] Iteration 63620, lr = 1.5625e-06
I0521 12:48:51.676761  3675 solver.cpp:243] Iteration 63640, loss = 0.00165922
I0521 12:48:51.676795  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00165912 (* 1 = 0.00165912 loss)
I0521 12:48:51.676803  3675 sgd_solver.cpp:138] Iteration 63640, lr = 1.5625e-06
I0521 12:48:55.214359  3675 solver.cpp:243] Iteration 63660, loss = 0.00209264
I0521 12:48:55.214529  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00209254 (* 1 = 0.00209254 loss)
I0521 12:48:55.214538  3675 sgd_solver.cpp:138] Iteration 63660, lr = 1.5625e-06
I0521 12:48:58.745980  3675 solver.cpp:243] Iteration 63680, loss = 0.00165522
I0521 12:48:58.746009  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00165512 (* 1 = 0.00165512 loss)
I0521 12:48:58.746016  3675 sgd_solver.cpp:138] Iteration 63680, lr = 1.5625e-06
I0521 12:49:02.285452  3675 solver.cpp:243] Iteration 63700, loss = 0.00156418
I0521 12:49:02.285485  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00156408 (* 1 = 0.00156408 loss)
I0521 12:49:02.285508  3675 sgd_solver.cpp:138] Iteration 63700, lr = 1.5625e-06
I0521 12:49:05.817209  3675 solver.cpp:243] Iteration 63720, loss = 0.0022202
I0521 12:49:05.817241  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0022201 (* 1 = 0.0022201 loss)
I0521 12:49:05.817248  3675 sgd_solver.cpp:138] Iteration 63720, lr = 1.5625e-06
I0521 12:49:09.351307  3675 solver.cpp:243] Iteration 63740, loss = 0.00161123
I0521 12:49:09.351341  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00161113 (* 1 = 0.00161113 loss)
I0521 12:49:09.351348  3675 sgd_solver.cpp:138] Iteration 63740, lr = 1.5625e-06
I0521 12:49:12.884584  3675 solver.cpp:243] Iteration 63760, loss = 0.00187028
I0521 12:49:12.884614  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00187018 (* 1 = 0.00187018 loss)
I0521 12:49:12.884621  3675 sgd_solver.cpp:138] Iteration 63760, lr = 1.5625e-06
I0521 12:49:16.352811  3675 solver.cpp:243] Iteration 63780, loss = 0.00221537
I0521 12:49:16.352859  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00221527 (* 1 = 0.00221527 loss)
I0521 12:49:16.352864  3675 sgd_solver.cpp:138] Iteration 63780, lr = 1.5625e-06
I0521 12:49:19.885344  3675 solver.cpp:243] Iteration 63800, loss = 0.00174862
I0521 12:49:19.885375  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00174852 (* 1 = 0.00174852 loss)
I0521 12:49:19.885380  3675 sgd_solver.cpp:138] Iteration 63800, lr = 1.5625e-06
I0521 12:49:23.417469  3675 solver.cpp:243] Iteration 63820, loss = 0.00186905
I0521 12:49:23.417498  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00186895 (* 1 = 0.00186895 loss)
I0521 12:49:23.417505  3675 sgd_solver.cpp:138] Iteration 63820, lr = 1.5625e-06
I0521 12:49:26.946653  3675 solver.cpp:243] Iteration 63840, loss = 0.00202472
I0521 12:49:26.946856  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00202462 (* 1 = 0.00202462 loss)
I0521 12:49:26.946889  3675 sgd_solver.cpp:138] Iteration 63840, lr = 1.5625e-06
I0521 12:49:30.485396  3675 solver.cpp:243] Iteration 63860, loss = 0.00173205
I0521 12:49:30.485427  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00173194 (* 1 = 0.00173194 loss)
I0521 12:49:30.485433  3675 sgd_solver.cpp:138] Iteration 63860, lr = 1.5625e-06
I0521 12:49:34.022029  3675 solver.cpp:243] Iteration 63880, loss = 0.00148802
I0521 12:49:34.022059  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00148792 (* 1 = 0.00148792 loss)
I0521 12:49:34.022065  3675 sgd_solver.cpp:138] Iteration 63880, lr = 1.5625e-06
I0521 12:49:37.560600  3675 solver.cpp:243] Iteration 63900, loss = 0.00123084
I0521 12:49:37.560629  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00123074 (* 1 = 0.00123074 loss)
I0521 12:49:37.560636  3675 sgd_solver.cpp:138] Iteration 63900, lr = 1.5625e-06
I0521 12:49:41.091441  3675 solver.cpp:243] Iteration 63920, loss = 0.00299154
I0521 12:49:41.091471  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00299143 (* 1 = 0.00299143 loss)
I0521 12:49:41.091477  3675 sgd_solver.cpp:138] Iteration 63920, lr = 1.5625e-06
I0521 12:49:44.627319  3675 solver.cpp:243] Iteration 63940, loss = 0.00118101
I0521 12:49:44.627348  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00118091 (* 1 = 0.00118091 loss)
I0521 12:49:44.627354  3675 sgd_solver.cpp:138] Iteration 63940, lr = 1.5625e-06
I0521 12:49:48.163076  3675 solver.cpp:243] Iteration 63960, loss = 0.00143113
I0521 12:49:48.163106  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00143103 (* 1 = 0.00143103 loss)
I0521 12:49:48.163112  3675 sgd_solver.cpp:138] Iteration 63960, lr = 1.5625e-06
I0521 12:49:51.694375  3675 solver.cpp:243] Iteration 63980, loss = 0.00185018
I0521 12:49:51.694406  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00185008 (* 1 = 0.00185008 loss)
I0521 12:49:51.694411  3675 sgd_solver.cpp:138] Iteration 63980, lr = 1.5625e-06
I0521 12:49:55.098372  3675 solver.cpp:596] Snapshotting to binary proto file models/LPR/lpr_resnet_lstm_iter_64000.caffemodel
I0521 12:49:55.125628  3675 sgd_solver.cpp:307] Snapshotting solver state to binary proto file models/LPR/lpr_resnet_lstm_iter_64000.solverstate
I0521 12:49:55.140177  3675 solver.cpp:358] Iteration 64000, Testing net (#0)
I0521 12:49:59.902756  3675 solver.cpp:425]     Test net output #0: acc = 1
I0521 12:49:59.902907  3675 solver.cpp:425]     Test net output #1: acc = 1
I0521 12:49:59.902917  3675 solver.cpp:425]     Test net output #2: ctcloss = 0.000621473 (* 1 = 0.000621473 loss)
I0521 12:50:00.040948  3675 solver.cpp:243] Iteration 64000, loss = 0.00172189
I0521 12:50:00.040979  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00172179 (* 1 = 0.00172179 loss)
I0521 12:50:00.040985  3675 sgd_solver.cpp:138] Iteration 64000, lr = 1.5625e-06
I0521 12:50:03.578348  3675 solver.cpp:243] Iteration 64020, loss = 0.00248528
I0521 12:50:03.578378  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00248518 (* 1 = 0.00248518 loss)
I0521 12:50:03.578400  3675 sgd_solver.cpp:138] Iteration 64020, lr = 1.5625e-06
I0521 12:50:07.113961  3675 solver.cpp:243] Iteration 64040, loss = 0.00187527
I0521 12:50:07.113993  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00187517 (* 1 = 0.00187517 loss)
I0521 12:50:07.114001  3675 sgd_solver.cpp:138] Iteration 64040, lr = 1.5625e-06
I0521 12:50:10.647327  3675 solver.cpp:243] Iteration 64060, loss = 0.0028826
I0521 12:50:10.647359  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0028825 (* 1 = 0.0028825 loss)
I0521 12:50:10.647364  3675 sgd_solver.cpp:138] Iteration 64060, lr = 1.5625e-06
I0521 12:50:14.187549  3675 solver.cpp:243] Iteration 64080, loss = 0.00154025
I0521 12:50:14.187580  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00154014 (* 1 = 0.00154014 loss)
I0521 12:50:14.187588  3675 sgd_solver.cpp:138] Iteration 64080, lr = 1.5625e-06
I0521 12:50:17.724288  3675 solver.cpp:243] Iteration 64100, loss = 0.00151779
I0521 12:50:17.724319  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00151769 (* 1 = 0.00151769 loss)
I0521 12:50:17.724325  3675 sgd_solver.cpp:138] Iteration 64100, lr = 1.5625e-06
I0521 12:50:21.260892  3675 solver.cpp:243] Iteration 64120, loss = 0.00133177
I0521 12:50:21.260924  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00133167 (* 1 = 0.00133167 loss)
I0521 12:50:21.260931  3675 sgd_solver.cpp:138] Iteration 64120, lr = 1.5625e-06
I0521 12:50:24.792117  3675 solver.cpp:243] Iteration 64140, loss = 0.0020429
I0521 12:50:24.792147  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0020428 (* 1 = 0.0020428 loss)
I0521 12:50:24.792153  3675 sgd_solver.cpp:138] Iteration 64140, lr = 1.5625e-06
I0521 12:50:28.325368  3675 solver.cpp:243] Iteration 64160, loss = 0.0023603
I0521 12:50:28.325399  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0023602 (* 1 = 0.0023602 loss)
I0521 12:50:28.325407  3675 sgd_solver.cpp:138] Iteration 64160, lr = 1.5625e-06
I0521 12:50:31.858924  3675 solver.cpp:243] Iteration 64180, loss = 0.00284173
I0521 12:50:31.859040  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00284163 (* 1 = 0.00284163 loss)
I0521 12:50:31.859048  3675 sgd_solver.cpp:138] Iteration 64180, lr = 1.5625e-06
I0521 12:50:35.404395  3675 solver.cpp:243] Iteration 64200, loss = 0.00249313
I0521 12:50:35.404426  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00249303 (* 1 = 0.00249303 loss)
I0521 12:50:35.404433  3675 sgd_solver.cpp:138] Iteration 64200, lr = 1.5625e-06
I0521 12:50:38.943518  3675 solver.cpp:243] Iteration 64220, loss = 0.00184385
I0521 12:50:38.943550  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00184374 (* 1 = 0.00184374 loss)
I0521 12:50:38.943572  3675 sgd_solver.cpp:138] Iteration 64220, lr = 1.5625e-06
I0521 12:50:42.478690  3675 solver.cpp:243] Iteration 64240, loss = 0.00235507
I0521 12:50:42.478731  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00235497 (* 1 = 0.00235497 loss)
I0521 12:50:42.478740  3675 sgd_solver.cpp:138] Iteration 64240, lr = 1.5625e-06
I0521 12:50:46.013620  3675 solver.cpp:243] Iteration 64260, loss = 0.00143722
I0521 12:50:46.013653  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00143712 (* 1 = 0.00143712 loss)
I0521 12:50:46.013659  3675 sgd_solver.cpp:138] Iteration 64260, lr = 1.5625e-06
I0521 12:50:49.548059  3675 solver.cpp:243] Iteration 64280, loss = 0.00156631
I0521 12:50:49.548090  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00156621 (* 1 = 0.00156621 loss)
I0521 12:50:49.548096  3675 sgd_solver.cpp:138] Iteration 64280, lr = 1.5625e-06
I0521 12:50:53.083762  3675 solver.cpp:243] Iteration 64300, loss = 0.00150001
I0521 12:50:53.083793  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00149991 (* 1 = 0.00149991 loss)
I0521 12:50:53.083798  3675 sgd_solver.cpp:138] Iteration 64300, lr = 1.5625e-06
I0521 12:50:56.619426  3675 solver.cpp:243] Iteration 64320, loss = 0.00130852
I0521 12:50:56.619457  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00130842 (* 1 = 0.00130842 loss)
I0521 12:50:56.619462  3675 sgd_solver.cpp:138] Iteration 64320, lr = 1.5625e-06
I0521 12:51:00.153530  3675 solver.cpp:243] Iteration 64340, loss = 0.00203004
I0521 12:51:00.153563  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00202994 (* 1 = 0.00202994 loss)
I0521 12:51:00.153569  3675 sgd_solver.cpp:138] Iteration 64340, lr = 1.5625e-06
I0521 12:51:03.679816  3675 solver.cpp:243] Iteration 64360, loss = 0.00173003
I0521 12:51:03.679944  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00172993 (* 1 = 0.00172993 loss)
I0521 12:51:03.679951  3675 sgd_solver.cpp:138] Iteration 64360, lr = 1.5625e-06
I0521 12:51:07.220089  3675 solver.cpp:243] Iteration 64380, loss = 0.00286047
I0521 12:51:07.220122  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00286037 (* 1 = 0.00286037 loss)
I0521 12:51:07.220129  3675 sgd_solver.cpp:138] Iteration 64380, lr = 1.5625e-06
I0521 12:51:10.751020  3675 solver.cpp:243] Iteration 64400, loss = 0.00162515
I0521 12:51:10.751051  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00162505 (* 1 = 0.00162505 loss)
I0521 12:51:10.751057  3675 sgd_solver.cpp:138] Iteration 64400, lr = 1.5625e-06
I0521 12:51:14.284837  3675 solver.cpp:243] Iteration 64420, loss = 0.00182418
I0521 12:51:14.284868  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00182408 (* 1 = 0.00182408 loss)
I0521 12:51:14.284875  3675 sgd_solver.cpp:138] Iteration 64420, lr = 1.5625e-06
I0521 12:51:17.818701  3675 solver.cpp:243] Iteration 64440, loss = 0.0017839
I0521 12:51:17.818734  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0017838 (* 1 = 0.0017838 loss)
I0521 12:51:17.818740  3675 sgd_solver.cpp:138] Iteration 64440, lr = 1.5625e-06
I0521 12:51:21.351675  3675 solver.cpp:243] Iteration 64460, loss = 0.00192413
I0521 12:51:21.351706  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00192403 (* 1 = 0.00192403 loss)
I0521 12:51:21.351711  3675 sgd_solver.cpp:138] Iteration 64460, lr = 1.5625e-06
I0521 12:51:24.891593  3675 solver.cpp:243] Iteration 64480, loss = 0.00159301
I0521 12:51:24.891623  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0015929 (* 1 = 0.0015929 loss)
I0521 12:51:24.891646  3675 sgd_solver.cpp:138] Iteration 64480, lr = 1.5625e-06
I0521 12:51:28.425532  3675 solver.cpp:243] Iteration 64500, loss = 0.00153653
I0521 12:51:28.425561  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00153643 (* 1 = 0.00153643 loss)
I0521 12:51:28.425567  3675 sgd_solver.cpp:138] Iteration 64500, lr = 1.5625e-06
I0521 12:51:31.959527  3675 solver.cpp:243] Iteration 64520, loss = 0.00167055
I0521 12:51:31.959558  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00167045 (* 1 = 0.00167045 loss)
I0521 12:51:31.959579  3675 sgd_solver.cpp:138] Iteration 64520, lr = 1.5625e-06
I0521 12:51:35.499671  3675 solver.cpp:243] Iteration 64540, loss = 0.00125641
I0521 12:51:35.499846  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00125631 (* 1 = 0.00125631 loss)
I0521 12:51:35.499855  3675 sgd_solver.cpp:138] Iteration 64540, lr = 1.5625e-06
I0521 12:51:39.033354  3675 solver.cpp:243] Iteration 64560, loss = 0.00138184
I0521 12:51:39.033387  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00138173 (* 1 = 0.00138173 loss)
I0521 12:51:39.033393  3675 sgd_solver.cpp:138] Iteration 64560, lr = 1.5625e-06
I0521 12:51:42.568259  3675 solver.cpp:243] Iteration 64580, loss = 0.00161734
I0521 12:51:42.568289  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00161723 (* 1 = 0.00161723 loss)
I0521 12:51:42.568295  3675 sgd_solver.cpp:138] Iteration 64580, lr = 1.5625e-06
I0521 12:51:46.100013  3675 solver.cpp:243] Iteration 64600, loss = 0.00189294
I0521 12:51:46.100041  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00189284 (* 1 = 0.00189284 loss)
I0521 12:51:46.100049  3675 sgd_solver.cpp:138] Iteration 64600, lr = 1.5625e-06
I0521 12:51:49.630539  3675 solver.cpp:243] Iteration 64620, loss = 0.00211574
I0521 12:51:49.630570  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00211564 (* 1 = 0.00211564 loss)
I0521 12:51:49.630576  3675 sgd_solver.cpp:138] Iteration 64620, lr = 1.5625e-06
I0521 12:51:53.163585  3675 solver.cpp:243] Iteration 64640, loss = 0.00187307
I0521 12:51:53.163616  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00187297 (* 1 = 0.00187297 loss)
I0521 12:51:53.163622  3675 sgd_solver.cpp:138] Iteration 64640, lr = 1.5625e-06
I0521 12:51:56.691498  3675 solver.cpp:243] Iteration 64660, loss = 0.00217055
I0521 12:51:56.691529  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00217044 (* 1 = 0.00217044 loss)
I0521 12:51:56.691535  3675 sgd_solver.cpp:138] Iteration 64660, lr = 1.5625e-06
I0521 12:52:00.223819  3675 solver.cpp:243] Iteration 64680, loss = 0.00402021
I0521 12:52:00.223850  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00402011 (* 1 = 0.00402011 loss)
I0521 12:52:00.223856  3675 sgd_solver.cpp:138] Iteration 64680, lr = 1.5625e-06
I0521 12:52:03.751706  3675 solver.cpp:243] Iteration 64700, loss = 0.00205446
I0521 12:52:03.751737  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00205436 (* 1 = 0.00205436 loss)
I0521 12:52:03.751744  3675 sgd_solver.cpp:138] Iteration 64700, lr = 1.5625e-06
I0521 12:52:07.278823  3675 solver.cpp:243] Iteration 64720, loss = 0.00408078
I0521 12:52:07.278995  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00408068 (* 1 = 0.00408068 loss)
I0521 12:52:07.279002  3675 sgd_solver.cpp:138] Iteration 64720, lr = 1.5625e-06
I0521 12:52:10.809022  3675 solver.cpp:243] Iteration 64740, loss = 0.00224295
I0521 12:52:10.809052  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00224285 (* 1 = 0.00224285 loss)
I0521 12:52:10.809058  3675 sgd_solver.cpp:138] Iteration 64740, lr = 1.5625e-06
I0521 12:52:14.338925  3675 solver.cpp:243] Iteration 64760, loss = 0.00182203
I0521 12:52:14.338954  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00182193 (* 1 = 0.00182193 loss)
I0521 12:52:14.338960  3675 sgd_solver.cpp:138] Iteration 64760, lr = 1.5625e-06
I0521 12:52:17.873663  3675 solver.cpp:243] Iteration 64780, loss = 0.00169305
I0521 12:52:17.873694  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00169294 (* 1 = 0.00169294 loss)
I0521 12:52:17.873701  3675 sgd_solver.cpp:138] Iteration 64780, lr = 1.5625e-06
I0521 12:52:21.412793  3675 solver.cpp:243] Iteration 64800, loss = 0.00151806
I0521 12:52:21.412823  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00151796 (* 1 = 0.00151796 loss)
I0521 12:52:21.412829  3675 sgd_solver.cpp:138] Iteration 64800, lr = 1.5625e-06
I0521 12:52:24.944651  3675 solver.cpp:243] Iteration 64820, loss = 0.00168868
I0521 12:52:24.944680  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00168858 (* 1 = 0.00168858 loss)
I0521 12:52:24.944702  3675 sgd_solver.cpp:138] Iteration 64820, lr = 1.5625e-06
I0521 12:52:28.485653  3675 solver.cpp:243] Iteration 64840, loss = 0.00184169
I0521 12:52:28.485685  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00184159 (* 1 = 0.00184159 loss)
I0521 12:52:28.485692  3675 sgd_solver.cpp:138] Iteration 64840, lr = 1.5625e-06
I0521 12:52:32.014055  3675 solver.cpp:243] Iteration 64860, loss = 0.00224969
I0521 12:52:32.014086  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00224958 (* 1 = 0.00224958 loss)
I0521 12:52:32.014091  3675 sgd_solver.cpp:138] Iteration 64860, lr = 1.5625e-06
I0521 12:52:35.543910  3675 solver.cpp:243] Iteration 64880, loss = 0.0019179
I0521 12:52:35.543944  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0019178 (* 1 = 0.0019178 loss)
I0521 12:52:35.543951  3675 sgd_solver.cpp:138] Iteration 64880, lr = 1.5625e-06
I0521 12:52:39.079247  3675 solver.cpp:243] Iteration 64900, loss = 0.00168963
I0521 12:52:39.079430  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00168953 (* 1 = 0.00168953 loss)
I0521 12:52:39.079437  3675 sgd_solver.cpp:138] Iteration 64900, lr = 1.5625e-06
I0521 12:52:42.605430  3675 solver.cpp:243] Iteration 64920, loss = 0.00125325
I0521 12:52:42.605460  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00125315 (* 1 = 0.00125315 loss)
I0521 12:52:42.605466  3675 sgd_solver.cpp:138] Iteration 64920, lr = 1.5625e-06
I0521 12:52:46.136992  3675 solver.cpp:243] Iteration 64940, loss = 0.0019681
I0521 12:52:46.137023  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.001968 (* 1 = 0.001968 loss)
I0521 12:52:46.137029  3675 sgd_solver.cpp:138] Iteration 64940, lr = 1.5625e-06
I0521 12:52:49.669278  3675 solver.cpp:243] Iteration 64960, loss = 0.00222652
I0521 12:52:49.669308  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00222642 (* 1 = 0.00222642 loss)
I0521 12:52:49.669314  3675 sgd_solver.cpp:138] Iteration 64960, lr = 1.5625e-06
I0521 12:52:53.202353  3675 solver.cpp:243] Iteration 64980, loss = 0.00181013
I0521 12:52:53.202383  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00181003 (* 1 = 0.00181003 loss)
I0521 12:52:53.202390  3675 sgd_solver.cpp:138] Iteration 64980, lr = 1.5625e-06
I0521 12:52:56.540709  3675 solver.cpp:358] Iteration 65000, Testing net (#0)
I0521 12:53:01.296150  3675 solver.cpp:425]     Test net output #0: acc = 1
I0521 12:53:01.296176  3675 solver.cpp:425]     Test net output #1: acc = 1
I0521 12:53:01.296183  3675 solver.cpp:425]     Test net output #2: ctcloss = 0.000623202 (* 1 = 0.000623202 loss)
I0521 12:53:01.495472  3675 solver.cpp:243] Iteration 65000, loss = 0.00197411
I0521 12:53:01.495501  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00197401 (* 1 = 0.00197401 loss)
I0521 12:53:01.495507  3675 sgd_solver.cpp:138] Iteration 65000, lr = 1.5625e-06
I0521 12:53:05.035531  3675 solver.cpp:243] Iteration 65020, loss = 0.00179248
I0521 12:53:05.035562  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00179238 (* 1 = 0.00179238 loss)
I0521 12:53:05.035585  3675 sgd_solver.cpp:138] Iteration 65020, lr = 1.5625e-06
I0521 12:53:08.568986  3675 solver.cpp:243] Iteration 65040, loss = 0.00268565
I0521 12:53:08.569016  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00268555 (* 1 = 0.00268555 loss)
I0521 12:53:08.569023  3675 sgd_solver.cpp:138] Iteration 65040, lr = 1.5625e-06
I0521 12:53:12.101470  3675 solver.cpp:243] Iteration 65060, loss = 0.00178503
I0521 12:53:12.101624  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00178493 (* 1 = 0.00178493 loss)
I0521 12:53:12.101632  3675 sgd_solver.cpp:138] Iteration 65060, lr = 1.5625e-06
I0521 12:53:15.582856  3675 solver.cpp:243] Iteration 65080, loss = 0.00227663
I0521 12:53:15.582886  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00227653 (* 1 = 0.00227653 loss)
I0521 12:53:15.582907  3675 sgd_solver.cpp:138] Iteration 65080, lr = 1.5625e-06
I0521 12:53:19.116783  3675 solver.cpp:243] Iteration 65100, loss = 0.0024198
I0521 12:53:19.116814  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0024197 (* 1 = 0.0024197 loss)
I0521 12:53:19.116820  3675 sgd_solver.cpp:138] Iteration 65100, lr = 1.5625e-06
I0521 12:53:22.656132  3675 solver.cpp:243] Iteration 65120, loss = 0.00199055
I0521 12:53:22.656163  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00199045 (* 1 = 0.00199045 loss)
I0521 12:53:22.656169  3675 sgd_solver.cpp:138] Iteration 65120, lr = 1.5625e-06
I0521 12:53:26.195447  3675 solver.cpp:243] Iteration 65140, loss = 0.00160137
I0521 12:53:26.195478  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00160127 (* 1 = 0.00160127 loss)
I0521 12:53:26.195500  3675 sgd_solver.cpp:138] Iteration 65140, lr = 1.5625e-06
I0521 12:53:29.735455  3675 solver.cpp:243] Iteration 65160, loss = 0.00152612
I0521 12:53:29.735486  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00152602 (* 1 = 0.00152602 loss)
I0521 12:53:29.735508  3675 sgd_solver.cpp:138] Iteration 65160, lr = 1.5625e-06
I0521 12:53:33.277801  3675 solver.cpp:243] Iteration 65180, loss = 0.00216527
I0521 12:53:33.277832  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00216517 (* 1 = 0.00216517 loss)
I0521 12:53:33.277838  3675 sgd_solver.cpp:138] Iteration 65180, lr = 1.5625e-06
I0521 12:53:36.817495  3675 solver.cpp:243] Iteration 65200, loss = 0.00276939
I0521 12:53:36.817523  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00276929 (* 1 = 0.00276929 loss)
I0521 12:53:36.817529  3675 sgd_solver.cpp:138] Iteration 65200, lr = 1.5625e-06
I0521 12:53:40.359292  3675 solver.cpp:243] Iteration 65220, loss = 0.00222527
I0521 12:53:40.359321  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00222517 (* 1 = 0.00222517 loss)
I0521 12:53:40.359328  3675 sgd_solver.cpp:138] Iteration 65220, lr = 1.5625e-06
I0521 12:53:43.897066  3675 solver.cpp:243] Iteration 65240, loss = 0.00162453
I0521 12:53:43.897192  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00162443 (* 1 = 0.00162443 loss)
I0521 12:53:43.897198  3675 sgd_solver.cpp:138] Iteration 65240, lr = 1.5625e-06
I0521 12:53:47.435642  3675 solver.cpp:243] Iteration 65260, loss = 0.00133686
I0521 12:53:47.435672  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00133676 (* 1 = 0.00133676 loss)
I0521 12:53:47.435679  3675 sgd_solver.cpp:138] Iteration 65260, lr = 1.5625e-06
I0521 12:53:50.972180  3675 solver.cpp:243] Iteration 65280, loss = 0.00227195
I0521 12:53:50.972210  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00227185 (* 1 = 0.00227185 loss)
I0521 12:53:50.972232  3675 sgd_solver.cpp:138] Iteration 65280, lr = 1.5625e-06
I0521 12:53:54.509563  3675 solver.cpp:243] Iteration 65300, loss = 0.00227855
I0521 12:53:54.509594  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00227845 (* 1 = 0.00227845 loss)
I0521 12:53:54.509600  3675 sgd_solver.cpp:138] Iteration 65300, lr = 1.5625e-06
I0521 12:53:58.041380  3675 solver.cpp:243] Iteration 65320, loss = 0.00124271
I0521 12:53:58.041412  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00124261 (* 1 = 0.00124261 loss)
I0521 12:53:58.041419  3675 sgd_solver.cpp:138] Iteration 65320, lr = 1.5625e-06
I0521 12:54:01.577168  3675 solver.cpp:243] Iteration 65340, loss = 0.00249819
I0521 12:54:01.577199  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00249809 (* 1 = 0.00249809 loss)
I0521 12:54:01.577208  3675 sgd_solver.cpp:138] Iteration 65340, lr = 1.5625e-06
I0521 12:54:05.115015  3675 solver.cpp:243] Iteration 65360, loss = 0.00181812
I0521 12:54:05.115044  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00181802 (* 1 = 0.00181802 loss)
I0521 12:54:05.115051  3675 sgd_solver.cpp:138] Iteration 65360, lr = 1.5625e-06
I0521 12:54:08.664065  3675 solver.cpp:243] Iteration 65380, loss = 0.00156194
I0521 12:54:08.664095  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00156184 (* 1 = 0.00156184 loss)
I0521 12:54:08.664103  3675 sgd_solver.cpp:138] Iteration 65380, lr = 1.5625e-06
I0521 12:54:12.199685  3675 solver.cpp:243] Iteration 65400, loss = 0.00293459
I0521 12:54:12.199715  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00293449 (* 1 = 0.00293449 loss)
I0521 12:54:12.199738  3675 sgd_solver.cpp:138] Iteration 65400, lr = 1.5625e-06
I0521 12:54:15.736132  3675 solver.cpp:243] Iteration 65420, loss = 0.00172436
I0521 12:54:15.736341  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00172426 (* 1 = 0.00172426 loss)
I0521 12:54:15.736349  3675 sgd_solver.cpp:138] Iteration 65420, lr = 1.5625e-06
I0521 12:54:19.268823  3675 solver.cpp:243] Iteration 65440, loss = 0.00230609
I0521 12:54:19.268856  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00230599 (* 1 = 0.00230599 loss)
I0521 12:54:19.268862  3675 sgd_solver.cpp:138] Iteration 65440, lr = 1.5625e-06
I0521 12:54:22.810611  3675 solver.cpp:243] Iteration 65460, loss = 0.00170718
I0521 12:54:22.810642  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00170708 (* 1 = 0.00170708 loss)
I0521 12:54:22.810647  3675 sgd_solver.cpp:138] Iteration 65460, lr = 1.5625e-06
I0521 12:54:26.345754  3675 solver.cpp:243] Iteration 65480, loss = 0.00175465
I0521 12:54:26.345785  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00175455 (* 1 = 0.00175455 loss)
I0521 12:54:26.345791  3675 sgd_solver.cpp:138] Iteration 65480, lr = 1.5625e-06
I0521 12:54:29.884816  3675 solver.cpp:243] Iteration 65500, loss = 0.000998869
I0521 12:54:29.884847  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.000998769 (* 1 = 0.000998769 loss)
I0521 12:54:29.884852  3675 sgd_solver.cpp:138] Iteration 65500, lr = 1.5625e-06
I0521 12:54:33.425873  3675 solver.cpp:243] Iteration 65520, loss = 0.00177151
I0521 12:54:33.425905  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00177141 (* 1 = 0.00177141 loss)
I0521 12:54:33.425911  3675 sgd_solver.cpp:138] Iteration 65520, lr = 1.5625e-06
I0521 12:54:36.962424  3675 solver.cpp:243] Iteration 65540, loss = 0.00151401
I0521 12:54:36.962455  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00151391 (* 1 = 0.00151391 loss)
I0521 12:54:36.962461  3675 sgd_solver.cpp:138] Iteration 65540, lr = 1.5625e-06
I0521 12:54:40.505919  3675 solver.cpp:243] Iteration 65560, loss = 0.001875
I0521 12:54:40.505949  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0018749 (* 1 = 0.0018749 loss)
I0521 12:54:40.505955  3675 sgd_solver.cpp:138] Iteration 65560, lr = 1.5625e-06
I0521 12:54:44.040489  3675 solver.cpp:243] Iteration 65580, loss = 0.00194004
I0521 12:54:44.040521  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00193994 (* 1 = 0.00193994 loss)
I0521 12:54:44.040527  3675 sgd_solver.cpp:138] Iteration 65580, lr = 1.5625e-06
I0521 12:54:47.579093  3675 solver.cpp:243] Iteration 65600, loss = 0.00221905
I0521 12:54:47.579262  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00221895 (* 1 = 0.00221895 loss)
I0521 12:54:47.579269  3675 sgd_solver.cpp:138] Iteration 65600, lr = 1.5625e-06
I0521 12:54:51.120329  3675 solver.cpp:243] Iteration 65620, loss = 0.00189125
I0521 12:54:51.120360  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00189115 (* 1 = 0.00189115 loss)
I0521 12:54:51.120368  3675 sgd_solver.cpp:138] Iteration 65620, lr = 1.5625e-06
I0521 12:54:54.655387  3675 solver.cpp:243] Iteration 65640, loss = 0.00204614
I0521 12:54:54.655418  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00204604 (* 1 = 0.00204604 loss)
I0521 12:54:54.655424  3675 sgd_solver.cpp:138] Iteration 65640, lr = 1.5625e-06
I0521 12:54:58.197731  3675 solver.cpp:243] Iteration 65660, loss = 0.00177613
I0521 12:54:58.197760  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00177603 (* 1 = 0.00177603 loss)
I0521 12:54:58.197767  3675 sgd_solver.cpp:138] Iteration 65660, lr = 1.5625e-06
I0521 12:55:01.734191  3675 solver.cpp:243] Iteration 65680, loss = 0.00145906
I0521 12:55:01.734220  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00145896 (* 1 = 0.00145896 loss)
I0521 12:55:01.734227  3675 sgd_solver.cpp:138] Iteration 65680, lr = 1.5625e-06
I0521 12:55:05.276818  3675 solver.cpp:243] Iteration 65700, loss = 0.00149745
I0521 12:55:05.276849  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00149735 (* 1 = 0.00149735 loss)
I0521 12:55:05.276855  3675 sgd_solver.cpp:138] Iteration 65700, lr = 1.5625e-06
I0521 12:55:08.811251  3675 solver.cpp:243] Iteration 65720, loss = 0.00181815
I0521 12:55:08.811282  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00181805 (* 1 = 0.00181805 loss)
I0521 12:55:08.811305  3675 sgd_solver.cpp:138] Iteration 65720, lr = 1.5625e-06
I0521 12:55:12.355152  3675 solver.cpp:243] Iteration 65740, loss = 0.00181284
I0521 12:55:12.355185  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00181274 (* 1 = 0.00181274 loss)
I0521 12:55:12.355206  3675 sgd_solver.cpp:138] Iteration 65740, lr = 1.5625e-06
I0521 12:55:15.902356  3675 solver.cpp:243] Iteration 65760, loss = 0.00137259
I0521 12:55:15.902390  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00137249 (* 1 = 0.00137249 loss)
I0521 12:55:15.902395  3675 sgd_solver.cpp:138] Iteration 65760, lr = 1.5625e-06
I0521 12:55:19.437237  3675 solver.cpp:243] Iteration 65780, loss = 0.00181489
I0521 12:55:19.437386  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00181479 (* 1 = 0.00181479 loss)
I0521 12:55:19.437395  3675 sgd_solver.cpp:138] Iteration 65780, lr = 1.5625e-06
I0521 12:55:22.979693  3675 solver.cpp:243] Iteration 65800, loss = 0.00214462
I0521 12:55:22.979723  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00214452 (* 1 = 0.00214452 loss)
I0521 12:55:22.979729  3675 sgd_solver.cpp:138] Iteration 65800, lr = 1.5625e-06
I0521 12:55:26.522039  3675 solver.cpp:243] Iteration 65820, loss = 0.00223585
I0521 12:55:26.522079  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00223575 (* 1 = 0.00223575 loss)
I0521 12:55:26.522089  3675 sgd_solver.cpp:138] Iteration 65820, lr = 1.5625e-06
I0521 12:55:30.068142  3675 solver.cpp:243] Iteration 65840, loss = 0.00289946
I0521 12:55:30.068172  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00289936 (* 1 = 0.00289936 loss)
I0521 12:55:30.068194  3675 sgd_solver.cpp:138] Iteration 65840, lr = 1.5625e-06
I0521 12:55:33.611639  3675 solver.cpp:243] Iteration 65860, loss = 0.00130815
I0521 12:55:33.611670  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00130805 (* 1 = 0.00130805 loss)
I0521 12:55:33.611676  3675 sgd_solver.cpp:138] Iteration 65860, lr = 1.5625e-06
I0521 12:55:37.149080  3675 solver.cpp:243] Iteration 65880, loss = 0.00166963
I0521 12:55:37.149111  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00166953 (* 1 = 0.00166953 loss)
I0521 12:55:37.149116  3675 sgd_solver.cpp:138] Iteration 65880, lr = 1.5625e-06
I0521 12:55:40.689208  3675 solver.cpp:243] Iteration 65900, loss = 0.00161974
I0521 12:55:40.689237  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00161964 (* 1 = 0.00161964 loss)
I0521 12:55:40.689244  3675 sgd_solver.cpp:138] Iteration 65900, lr = 1.5625e-06
I0521 12:55:44.228963  3675 solver.cpp:243] Iteration 65920, loss = 0.00221128
I0521 12:55:44.228994  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00221118 (* 1 = 0.00221118 loss)
I0521 12:55:44.229001  3675 sgd_solver.cpp:138] Iteration 65920, lr = 1.5625e-06
I0521 12:55:47.770937  3675 solver.cpp:243] Iteration 65940, loss = 0.00259153
I0521 12:55:47.770967  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00259143 (* 1 = 0.00259143 loss)
I0521 12:55:47.770972  3675 sgd_solver.cpp:138] Iteration 65940, lr = 1.5625e-06
I0521 12:55:51.304988  3675 solver.cpp:243] Iteration 65960, loss = 0.00316595
I0521 12:55:51.305155  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00316585 (* 1 = 0.00316585 loss)
I0521 12:55:51.305164  3675 sgd_solver.cpp:138] Iteration 65960, lr = 1.5625e-06
I0521 12:55:54.842501  3675 solver.cpp:243] Iteration 65980, loss = 0.00166212
I0521 12:55:54.842530  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00166202 (* 1 = 0.00166202 loss)
I0521 12:55:54.842536  3675 sgd_solver.cpp:138] Iteration 65980, lr = 1.5625e-06
I0521 12:55:58.245230  3675 solver.cpp:596] Snapshotting to binary proto file models/LPR/lpr_resnet_lstm_iter_66000.caffemodel
I0521 12:55:58.274739  3675 sgd_solver.cpp:307] Snapshotting solver state to binary proto file models/LPR/lpr_resnet_lstm_iter_66000.solverstate
I0521 12:55:58.290871  3675 solver.cpp:358] Iteration 66000, Testing net (#0)
I0521 12:56:03.050573  3675 solver.cpp:425]     Test net output #0: acc = 1
I0521 12:56:03.050601  3675 solver.cpp:425]     Test net output #1: acc = 1
I0521 12:56:03.050607  3675 solver.cpp:425]     Test net output #2: ctcloss = 0.000620454 (* 1 = 0.000620454 loss)
I0521 12:56:03.187798  3675 solver.cpp:243] Iteration 66000, loss = 0.00169737
I0521 12:56:03.187827  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00169727 (* 1 = 0.00169727 loss)
I0521 12:56:03.187834  3675 sgd_solver.cpp:138] Iteration 66000, lr = 1.5625e-06
I0521 12:56:06.721701  3675 solver.cpp:243] Iteration 66020, loss = 0.00261768
I0521 12:56:06.721735  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00261758 (* 1 = 0.00261758 loss)
I0521 12:56:06.721742  3675 sgd_solver.cpp:138] Iteration 66020, lr = 1.5625e-06
I0521 12:56:10.264547  3675 solver.cpp:243] Iteration 66040, loss = 0.00251232
I0521 12:56:10.264580  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00251222 (* 1 = 0.00251222 loss)
I0521 12:56:10.264600  3675 sgd_solver.cpp:138] Iteration 66040, lr = 1.5625e-06
I0521 12:56:13.798137  3675 solver.cpp:243] Iteration 66060, loss = 0.00172603
I0521 12:56:13.798168  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00172593 (* 1 = 0.00172593 loss)
I0521 12:56:13.798175  3675 sgd_solver.cpp:138] Iteration 66060, lr = 1.5625e-06
I0521 12:56:17.334197  3675 solver.cpp:243] Iteration 66080, loss = 0.00145658
I0521 12:56:17.334226  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00145648 (* 1 = 0.00145648 loss)
I0521 12:56:17.334247  3675 sgd_solver.cpp:138] Iteration 66080, lr = 1.5625e-06
I0521 12:56:20.871848  3675 solver.cpp:243] Iteration 66100, loss = 0.00192228
I0521 12:56:20.871879  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00192218 (* 1 = 0.00192218 loss)
I0521 12:56:20.871886  3675 sgd_solver.cpp:138] Iteration 66100, lr = 1.5625e-06
I0521 12:56:24.411424  3675 solver.cpp:243] Iteration 66120, loss = 0.00153546
I0521 12:56:24.411593  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00153536 (* 1 = 0.00153536 loss)
I0521 12:56:24.411602  3675 sgd_solver.cpp:138] Iteration 66120, lr = 1.5625e-06
I0521 12:56:27.947999  3675 solver.cpp:243] Iteration 66140, loss = 0.00169109
I0521 12:56:27.948030  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.001691 (* 1 = 0.001691 loss)
I0521 12:56:27.948036  3675 sgd_solver.cpp:138] Iteration 66140, lr = 1.5625e-06
I0521 12:56:31.486292  3675 solver.cpp:243] Iteration 66160, loss = 0.0021083
I0521 12:56:31.486322  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0021082 (* 1 = 0.0021082 loss)
I0521 12:56:31.486327  3675 sgd_solver.cpp:138] Iteration 66160, lr = 1.5625e-06
I0521 12:56:35.016754  3675 solver.cpp:243] Iteration 66180, loss = 0.00231555
I0521 12:56:35.016791  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00231545 (* 1 = 0.00231545 loss)
I0521 12:56:35.016798  3675 sgd_solver.cpp:138] Iteration 66180, lr = 1.5625e-06
I0521 12:56:38.556129  3675 solver.cpp:243] Iteration 66200, loss = 0.00165524
I0521 12:56:38.556159  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00165514 (* 1 = 0.00165514 loss)
I0521 12:56:38.556165  3675 sgd_solver.cpp:138] Iteration 66200, lr = 1.5625e-06
I0521 12:56:42.084866  3675 solver.cpp:243] Iteration 66220, loss = 0.00188501
I0521 12:56:42.084897  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00188491 (* 1 = 0.00188491 loss)
I0521 12:56:42.084904  3675 sgd_solver.cpp:138] Iteration 66220, lr = 1.5625e-06
I0521 12:56:45.615715  3675 solver.cpp:243] Iteration 66240, loss = 0.00172299
I0521 12:56:45.615746  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00172289 (* 1 = 0.00172289 loss)
I0521 12:56:45.615752  3675 sgd_solver.cpp:138] Iteration 66240, lr = 1.5625e-06
I0521 12:56:49.151621  3675 solver.cpp:243] Iteration 66260, loss = 0.00126833
I0521 12:56:49.151654  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00126823 (* 1 = 0.00126823 loss)
I0521 12:56:49.151660  3675 sgd_solver.cpp:138] Iteration 66260, lr = 1.5625e-06
I0521 12:56:52.686890  3675 solver.cpp:243] Iteration 66280, loss = 0.00201223
I0521 12:56:52.686923  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00201213 (* 1 = 0.00201213 loss)
I0521 12:56:52.686928  3675 sgd_solver.cpp:138] Iteration 66280, lr = 1.5625e-06
I0521 12:56:56.215085  3675 solver.cpp:243] Iteration 66300, loss = 0.0016721
I0521 12:56:56.215271  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.001672 (* 1 = 0.001672 loss)
I0521 12:56:56.215281  3675 sgd_solver.cpp:138] Iteration 66300, lr = 1.5625e-06
I0521 12:56:59.743764  3675 solver.cpp:243] Iteration 66320, loss = 0.00196859
I0521 12:56:59.743794  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00196849 (* 1 = 0.00196849 loss)
I0521 12:56:59.743801  3675 sgd_solver.cpp:138] Iteration 66320, lr = 1.5625e-06
I0521 12:57:03.276386  3675 solver.cpp:243] Iteration 66340, loss = 0.00171939
I0521 12:57:03.276419  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00171929 (* 1 = 0.00171929 loss)
I0521 12:57:03.276441  3675 sgd_solver.cpp:138] Iteration 66340, lr = 1.5625e-06
I0521 12:57:06.814676  3675 solver.cpp:243] Iteration 66360, loss = 0.0021311
I0521 12:57:06.814707  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.002131 (* 1 = 0.002131 loss)
I0521 12:57:06.814713  3675 sgd_solver.cpp:138] Iteration 66360, lr = 1.5625e-06
I0521 12:57:10.282596  3675 solver.cpp:243] Iteration 66380, loss = 0.00145782
I0521 12:57:10.282627  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00145772 (* 1 = 0.00145772 loss)
I0521 12:57:10.282634  3675 sgd_solver.cpp:138] Iteration 66380, lr = 1.5625e-06
I0521 12:57:13.817863  3675 solver.cpp:243] Iteration 66400, loss = 0.00136485
I0521 12:57:13.817894  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00136475 (* 1 = 0.00136475 loss)
I0521 12:57:13.817900  3675 sgd_solver.cpp:138] Iteration 66400, lr = 1.5625e-06
I0521 12:57:17.347703  3675 solver.cpp:243] Iteration 66420, loss = 0.00149967
I0521 12:57:17.347735  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00149957 (* 1 = 0.00149957 loss)
I0521 12:57:17.347741  3675 sgd_solver.cpp:138] Iteration 66420, lr = 1.5625e-06
I0521 12:57:20.885056  3675 solver.cpp:243] Iteration 66440, loss = 0.00136095
I0521 12:57:20.885087  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00136086 (* 1 = 0.00136086 loss)
I0521 12:57:20.885094  3675 sgd_solver.cpp:138] Iteration 66440, lr = 1.5625e-06
I0521 12:57:24.412575  3675 solver.cpp:243] Iteration 66460, loss = 0.0016028
I0521 12:57:24.412603  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00160271 (* 1 = 0.00160271 loss)
I0521 12:57:24.412609  3675 sgd_solver.cpp:138] Iteration 66460, lr = 1.5625e-06
I0521 12:57:27.937902  3675 solver.cpp:243] Iteration 66480, loss = 0.00332719
I0521 12:57:27.938057  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00332709 (* 1 = 0.00332709 loss)
I0521 12:57:27.938066  3675 sgd_solver.cpp:138] Iteration 66480, lr = 1.5625e-06
I0521 12:57:31.469188  3675 solver.cpp:243] Iteration 66500, loss = 0.00222301
I0521 12:57:31.469218  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00222291 (* 1 = 0.00222291 loss)
I0521 12:57:31.469223  3675 sgd_solver.cpp:138] Iteration 66500, lr = 1.5625e-06
I0521 12:57:34.993743  3675 solver.cpp:243] Iteration 66520, loss = 0.00156224
I0521 12:57:34.993775  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00156215 (* 1 = 0.00156215 loss)
I0521 12:57:34.993782  3675 sgd_solver.cpp:138] Iteration 66520, lr = 1.5625e-06
I0521 12:57:38.528928  3675 solver.cpp:243] Iteration 66540, loss = 0.00210383
I0521 12:57:38.528959  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00210374 (* 1 = 0.00210374 loss)
I0521 12:57:38.528965  3675 sgd_solver.cpp:138] Iteration 66540, lr = 1.5625e-06
I0521 12:57:42.058579  3675 solver.cpp:243] Iteration 66560, loss = 0.00237058
I0521 12:57:42.058610  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00237049 (* 1 = 0.00237049 loss)
I0521 12:57:42.058616  3675 sgd_solver.cpp:138] Iteration 66560, lr = 1.5625e-06
I0521 12:57:45.590108  3675 solver.cpp:243] Iteration 66580, loss = 0.0017289
I0521 12:57:45.590139  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0017288 (* 1 = 0.0017288 loss)
I0521 12:57:45.590147  3675 sgd_solver.cpp:138] Iteration 66580, lr = 1.5625e-06
I0521 12:57:49.236263  3675 solver.cpp:243] Iteration 66600, loss = 0.00169774
I0521 12:57:49.236294  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00169765 (* 1 = 0.00169765 loss)
I0521 12:57:49.236316  3675 sgd_solver.cpp:138] Iteration 66600, lr = 1.5625e-06
I0521 12:57:52.765719  3675 solver.cpp:243] Iteration 66620, loss = 0.00196387
I0521 12:57:52.765750  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00196377 (* 1 = 0.00196377 loss)
I0521 12:57:52.765756  3675 sgd_solver.cpp:138] Iteration 66620, lr = 1.5625e-06
I0521 12:57:56.347934  3675 solver.cpp:243] Iteration 66640, loss = 0.00192502
I0521 12:57:56.347968  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00192492 (* 1 = 0.00192492 loss)
I0521 12:57:56.347991  3675 sgd_solver.cpp:138] Iteration 66640, lr = 1.5625e-06
I0521 12:57:59.951542  3675 solver.cpp:243] Iteration 66660, loss = 0.00155466
I0521 12:57:59.951748  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00155456 (* 1 = 0.00155456 loss)
I0521 12:57:59.951757  3675 sgd_solver.cpp:138] Iteration 66660, lr = 1.5625e-06
I0521 12:58:03.605113  3675 solver.cpp:243] Iteration 66680, loss = 0.00161641
I0521 12:58:03.605144  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00161631 (* 1 = 0.00161631 loss)
I0521 12:58:03.605151  3675 sgd_solver.cpp:138] Iteration 66680, lr = 1.5625e-06
I0521 12:58:07.261008  3675 solver.cpp:243] Iteration 66700, loss = 0.00178271
I0521 12:58:07.261041  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00178261 (* 1 = 0.00178261 loss)
I0521 12:58:07.261049  3675 sgd_solver.cpp:138] Iteration 66700, lr = 1.5625e-06
I0521 12:58:10.990797  3675 solver.cpp:243] Iteration 66720, loss = 0.00139223
I0521 12:58:10.990829  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00139213 (* 1 = 0.00139213 loss)
I0521 12:58:10.990852  3675 sgd_solver.cpp:138] Iteration 66720, lr = 1.5625e-06
I0521 12:58:14.783020  3675 solver.cpp:243] Iteration 66740, loss = 0.00178207
I0521 12:58:14.783053  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00178198 (* 1 = 0.00178198 loss)
I0521 12:58:14.783077  3675 sgd_solver.cpp:138] Iteration 66740, lr = 1.5625e-06
I0521 12:58:18.595191  3675 solver.cpp:243] Iteration 66760, loss = 0.00229366
I0521 12:58:18.595222  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00229356 (* 1 = 0.00229356 loss)
I0521 12:58:18.595229  3675 sgd_solver.cpp:138] Iteration 66760, lr = 1.5625e-06
I0521 12:58:22.230615  3675 solver.cpp:243] Iteration 66780, loss = 0.00177156
I0521 12:58:22.230645  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00177146 (* 1 = 0.00177146 loss)
I0521 12:58:22.230669  3675 sgd_solver.cpp:138] Iteration 66780, lr = 1.5625e-06
I0521 12:58:25.847954  3675 solver.cpp:243] Iteration 66800, loss = 0.00164428
I0521 12:58:25.847985  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00164418 (* 1 = 0.00164418 loss)
I0521 12:58:25.847992  3675 sgd_solver.cpp:138] Iteration 66800, lr = 1.5625e-06
I0521 12:58:29.463685  3675 solver.cpp:243] Iteration 66820, loss = 0.00255805
I0521 12:58:29.463718  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00255795 (* 1 = 0.00255795 loss)
I0521 12:58:29.463742  3675 sgd_solver.cpp:138] Iteration 66820, lr = 1.5625e-06
I0521 12:58:33.087220  3675 solver.cpp:243] Iteration 66840, loss = 0.0015666
I0521 12:58:33.087385  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0015665 (* 1 = 0.0015665 loss)
I0521 12:58:33.087394  3675 sgd_solver.cpp:138] Iteration 66840, lr = 1.5625e-06
I0521 12:58:36.710012  3675 solver.cpp:243] Iteration 66860, loss = 0.00307551
I0521 12:58:36.710044  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00307542 (* 1 = 0.00307542 loss)
I0521 12:58:36.710067  3675 sgd_solver.cpp:138] Iteration 66860, lr = 1.5625e-06
I0521 12:58:40.333678  3675 solver.cpp:243] Iteration 66880, loss = 0.00175078
I0521 12:58:40.333710  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00175068 (* 1 = 0.00175068 loss)
I0521 12:58:40.333716  3675 sgd_solver.cpp:138] Iteration 66880, lr = 1.5625e-06
I0521 12:58:43.945717  3675 solver.cpp:243] Iteration 66900, loss = 0.00208487
I0521 12:58:43.945749  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00208477 (* 1 = 0.00208477 loss)
I0521 12:58:43.945756  3675 sgd_solver.cpp:138] Iteration 66900, lr = 1.5625e-06
I0521 12:58:47.575736  3675 solver.cpp:243] Iteration 66920, loss = 0.00150993
I0521 12:58:47.575770  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00150983 (* 1 = 0.00150983 loss)
I0521 12:58:47.575793  3675 sgd_solver.cpp:138] Iteration 66920, lr = 1.5625e-06
I0521 12:58:51.172170  3675 solver.cpp:243] Iteration 66940, loss = 0.00208644
I0521 12:58:51.172201  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00208634 (* 1 = 0.00208634 loss)
I0521 12:58:51.172224  3675 sgd_solver.cpp:138] Iteration 66940, lr = 1.5625e-06
I0521 12:58:54.797963  3675 solver.cpp:243] Iteration 66960, loss = 0.00128711
I0521 12:58:54.797994  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00128701 (* 1 = 0.00128701 loss)
I0521 12:58:54.798002  3675 sgd_solver.cpp:138] Iteration 66960, lr = 1.5625e-06
I0521 12:58:58.504673  3675 solver.cpp:243] Iteration 66980, loss = 0.00185659
I0521 12:58:58.504704  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00185649 (* 1 = 0.00185649 loss)
I0521 12:58:58.504729  3675 sgd_solver.cpp:138] Iteration 66980, lr = 1.5625e-06
I0521 12:59:02.209626  3675 solver.cpp:358] Iteration 67000, Testing net (#0)
I0521 12:59:07.286298  3675 solver.cpp:425]     Test net output #0: acc = 1
I0521 12:59:07.286448  3675 solver.cpp:425]     Test net output #1: acc = 1
I0521 12:59:07.286458  3675 solver.cpp:425]     Test net output #2: ctcloss = 0.000621747 (* 1 = 0.000621747 loss)
I0521 12:59:07.428376  3675 solver.cpp:243] Iteration 67000, loss = 0.00165704
I0521 12:59:07.428406  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00165694 (* 1 = 0.00165694 loss)
I0521 12:59:07.428428  3675 sgd_solver.cpp:138] Iteration 67000, lr = 1.5625e-06
I0521 12:59:11.045807  3675 solver.cpp:243] Iteration 67020, loss = 0.00173541
I0521 12:59:11.045840  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00173531 (* 1 = 0.00173531 loss)
I0521 12:59:11.045847  3675 sgd_solver.cpp:138] Iteration 67020, lr = 1.5625e-06
I0521 12:59:14.820014  3675 solver.cpp:243] Iteration 67040, loss = 0.00452957
I0521 12:59:14.820049  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00452947 (* 1 = 0.00452947 loss)
I0521 12:59:14.820055  3675 sgd_solver.cpp:138] Iteration 67040, lr = 1.5625e-06
I0521 12:59:18.535722  3675 solver.cpp:243] Iteration 67060, loss = 0.00372728
I0521 12:59:18.535753  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00372718 (* 1 = 0.00372718 loss)
I0521 12:59:18.535758  3675 sgd_solver.cpp:138] Iteration 67060, lr = 1.5625e-06
I0521 12:59:22.158203  3675 solver.cpp:243] Iteration 67080, loss = 0.00252671
I0521 12:59:22.158234  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00252661 (* 1 = 0.00252661 loss)
I0521 12:59:22.158257  3675 sgd_solver.cpp:138] Iteration 67080, lr = 1.5625e-06
I0521 12:59:25.781131  3675 solver.cpp:243] Iteration 67100, loss = 0.0024602
I0521 12:59:25.781160  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0024601 (* 1 = 0.0024601 loss)
I0521 12:59:25.781183  3675 sgd_solver.cpp:138] Iteration 67100, lr = 1.5625e-06
I0521 12:59:29.392784  3675 solver.cpp:243] Iteration 67120, loss = 0.00164415
I0521 12:59:29.392815  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00164406 (* 1 = 0.00164406 loss)
I0521 12:59:29.392822  3675 sgd_solver.cpp:138] Iteration 67120, lr = 1.5625e-06
I0521 12:59:33.014412  3675 solver.cpp:243] Iteration 67140, loss = 0.00190171
I0521 12:59:33.014443  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00190161 (* 1 = 0.00190161 loss)
I0521 12:59:33.014466  3675 sgd_solver.cpp:138] Iteration 67140, lr = 1.5625e-06
I0521 12:59:36.617684  3675 solver.cpp:243] Iteration 67160, loss = 0.00181744
I0521 12:59:36.617715  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00181735 (* 1 = 0.00181735 loss)
I0521 12:59:36.617722  3675 sgd_solver.cpp:138] Iteration 67160, lr = 1.5625e-06
I0521 12:59:40.255421  3675 solver.cpp:243] Iteration 67180, loss = 0.00154781
I0521 12:59:40.255581  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00154771 (* 1 = 0.00154771 loss)
I0521 12:59:40.255590  3675 sgd_solver.cpp:138] Iteration 67180, lr = 1.5625e-06
I0521 12:59:43.868031  3675 solver.cpp:243] Iteration 67200, loss = 0.00238974
I0521 12:59:43.868062  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00238964 (* 1 = 0.00238964 loss)
I0521 12:59:43.868067  3675 sgd_solver.cpp:138] Iteration 67200, lr = 1.5625e-06
I0521 12:59:47.493841  3675 solver.cpp:243] Iteration 67220, loss = 0.00179992
I0521 12:59:47.493875  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00179983 (* 1 = 0.00179983 loss)
I0521 12:59:47.493881  3675 sgd_solver.cpp:138] Iteration 67220, lr = 1.5625e-06
I0521 12:59:51.138613  3675 solver.cpp:243] Iteration 67240, loss = 0.00194911
I0521 12:59:51.138644  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00194901 (* 1 = 0.00194901 loss)
I0521 12:59:51.138650  3675 sgd_solver.cpp:138] Iteration 67240, lr = 1.5625e-06
I0521 12:59:54.770335  3675 solver.cpp:243] Iteration 67260, loss = 0.00202486
I0521 12:59:54.770366  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00202476 (* 1 = 0.00202476 loss)
I0521 12:59:54.770373  3675 sgd_solver.cpp:138] Iteration 67260, lr = 1.5625e-06
I0521 12:59:58.395341  3675 solver.cpp:243] Iteration 67280, loss = 0.0019094
I0521 12:59:58.395372  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0019093 (* 1 = 0.0019093 loss)
I0521 12:59:58.395378  3675 sgd_solver.cpp:138] Iteration 67280, lr = 1.5625e-06
I0521 13:00:02.027209  3675 solver.cpp:243] Iteration 67300, loss = 0.00167494
I0521 13:00:02.027243  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00167484 (* 1 = 0.00167484 loss)
I0521 13:00:02.027249  3675 sgd_solver.cpp:138] Iteration 67300, lr = 1.5625e-06
I0521 13:00:05.614049  3675 solver.cpp:243] Iteration 67320, loss = 0.00208721
I0521 13:00:05.614080  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00208711 (* 1 = 0.00208711 loss)
I0521 13:00:05.614087  3675 sgd_solver.cpp:138] Iteration 67320, lr = 1.5625e-06
I0521 13:00:09.239907  3675 solver.cpp:243] Iteration 67340, loss = 0.00213773
I0521 13:00:09.239938  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00213763 (* 1 = 0.00213763 loss)
I0521 13:00:09.239960  3675 sgd_solver.cpp:138] Iteration 67340, lr = 1.5625e-06
I0521 13:00:12.888478  3675 solver.cpp:243] Iteration 67360, loss = 0.0017943
I0521 13:00:12.888638  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00179421 (* 1 = 0.00179421 loss)
I0521 13:00:12.888646  3675 sgd_solver.cpp:138] Iteration 67360, lr = 1.5625e-06
I0521 13:00:16.502084  3675 solver.cpp:243] Iteration 67380, loss = 0.00160613
I0521 13:00:16.502115  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00160603 (* 1 = 0.00160603 loss)
I0521 13:00:16.502120  3675 sgd_solver.cpp:138] Iteration 67380, lr = 1.5625e-06
I0521 13:00:20.125464  3675 solver.cpp:243] Iteration 67400, loss = 0.00180961
I0521 13:00:20.125499  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00180951 (* 1 = 0.00180951 loss)
I0521 13:00:20.125505  3675 sgd_solver.cpp:138] Iteration 67400, lr = 1.5625e-06
I0521 13:00:23.754209  3675 solver.cpp:243] Iteration 67420, loss = 0.00204296
I0521 13:00:23.754242  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00204286 (* 1 = 0.00204286 loss)
I0521 13:00:23.754248  3675 sgd_solver.cpp:138] Iteration 67420, lr = 1.5625e-06
I0521 13:00:27.359987  3675 solver.cpp:243] Iteration 67440, loss = 0.00168012
I0521 13:00:27.360019  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00168002 (* 1 = 0.00168002 loss)
I0521 13:00:27.360025  3675 sgd_solver.cpp:138] Iteration 67440, lr = 1.5625e-06
I0521 13:00:30.966065  3675 solver.cpp:243] Iteration 67460, loss = 0.00182978
I0521 13:00:30.966097  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00182968 (* 1 = 0.00182968 loss)
I0521 13:00:30.966120  3675 sgd_solver.cpp:138] Iteration 67460, lr = 1.5625e-06
I0521 13:00:34.578110  3675 solver.cpp:243] Iteration 67480, loss = 0.00176337
I0521 13:00:34.578143  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00176327 (* 1 = 0.00176327 loss)
I0521 13:00:34.578166  3675 sgd_solver.cpp:138] Iteration 67480, lr = 1.5625e-06
I0521 13:00:38.202150  3675 solver.cpp:243] Iteration 67500, loss = 0.00208229
I0521 13:00:38.202183  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00208219 (* 1 = 0.00208219 loss)
I0521 13:00:38.202188  3675 sgd_solver.cpp:138] Iteration 67500, lr = 1.5625e-06
I0521 13:00:41.819310  3675 solver.cpp:243] Iteration 67520, loss = 0.00186316
I0521 13:00:41.819342  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00186306 (* 1 = 0.00186306 loss)
I0521 13:00:41.819350  3675 sgd_solver.cpp:138] Iteration 67520, lr = 1.5625e-06
I0521 13:00:45.433892  3675 solver.cpp:243] Iteration 67540, loss = 0.00208307
I0521 13:00:45.434041  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00208297 (* 1 = 0.00208297 loss)
I0521 13:00:45.434051  3675 sgd_solver.cpp:138] Iteration 67540, lr = 1.5625e-06
I0521 13:00:49.052055  3675 solver.cpp:243] Iteration 67560, loss = 0.00138698
I0521 13:00:49.052088  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00138688 (* 1 = 0.00138688 loss)
I0521 13:00:49.052095  3675 sgd_solver.cpp:138] Iteration 67560, lr = 1.5625e-06
I0521 13:00:52.669481  3675 solver.cpp:243] Iteration 67580, loss = 0.00180741
I0521 13:00:52.669512  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00180731 (* 1 = 0.00180731 loss)
I0521 13:00:52.669518  3675 sgd_solver.cpp:138] Iteration 67580, lr = 1.5625e-06
I0521 13:00:56.291595  3675 solver.cpp:243] Iteration 67600, loss = 0.00186634
I0521 13:00:56.291627  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00186624 (* 1 = 0.00186624 loss)
I0521 13:00:56.291633  3675 sgd_solver.cpp:138] Iteration 67600, lr = 1.5625e-06
I0521 13:00:59.901410  3675 solver.cpp:243] Iteration 67620, loss = 0.00161566
I0521 13:00:59.901443  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00161556 (* 1 = 0.00161556 loss)
I0521 13:00:59.901450  3675 sgd_solver.cpp:138] Iteration 67620, lr = 1.5625e-06
I0521 13:01:03.528446  3675 solver.cpp:243] Iteration 67640, loss = 0.00252182
I0521 13:01:03.528477  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00252172 (* 1 = 0.00252172 loss)
I0521 13:01:03.528483  3675 sgd_solver.cpp:138] Iteration 67640, lr = 1.5625e-06
I0521 13:01:07.147128  3675 solver.cpp:243] Iteration 67660, loss = 0.00175284
I0521 13:01:07.147161  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00175274 (* 1 = 0.00175274 loss)
I0521 13:01:07.147167  3675 sgd_solver.cpp:138] Iteration 67660, lr = 1.5625e-06
I0521 13:01:10.707860  3675 solver.cpp:243] Iteration 67680, loss = 0.00321028
I0521 13:01:10.707890  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00321018 (* 1 = 0.00321018 loss)
I0521 13:01:10.707896  3675 sgd_solver.cpp:138] Iteration 67680, lr = 1.5625e-06
I0521 13:01:14.321794  3675 solver.cpp:243] Iteration 67700, loss = 0.00226773
I0521 13:01:14.321825  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00226763 (* 1 = 0.00226763 loss)
I0521 13:01:14.321831  3675 sgd_solver.cpp:138] Iteration 67700, lr = 1.5625e-06
I0521 13:01:17.924149  3675 solver.cpp:243] Iteration 67720, loss = 0.00196479
I0521 13:01:17.924314  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00196469 (* 1 = 0.00196469 loss)
I0521 13:01:17.924322  3675 sgd_solver.cpp:138] Iteration 67720, lr = 1.5625e-06
I0521 13:01:21.529348  3675 solver.cpp:243] Iteration 67740, loss = 0.0018761
I0521 13:01:21.529381  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.001876 (* 1 = 0.001876 loss)
I0521 13:01:21.529387  3675 sgd_solver.cpp:138] Iteration 67740, lr = 1.5625e-06
I0521 13:01:25.161453  3675 solver.cpp:243] Iteration 67760, loss = 0.00325581
I0521 13:01:25.161485  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00325571 (* 1 = 0.00325571 loss)
I0521 13:01:25.161492  3675 sgd_solver.cpp:138] Iteration 67760, lr = 1.5625e-06
I0521 13:01:28.770560  3675 solver.cpp:243] Iteration 67780, loss = 0.00180948
I0521 13:01:28.770592  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00180938 (* 1 = 0.00180938 loss)
I0521 13:01:28.770598  3675 sgd_solver.cpp:138] Iteration 67780, lr = 1.5625e-06
I0521 13:01:32.389919  3675 solver.cpp:243] Iteration 67800, loss = 0.00138382
I0521 13:01:32.389950  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00138372 (* 1 = 0.00138372 loss)
I0521 13:01:32.389956  3675 sgd_solver.cpp:138] Iteration 67800, lr = 1.5625e-06
I0521 13:01:36.018133  3675 solver.cpp:243] Iteration 67820, loss = 0.00175221
I0521 13:01:36.018165  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00175211 (* 1 = 0.00175211 loss)
I0521 13:01:36.018173  3675 sgd_solver.cpp:138] Iteration 67820, lr = 1.5625e-06
I0521 13:01:39.611935  3675 solver.cpp:243] Iteration 67840, loss = 0.00228009
I0521 13:01:39.611968  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00227999 (* 1 = 0.00227999 loss)
I0521 13:01:39.611974  3675 sgd_solver.cpp:138] Iteration 67840, lr = 1.5625e-06
I0521 13:01:43.229796  3675 solver.cpp:243] Iteration 67860, loss = 0.00218984
I0521 13:01:43.229831  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00218974 (* 1 = 0.00218974 loss)
I0521 13:01:43.229837  3675 sgd_solver.cpp:138] Iteration 67860, lr = 1.5625e-06
I0521 13:01:46.848178  3675 solver.cpp:243] Iteration 67880, loss = 0.00159026
I0521 13:01:46.848212  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00159017 (* 1 = 0.00159017 loss)
I0521 13:01:46.848217  3675 sgd_solver.cpp:138] Iteration 67880, lr = 1.5625e-06
I0521 13:01:50.470533  3675 solver.cpp:243] Iteration 67900, loss = 0.00143568
I0521 13:01:50.470700  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00143558 (* 1 = 0.00143558 loss)
I0521 13:01:50.470707  3675 sgd_solver.cpp:138] Iteration 67900, lr = 1.5625e-06
I0521 13:01:54.089130  3675 solver.cpp:243] Iteration 67920, loss = 0.00273098
I0521 13:01:54.089164  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00273089 (* 1 = 0.00273089 loss)
I0521 13:01:54.089171  3675 sgd_solver.cpp:138] Iteration 67920, lr = 1.5625e-06
I0521 13:01:57.698405  3675 solver.cpp:243] Iteration 67940, loss = 0.00253193
I0521 13:01:57.698436  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00253183 (* 1 = 0.00253183 loss)
I0521 13:01:57.698442  3675 sgd_solver.cpp:138] Iteration 67940, lr = 1.5625e-06
I0521 13:02:01.321418  3675 solver.cpp:243] Iteration 67960, loss = 0.00126661
I0521 13:02:01.321449  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00126652 (* 1 = 0.00126652 loss)
I0521 13:02:01.321455  3675 sgd_solver.cpp:138] Iteration 67960, lr = 1.5625e-06
I0521 13:02:04.926259  3675 solver.cpp:243] Iteration 67980, loss = 0.00198463
I0521 13:02:04.926290  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00198453 (* 1 = 0.00198453 loss)
I0521 13:02:04.926297  3675 sgd_solver.cpp:138] Iteration 67980, lr = 1.5625e-06
I0521 13:02:08.407368  3675 solver.cpp:596] Snapshotting to binary proto file models/LPR/lpr_resnet_lstm_iter_68000.caffemodel
I0521 13:02:08.434790  3675 sgd_solver.cpp:307] Snapshotting solver state to binary proto file models/LPR/lpr_resnet_lstm_iter_68000.solverstate
I0521 13:02:08.449553  3675 solver.cpp:358] Iteration 68000, Testing net (#0)
I0521 13:02:13.303259  3675 solver.cpp:425]     Test net output #0: acc = 1
I0521 13:02:13.303287  3675 solver.cpp:425]     Test net output #1: acc = 1
I0521 13:02:13.303294  3675 solver.cpp:425]     Test net output #2: ctcloss = 0.000618172 (* 1 = 0.000618172 loss)
I0521 13:02:13.447088  3675 solver.cpp:243] Iteration 68000, loss = 0.00220438
I0521 13:02:13.447115  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00220428 (* 1 = 0.00220428 loss)
I0521 13:02:13.447137  3675 sgd_solver.cpp:138] Iteration 68000, lr = 1.5625e-06
I0521 13:02:17.067065  3675 solver.cpp:243] Iteration 68020, loss = 0.0025662
I0521 13:02:17.067095  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.0025661 (* 1 = 0.0025661 loss)
I0521 13:02:17.067101  3675 sgd_solver.cpp:138] Iteration 68020, lr = 1.5625e-06
I0521 13:02:20.689507  3675 solver.cpp:243] Iteration 68040, loss = 0.00173022
I0521 13:02:20.689664  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00173012 (* 1 = 0.00173012 loss)
I0521 13:02:20.689672  3675 sgd_solver.cpp:138] Iteration 68040, lr = 1.5625e-06
I0521 13:02:24.311964  3675 solver.cpp:243] Iteration 68060, loss = 0.00158924
I0521 13:02:24.311996  3675 solver.cpp:259]     Train net output #0: ctcloss = 0.00158914 (* 1 = 0.00158914 loss)
I0521 13:02:24.312003  3675 sgd_solver.cpp:138] Iteration 68060, lr = 1.5625e-06
